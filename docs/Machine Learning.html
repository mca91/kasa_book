<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="de" xml:lang="de"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>14&nbsp; Neuronale Netzwerke – Kausalanalyse mit R</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ex.html" rel="next">
<link href="./trees.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/live-runtime/live-runtime.js" type="module"></script>
<link href="site_libs/quarto-contrib/live-runtime/live-runtime.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Keine Treffer",
    "search-matching-documents-text": "Treffer",
    "search-copy-link-title": "Link in die Suche kopieren",
    "search-hide-matches-text": "Zusätzliche Treffer verbergen",
    "search-more-match-text": "weitere Treffer in diesem Dokument",
    "search-more-matches-text": "weitere Treffer in diesem Dokument",
    "search-clear-button-title": "Zurücksetzen",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Abbrechen",
    "search-submit-button-title": "Abschicken",
    "search-label": "Suchen"
  }
}</script><script type="module" src="site_libs/quarto-ojs/quarto-ojs-runtime.js"></script><link href="site_libs/quarto-ojs/quarto-ojs.css" rel="stylesheet">
<meta name="robots" content="noindex">
<script>
  MathJax = {
    tex: {
      tags: 'ams'  // should be 'ams', 'none', or 'all'
    }
  };
</script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.js" integrity="sha512-aoZChv+8imY/U1O7KIHXvO87EOzCuKO0GhFtpD6G2Cyjo/xPeTgdf3/bchB10iB+AojMTDkMHDPLKNxPJVqDcw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css">
<style>
  .panel-tabset .tab-content {
    border: 0;
    padding: 1em 0 0 0;
  }
  
  .panel-tabset .nav-item a {
    border-radius: 5px 5px 0 0;
  }
  
  .scientific_borders {
    border: 0;
    border-top: 2px solid black !important; 
    border-bottom: 2px solid black !important;
  }
  .table:not(.gt_table) > :not(caption)>*>* {
    border-bottom-width: 0;
  }
  .table:not(.gt_table) > thead {
    border-bottom: 1px solid black;
  }
  .soft-box-shadow {
    border: 1px solid rgba(233,236,239,.9) !important;
    border-radius: .5rem !important;
    background-color: rgba(250,250,250,.9) !important;
    box-shadow: 0px 1px 2px rgba(0,0,0,.1),
                0px 3px 7px rgba(0,0,0,.1),
                0px 12px 30px rgba(0,0,0,.08);
    margin-top: 2rem !important;
    margin-bottom: 2.5rem !important;
    padding: .25rem !important;
  }
  .obs-soft-box-shadow {
    border: 1px solid rgba(233,236,239,.9) !important;
    border-radius: .5rem !important;
    background-color: white !important;
    box-shadow: 0px 1px 2px rgba(0,0,0,.1),
                0px 3px 7px rgba(0,0,0,.1),
                0px 12px 30px rgba(0,0,0,.08);
    margin-top: 2rem !important;
    margin-bottom: 2.5rem !important;
    padding: .25rem !important;
  }
  
</style>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    
    var gt_tables = document.querySelectorAll(".gt_table");
    gt_tables.forEach(function(table) {
      table.classList.remove("table-striped");
    });
    
    var tables = document.querySelectorAll("table.table:not(.gt_table)");
    tables.forEach(function(table) {
      table.classList.remove("table-striped");
      table.classList.add("scientific_borders");
    });
    
    document.querySelectorAll("div.sourceCode").forEach(function(block) {
      block.classList.add("soft-box-shadow");
    });
    
    document.querySelectorAll("div.bg-white").forEach(function(block) {
      block.classList.remove("bg-white");
    });
    
const elements = document.querySelectorAll('[id^="qwebr-interactive-area"]');

    elements.forEach(element => {
        element.classList.add('box-shadow');
    });
    
    document.querySelectorAll('[id^="webr"]').forEach(function(block) {
      block.classList.add("box-shadow");
    });
    
        document.querySelectorAll('.card-header').forEach(function(block) {
      block.classList.add("box-shadow");
    });
    
  });
</script><style>
.qwebr-code-output-stdout {background-color: powderblue;}

.qwebr-button-run {
 width = 100%; 
}

.centered-caption {
   text-align: center;
}
</style>
<script src="https://cdn.jsdelivr.net/npm/quizdown@latest/public/build/quizdown.js"></script><script>quizdown.init();</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script><link rel="stylesheet" href="custom_styles.css">
</head>
<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Seitenleiste umschalten" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./RegReg.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="./Machine Learning.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Neuronale Netzwerke</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Seitenleiste umschalten" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Suchen" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./"></a><a href="./index.html">Kausalanalyse mit R</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Lesemodus umschalten">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Suchen"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Einführung</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Grundlagen</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./R_Einfuehrung.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Statistische Programmierung mit R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Reg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Simulation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Simulation</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Kausale Inferenz</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Matching.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Matching</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./FixedEffects.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Panel-Daten</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./IV.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">IV-Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./DiD.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Difference-in-Differences</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./EventStudies.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Event Studies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./RDD.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Regression Discontiniuty Designs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./SyntheticControl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Synthetic Control</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./RegReg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Regularisierte Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./trees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Baum-basierte Methoden</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Machine Learning.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Neuronale Netzwerke</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Übungsaufgaben</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Lineare Regression</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Literatur.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Literatur</span></a>
  </div>
</li>
    </ul>
</div>
    <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title"><a href="./index.html">Übersicht</a></h2>
   
  <ul>
<li>
<a href="#sec-nn-basics" id="toc-sec-nn-basics" class="nav-link active" data-scroll-target="#sec-nn-basics"><span class="header-section-number">14.1</span> Grundlagen und Vokabeln</a>
  <ul>
<li><a href="#training-neuronaler-netze" id="toc-training-neuronaler-netze" class="nav-link" data-scroll-target="#training-neuronaler-netze"><span class="header-section-number">14.1.1</span> Training Neuronaler Netze</a></li>
  </ul>
</li>
  <li><a href="#optimierung-mit-gradient-descent" id="toc-optimierung-mit-gradient-descent" class="nav-link" data-scroll-target="#optimierung-mit-gradient-descent"><span class="header-section-number">14.2</span> Optimierung mit Gradient Descent</a></li>
  <li><a href="#funktionale-zusammenh%C3%A4nge-lernen-regression" id="toc-funktionale-zusammenhänge-lernen-regression" class="nav-link" data-scroll-target="#funktionale-zusammenh%C3%A4nge-lernen-regression"><span class="header-section-number">14.3</span> Funktionale Zusammenhänge lernen: Regression</a></li>
  <li><a href="#multiple-regression" id="toc-multiple-regression" class="nav-link" data-scroll-target="#multiple-regression"><span class="header-section-number">14.4</span> Multiple Regression</a></li>
  <li><a href="#nicht-lineare-zusammenh%C3%A4nge" id="toc-nicht-lineare-zusammenhänge" class="nav-link" data-scroll-target="#nicht-lineare-zusammenh%C3%A4nge"><span class="header-section-number">14.5</span> Nicht-Lineare Zusammenhänge</a></li>
  <li><a href="#beispiel-boston-housing" id="toc-beispiel-boston-housing" class="nav-link" data-scroll-target="#beispiel-boston-housing"><span class="header-section-number">14.6</span> Beispiel: Boston Housing</a></li>
  <li><a href="#case-study-vorhersage-von-immobilienpreisen" id="toc-case-study-vorhersage-von-immobilienpreisen" class="nav-link" data-scroll-target="#case-study-vorhersage-von-immobilienpreisen"><span class="header-section-number">14.7</span> Case Study: Vorhersage von Immobilienpreisen</a></li>
  </ul></nav>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./RegReg.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="./Machine Learning.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Neuronale Netzwerke</span></a></li></ol></nav><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">
<span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Neuronale Netzwerke</span>
</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><p>Neuronale Netze (NN) sind leistungsstarke Modelle, die darauf spezialisiert sind, komplexe Muster in Daten zu erkennen und sind damit insbesondere ein hilfeiches Tool für Prognosen. Ein Nachteil neuronaler Netze ist die mangelnde Fähigkeit, kausale Zusammenhänge zu identifizieren und abzuleiten. Diese Limitation stellt eine signifikante Einschränkung dar, insbesondere für den Einsatz in empirischen Disziplinen, in denen das Verständnis kausaler Beziehungen von entscheidender Bedeutung ist. Während NN effektiv komplizierte Strukturen abbilden können, sind sie nicht mit den notwendigen Mechanismen ausgestattet, um Kausalität zu modellieren oder gar zu identifizieren. Grund hierfür ist die fehlende explizite Berücksichtigung kausaler Beziehungen und des zugrunde liegenden datenerzeugenden Prozesses: NN lernen lediglich funktionale Zusammenhänge in den Trainingsdaten. Auch wenn hierdurch komplexeste Relationen abgebildet werden können, erlaubt ein angepasstes Netz keine Differenzierung zwischen einer Korrelation und einer tatsächlichen kausalen Beziehung zwischen Variablen.</p>
<p>In diesem Kapitel erläutern wir die Funktionsweise und Anpassung neuronaler Netze mit Keras und TensorFlow in R und diskutieren deren Anwendung zur Prognose von Zielvariablen in Datensätzen mit vielen Variablen und Beobachtungen. Die hier erläuterten Grundlagen basieren auf den einleitenden Kapiteln in <span class="citation" data-cites="Bishop2007">Bishop (<a href="Literatur.html#ref-Bishop2007" role="doc-biblioref">2007</a>)</span> und <span class="citation" data-cites="Goodfellowetal2016">Goodfellow, Bengio, und Courville (<a href="Literatur.html#ref-Goodfellowetal2016" role="doc-biblioref">2016</a>)</span>. Für ausführliche Erläuterungen der R-API <code>keras</code> für die gleichnamige Python-Bibliothek empfehlen wir <span class="citation" data-cites="Allaire2018">Chollet und Allaire (<a href="Literatur.html#ref-Allaire2018" role="doc-biblioref">2018</a>)</span>.</p>
<section id="sec-nn-basics" class="level2 page-columns page-full" data-number="14.1"><h2 data-number="14.1" class="anchored" data-anchor-id="sec-nn-basics">
<span class="header-section-number">14.1</span> Grundlagen und Vokabeln</h2>
<p>NN bestehen aus einer (often großen) Anzahl so genannter <em>künstlicher Neuronen</em>. Ein Neuron ist eine mathematische Funktion, die mehrere Eingaben empfängt, diese unter Verwendung von Gewichten linear kombiniert und eine Ausgabe durch Verwendung einer Aktivierungsfunktion generiert.</p>
<p>Die Neuronen eines NN sind in Schichten (<em>Layers</em>) organisiert. Jedes Layer verarbeitet die Eingabedaten und gibt die Ergebnisse an das nächste Layer weiter, wobei die Neuronen verschiedener Layer miteinander verknüpft werden. Während das Eingabe-Layer (<em>Input</em>) die “Rohdaten” (bspw. beobachtete Regressorwerte) aufnimmt und sie an die erste versteckte Schicht (<em>Hidden Layer</em>) weiterleitet, ist die Hauptaufgabe der Neuronen in den Hidden Layers, komplexe Muster und Merkmale in den Daten zu erkennen und zu verarbeiten. Jedes Hidden Layer transformiert die empfangenen Daten anhand seiner Neuronen, bevor diese an das nächste Layer weitergeleitet werden. Das letzte Layer in einem neuronalen Netzwerk ist das Ausgabe-Layer (<em>Output Layer</em>), das die endgültige Vorhersage für die Outcome-Variable basierend auf den verarbeiteten Daten liefert.</p>
<p>Die Stärke der Verknüpfungen zwischen den Neuronen wird durch die Gewichte <span class="math inline">\(w\)</span> bestimmt, welche während des Trainingsprozesses angepasst werden, um das Modell hinsichtlich der (Vorhersage) einer Zielvariable zu optimieren. Die <span class="math inline">\(w\)</span> bestimmen, wie stark die Aktivierung eines Neurons in einer Schicht die Aktivierung der Neuronen in der nächsten Schicht beeinflusst. Das Netzwerk kann so tiefe und abstrakte Strukturen eines Datensatzes abbilden.</p>
<div class="cell page-columns page-full" data-fig-width="6" data-fig-height="4" data-layout-align="center">
<div class="cell-output-display page-columns page-full">
<div id="fig-nnex" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-nnex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="576" height="384" viewbox="0.00 0.00 497.95 361.62" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none"><g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 357.62)"><title>NNEX</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-357.62 493.95,-357.62 493.95,4 -4,4"></polygon><!-- X1 --><g id="node1" class="node"><title>X1</title>
<ellipse fill="lightblue" stroke="black" cx="25.14" cy="-248.81" rx="25.28" ry="25.28"></ellipse><text text-anchor="middle" x="25.14" y="-244.01" font-family="Helvetica,Arial,sans-serif" font-size="16.00">X1</text></g><!-- V1 --><g id="node3" class="node"><title>V1</title>
<ellipse fill="lightyellow" stroke="black" cx="241.14" cy="-320.81" rx="32.62" ry="32.62"></ellipse><text text-anchor="middle" x="241.14" y="-325.61" font-family="Helvetica,Arial,sans-serif" font-size="16.00">V1</text><text text-anchor="middle" x="241.14" y="-306.41" font-family="Helvetica,Arial,sans-serif" font-size="16.00">(A)</text></g><!-- X1&#45;&gt;V1 --><g id="edge1" class="edge"><title>X1-&gt;V1</title>
<path fill="none" stroke="black" d="M49.08,-256.79C85.54,-268.94 155.44,-292.24 200.1,-307.13"></path><polygon fill="black" stroke="black" points="199.18,-310.51 209.77,-310.35 201.39,-303.87 199.18,-310.51"></polygon><text text-anchor="middle" x="114.26" y="-285.56" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w11</text></g><!-- V2 --><g id="node4" class="node"><title>V2</title>
<ellipse fill="lightyellow" stroke="black" cx="241.14" cy="-176.81" rx="32.62" ry="32.62"></ellipse><text text-anchor="middle" x="241.14" y="-181.61" font-family="Helvetica,Arial,sans-serif" font-size="16.00">V2</text><text text-anchor="middle" x="241.14" y="-162.41" font-family="Helvetica,Arial,sans-serif" font-size="16.00">(A)</text></g><!-- X1&#45;&gt;V2 --><g id="edge2" class="edge"><title>X1-&gt;V2</title>
<path fill="none" stroke="black" d="M49.08,-240.83C85.54,-228.68 155.44,-205.38 200.1,-190.49"></path><polygon fill="black" stroke="black" points="201.39,-193.75 209.77,-187.27 199.18,-187.11 201.39,-193.75"></polygon><text text-anchor="middle" x="114.26" y="-219.26" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w12</text></g><!-- V3 --><g id="node5" class="node"><title>V3</title>
<ellipse fill="lightyellow" stroke="black" cx="241.14" cy="-32.81" rx="32.62" ry="32.62"></ellipse><text text-anchor="middle" x="241.14" y="-37.61" font-family="Helvetica,Arial,sans-serif" font-size="16.00">V3</text><text text-anchor="middle" x="241.14" y="-18.41" font-family="Helvetica,Arial,sans-serif" font-size="16.00">(A)</text></g><!-- X1&#45;&gt;V3 --><g id="edge3" class="edge"><title>X1-&gt;V3</title>
<path fill="none" stroke="black" d="M43.19,-230.77C80.16,-193.79 164.9,-109.05 210.6,-63.35"></path><polygon fill="black" stroke="black" points="213.25,-65.65 217.85,-56.1 208.3,-60.7 213.25,-65.65"></polygon><text text-anchor="middle" x="116.56" y="-150.66" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w13</text></g><!-- X2 --><g id="node2" class="node"><title>X2</title>
<ellipse fill="lightblue" stroke="black" cx="25.14" cy="-104.81" rx="25.28" ry="25.28"></ellipse><text text-anchor="middle" x="25.14" y="-100.01" font-family="Helvetica,Arial,sans-serif" font-size="16.00">X2</text></g><!-- X2&#45;&gt;V1 --><g id="edge4" class="edge"><title>X2-&gt;V1</title>
<path fill="none" stroke="black" d="M43.19,-122.85C80.16,-159.83 164.9,-244.57 210.6,-290.26"></path><polygon fill="black" stroke="black" points="208.3,-292.92 217.85,-297.52 213.25,-287.97 208.3,-292.92"></polygon><text text-anchor="middle" x="116.56" y="-195.76" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w21</text></g><!-- X2&#45;&gt;V2 --><g id="edge5" class="edge"><title>X2-&gt;V2</title>
<path fill="none" stroke="black" d="M49.08,-112.79C85.54,-124.94 155.44,-148.24 200.1,-163.13"></path><polygon fill="black" stroke="black" points="199.18,-166.51 209.77,-166.35 201.39,-159.87 199.18,-166.51"></polygon><text text-anchor="middle" x="114.26" y="-127.16" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w22</text></g><!-- X2&#45;&gt;V3 --><g id="edge6" class="edge"><title>X2-&gt;V3</title>
<path fill="none" stroke="black" d="M49.08,-96.83C85.54,-84.68 155.44,-61.38 200.1,-46.49"></path><polygon fill="black" stroke="black" points="201.39,-49.75 209.77,-43.27 199.18,-43.11 201.39,-49.75"></polygon><text text-anchor="middle" x="114.26" y="-75.26" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w23</text></g><!-- Y --><g id="node6" class="node"><title>Y</title>
<ellipse fill="lightgreen" stroke="black" cx="457.14" cy="-176.81" rx="32.62" ry="32.62"></ellipse><text text-anchor="middle" x="457.14" y="-181.61" font-family="Helvetica,Arial,sans-serif" font-size="16.00">Y</text><text text-anchor="middle" x="457.14" y="-162.41" font-family="Helvetica,Arial,sans-serif" font-size="16.00">(A)</text></g><!-- V1&#45;&gt;Y --><g id="edge7" class="edge"><title>V1-&gt;Y</title>
<path fill="none" stroke="black" d="M268.5,-302.57C307.26,-276.73 378.23,-229.42 421.2,-200.77"></path><polygon fill="black" stroke="black" points="423.29,-203.59 429.67,-195.13 419.4,-197.76 423.29,-203.59"></polygon><text text-anchor="middle" x="334.52" y="-255.27" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w31</text></g><!-- V2&#45;&gt;Y --><g id="edge8" class="edge"><title>V2-&gt;Y</title>
<path fill="none" stroke="black" d="M274.42,-176.81C311.87,-176.81 372.83,-176.81 413.93,-176.81"></path><polygon fill="black" stroke="black" points="414.18,-180.31 424.18,-176.81 414.18,-173.31 414.18,-180.31"></polygon><text text-anchor="middle" x="333.84" y="-180.41" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w32</text></g><!-- V3&#45;&gt;Y --><g id="edge9" class="edge"><title>V3-&gt;Y</title>
<path fill="none" stroke="black" d="M268.5,-51.05C307.26,-76.89 378.23,-124.2 421.2,-152.85"></path><polygon fill="black" stroke="black" points="419.4,-155.86 429.67,-158.49 423.29,-150.03 419.4,-155.86"></polygon><text text-anchor="middle" x="334.52" y="-105.55" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w33</text></g></g></svg>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-nnex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;14.1: Neuronales Netzwerk mit einem Hidden Layer
</figcaption></figure>
</div>
</div>
</div>
<p>Angenommen wir interessieren uns für die Vorhersage einer Outcome-Variable <span class="math inline">\(Y\)</span> mit den Regressoren <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span>. <a href="#fig-nnex" class="quarto-xref">Abbildung&nbsp;<span>14.1</span></a> zeigt ein mögliches NN mit 3 Neuronen <span class="math inline">\(V_1\)</span>, <span class="math inline">\(V_2\)</span>, <span class="math inline">\(V_3\)</span> in einem Hidden Layer. Die Neuronen im Hidden Layer empfangen Eingaben aus dem Input Layer, bestehend aus Beobachtungen der Variablen <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span>, und gewichten diese Informationen gemäß der Vorschrift</p>
<p><span class="math display">\[\begin{align*}
  h_i = A\left(\sum_{j=1}^{2} w_{ji} \cdot x_j + b_i\right) \quad \text{für } i = 1, 2, 3.
\end{align*}\]</span></p>
<p>Hierbei sind <span class="math inline">\(w_{ji}\)</span> die Gewichte der Verbindung von Input <span class="math inline">\(j\)</span> zu Neuron <span class="math inline">\(i\)</span> und <span class="math inline">\(b_i\)</span> ist ein <em>Bias</em>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> <span class="math inline">\(A(\cdot)\)</span> ist eine Aktivierungsfunktion, die in Abhängigkeit der zu modellierenden Daten gewählt wird.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Der Bias ist analog zur Konstante in einer Regression.</p></div></div><p>Das Ausgabe-Neuron für <span class="math inline">\(Y\)</span> verarbeitet die Informationen aus dem Hidden Layer ebenfalls anhand einer Linearkombination, die mit einer Aktivierungsfunktion transformiert wird,</p>
<p><span class="math display">\[\begin{align*}
  y = A\left(\sum_{i=1}^{3} w_{i} \cdot h_i + b_y\right).
\end{align*}\]</span></p>
<p>Ein solches NN “lernt” Relationen zwischen <span class="math inline">\(Y\)</span> und den Regressoren <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span>, indem die Gewichte anhand eines Algorithmus derart gewählt werden, dass der Fehler zwischen den vorhergesagten und den tatsächlichen Werten von <span class="math inline">\(Y\)</span> — gemessen mit einer Verlustfunktion (<em>Loss-Funktion</em>) — minimiert wird. Dieser Lernprozess erfolgt unter Verwendung numerischer Optimierungsverfahren wie <em>Gradientenabstieg</em> (<em>Gradient Descent</em>).</p>
<section id="training-neuronaler-netze" class="level3 page-columns page-full" data-number="14.1.1"><h3 data-number="14.1.1" class="anchored" data-anchor-id="training-neuronaler-netze">
<span class="header-section-number">14.1.1</span> Training Neuronaler Netze</h3>
<p>Der Anpassungsprozess eines NN an einen Datensatz (<em>Training</em>) wird grob durch folgende Schritte bestimmt:</p>
<ol type="1">
<li><p>Das Netz (Gewichte) wird initialisiert.</p></li>
<li><p>Die Inputs jeder Beobachtung im Trainingsdatensatz werden durch das NN geleitet (<em>Forward Pass</em>): Jedes Layer transformiert die Daten mit Hilfe von Gewichten und Aktivierungsfunktionen, um eine Vorhersage von <span class="math inline">\(Y\)</span> zu erzeugen.</p></li>
<li><p>Der Loss wird berechnet, indem die Vorhersage von <span class="math inline">\(Y\)</span> mit dem tatsächlichen Wert verglichen wird. Die Verlustfunktion wird entsprechend der Definition von <span class="math inline">\(Y\)</span> gewählt. Typische Verlustfunktionen sind <em>Quadratic Loss</em> (analog zur Schätzung von linearen Regressionsmodellen mit KQ) oder <em>Logistic Loss</em> (analog zu logistischer Regression).</p></li>
<li>
<p>Zur Anpassung der Gewichte wird der Gradient<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> der Verlustfunktion hinsichtlich der Gewichte des NN ermittelt.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> Ein Gradient-Descent-Algorithmus bestimmt, in welche Richtung die Gewichte verändert werden müssen, um den Vorhersagefehler zu verringern.</p>
<p>Für diese Berechnung wird ein <em>Backward Pass</em> (auch <em>Backpropagation</em> genannt) genutzt. Hierbei wird der anhand des Ausgabelayers ermittelte Loss rückwärts durch das Netzwerk propagiert, um die Gewichte so anzupassen, dass der Fehler bei der Vorhersage von <span class="math inline">\(Y\)</span> minimiert wird.</p>
</li>
<li>
<p>Die Gewichte werden in kleinen Schritten, die durch die so genannte <em>Lernrate</em> bestimmt werden, in Richtung des negativen Gradienten angepasst. Dies bewirkt, dass die Gewichte so verändert werden, dass der Loss im Vergleich zur letzten Iteration verringert wird.</p>
<p>Um den Lernprozess effizienter und stabiler zu machen, nutzen moderne Algorithmen weitere Schritte, bspw. eine Kombination von Gradientenabstieg mit <em>Momentum</em>. Dies beschleunigt die Anpassung der Gewichte und stabilisiert den Lernprozess. Fortgeschrittene Methoden verwenden adaptiven Lernraten, die die Schrittgröße für jedes Gewicht individuell anpassen können.</p>
</li>
</ol>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Der Gradient einer Funktion <span class="math inline">\(f(\boldsymbol{x}) = f(x_1, x_2, \ldots, x_k)\)</span> ist der Vektor der partiellen Ableitungen: <span class="math inline">\(\nabla f = \left( \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \ldots, \frac{\partial f}{\partial x_k} \right)\)</span>. <span class="math inline">\(\nabla f(\boldsymbol{x})\)</span> zeigt die Richtung und Stärke der steilsten Änderung von <span class="math inline">\(f\)</span> am Punkt <span class="math inline">\(\boldsymbol{x}\)</span> an.</p></div><div id="fn3"><p><sup>3</sup>&nbsp;<span class="math inline">\(\nabla f\)</span> ist in NN grundsätzlich unbekannt. Gradient-Desenct-Algorithmen verwenden numerische Verfahren, um den Gradienten anhand von <span class="math inline">\(f\)</span> zu approximieren.</p></div></div><p>Die Schritte 4 und 5 werden wiederholt, bis ein Abbruchkriterium erfüllt ist: Der Fehler ist ausreichend klein, oder weitere Iterationen bewirken keine signifikante Änderung des Gradienten.</p>
<p><strong>Epochen und Iterationen</strong></p>
<p>Der Gesamte Prozess wird für mehrere Epochen (<em>Epocs</em>) durchlaufen, in denen jeweils der gesamte Trainingsdatensatz durch das NN geleitet wird. Um das Training auch für große Datensätze durchführen zu können, werden die Trainingsdaten hierbei üblicherweise in zufällig zusammengesetzen, kleineren Datensätzen (<em>Batches</em>) gruppiert. In jeder Epoche erfolgt die Anpassung der Gewichte für jedes durch das Netz geleitete Batch (jede <em>Iteration</em>):</p>
<ol type="1">
<li>
<p><strong>Epoche</strong></p>
<ol type="1">
<li>
<p><strong>Batch</strong></p>
<p><em>Forward Pass</em> <span class="math inline">\(\rightarrow\)</span> <em>Loss-Berechnung</em> <span class="math inline">\(\rightarrow\)</span> <em>Backpropagation</em> <span class="math inline">\(\rightarrow\)</span> <em>Gradient-Descent-Update</em></p>
</li>
<li>
<p><strong>Batch</strong></p>
<p><em>Forward Pass</em> <span class="math inline">\(\rightarrow\)</span> <em>Loss-Berechnung</em> <span class="math inline">\(\rightarrow\)</span> <em>Backpropagation</em> <span class="math inline">\(\rightarrow\)</span> <em>Gradient-Descent-Update</em></p>
<p>…</p>
</li>
</ol>
</li>
<li>
<p><strong>Epoche</strong></p>
<pre><code>     ...</code></pre>
<p>…</p>
</li>
</ol>
<p>Für das Training eines NN sind mehrere Epochen notwendig, weil ein einzelner Durchlauf der Daten oft nicht ausreicht, um die zugrundeliegenden Muster zu lernen. Durch Anpassung über mehrere Epochen können die Gewichte des Modells verfeinert werden, was insbesondere die Fähigkeit zur Generalisierung für ungesehene Daten verbessert. Die zufällige Einteilung der Daten in Batches zu Beginn jeder Epoche verhindert unter anderem, dass das NN lediglich die Reihenfolge der durchgeleiteten Datenpunkte lernt.</p>
<p>Die Anzahl an zu durchlaufender Epochen ist ein Tuning-Parameter: Zu wenige Epochen führen zu einer schlechten Anpassung an die Daten, während zu viele Epochen das Risiko von Overfitting erhöhen. Um den Vorhersagefehler für ungesehene Daten einzuschätzen, wird ein Testdatensatz vorbehalten. Dieser Datensatz wird während des Trainings nicht zum Anpassen der Gewichte genutzt, sondern erst nach Abschluss einer Epoche für die Berechnung der Vorhersagequalität herangezogen. So kann jeweils nach dem Durchlauf einer Epoche beurteilt werden, wie gut das Modell auf neue, unbekannte Daten generalisiert. Hierbei können ein hoher Vorhersagefehler für den Testdatensatz und ein (viel) geringerer Fehler für den Trainingsdatensatz nach mehreren Epochen auf Overfitting hinweisen. Im empirischen Teil dieses Kapitels diskutieren wir (grafische) Methoden zur Beurteilung der Anpassung des Modells.</p>
<p>Beim Training von NN können sogenannte <em>Callback-Funktionen</em> eingesetzt werden, um den Anpassungsprozess unter Einbezug von Zwischenergebnissen zu bestimmten Zeitpunkten während des Trainingsprozesses, z. B. am Ende jeder Epoche oder nach einer bestimmten Anzahl von Iterationen, zu evaluieren. Callbacks werden verwendet, um bestimmte Aktionen auszuführen, wie das Anpassen der Lernrate oder das Überwachen der Trainingsleistung: Ein Callback kann das Training automatisch stoppen (<em>Early Stopping</em>), wenn Anzeichen von Overfitting erkannt werden, beispielsweise wenn die Vorhersagegüte auf dem Test-Datensatz über mehrere Epochen hinweg stagniert. Dadurch wird ein unnötiges Fortsetzen des Trainings vermieden und ein Verlust der Generalisierungsfähigkeit auf neuen Daten verhindert.</p>
<p>Wir fassen die wichtigsten Begriffe für die Beschreibung von NN nachfolgend kurz zusammen.</p>
<p><strong>Wesentliche Definitionen</strong></p>
<ul>
<li><p><strong>Layer</strong>: Eine Ebene von Neuronen im neuronalen Netzwerk. Es gibt das Eingabe-Layer, versteckte Layers (Hidden Layers) und das Ausgabe-Layer. Jedes Layer verarbeitet Informationen aus dem vorangegangenen Layer und gibt die Ergebnisse an das nächste Layer weiter.</p></li>
<li><p><strong>Input</strong>: Die Eingangsdaten oder Merkmale, die in das NN eingespeist werden. Jeder Input wird durch ein oder mehrere Neuronen im Eingabe-Layer repräsentiert.</p></li>
<li><p><strong>Output</strong>: Das Ergebnis, welches das NN nach der Verarbeitung der Inputs liefert. Der Output wird durch die Neuronen im Output-Layer des NN erstellt.</p></li>
<li><p><strong>Neuron</strong>: Die kleinste Komponente eines NN. Jedes Neuron empfängt Inputs, multipliziert sie mit Gewichten, addiert einen Bias und gibt das Ergebnis nach Anwendung einer Aktivierungsfunktion weiter: Ein Neuron ist also eine <em>mathematische Funktion</em>, die Inputs aus dem vorherigen Layer mit einer transformierten Linearkombination verarbeitet und das Ergebnis das nächste Layers weiterleitet.</p></li>
<li><p><strong>Forward Pass</strong>: Leitung der Trainingsdaten durch das NN und Berechnung der Vorhersage des Outcomes.</p></li>
<li><p><strong>Loss-Funktion</strong>: Mathematische Funktion, welche die Güte der Vorhersage des NN für das Outcome quantifiziert. Der Loss ist eine Funktion der zu trainierenden Parameter des NN.</p></li>
<li><p><strong>Backward Pass / Backpropagation</strong>: Ermittlung des Gradienten der Loss-Funktion durch Verkettung des Effekts der Gewichte über die Layers des NN.</p></li>
<li>
<p><strong>Aktivierungsfunktion</strong>: Eine mathematische Funktion, die auf die gewichtete Summe der Eingaben eines Neurons angewendet wird. Die Aktivierungsfunktion bestimmt, ob ein Neuron aktiviert wird. Beispiele sind</p>
<p><span class="math display">\[\begin{align*}
    \text{ReLU}(z) =&amp; \max(0, z), \\[.5ex]
    \sigma(z) =&amp;\, \frac{1}{1 + e^{-z}}, \\[.5ex]
    \tanh(z) =&amp;\, \frac{e^z - e^{-z}}{e^z + e^{-z}}.
  \end{align*}\]</span></p>
</li>
<li><p><strong>Epoche</strong>: Ein Trainingszyklus, bei dem der gesamte Trainingsdatensatz, aufgeteilt in Batches, das NN durchläuft.</p></li>
<li><p><strong>Batches</strong>: Zufällig eingeteilte Teilmengen der Beobachtungen des Trainingsdatensatzes.</p></li>
<li><p><strong>Callback</strong>: Eine Funktion, die im Zuge der Überwachung des des Trainings-Prozesses automatisch ausgeführt wird, um Aktionen wie Lernratenanpassung oder Trainingsstopp zu auszulösen.</p></li>
</ul>
<p>Im nächsten Abschnitt erläutern wir die Optimierung der Gewichte mit Gradient Descent beispielhaft anhand interaktiver Visualisierungen.</p>
</section></section><section id="optimierung-mit-gradient-descent" class="level2 page-columns page-full" data-number="14.2"><h2 data-number="14.2" class="anchored" data-anchor-id="optimierung-mit-gradient-descent">
<span class="header-section-number">14.2</span> Optimierung mit Gradient Descent</h2>
<p>Gradient Descent ist ein iteratives Optimierungsverfahren zur Minimierung einer differenzierbaren Zielfunktion <span class="math inline">\(f(w)\)</span>. Ausgehend von einem Startwert <span class="math inline">\(w_0\)</span> aktualisiert der Algorithmus die Variable <span class="math inline">\(w\)</span> schrittweise gemäß einer Lernrate <span class="math inline">\(\eta\)</span> in die entgegengesetzte Richtung des Gradienten <span class="math inline">\(\nabla f(w)\)</span> der Funktion an der aktuellen <span class="math inline">\(w\)</span>. Mit <span class="math inline">\(\nabla f(w)\)</span> wird mathematisch die Richtung des <em>steilsten Anstiegs</em> von <span class="math inline">\(f(w)\)</span> im Punkt <span class="math inline">\(w\)</span> ermittelt. Der Algorithmus vollzieht eine Veränderung von <span class="math inline">\(w\)</span> in die entgegengesetzten Richtung – die Richtung mit dem schnellsten <em>Abstieg</em> (Descent) der Zielfunktion.</p>
<p>Der folgende Algorithmus zeigt die grundlegende Vorgehensweise des Gradientenabstiegsverfahrens für einen einziegen zu optimierenden Parameter <span class="math inline">\(w\)</span> unter Einbeziehung eines Momentum-Terms <span class="math inline">\(v_t\)</span>.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> Der Momentum-Term dient dazu, das Konvergenzverhalten zu verbessern und lokale Minima effektiver zu überwinden. Die Stärke des Momentums <span class="math inline">\(v_t\)</span> wird durch den Momentum-Faktor <span class="math inline">\(\alpha \in [0,1)\)</span> bestimmt.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;In der Literatur wird <span class="math inline">\(v_t\)</span> häufig auch als <em>Velocity</em> bezeichnet.</p></div></div><p><span class="math display">\[\begin{align*}
  \small
  &amp; \textbf{Algorithmus: Gradientenabstiegsverfahren mit Momentum} \\
  &amp; \textup{Initialisiere: }\\[.5ex]
  &amp; \quad w_0 \text{ (Startpunkt) }\\
  &amp; \quad \eta \text{ (Lernrate) }\\
  &amp; \quad \alpha \text{ (Momentum-Faktor) }\\
  &amp; \quad v_0 = 0 \text{ (Anfangsmomentum) } \\[1em]
  &amp; \text{Iteriere für } t = 0, 1, 2, \dots \text{ bis Konvergenz:} \\[.5ex]
  &amp; \quad \text{1. Berechne den Gradienten: } \nabla f(w_t) \\
  &amp; \quad \text{2. Aktualisiere den Momentum-Term: } v_{t+1} = \alpha v_t - \eta \nabla f(w_t) \\
  &amp; \quad \text{3. Aktualisiere die Position: } w_{t+1} = w_t + v_{t+1} \\
  &amp; \quad \text{4. Überprüfe das Abbruchkriterium } |\nabla f(w_t)| &lt; \epsilon\text{ (für ein kleines $\epsilon&gt;0$)} \\
\end{align*}\]</span></p>
<p>In der nachfolgenden interaktiven Visualisierung illustrieren wir die Minimierung einer univariaten Funktion <span class="math inline">\(\color{blue}{f(w_t)}\)</span> über <span class="math inline">\(w_t\)</span> anhand des obigen Algorithmus mit Lernrate <span class="math inline">\(\eta = .001\)</span> und Momentum-Faktor <span class="math inline">\(\alpha = .925\)</span>.</p>
<p>Der <span style="color:orange">Gradient</span><span class="math inline">\(\color{orange}{\nabla f(w_t)}\)</span> ist hier die 1. Ableitung von <span class="math inline">\(\color{blue}{f(w_t)}\)</span> nach <span class="math inline">\(w_t\)</span>. Die Richtung der Änderung von <span class="math inline">\(\color{blue}{f(w_t)}\)</span> in <span class="math inline">\(w_t\)</span> wird durch den <span style="color:orange">orangenen Pfeil</span> angezeigt. Beachte, wie sich der Gradient bei Variation des Start-Punkts mit dem Slider ändert. Während die Animation der Optimierung mit Gradient Descent läuft, zeigt der <span style="color:purple">lilane Pfeil</span> das <span style="color:purple">Momentum</span> (<span style="color:purple">Velocity <span class="math inline">\(v_t\)</span></span>) für Schirtt <span class="math inline">\(t\)</span> an.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> Der Algorithmus iteriert die Schritte 1. bis 3. solange, bis das Abbruchkriterium <span class="math inline">\(|\textcolor{orange}{\nabla f(w_t)}| &lt; \epsilon = 0.001\)</span> erreicht ist, die Änderung in <span class="math inline">\(\color{orange}{\nabla f(w_t)}\)</span> also hinreichend klein ist, dass ein Parameterwert <span class="math inline">\(w_t\)</span> mit <span class="math inline">\(\color{blue}{f(w_t)}\)</span> nahe des (globalen) Minimums von <span class="math inline">\(f\)</span> plausibel ist.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;Unterschiedliche Längen der Pfeile zeigen hier nicht Änderungen der tatsächlichen Beträge, sondern dienen lediglich der Interpretierbakeit der Grafik.</p></div></div><p>Folgende Eigenschaften der Optimierung mit Gradient Descent können anhand der Parameter geprüft werden:</p>
<ul>
<li>
<p>Für Startpunkte mit großen Werten des Gradienten beginnt der Algorithmus mit einem starken Momentum: Der Abstieg in Richtung des negativen Gradients erfolgt also in großen Schritten, sodass die Optimierung schneller erfolgt als für Startpunkte in flachen Regionen von <span class="math inline">\(\color{blue}{f}\)</span>.</p>
<p>Dieser Effekt des Momentum auf den Pfad der zu optimierenden Parameter bei Gradient Descent ist vergleichbar mit dem Effekt der Schwerkraft auf eine Murmel, die auf einer hügeligen Oberfläche rollt: Anfangs gewinnt die Murmel an Geschwindigkeit und bewegt sich beschleunigt in Richtung des steilsten Gefälles. In flacheren Regionen wird die Bewegung langsamer und die Murmel kann in Tälern stecken bleiben, ähnlich wie der Optimierungsprozess in flachen Regionen von <span class="math inline">\(\color{blue}{f}\)</span> langsamer verläuft oder gar stoppt, weil ein Abbruchkriterium erfüllt ist (geringe Änderung des Gradienten). Das Momentum hilft, auch in solchen flachen Bereichen weiter voranzukommen, indem es dem Parameterpfad eine gewisse “Trägheit” verleiht, die es ermöglicht, flache Stellen schneller zu durchqueren und die Optimierung effizienter zu gestalten.</p>
</li>
<li><p>Bei ungünstiger Wahl der Parameter konvergiert der Algorithmus nicht zum globalen Minimum, sondern stoppt im lokalen Minimum bei <span class="math inline">\(w = -0.5\)</span>. Dies unterstreicht die Notwendigkeit, die Hyperparameter Lernrate <span class="math inline">\(\eta\)</span> und Momentum-Faktor <span class="math inline">\(\alpha\)</span> sorgfältig zu wählen, beispielsweise indem die Modellgüte nach erfolgter Anpassung für verschiedene Parameter-Kombinationen verglichen wird.</p></li>
</ul>
<p>In empirischen Anwendungen ist es für eine hohe Modellgüte eines neuronalen Netzwerks nicht unbedingt erforderlich, das globale Minimum zu finden: Viele Optimierungsprobleme weisen zahlreiche lokale Minima auf, die eine ausreichend gute Annäherung an das Optimum bieten können. Besonders bei hochdimensionalen Optimierungsproblemen mit komplexen Loss-Funktionen können diese lokalen Minima zufriedenstellende Lösungen darstellen. In einigen Fällen existiert möglicherweise kein globales Minimum, und der Algorithmus konvergiert zwangsläufig zu einem stabilen lokalen Minimum, das dennoch eine gute Performance gewährleistet. Daher kann es sinnvoller sein, Algorithmen zu verwenden, die das Erreichen einer robusten Lösung legen, anstatt strikt nach dem globalen Minimum zu suchen.</p>
<p>In Software-Implementierungen für Machine und Deep Learning wie <code>tensorflow</code> und <code>keras</code> werden fortgeschrittene Techniken wie Momentum Tuning oder Stochastic <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Gradient Descent</a> (SGD) eingesetzt, um die Wahrscheinlichkeit zu erhöhen, dass der Algorithmus nicht in einem (ungünstigen) lokalen Minimum endet. Ein für die Anpassung von NN häufig verwendeter Algorithmus, der SGD verwendet, ist <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam">Adaptive Moment Estimation (Adam)</a>. Wir verwenden u.a. den Adam-Optimizer in den empirischen Beispielen.</p>
<iframe class="obs-soft-box-shadow" width="100%" height="761" frameborder="0" src="https://observablehq.com/embed/@mca91/gradient-descent-in-2d?cells=plot%2Cviewof+startAnimation%2Cviewof+startPoint%2Cviewof+alpha%2Cviewof+eta%2CoptimalReached%2CMathJax%2Cstyles">
</iframe>
<p>In empirischen Anwendungen sind die zu lernenden Zusammenhänge komplex und damit die Anzahl der zu optimierenden Parameter eines NN häufig groß. Der oben erläuterte Algorithmus für Gradient Descent mit Momentum kann einfach auf Optimierungsprobleme mit <span class="math inline">\(k\)</span> Parametern generalisiert werden. Dann ist <span class="math inline">\(\boldsymbol{w}_t\)</span> ein Vektor mit <span class="math inline">\(k\)</span> Gewichten, <span class="math inline">\(\boldsymbol{v}_{t+1}\)</span> eine vektorwertige Funktion von <span class="math inline">\(\boldsymbol{v}_t\)</span> und <span class="math inline">\(\nabla f(\boldsymbol{w}_t)\)</span> mit Dimension <span class="math inline">\(k\)</span> und <span class="math inline">\(f(\boldsymbol{w}_t)\)</span> ist eine Oberfläche in einem <span class="math inline">\(k+1\)</span>-dimensionalen Raum.</p>
<p>Die nachfolgende interaktive Grafik illustriert Gradient Descent mit Momentum für <span class="math inline">\(k=2\)</span> zu optimierende Gewichte. Statt der Parameter des Algorithmus kann hier die Form der zu optimierenden Funktion manipuliert werden, sodass bis zu 6 Extremstellen vorliegen können. Der <span style="color:red">rote Punkt</span> zeigt den Verlauf der Optimierung von <span class="math inline">\(\boldsymbol{w}_t\)</span>.</p>
<p>Die Animation verdeutlicht, dass lokale Minima insbesondere in höheren Dimensionen herausfordernd für Optimierungsalgorithmen sind: Durch Variation der Extrema lassen sich leicht Funktionen <span class="math inline">\(f(w_1,w_1)\)</span> konstruieren, für die Gradient Descent mit den voreingestellten Parametern nicht gegen das globale Minimum konvergiert, sofern vorhanden. Ein günstiger Initialwert für <span class="math inline">\(\boldsymbol{w}_t\)</span> kann die Wahrscheinlichkeit von Stops in lokalen Minima verringern: <em>Grid Search Initialization</em> wertet die Funktion über ein gleichmäßiges Gitter von Werten für <span class="math inline">\(\boldsymbol{w}_t\)</span> aus und wählt als Startwert <span class="math inline">\(\boldsymbol{w}_{0,\textup{init}}\)</span> den Punkt mit dem minimalen Funktionswert von <span class="math inline">\(f\)</span> über alle Punkte im Gitter.</p>
<iframe class="obs-soft-box-shadow" width="100%" height="1172" frameborder="0" src="https://observablehq.com/embed/@mca91/gradient-descent-in-3d-three-js?cells=renderer%2Cviewof+restart%2Cviewof+gridinit%2Cviewof+themin%2Cviewof+themin2%2Cviewof+themin3%2Cviewof+themin4%2Cviewof+themin5%2Cviewof+themin6%2Cscene%2Ccamera">
</iframe>
</section><section id="funktionale-zusammenhänge-lernen-regression" class="level2 page-columns page-full" data-number="14.3"><h2 data-number="14.3" class="anchored" data-anchor-id="funktionale-zusammenhänge-lernen-regression">
<span class="header-section-number">14.3</span> Funktionale Zusammenhänge lernen: Regression</h2>
<p>Für einen leichten Einstieg in die Modellierung funktionaler Zusammenhänge durch NN mit statistischer Programmierung in R betrachten wir zunächst den einfachsten Zusammenhang zwischen einer Outcome-Variable <span class="math inline">\(Y\)</span> und einem Regressor <span class="math inline">\(X\)</span>: Die einfache lineare Funktion <span class="math display">\[\begin{align*}
  Y = w_1 X + b,
\end{align*}\]</span> wobei der Regressionskoeffizient <span class="math inline">\(w_1\)</span> den Einfluss von <span class="math inline">\(X\)</span> auf <span class="math inline">\(Y\)</span> misst und <span class="math inline">\(b\)</span> eine Konstante ist. Gemäß der Definitionen in <a href="#sec-nn-basics" class="quarto-xref"><span>Kapitel 14.1</span></a> kann dieser Funktionale Zusammenhang als NN ohne Hidden Layer dargestellt werden, wobei <span class="math inline">\(X\)</span> ein Input-Neuron ist, dessen Information mit <span class="math inline">\(w_1\)</span> gewichtet an das Output Layer mit einem einzigen Neuron für <span class="math inline">\(Y\)</span> weitergegeben wird. Die Konstante <span class="math inline">\(b\)</span> ist ein <em>Bias</em>, der als von <span class="math inline">\(X\)</span> unabhängiger Einfluss von <span class="math inline">\(Y\)</span> behandelt wird, vgl. <a href="#fig-nn-lreg" class="quarto-xref">Abbildung&nbsp;<span>14.2</span></a>.</p>
<div class="cell page-columns page-full" data-fig-width="6" data-fig-height="2" data-layout-align="default">
<div class="cell-output-display page-columns page-full">
<div id="fig-nn-lreg" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-nn-lreg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="576" height="192" viewbox="0.00 0.00 332.02 200.11" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none"><g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 196.11)"><title>NEURALNET</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-196.11 328.02,-196.11 328.02,4 -4,4"></polygon><!-- X --><g id="node1" class="node"><title>X</title>
<ellipse fill="none" stroke="black" cx="18.01" cy="-30.11" rx="18.02" ry="18.02"></ellipse><text text-anchor="middle" x="18.01" y="-25.91" font-family="Helvetica,Arial,sans-serif" font-size="14.00">X</text></g><!-- Y --><g id="node2" class="node"><title>Y</title>
<ellipse fill="lightgreen" stroke="black" cx="306.01" cy="-30.11" rx="18.02" ry="18.02"></ellipse><text text-anchor="middle" x="306.01" y="-25.91" font-family="Helvetica,Arial,sans-serif" font-size="14.00">Y</text></g><!-- X&#45;&gt;Y --><g id="edge1" class="edge"><title>X-&gt;Y</title>
<path fill="none" stroke="black" d="M36.03,-30.11C84.6,-30.11 218.57,-30.11 277.53,-30.11"></path><polygon fill="black" stroke="black" points="277.63,-33.61 287.63,-30.11 277.63,-26.61 277.63,-33.61"></polygon><text text-anchor="middle" x="164.53" y="-4.2" font-family="Helvetica,Arial,sans-serif" font-size="14.00">w1</text></g><!-- B --><g id="node3" class="node"><title>B</title>
<ellipse fill="none" stroke="black" cx="162.01" cy="-174.11" rx="18" ry="18"></ellipse><text text-anchor="middle" x="162.01" y="-169.91" font-family="Helvetica,Arial,sans-serif" font-size="14.00">1</text></g><!-- B&#45;&gt;Y --><g id="edge2" class="edge"><title>B-&gt;Y</title>
<path fill="none" stroke="black" d="M174.79,-161.33C199.81,-136.31 255.45,-80.67 285.62,-50.5"></path><polygon fill="black" stroke="black" points="288.46,-52.61 293.05,-43.06 283.51,-47.66 288.46,-52.61"></polygon><text text-anchor="middle" x="248.05" y="-116.81" font-family="Helvetica,Arial,sans-serif" font-size="14.00">Bias (b)</text></g></g></svg>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-nn-lreg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;14.2: Neuronales Netzwerk: Lineare Regression mit einer Variable und Konstante
</figcaption></figure>
</div>
</div>
</div>
<p>Für die Illustration der Schätzung des in <a href="#sec-nn-basics" class="quarto-xref"><span>Kapitel 14.1</span></a> dargestellten NN verwenden wir <span class="math inline">\(n=1000\)</span> simulierte Datenpunkte gemäß der Vorschrift <span class="math display">\[\begin{align}
  Y = 5 + 3 \cdot X + u
\end{align}\]</span> mit <span class="math inline">\(X\sim U[0,10]\)</span> und <span class="math inline">\(u\sim N(0,1)\)</span>.</p>
<div class="cell">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Daten simulieren</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">1000</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">n</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">5</span> <span class="op">+</span> <span class="fl">3</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span> </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Für das Training von NN verwenden wir das Python-Paket <a href="https://keras.io/">keras</a>. Hierzu muss lediglich eine lokale Python-Installation vorhanden sein.</p>
<p>Die in diesem Kapitel betrachteten NN sind <em>sequentielle</em> NN. Solche Modelle können in <code>keras</code> mit der Funktion <code><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html">keras_model_sequential()</a></code> definiert werden. Die Struktur des Modells kann über eine Verkettung von Funktionen für Layers (<code><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">keras::layer_dense()</a></code>) und Aktivierungen (<code><a href="https://rdrr.io/pkg/keras/man/layer_activation.html">keras::layer_activation()</a></code>) definiert werden.</p>
<p>Für die Implementierung des Modells in <a href="#fig-nn-lreg" class="quarto-xref">Abbildung&nbsp;<span>14.2</span></a> wählen wir mit <code>units = 1</code> und <code>input_shape = 1</code> ein Modell mit einem Neuron im Output Layer, das skalare Informationen verarbeitet. <code>activation = 'linear'</code> in <code><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense()</a></code> führt zu der Aktivierungsfunktion <span class="math inline">\(A(x) = x\)</span>, d.h. die Ausgabe des Input Layers ist die gewichtete Summe der Eingaben plus Bias, <em>ohne</em> eine zusätzliche Transformation.</p>
<div class="cell">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tensorflow.rstudio.com/">keras</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># NN für einfache Regression</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span></span>
<span>    units <span class="op">=</span> <span class="fl">1</span>, </span>
<span>    input_shape <span class="op">=</span> <span class="fl">1</span>, </span>
<span>    activation <span class="op">=</span> <span class="st">'linear'</span></span>
<span>    <span class="op">)</span></span>
<span></span>
<span><span class="co"># Modell-Definition prüfen</span></span>
<span><span class="va">model</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense (Dense)                      (None, 1)                       2           
================================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
________________________________________________________________________________</code></pre>
</div>
</div>
<p>Die Übersicht zeigt, dass <code>model</code> aus einem Layer für skalare Inputs und Outputs sowie zwei trainierbaren Parameters (<span class="math inline">\(w_1\)</span> und <span class="math inline">\(b\)</span>) besteht.</p>
<p>Bevor das im Objekt <code>model</code> definierte Modell trainiert werden kann, muss der Code <em>kompiliert</em> werden. Dieser Vorgang ist notwendig, da sämtliche Berechnungen in Python durchgeführt werden. Der Python-Code wird beim kompilieren in eine Zwischendarstellung (<em>Bytecode</em>) übersetzt, die dann von der Python-Interpreter-Laufzeitumgebung ausgeführt wird.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;Im Gegensatz zu Python ist R eine <em>interpretierte Programmiersprache</em>. Kompilierung von R-Ccode ist daher nicht notwendig.</p></div></div><p>Mit <code><a href="https://generics.r-lib.org/reference/compile.html">keras::compile()</a></code> kompilieren wir das Modell und wählen als Optimierungsfunktion Adam mit einer Lernrate von <span class="math inline">\(.01\)</span>. Die Loss-Funktion wird über das Argument <code>loss</code> festgelegt, hier der mittlere absolute Fehler, <span class="math display">\[\begin{align*}
  \textup{MAE} = \frac{1}{n} \sum_{i=1}^{n} \lvert y_i - \widehat{y}_i\rvert.
\end{align*}\]</span></p>
<div class="cell">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Modell kompilieren</span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span></span>
<span>    optimizer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/optimizer_adam.html">optimizer_adam</a></span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span>,</span>
<span>    loss <span class="op">=</span> <span class="st">'mean_absolute_error'</span></span>
<span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Die Kompilierung erfolgt meist innerhalb von Sekundenbruchteilen und geschieht <em>in-place</em>: Eine Zuweisung des kompilierten Modells in <code>model</code> ist <em>nicht</em> notwendig.</p>
<p>Um das Modell zu trainieren verwenden wir <code><a href="https://generics.r-lib.org/reference/fit.html">keras::fit()</a></code>. Neben den (simulierten) Daten übergeben wir die Anzahl der zudurchlaufenden Epochen <code>epocs</code>. Über das Argument <code>validation_split</code> legen wir fest, dass 20% der Datensatzes zufällig ausgewählt und als Test-Datensatz für die Modell-Validierung während des Trainings genutzt werden sollen.</p>
<div class="cell">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Modell trainieren</span></span>
<span><span class="va">history_snn</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="va">x</span>, </span>
<span>    y <span class="op">=</span> <span class="va">y</span>, </span>
<span>    epochs <span class="op">=</span> <span class="fl">50</span>, </span>
<span>    validation_split <span class="op">=</span> <span class="fl">.2</span></span>
<span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/50
25/25 - 0s - loss: 18.6900 - val_loss: 17.5884 - 431ms/epoch - 17ms/step
Epoch 2/50
25/25 - 0s - loss: 17.1817 - val_loss: 16.0962 - 99ms/epoch - 4ms/step
Epoch 3/50
25/25 - 0s - loss: 15.6553 - val_loss: 14.6251 - 90ms/epoch - 4ms/step
Epoch 4/50
25/25 - 0s - loss: 14.1373 - val_loss: 13.1487 - 92ms/epoch - 4ms/step
Epoch 5/50
25/25 - 0s - loss: 12.6202 - val_loss: 11.6663 - 91ms/epoch - 4ms/step
Epoch 6/50
25/25 - 0s - loss: 11.0948 - val_loss: 10.1931 - 89ms/epoch - 4ms/step
Epoch 7/50
25/25 - 0s - loss: 9.5805 - val_loss: 8.7063 - 89ms/epoch - 4ms/step
Epoch 8/50
25/25 - 0s - loss: 8.0555 - val_loss: 7.2279 - 92ms/epoch - 4ms/step
Epoch 9/50
25/25 - 0s - loss: 6.5362 - val_loss: 5.7443 - 90ms/epoch - 4ms/step
Epoch 10/50
25/25 - 0s - loss: 5.0179 - val_loss: 4.2567 - 89ms/epoch - 4ms/step
Epoch 11/50
25/25 - 0s - loss: 3.4984 - val_loss: 2.7729 - 90ms/epoch - 4ms/step
Epoch 12/50
25/25 - 0s - loss: 2.0163 - val_loss: 1.4789 - 88ms/epoch - 4ms/step
Epoch 13/50
25/25 - 0s - loss: 1.1482 - val_loss: 1.1333 - 90ms/epoch - 4ms/step
Epoch 14/50
25/25 - 0s - loss: 1.0641 - val_loss: 1.1069 - 90ms/epoch - 4ms/step
Epoch 15/50
25/25 - 0s - loss: 1.0418 - val_loss: 1.0893 - 92ms/epoch - 4ms/step
Epoch 16/50
25/25 - 0s - loss: 1.0205 - val_loss: 1.0645 - 89ms/epoch - 4ms/step
Epoch 17/50
25/25 - 0s - loss: 1.0015 - val_loss: 1.0427 - 93ms/epoch - 4ms/step
Epoch 18/50
25/25 - 0s - loss: 0.9832 - val_loss: 1.0162 - 90ms/epoch - 4ms/step
Epoch 19/50
25/25 - 0s - loss: 0.9647 - val_loss: 0.9976 - 89ms/epoch - 4ms/step
Epoch 20/50
25/25 - 0s - loss: 0.9488 - val_loss: 0.9756 - 90ms/epoch - 4ms/step
Epoch 21/50
25/25 - 0s - loss: 0.9325 - val_loss: 0.9550 - 88ms/epoch - 4ms/step
Epoch 22/50
25/25 - 0s - loss: 0.9173 - val_loss: 0.9339 - 88ms/epoch - 4ms/step
Epoch 23/50
25/25 - 0s - loss: 0.9031 - val_loss: 0.9152 - 89ms/epoch - 4ms/step
Epoch 24/50
25/25 - 0s - loss: 0.8883 - val_loss: 0.8944 - 88ms/epoch - 4ms/step
Epoch 25/50
25/25 - 0s - loss: 0.8754 - val_loss: 0.8760 - 90ms/epoch - 4ms/step
Epoch 26/50
25/25 - 0s - loss: 0.8623 - val_loss: 0.8582 - 90ms/epoch - 4ms/step
Epoch 27/50
25/25 - 0s - loss: 0.8507 - val_loss: 0.8400 - 89ms/epoch - 4ms/step
Epoch 28/50
25/25 - 0s - loss: 0.8387 - val_loss: 0.8240 - 89ms/epoch - 4ms/step
Epoch 29/50
25/25 - 0s - loss: 0.8287 - val_loss: 0.8108 - 89ms/epoch - 4ms/step
Epoch 30/50
25/25 - 0s - loss: 0.8197 - val_loss: 0.7981 - 89ms/epoch - 4ms/step
Epoch 31/50
25/25 - 0s - loss: 0.8109 - val_loss: 0.7886 - 90ms/epoch - 4ms/step
Epoch 32/50
25/25 - 0s - loss: 0.8035 - val_loss: 0.7790 - 88ms/epoch - 4ms/step
Epoch 33/50
25/25 - 0s - loss: 0.7975 - val_loss: 0.7715 - 89ms/epoch - 4ms/step
Epoch 34/50
25/25 - 0s - loss: 0.7912 - val_loss: 0.7629 - 89ms/epoch - 4ms/step
Epoch 35/50
25/25 - 0s - loss: 0.7856 - val_loss: 0.7574 - 88ms/epoch - 4ms/step
Epoch 36/50
25/25 - 0s - loss: 0.7813 - val_loss: 0.7526 - 89ms/epoch - 4ms/step
Epoch 37/50
25/25 - 0s - loss: 0.7774 - val_loss: 0.7468 - 89ms/epoch - 4ms/step
Epoch 38/50
25/25 - 0s - loss: 0.7740 - val_loss: 0.7425 - 90ms/epoch - 4ms/step
Epoch 39/50
25/25 - 0s - loss: 0.7716 - val_loss: 0.7395 - 88ms/epoch - 4ms/step
Epoch 40/50
25/25 - 0s - loss: 0.7713 - val_loss: 0.7331 - 93ms/epoch - 4ms/step
Epoch 41/50
25/25 - 0s - loss: 0.7691 - val_loss: 0.7336 - 105ms/epoch - 4ms/step
Epoch 42/50
25/25 - 0s - loss: 0.7686 - val_loss: 0.7293 - 124ms/epoch - 5ms/step
Epoch 43/50
25/25 - 0s - loss: 0.7642 - val_loss: 0.7259 - 92ms/epoch - 4ms/step
Epoch 44/50
25/25 - 0s - loss: 0.7630 - val_loss: 0.7238 - 91ms/epoch - 4ms/step
Epoch 45/50
25/25 - 0s - loss: 0.7634 - val_loss: 0.7206 - 91ms/epoch - 4ms/step
Epoch 46/50
25/25 - 0s - loss: 0.7627 - val_loss: 0.7195 - 90ms/epoch - 4ms/step
Epoch 47/50
25/25 - 0s - loss: 0.7610 - val_loss: 0.7211 - 87ms/epoch - 3ms/step
Epoch 48/50
25/25 - 0s - loss: 0.7623 - val_loss: 0.7169 - 85ms/epoch - 3ms/step
Epoch 49/50
25/25 - 0s - loss: 0.7632 - val_loss: 0.7164 - 84ms/epoch - 3ms/step
Epoch 50/50
25/25 - 0s - loss: 0.7632 - val_loss: 0.7145 - 84ms/epoch - 3ms/step</code></pre>
</div>
</div>
<p>Der Output zeigt die Enwicklung des Loss (MAE) für Vorhersagen des Trainingsdatensatzes (<code>loss</code>) und für den Test-Datensatz (<code>val_loss</code>) für alle 25 Epochen. Diese Informationen können mit <code><a href="https://rdrr.io/r/graphics/plot.default.html">plot()</a></code> einfach visualisiert werden.</p>
<div class="cell page-columns page-full">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://wilkelab.org/cowplot/">cowplot</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://purrr.tidyverse.org/">purrr</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Entwicklung des Loss über Epochen plotten</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">history_snn</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="st">"Epoche"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Wert der Verlustfunktion"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://wilkelab.org/cowplot/reference/theme_cowplot.html">theme_cowplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"top"</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display page-columns page-full">
<div id="fig-snn-loss" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-snn-loss-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Machine-Learning_files/figure-html/fig-snn-loss-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-snn-loss-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;14.3: Einfaches lineares NN: Entwicklung des Loss für 25 Epochen
</figcaption></figure>
</div>
</div>
</div>
<p><a href="#fig-snn-loss" class="quarto-xref">Abbildung&nbsp;<span>14.3</span></a> zeigt, dass sich sowohl die Anpassung des NN auf dem Trainingsdatenstz als auch die Generalisierung auf dem Testdatensatz innerhalb der ersten Epochen dramatisch verbessert. Jenseits der 15. Epoche hingegen bewirken weitere Trainingszyklen keine weitere Verbesserung des Loss.</p>
<p>Mit <code><a href="https://rdrr.io/pkg/keras/man/get_weights.html">keras::get_weights()</a></code> können wir die optimierten Parameter aus dem Modell-Objekt auslesen.</p>
<div class="cell">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Gewichtung und Bias des trainierten NN auslesen</span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu">keras</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/get_weights.html">get_weights</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu">flatten_dbl</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://rlang.r-lib.org/reference/set_names.html">set_names</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"w_1"</span>, <span class="st">"bias"</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     w_1     bias 
3.011411 4.925850 </code></pre>
</div>
</div>
<p>Das NN hat den funktionalen Zusammengang zwischen <code>x</code> und <code>y</code> erfolgreich gelernt: Die optimierten Parameter-Werte <code>bias</code> und <code>w_1</code> liegen nahe der wahren Parameter. Bei Parameter sind mit ihren KQ-Schätzungen vergleichbar.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;Beachte, dass die KQ-Schätzung der Einfachheit halber hier den gesamten Datensatz nutzt und daher präziser sein kann als das NN.</p></div></div><div class="cell">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># lineares Modell</span></span>
<span><span class="va">lm_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lm_model</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.91933 -0.62956  0.01084  0.63819  2.73178 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  5.04449    0.06028   83.69   &lt;2e-16 ***
x            2.98893    0.01031  290.01   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.9486 on 998 degrees of freedom
Multiple R-squared:  0.9883,    Adjusted R-squared:  0.9883 
F-statistic: 8.411e+04 on 1 and 998 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Koeffizienten der KQ-Schätzung auslesen</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">lm_model</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)           x 
   5.044491    2.988928 </code></pre>
</div>
</div>
<p>Mit <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> erhalten wir Vorhersagen des NN und können so beispielsweise die Residuen für den gesamten Datensatz mit denen der KQ-Schätzung vergleichen.</p>
<div class="cell page-columns page-full">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Residuen vergleichen</span></span>
<span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span></span>
<span>   NN <span class="op">=</span> <span class="va">y</span> <span class="op">-</span> <span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>,</span>
<span>   lm <span class="op">=</span> <span class="va">lm_model</span><span class="op">$</span><span class="va">residuals</span></span>
<span> <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">NN</span>, y <span class="op">=</span> <span class="va">lm</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">.5</span>, color <span class="op">=</span> <span class="st">"steelblue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://wilkelab.org/cowplot/reference/theme_cowplot.html">theme_cowplot</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>32/32 - 0s - 67ms/epoch - 2ms/step</code></pre>
</div>
<div class="cell-output-display page-columns page-full">
<div id="fig-res-nn" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-res-nn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Machine-Learning_files/figure-html/fig-res-nn-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-res-nn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;14.4: Vergleich von Residuen für NN und KQ-Schätzung
</figcaption></figure>
</div>
</div>
</div>
<p><a href="#fig-res-nn" class="quarto-xref">Abbildung&nbsp;<span>14.4</span></a> zeigt eine gute Korrespondenz zwischen der Anpassung des NN und der KQ-Schätzung des einfachen linearen Modells.</p>
</section><section id="multiple-regression" class="level2 page-columns page-full" data-number="14.4"><h2 data-number="14.4" class="anchored" data-anchor-id="multiple-regression">
<span class="header-section-number">14.4</span> Multiple Regression</h2>
<p>Ein neuronales Netz für multiple Regression kann als eine Erweiterung des Netzes für einfache Regression betrachtet werden. Das Netz enthält nun mehrere Input-Neuronen, von denen jedes eine der unabhängigen Variablen <span class="math inline">\(X_1, X_2, \dots, X_k\)</span> repräsentiert. Diese Input-Neuronen sind mit einem einzigen Output-Neuron verbunden, das die Vorhersage für <span class="math inline">\(Y\)</span> liefert. Jede dieser Verbindungen wird mit einem Gewicht <span class="math inline">\(w_i\)</span> multipliziert, das die Stärke des Einflusses der jeweiligen unabhängigen Variable <span class="math inline">\(X_i\)</span> auf die abhängige Variable <span class="math inline">\(Y\)</span> repräsentiert. Wie im einfachen Modell gibt es einen Bias-Term <span class="math inline">\(b\)</span>, der ähnlich wie in der einen konstanten Einfluss darstellt.</p>
<p>Die Struktur eines NN für multiple Regression ist in <a href="#fig-nn-mlreg" class="quarto-xref">Abbildung&nbsp;<span>14.5</span></a> dargestellt. In diesem Beispiel gibt es drei unabhängige Variablen <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span> und <span class="math inline">\(X_3\)</span>, die jeweils ein eigenes Input-Neuron haben und mit dem Output-Neuron <span class="math inline">\(Y\)</span> verbunden sind. <span class="math inline">\(Y\)</span> ist eine Linear-Kombination der Inputs, gewichtet mit den jeweiligen Gewichten <span class="math inline">\(w_1\)</span>, <span class="math inline">\(w_2\)</span> und <span class="math inline">\(w_3\)</span>, sowie dem Bias <span class="math inline">\(b\)</span>.</p>
<div class="cell page-columns page-full" data-fig-width="6" data-fig-height="3" data-layout-align="default">
<div class="cell-output-display page-columns page-full">
<div id="fig-nn-mlreg" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-nn-mlreg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="576" height="288" viewbox="0.00 0.00 408.85 264.84" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none"><g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 260.84)"><title>NEURALNET</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-260.84 404.85,-260.84 404.85,4 -4,4"></polygon><!-- X1 --><g id="node1" class="node"><title>X1</title>
<ellipse fill="none" stroke="black" cx="22.84" cy="-166.84" rx="22.68" ry="22.68"></ellipse><text text-anchor="middle" x="22.84" y="-162.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">X1</text></g><!-- SUM --><g id="node4" class="node"><title>SUM</title>
<ellipse fill="lightgray" stroke="black" cx="238.84" cy="-94.84" rx="18.06" ry="18.06"></ellipse><text text-anchor="middle" x="238.84" y="-90.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">∑</text></g><!-- X1&#45;&gt;SUM --><g id="edge1" class="edge"><title>X1-&gt;SUM</title>
<path fill="none" stroke="black" d="M44.74,-159.54C84.56,-146.27 168.68,-118.23 211.92,-103.81"></path><polygon fill="black" stroke="black" points="213.11,-107.1 221.49,-100.62 210.9,-100.46 213.11,-107.1"></polygon><text text-anchor="middle" x="119.78" y="-135.88" font-family="Helvetica,Arial,sans-serif" font-size="14.00">w1</text></g><!-- X2 --><g id="node2" class="node"><title>X2</title>
<ellipse fill="none" stroke="black" cx="22.84" cy="-94.84" rx="22.68" ry="22.68"></ellipse><text text-anchor="middle" x="22.84" y="-90.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">X2</text></g><!-- X2&#45;&gt;SUM --><g id="edge2" class="edge"><title>X2-&gt;SUM</title>
<path fill="none" stroke="black" d="M45.95,-94.84C85.79,-94.84 167.23,-94.84 210.44,-94.84"></path><polygon fill="black" stroke="black" points="210.56,-98.34 220.56,-94.84 210.56,-91.34 210.56,-98.34"></polygon><text text-anchor="middle" x="119.64" y="-99.04" font-family="Helvetica,Arial,sans-serif" font-size="14.00">w2</text></g><!-- X3 --><g id="node3" class="node"><title>X3</title>
<ellipse fill="none" stroke="black" cx="22.84" cy="-22.84" rx="22.68" ry="22.68"></ellipse><text text-anchor="middle" x="22.84" y="-18.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">X3</text></g><!-- X3&#45;&gt;SUM --><g id="edge3" class="edge"><title>X3-&gt;SUM</title>
<path fill="none" stroke="black" d="M44.74,-30.14C84.56,-43.41 168.68,-71.45 211.92,-85.87"></path><polygon fill="black" stroke="black" points="210.9,-89.21 221.49,-89.06 213.11,-82.57 210.9,-89.21"></polygon><text text-anchor="middle" x="119.78" y="-62.2" font-family="Helvetica,Arial,sans-serif" font-size="14.00">w3</text></g><!-- Y --><g id="node5" class="node"><title>Y</title>
<ellipse fill="lightgreen" stroke="black" cx="382.84" cy="-94.84" rx="18.02" ry="18.02"></ellipse><text text-anchor="middle" x="382.84" y="-90.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">Y</text></g><!-- SUM&#45;&gt;Y --><g id="edge5" class="edge"><title>SUM-&gt;Y</title>
<path fill="none" stroke="black" d="M257.37,-94.84C281.89,-94.84 325.36,-94.84 354.14,-94.84"></path><polygon fill="black" stroke="black" points="354.38,-98.34 364.38,-94.84 354.38,-91.34 354.38,-98.34"></polygon></g><!-- B --><g id="node6" class="node"><title>B</title>
<ellipse fill="lightblue" stroke="black" cx="238.84" cy="-238.84" rx="18" ry="18"></ellipse><text text-anchor="middle" x="238.84" y="-234.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00" fill="gray">1</text></g><!-- B&#45;&gt;SUM --><g id="edge4" class="edge"><title>B-&gt;SUM</title>
<path fill="none" stroke="black" d="M238.84,-220.6C238.84,-196.17 238.84,-152.57 238.84,-123.67"></path><polygon fill="black" stroke="black" points="242.34,-123.38 238.84,-113.38 235.34,-123.38 242.34,-123.38"></polygon><text text-anchor="middle" x="235.34" y="-176.33" font-family="Helvetica,Arial,sans-serif" font-size="14.00">b</text></g></g></svg>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-nn-mlreg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;14.5: Neuronales Netzwerk: Multiple lineare Regression
</figcaption></figure>
</div>
</div>
</div>
<p>Um die Vorgehensweise in R zu zeigen, generieren wir zunächst <span class="math inline">\(n=250\)</span> Datenpunkte gemäß der Vorschrift <span class="math display">\[\begin{align}
  Y = 5 + 3 \cdot X_1 + 2\cdot X_2 - 1.5 \cdot X_k + u
\end{align}\]</span> mit <span class="math inline">\(X_1,X_2,X_3 \sim\textup{u.i.v.} N(0, 1)\)</span> und <span class="math inline">\(u\sim N(0,1)\)</span>.</p>
<div class="cell">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Erstellen von Trainingsdaten</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">250</span></span>
<span><span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">3</span></span>
<span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span> <span class="op">*</span> <span class="va">k</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="va">k</span><span class="op">)</span></span>
<span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">2</span>, <span class="op">-</span><span class="fl">1.5</span><span class="op">)</span></span>
<span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="fl">5</span> <span class="op">+</span> <span class="va">X</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">w</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Anschließend definieren wir ein einfaches NN und fügen ein Layer hinzu. Da wir eine multiple Regression durchführen, wählen wir <code>input_shape = k</code>, wobei <code>k</code> die Anzahl der unabhängigen Variablen ist. Wie im einfachen Modell ist die Aktivierungsfunktion linear, da wir an der Anpassung von <span class="math inline">\(Y\)</span> mit einer linearen Kombination der Inputs interessiert sind.</p>
<div class="cell">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Erstellen und Kompilieren des Modells</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span></span>
<span>    units <span class="op">=</span> <span class="fl">1</span>, </span>
<span>    input_shape <span class="op">=</span> <span class="va">k</span>, </span>
<span>    activation <span class="op">=</span> <span class="st">'linear'</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="co"># Modelldefinition prüfen</span></span>
<span><span class="va">model</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_1"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_1 (Dense)                    (None, 1)                       4           
================================================================================
Total params: 4
Trainable params: 4
Non-trainable params: 0
________________________________________________________________________________</code></pre>
</div>
</div>
<p>Wir kompilieren das Modell mit dem mittleren quadratischen Fehler (mean squared error, MSE) und SGD als Loss-Funktion mit einer moderaten Lernrate.</p>
<div class="cell">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span></span>
<span>    loss <span class="op">=</span> <span class="st">'mean_squared_error'</span>,</span>
<span>    optimizer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/optimizer_sgd.html">optimizer_sgd</a></span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Die Anpassung des Modells erfolgt wie bei einfacher Regression mit <code><a href="https://generics.r-lib.org/reference/fit.html">keras::fit()</a></code>.</p>
<div class="cell">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Training des Modells</span></span>
<span><span class="va">history_mnn</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="va">X</span>, </span>
<span>    y <span class="op">=</span> <span class="va">Y</span>, </span>
<span>    validation_split <span class="op">=</span> <span class="fl">.2</span>,</span>
<span>    epochs <span class="op">=</span> <span class="fl">25</span></span>
<span>  <span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/25
7/7 - 0s - loss: 38.3883 - val_loss: 33.1020 - 303ms/epoch - 43ms/step
Epoch 2/25
7/7 - 0s - loss: 29.7203 - val_loss: 25.1582 - 38ms/epoch - 5ms/step
Epoch 3/25
7/7 - 0s - loss: 22.4852 - val_loss: 19.1626 - 34ms/epoch - 5ms/step
Epoch 4/25
7/7 - 0s - loss: 17.0425 - val_loss: 14.7791 - 34ms/epoch - 5ms/step
Epoch 5/25
7/7 - 0s - loss: 13.0347 - val_loss: 11.6410 - 34ms/epoch - 5ms/step
Epoch 6/25
7/7 - 0s - loss: 10.1893 - val_loss: 9.1315 - 35ms/epoch - 5ms/step
Epoch 7/25
7/7 - 0s - loss: 7.9020 - val_loss: 7.3533 - 36ms/epoch - 5ms/step
Epoch 8/25
7/7 - 0s - loss: 6.2794 - val_loss: 5.9200 - 35ms/epoch - 5ms/step
Epoch 9/25
7/7 - 0s - loss: 4.9748 - val_loss: 4.8933 - 35ms/epoch - 5ms/step
Epoch 10/25
7/7 - 0s - loss: 4.0321 - val_loss: 4.0392 - 35ms/epoch - 5ms/step
Epoch 11/25
7/7 - 0s - loss: 3.2686 - val_loss: 3.4651 - 35ms/epoch - 5ms/step
Epoch 12/25
7/7 - 0s - loss: 2.7321 - val_loss: 3.0184 - 39ms/epoch - 6ms/step
Epoch 13/25
7/7 - 0s - loss: 2.3315 - val_loss: 2.6956 - 37ms/epoch - 5ms/step
Epoch 14/25
7/7 - 0s - loss: 2.0330 - val_loss: 2.4417 - 39ms/epoch - 6ms/step
Epoch 15/25
7/7 - 0s - loss: 1.7999 - val_loss: 2.2487 - 38ms/epoch - 5ms/step
Epoch 16/25
7/7 - 0s - loss: 1.6210 - val_loss: 2.0981 - 34ms/epoch - 5ms/step
Epoch 17/25
7/7 - 0s - loss: 1.4825 - val_loss: 2.0079 - 47ms/epoch - 7ms/step
Epoch 18/25
7/7 - 0s - loss: 1.3839 - val_loss: 1.9213 - 34ms/epoch - 5ms/step
Epoch 19/25
7/7 - 0s - loss: 1.2951 - val_loss: 1.8556 - 34ms/epoch - 5ms/step
Epoch 20/25
7/7 - 0s - loss: 1.2304 - val_loss: 1.8021 - 34ms/epoch - 5ms/step
Epoch 21/25
7/7 - 0s - loss: 1.1691 - val_loss: 1.7750 - 35ms/epoch - 5ms/step
Epoch 22/25
7/7 - 0s - loss: 1.1370 - val_loss: 1.7624 - 34ms/epoch - 5ms/step
Epoch 23/25
7/7 - 0s - loss: 1.1062 - val_loss: 1.7409 - 34ms/epoch - 5ms/step
Epoch 24/25
7/7 - 0s - loss: 1.0835 - val_loss: 1.7315 - 34ms/epoch - 5ms/step
Epoch 25/25
7/7 - 0s - loss: 1.0692 - val_loss: 1.7293 - 34ms/epoch - 5ms/step</code></pre>
</div>
</div>
<div class="cell page-columns page-full">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Entwicklung des Loss über Epochen plotten</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">history_mnn</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="st">"Epoche"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Wert der Verlustfunktion"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://wilkelab.org/cowplot/reference/theme_cowplot.html">theme_cowplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"top"</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display page-columns page-full">
<div id="fig-mnn-loss" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-mnn-loss-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Machine-Learning_files/figure-html/fig-mnn-loss-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-mnn-loss-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;14.6: NN für mult. Regression: Entwicklung des Loss für 25 Epochen
</figcaption></figure>
</div>
</div>
</div>
<p>Wie bei der einfachen Regression zeigt ein Vergleich der angepassten Gewichte mit den KQ-Schätzungen eines entsprechenden linearen Regressionsmodells ähnliche Ergebnisse beider Ansätze.</p>
<div class="cell">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Gewichtung und Bias des trainierten NN auslesen</span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu">keras</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/get_weights.html">get_weights</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu">flatten_dbl</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://rlang.r-lib.org/reference/set_names.html">set_names</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"w_1"</span>, <span class="st">"w_2"</span>, <span class="st">"w_3"</span>, <span class="st">"bias"</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      w_1       w_2       w_3      bias 
 2.956442  1.916142 -1.451843  4.807587 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Multiples lineares Modell mit KQ schätzen</span></span>
<span><span class="va">lm_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">Y</span> <span class="op">~</span> <span class="va">X</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lm_model</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Y ~ X)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.3129 -0.7286  0.0900  0.7439  3.4086 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  5.01583    0.06843   73.30   &lt;2e-16 ***
X1           2.97449    0.07028   42.32   &lt;2e-16 ***
X2           1.94345    0.07061   27.52   &lt;2e-16 ***
X3          -1.47278    0.06914  -21.30   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.079 on 246 degrees of freedom
Multiple R-squared:  0.9271,    Adjusted R-squared:  0.9262 
F-statistic:  1042 on 3 and 246 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
</section><section id="nicht-lineare-zusammenhänge" class="level2 page-columns page-full" data-number="14.5"><h2 data-number="14.5" class="anchored" data-anchor-id="nicht-lineare-zusammenhänge">
<span class="header-section-number">14.5</span> Nicht-Lineare Zusammenhänge</h2>
<p>In diesem Abschnitt verwenden trainieren wir ein NN, um eine logistische Regression durchzuführen. Dieser Ansatz wird häufig verwendet, um eine binäre Outcome-Variablen <span class="math inline">\(Y\)</span> zu modellieren, also Variablen, die zwei mögliche Ausgänge haben (oft als 0 oder 1 dargestellt), siehe <a href="Reg.html#sec-logreg" class="quarto-xref"><span>Kapitel 3.2.3</span></a> für Details. Anstatt die Eingaben lediglich linear zu kombinieren, verwenden wir eine Sigmoid-Aktivierungsfunktion<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>, <span class="math display">\[\begin{align*}
  \sigma(z) = \frac{1}{1 + \exp(-z)},
\end{align*}\]</span> welche die Ausgaben auf einen Wertebereich zwischen 0 und 1 abbildet. Dadurch kann das NN Wahrscheinlichkeiten <span class="math inline">\(P(Y=1\vert \boldsymbol{X} = \boldsymbol{x})\)</span> vorhersagen, die anschließend für die <em>Klassifikation</em> von Beobachtungen verwendet werden können.</p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;Die Sigmoid-Aktivierungsfunktion entspricht der logistischen Funktion <span class="math inline">\(\Lambda(z)\)</span> aus <a href="Reg.html#sec-logreg" class="quarto-xref"><span>Kapitel 3.2.3</span></a>.</p></div></div><p>Für die Illustration der Schätzung mit <code>keras</code> verwenden wir den DGP aus <a href="Reg.html#sec-probitreg" class="quarto-xref"><span>Kapitel 3.2.2</span></a>.</p>
<div class="cell">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Erstellen von Trainingsdaten</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">500</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mean <span class="op">=</span> <span class="fl">5</span>, sd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="co"># Regressor</span></span>
<span><span class="va">P</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="op">-</span><span class="fl">4</span> <span class="op">+</span> <span class="fl">0.7</span> <span class="op">*</span> <span class="va">X</span><span class="op">)</span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span> <span class="op">&lt;</span> <span class="va">P</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a href="#fig-nn-log-reg" class="quarto-xref">Abbildung&nbsp;<span>14.7</span></a> zeigt ein einfaches NN für eine binäre Outcome-Variable.</p>
<div class="cell page-columns page-full" data-fig-width="6" data-fig-height="4" data-layout-align="default">
<div class="cell-output-display page-columns page-full">
<div id="fig-nn-log-reg" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-nn-log-reg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="576" height="384" viewbox="0.00 0.00 552.85 192.84" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none"><g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 188.84)"><title>NNlogit</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-188.84 548.85,-188.84 548.85,4 -4,4"></polygon><!-- X --><g id="node1" class="node"><title>X</title>
<ellipse fill="none" stroke="black" cx="22.84" cy="-22.84" rx="22.68" ry="22.68"></ellipse><text text-anchor="middle" x="22.84" y="-18.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">X1</text></g><!-- SUM --><g id="node2" class="node"><title>SUM</title>
<ellipse fill="lightgrey" stroke="black" cx="238.84" cy="-22.84" rx="18.06" ry="18.06"></ellipse><text text-anchor="middle" x="238.84" y="-18.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">∑</text></g><!-- X&#45;&gt;SUM --><g id="edge1" class="edge"><title>X-&gt;SUM</title>
<path fill="none" stroke="black" d="M45.95,-22.84C85.79,-22.84 167.23,-22.84 210.44,-22.84"></path><polygon fill="black" stroke="black" points="210.56,-26.34 220.56,-22.84 210.56,-19.34 210.56,-26.34"></polygon><text text-anchor="middle" x="119.64" y="-27.04" font-family="Helvetica,Arial,sans-serif" font-size="14.00">w1</text></g><!-- sigmoid --><g id="node3" class="node"><title>sigmoid</title>
<ellipse fill="lightblue" stroke="black" cx="382.84" cy="-22.84" rx="18" ry="18"></ellipse><text text-anchor="middle" x="382.84" y="-18.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">σ</text></g><!-- SUM&#45;&gt;sigmoid --><g id="edge3" class="edge"><title>SUM-&gt;sigmoid</title>
<path fill="none" stroke="black" d="M257.37,-22.84C282.02,-22.84 325.83,-22.84 354.61,-22.84"></path><polygon fill="black" stroke="black" points="354.83,-26.34 364.83,-22.84 354.83,-19.34 354.83,-26.34"></polygon></g><!-- Y --><g id="node4" class="node"><title>Y</title>
<ellipse fill="lightgreen" stroke="black" cx="526.84" cy="-22.84" rx="18.02" ry="18.02"></ellipse><text text-anchor="middle" x="526.84" y="-18.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">Y</text></g><!-- sigmoid&#45;&gt;Y --><g id="edge4" class="edge"><title>sigmoid-&gt;Y</title>
<path fill="none" stroke="black" d="M401.08,-22.84C425.64,-22.84 469.59,-22.84 498.48,-22.84"></path><polygon fill="black" stroke="black" points="498.75,-26.34 508.75,-22.84 498.75,-19.34 498.75,-26.34"></polygon></g><!-- B --><g id="node5" class="node"><title>B</title>
<ellipse fill="none" stroke="black" cx="238.84" cy="-166.84" rx="18" ry="18"></ellipse><text text-anchor="middle" x="238.84" y="-162.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">1</text></g><!-- B&#45;&gt;SUM --><g id="edge2" class="edge"><title>B-&gt;SUM</title>
<path fill="none" stroke="black" d="M238.84,-148.6C238.84,-124.17 238.84,-80.57 238.84,-51.67"></path><polygon fill="black" stroke="black" points="242.34,-51.38 238.84,-41.38 235.34,-51.38 242.34,-51.38"></polygon><text text-anchor="middle" x="235.34" y="-104.33" font-family="Helvetica,Arial,sans-serif" font-size="14.00">b</text></g></g></svg>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-nn-log-reg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;14.7: Neuronales Netzwerk mit Sigmoid-Aktivierungsfunktion
</figcaption></figure>
</div>
</div>
</div>
<p>Nach der Definition des NN wird das Modell mit dem Binary-Cross-Entropy-Loss (BCEL) und dem Adam-Optimierer kompiliert. BCEL ist für binäre Klassifikationsprobleme geeignet: Diese Loss-Funktion misst die die Unterschiede zwischen den vorhergesagten Wahrscheinlichkeiten <span class="math inline">\(\widehat{p}_i\)</span> und den tatsächlichen binären Zielen <span class="math inline">\(y_i\)</span>, <span class="math display">\[\begin{align*}
  \textup{BCEL} = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \cdot \log(\widehat{p}_i) + (1 - y_i) \cdot \log(1 - \widehat{p}_i) \right].
\end{align*}\]</span> Als weitere zu berechnende Metrik wählen wir <span class="math inline">\(\textup{Accuracy}\)</span>, ein geläufiges Maß zur Bewertung der Leistung von Klassifikationsmodellen. <span class="math inline">\(\textup{Accuracy}\)</span> gibt an, wie oft das Modell korrekte Vorhersagen getroffen hat, ausgedrückt als Verhältnis der Anzahl der korrekten Vorhersagen zur Gesamtzahl der Vorhersagen, <span class="math display">\[\begin{align*}
  \text{Accuracy} = \frac{\textup{TP} + \textup{TN} }{ \textup{TP} + \textup{TN} + \textup{FP} + \textup{FN} } = \frac{\textup{Anz. korrekte Vorhersagen}}{\textup{Anz. alle Vorhersagen}}.
\end{align*}\]</span> Hierbei sind <span class="math inline">\(\textup{TP}\)</span> und <span class="math inline">\(\textup{FP}\)</span> die Anazhl korrekter (<em>true positive</em>) und falscher (<em>false positiv</em>) Vorhersagen für Beobachtungen mit <span class="math inline">\(y_i = 1\)</span>. <span class="math inline">\(\textup{TN}\)</span> und <span class="math inline">\(\textup{FN}\)</span> sind analog für Beobachtungen mit tatsächlichen Werten <span class="math inline">\(y_i = 0\)</span> definiert.</p>
<p>Die Vorhersage von <span class="math inline">\(y_i\)</span> zur Berechnung von <span class="math inline">\(\textup{Accuracy}\)</span> erfolgt durch <code><a href="https://generics.r-lib.org/reference/fit.html">keras::fit()</a></code> standardmäßig nach der Regel <span class="math display">\[\begin{align*}
  \hat{y}_i =
  \begin{cases}
    1 &amp; \text{wenn } \hat{p}_i \geq 0.5, \\
    0 &amp; \text{wenn } \hat{p}_i &lt; 0.5.
  \end{cases}
\end{align*}\]</span></p>
<p>Wir definieren nachchfolgend das Modell-Objekt und passen das NN über 150 Epochen an.</p>
<div class="cell">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Erstellen und Kompilieren des Modells</span></span>
<span><span class="va">model_nn_logit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span></span>
<span>    units <span class="op">=</span> <span class="fl">1</span>, </span>
<span>    input_shape <span class="op">=</span> <span class="fl">1</span>, </span>
<span>    activation <span class="op">=</span> <span class="st">'sigmoid'</span> <span class="co"># &lt;= für Logit-Modell</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="va">model_nn_logit</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_2"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_2 (Dense)                    (None, 1)                       2           
================================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
________________________________________________________________________________</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Modell kompilieren</span></span>
<span><span class="va">model_nn_logit</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span></span>
<span>    loss <span class="op">=</span> <span class="st">'binary_crossentropy'</span>, <span class="co"># Für BCEL</span></span>
<span>    optimizer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/optimizer_adam.html">optimizer_adam</a></span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span>,</span>
<span>    metrics <span class="op">=</span> <span class="st">'accuracy'</span></span>
<span>  <span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Anpassen des Modells</span></span>
<span><span class="va">history_nn_logit</span> <span class="op">&lt;-</span> <span class="va">model_nn_logit</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="va">X</span>, </span>
<span>    y <span class="op">=</span> <span class="va">Y</span>, </span>
<span>    validation_split <span class="op">=</span> <span class="fl">.2</span>,</span>
<span>    epochs <span class="op">=</span> <span class="fl">150</span>,</span>
<span>    verbose <span class="op">=</span> <span class="cn">F</span></span>
<span>  <span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Die Zusammenfassung der Anpassung für die letzte Epoche in <code>history_nn_logit</code> zeigt ergibt eine Genauigkeit von über 80% auf dem Validierungsdatensatz.</p>
<div class="cell">
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">history_nn_logit</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Final epoch (plot to see history):
        loss: 0.3999
    accuracy: 0.8025
    val_loss: 0.3425
val_accuracy: 0.85 </code></pre>
</div>
</div>
<div class="cell page-columns page-full">
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Entwicklung des Loss über Epochen plotten</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">history_nn_logit</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="st">"Epoche"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">""</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://wilkelab.org/cowplot/reference/theme_cowplot.html">theme_cowplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"top"</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display page-columns page-full">
<div id="fig-mnn-logithist" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-mnn-logithist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Machine-Learning_files/figure-html/fig-mnn-logithist-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-mnn-logithist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;14.8: NN für Logit-Regression: Entwicklung der Metriken für 25 Epochen
</figcaption></figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Gewicht und Bias extrahieren</span></span>
<span><span class="va">model_nn_logit</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu">keras</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/get_weights.html">get_weights</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu">flatten_dbl</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://rlang.r-lib.org/reference/set_names.html">set_names</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"w_1"</span>, <span class="st">"bias"</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       w_1       bias 
 0.9700643 -5.3429317 </code></pre>
</div>
</div>
<p>Für einen Vergleich der Vorhersagegüter mit logistischer Regression schätzen wir zunächst ein entsprechendes GLM mit <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code>.</p>
<div class="cell">
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Logistisches Modell mit glm() anpassen</span></span>
<span><span class="va">glm_mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">Y</span> <span class="op">~</span> <span class="va">X</span>, </span>
<span>  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">glm_mod</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = Y ~ X, family = binomial(link = "logit"))

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -7.3289     0.6520  -11.24   &lt;2e-16 ***
X             1.3140     0.1191   11.04   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 673.01  on 499  degrees of freedom
Residual deviance: 375.96  on 498  degrees of freedom
AIC: 379.96

Number of Fisher Scoring iterations: 6</code></pre>
</div>
</div>
<p>Wir erzeugen nun einen Testdatensatz mit 250 Beobachtungen gemäß des oben gewählten DGP.</p>
<div class="cell">
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">4321</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">250</span></span>
<span><span class="va">data_new</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span></span>
<span>  X <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mean <span class="op">=</span> <span class="fl">5</span>, sd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>,</span>
<span>  P <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="op">-</span><span class="fl">4</span> <span class="op">+</span> <span class="fl">0.7</span> <span class="op">*</span> <span class="va">X</span><span class="op">)</span>,</span>
<span>  Y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span> <span class="op">&lt;</span> <span class="va">P</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Für die neuen Datenpunkte <code>data_new</code> erzeugen wir Vorhersagen von <span class="math inline">\(P(Y=1\vert X=x)\)</span> mit <code>model_nn_logit</code> und <code>glm_mod</code> und erweitern <code>data_new</code> um diese.</p>
<div class="cell">
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Vorhersagen für Trainingsdaten erstellen</span></span>
<span><span class="va">predictions_nn_logit</span> <span class="op">&lt;-</span> <span class="va">model_nn_logit</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">data_new</span><span class="op">$</span><span class="va">X</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>8/8 - 0s - 41ms/epoch - 5ms/step</code></pre>
</div>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">predictions_glm_logit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span></span>
<span>    <span class="va">glm_mod</span>, </span>
<span>    newdata <span class="op">=</span> <span class="va">data_new</span>, </span>
<span>    type <span class="op">=</span> <span class="st">"response"</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="co"># Zusammenfassen</span></span>
<span><span class="va">results</span> <span class="op">&lt;-</span> <span class="va">data_new</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span></span>
<span>    nn_logit <span class="op">=</span> <span class="va">predictions_nn_logit</span>,</span>
<span>    glm_logit <span class="op">=</span> <span class="va">predictions_glm_logit</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/slice.html">slice_head</a></span><span class="op">(</span><span class="va">results</span>, n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 10 × 5
       X      P     Y nn_logit glm_logit
   &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;
 1  4.15 0.136      1    0.211    0.132 
 2  4.55 0.208      0    0.284    0.206 
 3  6.44 0.693      1    0.711    0.755 
 4  6.68 0.751      1    0.758    0.810 
 5  4.74 0.248      0    0.323    0.250 
 6  8.22 0.960      1    0.933    0.970 
 7  4.41 0.180      0    0.256    0.177 
 8  5.39 0.411      0    0.472    0.439 
 9  7.48 0.892      0    0.872    0.924 
10  3.56 0.0660     0    0.132    0.0661</code></pre>
</div>
</div>
<p>Für eine erste Beurteilung anhand der Vorhersagen auf dem Testdatensatz plotten wir die vorhergesagten Wahrscheinlichkeiten als Funktion von <code>X</code> gemeinsam mit den tatsächlichen Ausprägungen der Outcome-Variable <code>Y</code>.</p>
<div class="cell">
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://wilkelab.org/cowplot/">cowplot</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot der tatsächlichen Werte gegen die vorhergesagten Wahrscheinlichkeiten</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">results</span>,</span>
<span>  mapping <span class="op">=</span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">X</span>, y <span class="op">=</span> <span class="va">Y</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span></span>
<span>    position <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/position_jitter.html">position_jitter</a></span><span class="op">(</span>height <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span>, </span>
<span>    alpha <span class="op">=</span> <span class="fl">0.5</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span></span>
<span>     mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">nn_logit</span><span class="op">)</span>,</span>
<span>    col <span class="op">=</span> <span class="st">"darkred"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span></span>
<span>    method <span class="op">=</span> <span class="st">"glm"</span>, </span>
<span>    method.args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span>, </span>
<span>    se <span class="op">=</span> <span class="cn">FALSE</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"Logistische Regression vs. NN"</span>,</span>
<span>       x <span class="op">=</span> <span class="st">"x"</span>,</span>
<span>       y <span class="op">=</span> <span class="st">"Schätzung v. P(Y=1|X=x)"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://wilkelab.org/cowplot/reference/theme_cowplot.html">theme_cowplot</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="Machine-Learning_files/figure-html/unnamed-chunk-31-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Die geschätzten Wahrscheinlichkeitsfunktionen zeigen eine gute Übereinstimmung. Um die Vorhersagegüte von <code>model_nn_logit</code> und <code>model_glm_logit</code> genauer zu untersuchen, erstellen wir Plots der jeweilgen <em>Receiver Operating Characteristic</em> (ROC). ROC zeigt den Zusammenhang zwischen der <em>True Positive Rate</em> (TPR), dem Anteil korrekter Vorhersagen für <span class="math inline">\(y_i=1\)</span> (auch <em>Sensitivität</em> gennant) und der <em>False Positive Rate</em> (FPR), dem Anteil falscher Vorhersagen für <span class="math inline">\(y_i=1\)</span> in Abhängigkeit des Schwellenwerts von <span class="math inline">\(\widehat{p}\)</span> für die Klassifikation des Outcomes einer Beobachtung <span class="math inline">\(y_i = 1\)</span>. Es gilt</p>
<p><span class="math display">\[\begin{align*}
  TPR =&amp;\, \frac{TP}{TP + FN},\\
  \\
  FPR =&amp;\, \frac{FP}{FP + TN}.
\end{align*}\]</span></p>
<p>Der Schwellenwert <span class="math inline">\(\widehat{p}\)</span> reguliert den Trade-Off zwischen <span class="math inline">\(\textup{FPR}\)</span> und <span class="math inline">\(\textup{TPR}\)</span>: Kleine <span class="math inline">\(\widehat{p}\)</span> führen tendenziell zu großer <span class="math inline">\(\textup{TPR}\)</span> (gut), aber auch zu großer <span class="math inline">\(\textup{FPR}\)</span> (schlecht). Für ein Modell, das zufällig klassifiziert, entspricht die ROC-Kurve der Winkelhalbierenden. Wünschenwert ist ein verlauf der ROC-Kurve möglichst oberhalb der Winkelhalbierenden.</p>
<p>Eine ROC-Kurve kann in R mit dem <code>plotROC</code> anhand der Vorhergesagten und tatsächlichen Werte der Outcome-Varibale berechnet und geplottet werden. Hierzu transformieren wir <code>results</code> in langes Format und verwenden <code><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot()</a></code> mit dem Layer <code><a href="https://rdrr.io/pkg/plotROC/man/geom_roc.html">geom_roc()</a></code>.</p>
<div class="cell page-columns page-full">
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://sachsmc.github.io/plotROC/">plotROC</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyr.tidyverse.org">tidyr</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">roc_data</span> <span class="op">&lt;-</span> <span class="va">results</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/pivot_longer.html">pivot_longer</a></span><span class="op">(</span></span>
<span>    cols <span class="op">=</span> <span class="va">glm_logit</span><span class="op">:</span><span class="va">nn_logit</span>,</span>
<span>    names_to <span class="op">=</span> <span class="st">"model"</span>, </span>
<span>    values_to <span class="op">=</span> <span class="st">"pp"</span></span>
<span>    <span class="op">)</span></span>
<span></span>
<span><span class="co"># ROC-Kurve plotten</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span></span>
<span>    data <span class="op">=</span> <span class="va">roc_data</span>, </span>
<span>    mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span></span>
<span>      m <span class="op">=</span> <span class="va">pp</span>, </span>
<span>      d <span class="op">=</span> <span class="va">Y</span>, </span>
<span>      colour <span class="op">=</span> <span class="va">model</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/plotROC/man/geom_roc.html">geom_roc</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/plotROC/man/style_roc.html">style_roc</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span> <span class="va">model</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"top"</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display page-columns page-full">
<div id="fig-nnlogit-roc" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-nnlogit-roc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Machine-Learning_files/figure-html/fig-nnlogit-roc-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-nnlogit-roc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;14.9: ROC-Kurve für logistische Modelle
</figcaption></figure>
</div>
</div>
</div>
<p><a href="#fig-nnlogit-roc" class="quarto-xref">Abbildung&nbsp;<span>14.9</span></a> zeigt sehr ähnliche ROC-Kurven für <code>model_nn_logit</code> und <code>model_glm_logit</code>.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> Für die Quantifizierung der Vorhersageleistung wird <em>Area under the Curve</em> (AUC), die Fläche unterhalb der ROC-Kurve, herangezogen. Mit <code><a href="https://rdrr.io/pkg/plotROC/man/calc_auc.html">plotROC::calc_auc()</a></code> kann AUC aus dem <code><a href="https://rdrr.io/pkg/plotROC/man/geom_roc.html">geom_roc()</a></code>-Layer berechnet werden. Für ein geschätztes Modell <span class="math inline">\(\widehat{M}\)</span> gilt <span class="math inline">\(0\leq\textup{AUC}(\widehat{M})\leq1\)</span>.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;Beide Plots enthalten Indikatoren des ROC für bestimmte Schwellenwerte <span class="math inline">\(\widehat{p}\)</span>.</p></div><div id="fn10"><p><sup>10</sup>&nbsp;Ein geschätzes, dass nicht besser als raten ist, gilt <span class="math inline">\(\textup{AUC}(\widehat{M})=.5\)</span>.</p></div></div><div class="cell">
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># AUC berechnen</span></span>
<span><span class="va">roc_data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarise</a></span><span class="op">(</span></span>
<span>    AUC <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/plotROC/man/calc_auc.html">calc_auc</a></span><span class="op">(</span></span>
<span>      <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>m <span class="op">=</span> <span class="va">pp</span>, d <span class="op">=</span> <span class="va">Y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/pkg/plotROC/man/geom_roc.html">geom_roc</a></span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="op">)</span><span class="op">$</span><span class="va">AUC</span></span>
<span>  <span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 2
  model       AUC
  &lt;chr&gt;     &lt;dbl&gt;
1 glm_logit 0.890
2 nn_logit  0.890</code></pre>
</div>
</div>
<p>Der Vergleich der AUC-Statistiken beider Modelle für den Testdatensatz zeigt, dass das NN ähnlich gut klassifizert, wie das GLM mit logistischer Link-Funktion.</p>
</section><section id="beispiel-boston-housing" class="level2" data-number="14.6"><h2 data-number="14.6" class="anchored" data-anchor-id="beispiel-boston-housing">
<span class="header-section-number">14.6</span> Beispiel: Boston Housing</h2>
<div class="cell">
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidymodels.tidymodels.org">tidymodels</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Boston-Datensatz in ein tibble umwandeln (optional)</span></span>
<span><span class="va">boston_tbl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="fu">MASS</span><span class="fu">::</span><span class="va"><a href="https://rdrr.io/pkg/MASS/man/Boston.html">Boston</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Daten in Trainings- und Testdaten aufteilen (80% Training, 20% Test) mit tidymodels</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">split</span> <span class="op">&lt;-</span> <span class="fu">initial_split</span><span class="op">(</span><span class="va">boston_tbl</span>, prop <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span></span>
<span><span class="va">train_data</span> <span class="op">&lt;-</span> <span class="fu">training</span><span class="op">(</span><span class="va">split</span><span class="op">)</span></span>
<span><span class="va">test_data</span> <span class="op">&lt;-</span> <span class="fu">testing</span><span class="op">(</span><span class="va">split</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Zielvariable und Prädiktoren aufteilen</span></span>
<span><span class="va">train_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">train_data</span>, <span class="op">-</span><span class="va">medv</span><span class="op">)</span></span>
<span><span class="va">train_y</span> <span class="op">&lt;-</span> <span class="va">train_data</span><span class="op">$</span><span class="va">medv</span></span>
<span><span class="va">test_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">test_data</span>, <span class="op">-</span><span class="va">medv</span><span class="op">)</span></span>
<span><span class="va">test_y</span> <span class="op">&lt;-</span> <span class="va">test_data</span><span class="op">$</span><span class="va">medv</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Daten normalisieren (zentrieren und skalieren) mit recipe</span></span>
<span><span class="va">recipe_obj</span> <span class="op">&lt;-</span> <span class="fu">recipe</span><span class="op">(</span><span class="va">medv</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">train_data</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">step_normalize</span><span class="op">(</span><span class="fu">all_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">prepped_data</span> <span class="op">&lt;-</span> <span class="fu">prep</span><span class="op">(</span><span class="va">recipe_obj</span>, training <span class="op">=</span> <span class="va">train_data</span><span class="op">)</span></span>
<span></span>
<span><span class="va">train_x</span> <span class="op">&lt;-</span> <span class="fu">bake</span><span class="op">(</span><span class="va">prepped_data</span>, new_data <span class="op">=</span> <span class="va">train_data</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">medv</span><span class="op">)</span></span>
<span><span class="va">test_x</span> <span class="op">&lt;-</span> <span class="fu">bake</span><span class="op">(</span><span class="va">prepped_data</span>, new_data <span class="op">=</span> <span class="va">test_data</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">medv</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># OLS-Modell (lineare Regression) mit tidymodels erstellen</span></span>
<span><span class="va">ols_spec</span> <span class="op">&lt;-</span> <span class="fu">linear_reg</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"lm"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">ols_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">ols_spec</span>, <span class="va">medv</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">train_data</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># OLS-Vorhersagen auf den Testdaten</span></span>
<span><span class="va">ols_predictions</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">ols_fit</span>, <span class="va">test_data</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind_cols.html">bind_cols</a></span><span class="op">(</span><span class="va">test_data</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/rename.html">rename</a></span><span class="op">(</span>ols_pred <span class="op">=</span> <span class="va">.pred</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Neuronales Netz-Modell mit Keras erstellen</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">64</span>, activation <span class="op">=</span> <span class="st">"relu"</span>, input_shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">train_x</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">64</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Modell kompilieren</span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span></span>
<span>  optimizer <span class="op">=</span> <span class="st">"rmsprop"</span>,</span>
<span>  loss <span class="op">=</span> <span class="st">"mse"</span>,</span>
<span>  metrics <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"mae"</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Modell trainieren</span></span>
<span><span class="va">history</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">train_x</span><span class="op">)</span>,</span>
<span>  <span class="va">train_y</span>,</span>
<span>  epochs <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="fl">32</span>,</span>
<span>  validation_split <span class="op">=</span> <span class="fl">0.2</span>,</span>
<span>  verbose <span class="op">=</span> <span class="fl">0</span></span>
<span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Vorhersagen mit dem neuronalen Netz</span></span>
<span><span class="va">nn_predictions</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">test_x</span><span class="op">)</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>4/4 - 0s - 64ms/epoch - 16ms/step</code></pre>
</div>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Neuronale Netz-Vorhersagen mit Testdaten kombinieren</span></span>
<span><span class="va">nn_predictions</span> <span class="op">&lt;-</span> <span class="va">test_data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>nn_pred <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">as.vector</a></span><span class="op">(</span><span class="va">nn_predictions</span><span class="op">)</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Mittlerer quadratischer Fehler (MSE) berechnen</span></span>
<span><span class="va">ols_mse</span> <span class="op">&lt;-</span> <span class="va">ols_predictions</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarise</a></span><span class="op">(</span>mse <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">medv</span> <span class="op">-</span> <span class="va">ols_pred</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">mse</span><span class="op">)</span></span>
<span></span>
<span><span class="va">nn_mse</span> <span class="op">&lt;-</span> <span class="va">nn_predictions</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarise</a></span><span class="op">(</span>mse <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">medv</span> <span class="op">-</span> <span class="va">nn_pred</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">mse</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"MSE (OLS):"</span>, <span class="va">ols_mse</span>, <span class="st">"\n"</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE (OLS): 23.67863 </code></pre>
</div>
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"MSE (Neuronales Netz):"</span>, <span class="va">nn_mse</span>, <span class="st">"\n"</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE (Neuronales Netz): 21.36276 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Visualisierung der Ergebnisse mit ggplot2</span></span>
<span><span class="co"># Plot für OLS-Vorhersagen</span></span>
<span><span class="va">gg_ols</span> <span class="op">&lt;-</span> <span class="va">ols_predictions</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">medv</span>, y <span class="op">=</span> <span class="va">ols_pred</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_abline</a></span><span class="op">(</span>intercept <span class="op">=</span> <span class="fl">0</span>, slope <span class="op">=</span> <span class="fl">1</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"OLS-Vorhersagen vs. Wahre Werte"</span>,</span>
<span>    x <span class="op">=</span> <span class="st">"Wahre Werte (medv)"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"OLS-Vorhersagen"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot für neuronale Netz-Vorhersagen</span></span>
<span><span class="va">gg_nn</span> <span class="op">&lt;-</span> <span class="va">nn_predictions</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">medv</span>, y <span class="op">=</span> <span class="va">nn_pred</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"green"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_abline</a></span><span class="op">(</span>intercept <span class="op">=</span> <span class="fl">0</span>, slope <span class="op">=</span> <span class="fl">1</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"Neuronales Netz Vorhersagen vs. Wahre Werte"</span>,</span>
<span>    x <span class="op">=</span> <span class="st">"Wahre Werte (medv)"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"NN-Vorhersagen"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Ausgabe der Plots</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">gg_ols</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="Machine-Learning_files/figure-html/unnamed-chunk-41-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">gg_nn</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="Machine-Learning_files/figure-html/unnamed-chunk-41-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section><section id="case-study-vorhersage-von-immobilienpreisen" class="level2" data-number="14.7"><h2 data-number="14.7" class="anchored" data-anchor-id="case-study-vorhersage-von-immobilienpreisen">
<span class="header-section-number">14.7</span> Case Study: Vorhersage von Immobilienpreisen</h2>
<div class="cell">
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/topepo/AmesHousing">AmesHousing</a></span><span class="op">)</span></span>
<span><span class="va">housing</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/AmesHousing/man/make_ames.html">make_ames</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load the necessary libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-spatial.github.io/sf/">sf</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/walkerke/tigris">tigris</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Retrieve basemap for Ames, Iowa using the tigris package</span></span>
<span><span class="va">places_map</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/tigris/man/places.html">places</a></span><span class="op">(</span></span>
<span>  state <span class="op">=</span> <span class="st">'IA'</span>, </span>
<span>  cb <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>  progress <span class="op">=</span> <span class="cn">F</span></span>
<span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://r-spatial.github.io/sf/reference/st_as_sf.html">st_as_sf</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Filter for Ames city</span></span>
<span><span class="va">ames_map</span> <span class="op">&lt;-</span> <span class="va">places_map</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">NAME</span> <span class="op">==</span> <span class="st">"Ames"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">houses</span> <span class="op">&lt;-</span> <span class="va">housing</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">Latitude</span>, <span class="va">Longitude</span>, <span class="va">Sale_Price</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span></span>
<span>      Sale_Price <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cut.html">cut</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">Sale_Price</span>, base <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>, breaks <span class="op">=</span> <span class="fl">5</span>, labels <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>    <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://r-spatial.github.io/sf/reference/st_as_sf.html">st_as_sf</a></span><span class="op">(</span>coords <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Longitude"</span>, <span class="st">"Latitude"</span><span class="op">)</span>, </span>
<span>             crs <span class="op">=</span> <span class="fl">4326</span>, agr <span class="op">=</span> <span class="st">"constant"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">rainbow_colors</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/palettes.html">rainbow</a></span><span class="op">(</span><span class="fl">5</span>, rev <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Plot the map with just the outline of Ames</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggsf.html">geom_sf</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">ames_map</span>, color <span class="op">=</span> <span class="st">"black"</span>, fill <span class="op">=</span> <span class="fu"><a href="https://scales.r-lib.org/reference/alpha.html">alpha</a></span><span class="op">(</span><span class="st">"black"</span>, alpha <span class="op">=</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggsf.html">geom_sf</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">houses</span>, mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">Sale_Price</span><span class="op">)</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://wilkelab.org/cowplot/reference/theme_map.html">theme_map</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_color_manual</a></span><span class="op">(</span></span>
<span>    name <span class="op">=</span> <span class="st">"log(Verkaufspreis)"</span>, </span>
<span>    values <span class="op">=</span> <span class="va">rainbow_colors</span>, </span>
<span>    labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">houses</span><span class="op">$</span><span class="va">Sale_Price</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"bottom"</span>, legend.direction <span class="op">=</span> <span class="st">"horizontal"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"Verkaufte Häuser in Ames, Iowa"</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="Machine-Learning_files/figure-html/unnamed-chunk-44-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">housing</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Year_Built</span>, y <span class="op">=</span> <span class="va">Sale_Price</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">.5</span>, fill <span class="op">=</span> <span class="st">"steelblue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://wilkelab.org/cowplot/reference/theme_cowplot.html">theme_cowplot</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="Machine-Learning_files/figure-html/unnamed-chunk-45-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Split the data into training and testing sets</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidymodels.tidymodels.org">tidymodels</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">split</span> <span class="op">&lt;-</span> <span class="fu">initial_split</span><span class="op">(</span><span class="va">housing</span>, prop <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span></span>
<span></span>
<span><span class="va">housing_train</span> <span class="op">&lt;-</span> <span class="fu">training</span><span class="op">(</span><span class="va">split</span><span class="op">)</span></span>
<span><span class="va">housing_test</span> <span class="op">&lt;-</span> <span class="fu">testing</span><span class="op">(</span><span class="va">split</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Separate the predictors and the outcome</span></span>
<span><span class="va">housing_train_x</span> <span class="op">&lt;-</span> <span class="va">housing_train</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">Sale_Price</span><span class="op">)</span></span>
<span><span class="va">housing_train_y</span> <span class="op">&lt;-</span> <span class="va">housing_train</span><span class="op">$</span><span class="va">Sale_Price</span></span>
<span></span>
<span><span class="va">housing_test_x</span> <span class="op">&lt;-</span> <span class="va">housing_test</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">Sale_Price</span><span class="op">)</span></span>
<span><span class="va">housing_test_y</span> <span class="op">&lt;-</span> <span class="va">housing_test</span><span class="op">$</span><span class="va">Sale_Price</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">blueprint</span> <span class="op">&lt;-</span> <span class="fu">recipe</span><span class="op">(</span><span class="va">Sale_Price</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">housing_train</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">step_nzv</span><span class="op">(</span><span class="fu">all_nominal</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">step_other</span><span class="op">(</span><span class="fu">all_nominal</span><span class="op">(</span><span class="op">)</span>, threshold <span class="op">=</span> <span class="fl">.01</span>, other <span class="op">=</span> <span class="st">"other"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">step_integer</span><span class="op">(</span><span class="fu"><a href="https://tidyselect.r-lib.org/reference/starts_with.html">matches</a></span><span class="op">(</span><span class="st">"(Qual|Cond|QC|Qu)$"</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">step_YeoJohnson</span><span class="op">(</span><span class="fu">all_numeric</span><span class="op">(</span><span class="op">)</span>, <span class="op">-</span><span class="fu">all_outcomes</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">step_center</span><span class="op">(</span><span class="fu">all_numeric</span><span class="op">(</span><span class="op">)</span>, <span class="op">-</span><span class="fu">all_outcomes</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">step_scale</span><span class="op">(</span><span class="fu">all_numeric</span><span class="op">(</span><span class="op">)</span>, <span class="op">-</span><span class="fu">all_outcomes</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">step_dummy</span><span class="op">(</span><span class="fu">all_nominal</span><span class="op">(</span><span class="op">)</span>, <span class="op">-</span><span class="fu">all_outcomes</span><span class="op">(</span><span class="op">)</span>, one_hot <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">prepare</span> <span class="op">&lt;-</span> <span class="fu">prep</span><span class="op">(</span><span class="va">blueprint</span>, training <span class="op">=</span> <span class="va">housing_train</span><span class="op">)</span></span>
<span><span class="va">prepare</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">baked_train</span> <span class="op">&lt;-</span> <span class="fu">bake</span><span class="op">(</span><span class="va">prepare</span>, new_data <span class="op">=</span> <span class="va">housing_train</span><span class="op">)</span></span>
<span><span class="va">baked_test</span> <span class="op">&lt;-</span> <span class="fu">bake</span><span class="op">(</span><span class="va">prepare</span>, new_data <span class="op">=</span> <span class="va">housing_test</span><span class="op">)</span></span>
<span></span>
<span><span class="va">baked_train</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2,344 × 190
   Lot_Frontage  Lot_Area Overall_Qual Overall_Cond Year_Built Year_Remod_Add
          &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;
 1       1.15    0.350         -0.0340       -0.487     0.843           0.654
 2       0.277  -0.0336        -0.800        -0.487    -0.155          -0.839
 3      -0.129  -0.0213        -0.800        -1.76     -1.75           -1.66 
 4      -0.909  -3.19          -0.0340        0.479     0.277           0.365
 5       0.407  -0.223         -1.68          1.26     -0.0554         -0.694
 6      -1.88    0.0595         1.28         -0.487     1.01            0.847
 7       0.407   0.000506       0.655        -0.487     0.943           0.750
 8       0.144  -0.377         -0.0340       -0.487     0.910           0.895
 9      -0.0461 -1.52          -0.0340       -0.487     0.111          -0.453
10       1.98    0.501          1.28         -0.487     0.876           0.654
# ℹ 2,334 more rows
# ℹ 184 more variables: Mas_Vnr_Area &lt;dbl&gt;, Exter_Qual &lt;dbl&gt;, Exter_Cond &lt;dbl&gt;,
#   Bsmt_Qual &lt;dbl&gt;, BsmtFin_SF_1 &lt;dbl&gt;, BsmtFin_SF_2 &lt;dbl&gt;, Bsmt_Unf_SF &lt;dbl&gt;,
#   Total_Bsmt_SF &lt;dbl&gt;, Heating_QC &lt;dbl&gt;, First_Flr_SF &lt;dbl&gt;,
#   Second_Flr_SF &lt;dbl&gt;, Low_Qual_Fin_SF &lt;dbl&gt;, Gr_Liv_Area &lt;dbl&gt;,
#   Bsmt_Full_Bath &lt;dbl&gt;, Bsmt_Half_Bath &lt;dbl&gt;, Full_Bath &lt;dbl&gt;,
#   Half_Bath &lt;dbl&gt;, Bedroom_AbvGr &lt;dbl&gt;, Kitchen_AbvGr &lt;dbl&gt;, …</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://glmnet.stanford.edu">glmnet</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Prepare the data for glmnet (which requires matrices)</span></span>
<span><span class="va">x_train_glmnet</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">baked_train</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">Sale_Price</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">y_train_glmnet</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log10</a></span><span class="op">(</span><span class="va">baked_train</span><span class="op">$</span><span class="va">Sale_Price</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x_test_glmnet</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">baked_test</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">Sale_Price</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit a Ridge Regression model</span></span>
<span><span class="va">ridge_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/glmnet.html">glmnet</a></span><span class="op">(</span><span class="va">x_train_glmnet</span>, <span class="va">y_train_glmnet</span>, alpha <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Use cross-validation to find the optimal lambda</span></span>
<span><span class="va">cv_ridge</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">x_train_glmnet</span>, <span class="va">y_train_glmnet</span>, alpha <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">best_lambda</span> <span class="op">&lt;-</span> <span class="va">cv_ridge</span><span class="op">$</span><span class="va">lambda.min</span></span>
<span></span>
<span><span class="co"># Predict on the test set using the best lambda</span></span>
<span><span class="va">ridge_preds_log</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">cv_ridge</span>, s <span class="op">=</span> <span class="va">best_lambda</span>, newx <span class="op">=</span> <span class="va">x_test_glmnet</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Convert predictions back from log scale</span></span>
<span><span class="va">ridge_preds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fl">10</span><span class="op">^</span><span class="va">ridge_preds_log</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Evaluate the performance</span></span>
<span><span class="fu">mae_vec</span><span class="op">(</span></span>
<span>  truth <span class="op">=</span> <span class="va">housing_test_y</span>, </span>
<span>  estimate <span class="op">=</span> <span class="va">ridge_preds</span></span>
<span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14695.86</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">x_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">baked_train</span>, <span class="op">-</span><span class="va">Sale_Price</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">y_train</span> <span class="op">&lt;-</span> <span class="va">baked_train</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">Sale_Price</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">baked_test</span>, <span class="op">-</span><span class="va">Sale_Price</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">y_test</span> <span class="op">&lt;-</span> <span class="va">baked_test</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">Sale_Price</span><span class="op">)</span></span>
<span></span>
<span><span class="va">network</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">512</span>, activation <span class="op">=</span> <span class="st">"relu"</span>, input_shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">x_train</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">512</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">512</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">512</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">512</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">network</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span></span>
<span>    optimizer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/optimizer_rmsprop.html">optimizer_rmsprop</a></span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span>,</span>
<span>    loss <span class="op">=</span> <span class="st">"msle"</span>,</span>
<span>    metrics <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"mae"</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">history</span> <span class="op">&lt;-</span> <span class="va">network</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span></span>
<span>  <span class="va">x_train</span>,</span>
<span>  <span class="va">y_train</span>,</span>
<span>  epochs <span class="op">=</span> <span class="fl">30</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="fl">32</span>,</span>
<span>  validation_split <span class="op">=</span> <span class="fl">0.2</span>,</span>
<span>  callbacks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/pkg/keras/man/callback_early_stopping.html">callback_early_stopping</a></span><span class="op">(</span>patience <span class="op">=</span> <span class="fl">10</span>, restore_best_weights <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>        <span class="fu"><a href="https://rdrr.io/pkg/keras/man/callback_reduce_lr_on_plateau.html">callback_reduce_lr_on_plateau</a></span><span class="op">(</span>factor <span class="op">=</span> <span class="fl">0.2</span>, patience <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/30
59/59 - 2s - loss: 2.6405 - mae: 68385.3828 - val_loss: 0.3512 - val_mae: 151325.8906 - lr: 0.0100 - 2s/epoch - 28ms/step
Epoch 2/30
59/59 - 1s - loss: 0.3256 - mae: 101509.1016 - val_loss: 0.2404 - val_mae: 66785.9141 - lr: 0.0100 - 526ms/epoch - 9ms/step
Epoch 3/30
59/59 - 0s - loss: 0.2262 - mae: 83049.4375 - val_loss: 0.0513 - val_mae: 37775.5195 - lr: 0.0100 - 487ms/epoch - 8ms/step
Epoch 4/30
59/59 - 0s - loss: 0.1607 - mae: 66285.2812 - val_loss: 0.0836 - val_mae: 40633.5820 - lr: 0.0100 - 476ms/epoch - 8ms/step
Epoch 5/30
59/59 - 0s - loss: 0.1273 - mae: 58683.1133 - val_loss: 0.1126 - val_mae: 62489.0508 - lr: 0.0100 - 472ms/epoch - 8ms/step
Epoch 6/30
59/59 - 0s - loss: 0.0995 - mae: 47354.8594 - val_loss: 0.1179 - val_mae: 52137.7539 - lr: 0.0100 - 471ms/epoch - 8ms/step
Epoch 7/30
59/59 - 0s - loss: 0.0866 - mae: 46834.8516 - val_loss: 0.1663 - val_mae: 60094.2773 - lr: 0.0100 - 471ms/epoch - 8ms/step
Epoch 8/30
59/59 - 0s - loss: 0.0199 - mae: 16935.8984 - val_loss: 0.0259 - val_mae: 19971.5391 - lr: 0.0020 - 480ms/epoch - 8ms/step
Epoch 9/30
59/59 - 1s - loss: 0.0162 - mae: 16141.2100 - val_loss: 0.0211 - val_mae: 17745.1406 - lr: 0.0020 - 540ms/epoch - 9ms/step
Epoch 10/30
59/59 - 0s - loss: 0.0135 - mae: 14763.9883 - val_loss: 0.0206 - val_mae: 17303.9277 - lr: 0.0020 - 490ms/epoch - 8ms/step
Epoch 11/30
59/59 - 1s - loss: 0.0134 - mae: 14804.5459 - val_loss: 0.0213 - val_mae: 18030.2734 - lr: 0.0020 - 504ms/epoch - 9ms/step
Epoch 12/30
59/59 - 0s - loss: 0.0123 - mae: 14398.2773 - val_loss: 0.0213 - val_mae: 17814.8984 - lr: 0.0020 - 479ms/epoch - 8ms/step
Epoch 13/30
59/59 - 0s - loss: 0.0119 - mae: 13653.6865 - val_loss: 0.0187 - val_mae: 15159.7764 - lr: 0.0020 - 486ms/epoch - 8ms/step
Epoch 14/30
59/59 - 0s - loss: 0.0116 - mae: 13893.7451 - val_loss: 0.0205 - val_mae: 17413.0605 - lr: 0.0020 - 473ms/epoch - 8ms/step
Epoch 15/30
59/59 - 0s - loss: 0.0117 - mae: 13409.8643 - val_loss: 0.0220 - val_mae: 18153.7422 - lr: 0.0020 - 473ms/epoch - 8ms/step
Epoch 16/30
59/59 - 0s - loss: 0.0101 - mae: 13022.0840 - val_loss: 0.0235 - val_mae: 18409.3594 - lr: 0.0020 - 471ms/epoch - 8ms/step
Epoch 17/30
59/59 - 0s - loss: 0.0093 - mae: 12773.8232 - val_loss: 0.0217 - val_mae: 17953.0879 - lr: 0.0020 - 473ms/epoch - 8ms/step
Epoch 18/30
59/59 - 0s - loss: 0.0061 - mae: 9730.9385 - val_loss: 0.0198 - val_mae: 15762.1855 - lr: 4.0000e-04 - 475ms/epoch - 8ms/step
Epoch 19/30
59/59 - 1s - loss: 0.0057 - mae: 9530.0889 - val_loss: 0.0191 - val_mae: 15014.7354 - lr: 4.0000e-04 - 500ms/epoch - 8ms/step
Epoch 20/30
59/59 - 0s - loss: 0.0056 - mae: 9361.5186 - val_loss: 0.0190 - val_mae: 14955.1758 - lr: 4.0000e-04 - 477ms/epoch - 8ms/step
Epoch 21/30
59/59 - 0s - loss: 0.0053 - mae: 9141.9238 - val_loss: 0.0191 - val_mae: 15055.0273 - lr: 4.0000e-04 - 477ms/epoch - 8ms/step
Epoch 22/30
59/59 - 0s - loss: 0.0049 - mae: 8753.4365 - val_loss: 0.0191 - val_mae: 15074.8672 - lr: 8.0000e-05 - 478ms/epoch - 8ms/step
Epoch 23/30
59/59 - 968s - loss: 0.0049 - mae: 8659.4756 - val_loss: 0.0191 - val_mae: 14975.2236 - lr: 8.0000e-05 - 968s/epoch - 16s/step</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">history</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Final epoch (plot to see history):
    loss: 0.004851
     mae: 8,659
val_loss: 0.01909
 val_mae: 14,975
      lr: 0.00008 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb77"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">history</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_log10</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://wilkelab.org/cowplot/reference/theme_cowplot.html">theme_cowplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"top"</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="Machine-Learning_files/figure-html/unnamed-chunk-52-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>


<!-- -->

<script type="ojs-module-contents">
eyJjb250ZW50cyI6W119
</script><div id="exercise-loading-indicator" class="exercise-loading-indicator d-none d-flex align-items-center gap-2">
<div id="exercise-loading-status" class="d-flex gap-2">

</div>
<div class="spinner-grow spinner-grow-sm">

</div>
</div>
<script type="vfs-file">
W10=
</script><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Bishop2007" class="csl-entry" role="listitem">
Bishop, Christopher M. 2007. <em>Pattern recognition and machine learning</em>. Information Science and Statistics. New York, NY: Springer Science+Business Media, LLC.
</div>
<div id="ref-Allaire2018" class="csl-entry" role="listitem">
Chollet, Francois, und J. J. Allaire. 2018. <em>Deep Learning with R</em>. New York: Manning Publications Co. LLC.
</div>
<div id="ref-Goodfellowetal2016" class="csl-entry" role="listitem">
Goodfellow, Ian, Yoshua Bengio, und Aaron Courville. 2016. <em>Deep Learning</em>. MIT Press.
</div>
</div>
</section></main><!-- /main --><script type="ojs-module-contents">
eyJjb250ZW50cyI6W119
</script><script type="module">
if (window.location.protocol === "file:") { alert("The OJS runtime does not work with file:// URLs. Please use a web server to view this document."); }
window._ojs.paths.runtimeToDoc = "../..";
window._ojs.paths.runtimeToRoot = "../..";
window._ojs.paths.docToRoot = "";
window._ojs.selfContained = false;
window._ojs.runtime.interpretFromScriptTags();
</script><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Kopiert");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Kopiert");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./trees.html" class="pagination-link" aria-label="Baum-basierte Methoden">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Baum-basierte Methoden</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./ex.html" class="pagination-link" aria-label="Lineare Regression">
        <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Lineare Regression</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Quellcode</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb78" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> live-html</span></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="an">engine:</span><span class="co"> knitr</span></span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a><span class="fu"># Neuronale Netzwerke</span></span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a>Neuronale Netze (NN) sind leistungsstarke Modelle, die darauf spezialisiert sind, komplexe Muster in Daten zu erkennen und sind damit insbesondere ein hilfeiches Tool für Prognosen. Ein Nachteil neuronaler Netze ist die mangelnde Fähigkeit, kausale Zusammenhänge zu identifizieren und abzuleiten. Diese Limitation stellt eine signifikante Einschränkung dar, insbesondere für den Einsatz in empirischen Disziplinen, in denen das Verständnis kausaler Beziehungen von entscheidender Bedeutung ist. Während NN effektiv komplizierte Strukturen abbilden können, sind sie nicht mit den notwendigen Mechanismen ausgestattet, um Kausalität zu modellieren oder gar zu identifizieren. Grund hierfür ist die fehlende explizite Berücksichtigung kausaler Beziehungen und des zugrunde liegenden datenerzeugenden Prozesses: NN lernen lediglich funktionale Zusammenhänge in den Trainingsdaten. Auch wenn hierdurch komplexeste Relationen abgebildet werden können, erlaubt ein angepasstes Netz keine Differenzierung zwischen einer Korrelation und einer tatsächlichen kausalen Beziehung zwischen Variablen.</span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a>Weiterhin ist statistische Inferenz, etwa mit Konfidenzintervallen oder p-Werten, bei neuronalen Netzen grundsätzlich nicht wie gewohnt anwendbar: Das liegt insbesondere an der komplexen nicht-linearen Struktur und der Interaktion vieler Parameter, die schwer isoliert (und interpretiert) werden können.</span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a>In diesem Kapitel erläutern wir die Funktionsweise und Anpassung von NN und diskutieren deren Anwendung zur Prognose von Zielvariablen in Datensätzen mit vielen Variablen und Beobachtungen in R mit <span class="in">`keras`</span>. Die hier erläuterten Grundlagen basieren auf den einleitenden Kapiteln in @Bishop2007 und @Goodfellowetal2016. Für ausführliche Erläuterungen der R-API <span class="in">`keras`</span> für die gleichnamige Python-Bibliothek empfehlen wir @Allaire2018.</span>
<span id="cb78-13"><a href="#cb78-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-14"><a href="#cb78-14" aria-hidden="true" tabindex="-1"></a><span class="fu">## Grundlagen und Vokabeln {#sec-nn-basics}</span></span>
<span id="cb78-15"><a href="#cb78-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-16"><a href="#cb78-16" aria-hidden="true" tabindex="-1"></a>NN bestehen aus einer (often großen) Anzahl so genannter *künstlicher Neuronen*. Ein Neuron ist eine mathematische Funktion, die mehrere Eingaben empfängt, diese unter Verwendung von Gewichten linear kombiniert und eine Ausgabe durch Verwendung einer Aktivierungsfunktion generiert.</span>
<span id="cb78-17"><a href="#cb78-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-18"><a href="#cb78-18" aria-hidden="true" tabindex="-1"></a>Die Neuronen eines NN sind in Schichten (*Layers*) organisiert. Jedes Layer verarbeitet die Eingabedaten und gibt die Ergebnisse an das nächste Layer weiter, wobei die Neuronen verschiedener Layer miteinander verknüpft werden. Während das Eingabe-Layer (*Input*) die "Rohdaten" (bspw. beobachtete Regressorwerte) aufnimmt und sie an die erste versteckte Schicht (*Hidden Layer*) weiterleitet, ist die Hauptaufgabe der Neuronen in den Hidden Layers, komplexe Muster und Merkmale in den Daten zu erkennen und zu verarbeiten. Jedes Hidden Layer transformiert die empfangenen Daten anhand seiner Neuronen, bevor diese an das nächste Layer weitergeleitet werden. Das letzte Layer in einem neuronalen Netzwerk ist das Ausgabe-Layer (*Output Layer*), das die endgültige Vorhersage für die Outcome-Variable basierend auf den verarbeiteten Daten liefert.</span>
<span id="cb78-19"><a href="#cb78-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-20"><a href="#cb78-20" aria-hidden="true" tabindex="-1"></a>Die Stärke der Verknüpfungen zwischen den Neuronen wird durch die Gewichte $w$ bestimmt, welche während des Trainingsprozesses angepasst werden, um das Modell hinsichtlich der (Vorhersage) einer Zielvariable zu optimieren. Die $w$ bestimmen, wie stark die Aktivierung eines Neurons in einer Schicht die Aktivierung der Neuronen in der nächsten Schicht beeinflusst. Das Netzwerk kann so tiefe und abstrakte Strukturen eines Datensatzes abbilden. </span>
<span id="cb78-21"><a href="#cb78-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-24"><a href="#cb78-24" aria-hidden="true" tabindex="-1"></a><span class="in">```{dot}</span></span>
<span id="cb78-25"><a href="#cb78-25" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-width: 6</span></span>
<span id="cb78-26"><a href="#cb78-26" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-height: 4</span></span>
<span id="cb78-27"><a href="#cb78-27" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-align: 'center'</span></span>
<span id="cb78-28"><a href="#cb78-28" aria-hidden="true" tabindex="-1"></a><span class="in">//| label: fig-nnex</span></span>
<span id="cb78-29"><a href="#cb78-29" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-cap: "Neuronales Netzwerk mit einem Hidden Layer"</span></span>
<span id="cb78-30"><a href="#cb78-30" aria-hidden="true" tabindex="-1"></a><span class="in">digraph NNEX {</span></span>
<span id="cb78-31"><a href="#cb78-31" aria-hidden="true" tabindex="-1"></a><span class="in">    layout=neato;</span></span>
<span id="cb78-32"><a href="#cb78-32" aria-hidden="true" tabindex="-1"></a><span class="in">    fontname="Helvetica,Arial,sans-serif";</span></span>
<span id="cb78-33"><a href="#cb78-33" aria-hidden="true" tabindex="-1"></a><span class="in">    node [fontname="Helvetica,Arial,sans-serif", shape="circle", style=filled, fontsize=16];</span></span>
<span id="cb78-34"><a href="#cb78-34" aria-hidden="true" tabindex="-1"></a><span class="in">    edge [fontname="Helvetica,Arial,sans-serif", fontsize=12];</span></span>
<span id="cb78-35"><a href="#cb78-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-36"><a href="#cb78-36" aria-hidden="true" tabindex="-1"></a><span class="in">    // Eingabeschicht</span></span>
<span id="cb78-37"><a href="#cb78-37" aria-hidden="true" tabindex="-1"></a><span class="in">    X1 [label="X1", pos="0,1!", fillcolor=lightblue];</span></span>
<span id="cb78-38"><a href="#cb78-38" aria-hidden="true" tabindex="-1"></a><span class="in">    X2 [label="X2", pos="0,-1!", fillcolor=lightblue];</span></span>
<span id="cb78-39"><a href="#cb78-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-40"><a href="#cb78-40" aria-hidden="true" tabindex="-1"></a><span class="in">    // Versteckte Schicht</span></span>
<span id="cb78-41"><a href="#cb78-41" aria-hidden="true" tabindex="-1"></a><span class="in">    V1 [label="V1\n(A)", pos="3,2!", fillcolor=lightyellow];</span></span>
<span id="cb78-42"><a href="#cb78-42" aria-hidden="true" tabindex="-1"></a><span class="in">    V2 [label="V2\n(A)", pos="3,0!", fillcolor=lightyellow];</span></span>
<span id="cb78-43"><a href="#cb78-43" aria-hidden="true" tabindex="-1"></a><span class="in">    V3 [label="V3\n(A)", pos="3,-2!", fillcolor=lightyellow];</span></span>
<span id="cb78-44"><a href="#cb78-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-45"><a href="#cb78-45" aria-hidden="true" tabindex="-1"></a><span class="in">    // Ausgabeneuron</span></span>
<span id="cb78-46"><a href="#cb78-46" aria-hidden="true" tabindex="-1"></a><span class="in">    Y [label="Y\n(A)", pos="6,0!", fillcolor=lightgreen];</span></span>
<span id="cb78-47"><a href="#cb78-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-48"><a href="#cb78-48" aria-hidden="true" tabindex="-1"></a><span class="in">    // Kanten von Eingabeschicht zur versteckten Schicht</span></span>
<span id="cb78-49"><a href="#cb78-49" aria-hidden="true" tabindex="-1"></a><span class="in">    X1 -&gt; V1 [label="w11"];</span></span>
<span id="cb78-50"><a href="#cb78-50" aria-hidden="true" tabindex="-1"></a><span class="in">    X1 -&gt; V2 [label="w12"];</span></span>
<span id="cb78-51"><a href="#cb78-51" aria-hidden="true" tabindex="-1"></a><span class="in">    X1 -&gt; V3 [label="w13"];</span></span>
<span id="cb78-52"><a href="#cb78-52" aria-hidden="true" tabindex="-1"></a><span class="in">    X2 -&gt; V1 [label="w21"];</span></span>
<span id="cb78-53"><a href="#cb78-53" aria-hidden="true" tabindex="-1"></a><span class="in">    X2 -&gt; V2 [label="w22"];</span></span>
<span id="cb78-54"><a href="#cb78-54" aria-hidden="true" tabindex="-1"></a><span class="in">    X2 -&gt; V3 [label="w23"];</span></span>
<span id="cb78-55"><a href="#cb78-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-56"><a href="#cb78-56" aria-hidden="true" tabindex="-1"></a><span class="in">    // Kanten von der versteckten Schicht zur Ausgabeschicht</span></span>
<span id="cb78-57"><a href="#cb78-57" aria-hidden="true" tabindex="-1"></a><span class="in">    V1 -&gt; Y [label="w31"];</span></span>
<span id="cb78-58"><a href="#cb78-58" aria-hidden="true" tabindex="-1"></a><span class="in">    V2 -&gt; Y [label="w32"];</span></span>
<span id="cb78-59"><a href="#cb78-59" aria-hidden="true" tabindex="-1"></a><span class="in">    V3 -&gt; Y [label="w33"];</span></span>
<span id="cb78-60"><a href="#cb78-60" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb78-61"><a href="#cb78-61" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-62"><a href="#cb78-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-63"><a href="#cb78-63" aria-hidden="true" tabindex="-1"></a>Angenommen wir interessieren uns für die Vorhersage einer Outcome-Variable $Y$ mit den Regressoren $X_1$ und $X_2$. @fig-nnex zeigt ein mögliches NN mit 3 Neuronen $V_1$, $V_2$, $V_3$ in einem Hidden Layer. Die Neuronen im Hidden Layer empfangen Eingaben aus dem Input Layer, bestehend aus Beobachtungen der Variablen $X_1$ und $X_2$, und gewichten diese Informationen gemäß der Vorschrift</span>
<span id="cb78-64"><a href="#cb78-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-65"><a href="#cb78-65" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb78-66"><a href="#cb78-66" aria-hidden="true" tabindex="-1"></a>  h_i = A\left(\sum_{j=1}^{2} w_{ji} \cdot x_j + b_i\right) \quad \text{für } i = 1, 2, 3.</span>
<span id="cb78-67"><a href="#cb78-67" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb78-68"><a href="#cb78-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-69"><a href="#cb78-69" aria-hidden="true" tabindex="-1"></a>Hierbei sind $w_{ji}$ die Gewichte der Verbindung von Input $j$ zu Neuron $i$ und $b_i$ ist ein *Bias*.^<span class="co">[</span><span class="ot">Der Bias ist analog zur Konstante in einer Regression.</span><span class="co">]</span> $A(\cdot)$ ist eine Aktivierungsfunktion, die in Abhängigkeit der zu modellierenden Daten gewählt wird.</span>
<span id="cb78-70"><a href="#cb78-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-71"><a href="#cb78-71" aria-hidden="true" tabindex="-1"></a>Das Ausgabe-Neuron für $Y$ verarbeitet die Informationen aus dem Hidden Layer ebenfalls anhand einer Linearkombination, die mit einer Aktivierungsfunktion transformiert wird,</span>
<span id="cb78-72"><a href="#cb78-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-73"><a href="#cb78-73" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb78-74"><a href="#cb78-74" aria-hidden="true" tabindex="-1"></a>  y = A\left(\sum_{i=1}^{3} w_{i} \cdot h_i + b_y\right).</span>
<span id="cb78-75"><a href="#cb78-75" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb78-76"><a href="#cb78-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-77"><a href="#cb78-77" aria-hidden="true" tabindex="-1"></a>Ein solches NN "lernt" Relationen zwischen $Y$ und den Regressoren $X_1$ und $X_2$, indem die Gewichte anhand eines Algorithmus derart gewählt werden, dass der Fehler zwischen den vorhergesagten und den tatsächlichen Werten von $Y$ --- gemessen mit einer Verlustfunktion (*Loss-Funktion*) --- minimiert wird. Dieser Lernprozess erfolgt unter Verwendung numerischer Optimierungsverfahren wie *Gradientenabstieg* (*Gradient Descent*).</span>
<span id="cb78-78"><a href="#cb78-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-79"><a href="#cb78-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-80"><a href="#cb78-80" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training Neuronaler Netze</span></span>
<span id="cb78-81"><a href="#cb78-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-82"><a href="#cb78-82" aria-hidden="true" tabindex="-1"></a>Der Anpassungsprozess eines NN an einen Datensatz (*Training*) wird grob durch folgende Schritte bestimmt:</span>
<span id="cb78-83"><a href="#cb78-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-84"><a href="#cb78-84" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Das Netz (Gewichte) wird initialisiert. </span>
<span id="cb78-85"><a href="#cb78-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-86"><a href="#cb78-86" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Die Inputs jeder Beobachtung im Trainingsdatensatz werden durch das NN geleitet (*Forward Pass*): Jedes Layer transformiert die Daten mit Hilfe von Gewichten und Aktivierungsfunktionen, um eine Vorhersage von $Y$ zu erzeugen.</span>
<span id="cb78-87"><a href="#cb78-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-88"><a href="#cb78-88" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Der Loss wird berechnet, indem die Vorhersage von $Y$ mit dem tatsächlichen Wert verglichen wird. Die Verlustfunktion wird entsprechend der Definition von $Y$ gewählt. Typische Verlustfunktionen sind *Quadratic Loss* (analog zur Schätzung von linearen Regressionsmodellen mit KQ) oder *Logistic Loss* (analog zu logistischer Regression).</span>
<span id="cb78-89"><a href="#cb78-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-90"><a href="#cb78-90" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Zur Anpassung der Gewichte wird der Gradient^<span class="co">[</span><span class="ot">Der Gradient einer Funktion $f(\boldsymbol{x}) = f(x_1, x_2, \ldots, x_k)$ ist der Vektor der partiellen Ableitungen: $\nabla f = \left( \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \ldots, \frac{\partial f}{\partial x_k} \right)$. $\nabla f(\boldsymbol{x})$ zeigt die Richtung und Stärke der steilsten Änderung von $f$ am Punkt $\boldsymbol{x}$ an.</span><span class="co">]</span> der Verlustfunktion hinsichtlich der Gewichte des NN ermittelt.^<span class="co">[</span><span class="ot">$\nabla f$ ist in NN grundsätzlich unbekannt. Gradient-Desenct-Algorithmen verwenden numerische Verfahren, um den Gradienten anhand von $f$ zu approximieren.</span><span class="co">]</span> Ein Gradient-Descent-Algorithmus bestimmt, in welche Richtung die Gewichte verändert werden müssen, um den Vorhersagefehler zu verringern.</span>
<span id="cb78-91"><a href="#cb78-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-92"><a href="#cb78-92" aria-hidden="true" tabindex="-1"></a>    Für diese Berechnung wird ein *Backward Pass* (auch *Backpropagation* genannt) genutzt. Hierbei wird der anhand des Ausgabelayers ermittelte Loss rückwärts durch das Netzwerk propagiert, um die Gewichte so anzupassen, dass der Fehler bei der Vorhersage von $Y$ minimiert wird.</span>
<span id="cb78-93"><a href="#cb78-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-94"><a href="#cb78-94" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Die Gewichte werden in kleinen Schritten, die durch die so genannte *Lernrate* bestimmt werden, in Richtung des negativen Gradienten angepasst. Dies bewirkt, dass die Gewichte so verändert werden, dass der Loss im Vergleich zur letzten Iteration verringert wird.</span>
<span id="cb78-95"><a href="#cb78-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-96"><a href="#cb78-96" aria-hidden="true" tabindex="-1"></a>    Um den Lernprozess effizienter und stabiler zu machen, nutzen moderne Algorithmen weitere Schritte, bspw. eine Kombination von Gradientenabstieg mit *Momentum*. Dies beschleunigt die Anpassung der Gewichte und stabilisiert den Lernprozess. Fortgeschrittene Methoden verwenden adaptiven Lernraten, die die Schrittgröße für jedes Gewicht individuell anpassen können.</span>
<span id="cb78-97"><a href="#cb78-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-98"><a href="#cb78-98" aria-hidden="true" tabindex="-1"></a>Die Schritte 4 und 5 werden wiederholt, bis ein Abbruchkriterium erfüllt ist: Der Fehler ist ausreichend klein, oder weitere Iterationen bewirken keine signifikante Änderung des Gradienten. </span>
<span id="cb78-99"><a href="#cb78-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-100"><a href="#cb78-100" aria-hidden="true" tabindex="-1"></a>**Epochen und Iterationen**</span>
<span id="cb78-101"><a href="#cb78-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-102"><a href="#cb78-102" aria-hidden="true" tabindex="-1"></a>Der Gesamte Prozess wird für mehrere Epochen (*Epocs*) durchlaufen, in denen jeweils der gesamte Trainingsdatensatz durch das NN geleitet wird. Um das Training auch für große Datensätze durchführen zu können, werden die Trainingsdaten hierbei üblicherweise in zufällig zusammengesetzen, kleineren Datensätzen (*Batches*) gruppiert. In jeder Epoche erfolgt die Anpassung der Gewichte für jedes durch das Netz geleitete Batch (jede *Iteration*):</span>
<span id="cb78-103"><a href="#cb78-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-104"><a href="#cb78-104" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Epoche**</span>
<span id="cb78-105"><a href="#cb78-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-106"><a href="#cb78-106" aria-hidden="true" tabindex="-1"></a><span class="ss">    1. </span>**Batch**</span>
<span id="cb78-107"><a href="#cb78-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-108"><a href="#cb78-108" aria-hidden="true" tabindex="-1"></a>        *Forward Pass* $\rightarrow$ *Loss-Berechnung* $\rightarrow$ *Backpropagation* $\rightarrow$ *Gradient-Descent-Update*</span>
<span id="cb78-109"><a href="#cb78-109" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb78-110"><a href="#cb78-110" aria-hidden="true" tabindex="-1"></a><span class="ss">    2. </span>**Batch**</span>
<span id="cb78-111"><a href="#cb78-111" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb78-112"><a href="#cb78-112" aria-hidden="true" tabindex="-1"></a>        *Forward Pass* $\rightarrow$ *Loss-Berechnung* $\rightarrow$ *Backpropagation* $\rightarrow$ *Gradient-Descent-Update*</span>
<span id="cb78-113"><a href="#cb78-113" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb78-114"><a href="#cb78-114" aria-hidden="true" tabindex="-1"></a>        ...</span>
<span id="cb78-115"><a href="#cb78-115" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb78-116"><a href="#cb78-116" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Epoche**</span>
<span id="cb78-117"><a href="#cb78-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-118"><a href="#cb78-118" aria-hidden="true" tabindex="-1"></a><span class="in">            ...</span></span>
<span id="cb78-119"><a href="#cb78-119" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb78-120"><a href="#cb78-120" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb78-121"><a href="#cb78-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-122"><a href="#cb78-122" aria-hidden="true" tabindex="-1"></a>Für das Training eines NN sind mehrere Epochen notwendig, weil ein einzelner Durchlauf der Daten oft nicht ausreicht, um die zugrundeliegenden Muster zu lernen. Durch Anpassung über mehrere Epochen können die Gewichte des Modells verfeinert werden, was insbesondere die Fähigkeit zur Generalisierung für ungesehene Daten verbessert. Die zufällige Einteilung der Daten in Batches zu Beginn jeder Epoche verhindert unter anderem, dass das NN lediglich die Reihenfolge der durchgeleiteten Datenpunkte lernt. </span>
<span id="cb78-123"><a href="#cb78-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-124"><a href="#cb78-124" aria-hidden="true" tabindex="-1"></a>Die Anzahl an zu durchlaufender Epochen ist ein Tuning-Parameter: Zu wenige Epochen führen zu einer schlechten Anpassung an die Daten, während zu viele Epochen das Risiko von Overfitting erhöhen. Um den Vorhersagefehler für ungesehene Daten einzuschätzen, wird ein Testdatensatz vorbehalten. Dieser Datensatz wird während des Trainings nicht zum Anpassen der Gewichte genutzt, sondern erst nach Abschluss einer Epoche für die Berechnung der Vorhersagequalität herangezogen. So kann jeweils nach dem Durchlauf einer Epoche beurteilt werden, wie gut das Modell auf neue, unbekannte Daten generalisiert. Hierbei können ein hoher Vorhersagefehler für den Testdatensatz und ein (viel) geringerer Fehler für den Trainingsdatensatz nach mehreren Epochen auf Overfitting hinweisen. Im empirischen Teil dieses Kapitels diskutieren wir (grafische) Methoden zur Beurteilung der Anpassung des Modells.</span>
<span id="cb78-125"><a href="#cb78-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-126"><a href="#cb78-126" aria-hidden="true" tabindex="-1"></a>Beim Training von NN können sogenannte *Callback-Funktionen* eingesetzt werden, um den Anpassungsprozess unter Einbezug von Zwischenergebnissen zu bestimmten Zeitpunkten während des Trainingsprozesses, z. B. am Ende jeder Epoche oder nach einer bestimmten Anzahl von Iterationen, zu evaluieren. Callbacks werden verwendet, um bestimmte Aktionen auszuführen, wie das Anpassen der Lernrate oder das Überwachen der Trainingsleistung: Ein Callback kann das Training automatisch stoppen (*Early Stopping*), wenn Anzeichen von Overfitting erkannt werden, beispielsweise wenn die Vorhersagegüte auf dem Test-Datensatz über mehrere Epochen hinweg stagniert. Dadurch wird ein unnötiges Fortsetzen des Trainings vermieden und ein Verlust der Generalisierungsfähigkeit auf neuen Daten verhindert.</span>
<span id="cb78-127"><a href="#cb78-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-128"><a href="#cb78-128" aria-hidden="true" tabindex="-1"></a>Wir fassen die wichtigsten Begriffe für die Beschreibung von NN nachfolgend kurz zusammen.</span>
<span id="cb78-129"><a href="#cb78-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-130"><a href="#cb78-130" aria-hidden="true" tabindex="-1"></a>**Wesentliche Definitionen**</span>
<span id="cb78-131"><a href="#cb78-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-132"><a href="#cb78-132" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Layer**: Eine Ebene von Neuronen im neuronalen Netzwerk. Es gibt das Eingabe-Layer, versteckte Layers (Hidden Layers) und das Ausgabe-Layer. Jedes Layer verarbeitet Informationen aus dem vorangegangenen Layer und gibt die Ergebnisse an das nächste Layer weiter.</span>
<span id="cb78-133"><a href="#cb78-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-134"><a href="#cb78-134" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Input**: Die Eingangsdaten oder Merkmale, die in das NN eingespeist werden. Jeder Input wird durch ein oder mehrere Neuronen im Eingabe-Layer repräsentiert.</span>
<span id="cb78-135"><a href="#cb78-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-136"><a href="#cb78-136" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Output**: Das Ergebnis, welches das NN nach der Verarbeitung der Inputs liefert. Der Output wird durch die Neuronen im Output-Layer des NN erstellt.</span>
<span id="cb78-137"><a href="#cb78-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-138"><a href="#cb78-138" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Neuron**: Die kleinste Komponente eines NN. Jedes Neuron empfängt Inputs, multipliziert sie mit Gewichten, addiert einen Bias und gibt das Ergebnis nach Anwendung einer Aktivierungsfunktion weiter: Ein Neuron ist also eine *mathematische Funktion*, die Inputs aus dem vorherigen Layer mit einer transformierten Linearkombination verarbeitet und das Ergebnis das nächste Layers weiterleitet. </span>
<span id="cb78-139"><a href="#cb78-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-140"><a href="#cb78-140" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Forward Pass**: Leitung der Trainingsdaten durch das NN und Berechnung der Vorhersage des Outcomes.</span>
<span id="cb78-141"><a href="#cb78-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-142"><a href="#cb78-142" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Loss-Funktion**: Mathematische Funktion, welche die Güte der Vorhersage des NN für das Outcome quantifiziert. Der Loss ist eine Funktion der zu trainierenden Parameter des NN.</span>
<span id="cb78-143"><a href="#cb78-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-144"><a href="#cb78-144" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Backward Pass / Backpropagation**: Ermittlung des Gradienten der Loss-Funktion durch Verkettung des Effekts der Gewichte über die Layers des NN.</span>
<span id="cb78-145"><a href="#cb78-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-146"><a href="#cb78-146" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Aktivierungsfunktion**: Eine mathematische Funktion, die auf die gewichtete Summe der Eingaben eines Neurons angewendet wird. Die Aktivierungsfunktion bestimmt, ob ein Neuron aktiviert wird. Beispiele sind </span>
<span id="cb78-147"><a href="#cb78-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-148"><a href="#cb78-148" aria-hidden="true" tabindex="-1"></a>    \begin{align*}</span>
<span id="cb78-149"><a href="#cb78-149" aria-hidden="true" tabindex="-1"></a>      \textup{ReLU}(z) =&amp; \max(0, z), <span class="sc">\\</span><span class="co">[</span><span class="ot">.5ex</span><span class="co">]</span></span>
<span id="cb78-150"><a href="#cb78-150" aria-hidden="true" tabindex="-1"></a>      \sigma(z) =&amp;\, \frac{1}{1 + e^{-z}}, <span class="sc">\\</span><span class="co">[</span><span class="ot">.5ex</span><span class="co">]</span></span>
<span id="cb78-151"><a href="#cb78-151" aria-hidden="true" tabindex="-1"></a>      \tanh(z) =&amp;\, \frac{e^z - e^{-z}}{e^z + e^{-z}}.</span>
<span id="cb78-152"><a href="#cb78-152" aria-hidden="true" tabindex="-1"></a>    \end{align*}</span>
<span id="cb78-153"><a href="#cb78-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-154"><a href="#cb78-154" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Epoche**: Ein Trainingszyklus, bei dem der gesamte Trainingsdatensatz, aufgeteilt in Batches, das NN durchläuft.</span>
<span id="cb78-155"><a href="#cb78-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-156"><a href="#cb78-156" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Batches**: Zufällig eingeteilte Teilmengen der Beobachtungen des Trainingsdatensatzes.</span>
<span id="cb78-157"><a href="#cb78-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-158"><a href="#cb78-158" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Callback**: Eine Funktion, die im Zuge der Überwachung des des Trainings-Prozesses automatisch ausgeführt wird, um Aktionen wie Lernratenanpassung oder Trainingsstopp zu auszulösen.</span>
<span id="cb78-159"><a href="#cb78-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-160"><a href="#cb78-160" aria-hidden="true" tabindex="-1"></a>Im nächsten Abschnitt erläutern wir die Optimierung der Gewichte mit Gradient Descent beispielhaft anhand interaktiver Visualisierungen.</span>
<span id="cb78-161"><a href="#cb78-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-162"><a href="#cb78-162" aria-hidden="true" tabindex="-1"></a><span class="fu">## Optimierung mit Gradient Descent</span></span>
<span id="cb78-163"><a href="#cb78-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-164"><a href="#cb78-164" aria-hidden="true" tabindex="-1"></a>Gradient Descent ist ein iteratives Optimierungsverfahren zur Minimierung einer differenzierbaren Zielfunktion $f(w)$. Ausgehend von einem Startwert $w_0$ aktualisiert der Algorithmus die Variable $w$ schrittweise gemäß einer Lernrate $\eta$ in die entgegengesetzte Richtung des Gradienten $\nabla f(w)$ der Funktion an der aktuellen $w$. Mit $\nabla f(w)$ wird mathematisch die Richtung des *steilsten Anstiegs* von $f(w)$ im Punkt $w$ ermittelt. Der Algorithmus vollzieht eine Veränderung von $w$ in die entgegengesetzten Richtung -- die Richtung mit dem schnellsten *Abstieg* (Descent) der Zielfunktion.</span>
<span id="cb78-165"><a href="#cb78-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-166"><a href="#cb78-166" aria-hidden="true" tabindex="-1"></a>Der folgende Algorithmus zeigt die grundlegende Vorgehensweise des Gradientenabstiegsverfahrens für einen einziegen zu optimierenden Parameter $w$ unter Einbeziehung eines Momentum-Terms $v_t$.^<span class="co">[</span><span class="ot">In der Literatur wird $v_t$ häufig auch als *Velocity* bezeichnet.</span><span class="co">]</span> Der Momentum-Term dient dazu, das Konvergenzverhalten zu verbessern und lokale Minima effektiver zu überwinden. Die Stärke des Momentums $v_t$ wird durch den Momentum-Faktor $\alpha \in [0,1)$ bestimmt. </span>
<span id="cb78-167"><a href="#cb78-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-168"><a href="#cb78-168" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb78-169"><a href="#cb78-169" aria-hidden="true" tabindex="-1"></a>  \small</span>
<span id="cb78-170"><a href="#cb78-170" aria-hidden="true" tabindex="-1"></a>  &amp; \textbf{Algorithmus: Gradientenabstiegsverfahren mit Momentum} <span class="sc">\\</span></span>
<span id="cb78-171"><a href="#cb78-171" aria-hidden="true" tabindex="-1"></a>  &amp; \textup{Initialisiere: }<span class="sc">\\</span><span class="co">[</span><span class="ot">.5ex</span><span class="co">]</span></span>
<span id="cb78-172"><a href="#cb78-172" aria-hidden="true" tabindex="-1"></a>  &amp; \quad w_0 \text{ (Startpunkt) }<span class="sc">\\</span></span>
<span id="cb78-173"><a href="#cb78-173" aria-hidden="true" tabindex="-1"></a>  &amp; \quad \eta \text{ (Lernrate) }<span class="sc">\\</span></span>
<span id="cb78-174"><a href="#cb78-174" aria-hidden="true" tabindex="-1"></a>  &amp; \quad \alpha \text{ (Momentum-Faktor) }<span class="sc">\\</span> </span>
<span id="cb78-175"><a href="#cb78-175" aria-hidden="true" tabindex="-1"></a>  &amp; \quad v_0 = 0 \text{ (Anfangsmomentum) } <span class="sc">\\</span><span class="co">[</span><span class="ot">1em</span><span class="co">]</span></span>
<span id="cb78-176"><a href="#cb78-176" aria-hidden="true" tabindex="-1"></a>  &amp; \text{Iteriere für } t = 0, 1, 2, \dots \text{ bis Konvergenz:} <span class="sc">\\</span><span class="co">[</span><span class="ot">.5ex</span><span class="co">]</span></span>
<span id="cb78-177"><a href="#cb78-177" aria-hidden="true" tabindex="-1"></a>  &amp; \quad \text{1. Berechne den Gradienten: } \nabla f(w_t) <span class="sc">\\</span></span>
<span id="cb78-178"><a href="#cb78-178" aria-hidden="true" tabindex="-1"></a>  &amp; \quad \text{2. Aktualisiere den Momentum-Term: } v_{t+1} = \alpha v_t - \eta \nabla f(w_t) <span class="sc">\\</span></span>
<span id="cb78-179"><a href="#cb78-179" aria-hidden="true" tabindex="-1"></a>  &amp; \quad \text{3. Aktualisiere die Position: } w_{t+1} = w_t + v_{t+1} <span class="sc">\\</span></span>
<span id="cb78-180"><a href="#cb78-180" aria-hidden="true" tabindex="-1"></a>  &amp; \quad \text{4. Überprüfe das Abbruchkriterium } |\nabla f(w_t)| &lt; \epsilon\text{ (für ein kleines $\epsilon&gt;0$)} <span class="sc">\\</span></span>
<span id="cb78-181"><a href="#cb78-181" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb78-182"><a href="#cb78-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-183"><a href="#cb78-183" aria-hidden="true" tabindex="-1"></a>In der nachfolgenden interaktiven Visualisierung illustrieren wir die Minimierung einer univariaten Funktion $\color{blue}{f(w_t)}$ über $w_t$ anhand des obigen Algorithmus mit Lernrate $\eta = .001$ und Momentum-Faktor $\alpha = .925$.</span>
<span id="cb78-184"><a href="#cb78-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-185"><a href="#cb78-185" aria-hidden="true" tabindex="-1"></a>Der &lt;span style="color:orange"&gt;Gradient&lt;/span&gt;$\color{orange}{\nabla f(w_t)}$ ist hier die 1. Ableitung von $\color{blue}{f(w_t)}$ nach $w_t$. Die Richtung der Änderung von $\color{blue}{f(w_t)}$ in $w_t$ wird durch den &lt;span style="color:orange"&gt;orangenen Pfeil&lt;/span&gt; angezeigt. Beachte, wie sich der Gradient bei Variation des Start-Punkts mit dem Slider ändert. Während die Animation der Optimierung mit Gradient Descent läuft, zeigt der  &lt;span style="color:purple"&gt;lilane Pfeil&lt;/span&gt; das &lt;span style="color:purple"&gt;Momentum&lt;/span&gt; (&lt;span style="color:purple"&gt;Velocity $v_t$&lt;/span&gt;) für Schirtt $t$ an.^<span class="co">[</span><span class="ot">Unterschiedliche Längen der Pfeile zeigen hier nicht Änderungen der tatsächlichen Beträge, sondern dienen lediglich der Interpretierbakeit der Grafik.</span><span class="co">]</span> Der Algorithmus iteriert die Schritte 1. bis 3. solange, bis das Abbruchkriterium $|\textcolor{orange}{\nabla f(w_t)}| &lt; \epsilon = 0.001$ erreicht ist, die Änderung in $\color{orange}{\nabla f(w_t)}$ also hinreichend klein ist, dass ein Parameterwert $w_t$ mit $\color{blue}{f(w_t)}$ nahe des (globalen) Minimums von $f$ plausibel ist.</span>
<span id="cb78-186"><a href="#cb78-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-187"><a href="#cb78-187" aria-hidden="true" tabindex="-1"></a>Folgende Eigenschaften der Optimierung mit Gradient Descent können anhand der Parameter geprüft werden:</span>
<span id="cb78-188"><a href="#cb78-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-189"><a href="#cb78-189" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Für Startpunkte mit großen Werten des Gradienten beginnt der Algorithmus mit einem starken Momentum: Der Abstieg in Richtung des negativen Gradients erfolgt also in großen Schritten, sodass die Optimierung schneller erfolgt als für Startpunkte in flachen Regionen von $\color{blue}{f}$.</span>
<span id="cb78-190"><a href="#cb78-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-191"><a href="#cb78-191" aria-hidden="true" tabindex="-1"></a>    Dieser Effekt des Momentum auf den Pfad der zu optimierenden Parameter bei Gradient Descent ist vergleichbar mit dem Effekt der Schwerkraft auf eine Murmel, die auf einer hügeligen Oberfläche rollt: Anfangs gewinnt die Murmel an Geschwindigkeit und bewegt sich beschleunigt in Richtung des steilsten Gefälles. In flacheren Regionen wird die Bewegung langsamer und die Murmel kann in Tälern stecken bleiben, ähnlich wie der Optimierungsprozess in flachen Regionen von $\color{blue}{f}$ langsamer verläuft oder gar stoppt, weil ein Abbruchkriterium erfüllt ist (geringe Änderung des Gradienten). Das Momentum hilft, auch in solchen flachen Bereichen weiter voranzukommen, indem es dem Parameterpfad eine gewisse "Trägheit" verleiht, die es ermöglicht, flache Stellen schneller zu durchqueren und die Optimierung effizienter zu gestalten.</span>
<span id="cb78-192"><a href="#cb78-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-193"><a href="#cb78-193" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Bei ungünstiger Wahl der Parameter konvergiert der Algorithmus nicht zum globalen Minimum, sondern stoppt im lokalen Minimum bei $w = -0.5$. Dies unterstreicht die Notwendigkeit, die Hyperparameter Lernrate $\eta$ und Momentum-Faktor $\alpha$ sorgfältig zu wählen, beispielsweise indem die Modellgüte nach erfolgter Anpassung für verschiedene Parameter-Kombinationen verglichen wird. </span>
<span id="cb78-194"><a href="#cb78-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-195"><a href="#cb78-195" aria-hidden="true" tabindex="-1"></a>In empirischen Anwendungen ist es für eine hohe Modellgüte eines neuronalen Netzwerks nicht unbedingt erforderlich, das globale Minimum zu finden: Viele Optimierungsprobleme weisen zahlreiche lokale Minima auf, die eine ausreichend gute Annäherung an das Optimum bieten können. Besonders bei hochdimensionalen Optimierungsproblemen mit komplexen Loss-Funktionen können diese lokalen Minima zufriedenstellende Lösungen darstellen. In einigen Fällen existiert möglicherweise kein globales Minimum, und der Algorithmus konvergiert zwangsläufig zu einem stabilen lokalen Minimum, das dennoch eine gute Performance gewährleistet. Daher kann es sinnvoller sein, Algorithmen zu verwenden, die das Erreichen einer robusten Lösung legen, anstatt strikt nach dem globalen Minimum zu suchen.</span>
<span id="cb78-196"><a href="#cb78-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-197"><a href="#cb78-197" aria-hidden="true" tabindex="-1"></a>In Software-Implementierungen für Machine und Deep Learning wie <span class="in">`tensorflow`</span> und <span class="in">`keras`</span> werden fortgeschrittene Techniken wie Momentum Tuning oder Stochastic <span class="co">[</span><span class="ot">Gradient Descent</span><span class="co">](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)</span> (SGD) eingesetzt, um die Wahrscheinlichkeit zu erhöhen, dass der Algorithmus nicht in einem (ungünstigen) lokalen Minimum endet. Ein für die Anpassung von NN häufig verwendeter Algorithmus, der SGD verwendet, ist <span class="co">[</span><span class="ot">Adaptive Moment Estimation (Adam)</span><span class="co">](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam)</span>. Wir verwenden u.a. den Adam-Optimizer in den empirischen Beispielen. </span>
<span id="cb78-198"><a href="#cb78-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-199"><a href="#cb78-199" aria-hidden="true" tabindex="-1"></a>&lt;iframe class="obs-soft-box-shadow" width="100%" height="761" frameborder="0"</span>
<span id="cb78-200"><a href="#cb78-200" aria-hidden="true" tabindex="-1"></a>  src="https://observablehq.com/embed/@mca91/gradient-descent-in-2d?cells=plot%2Cviewof+startAnimation%2Cviewof+startPoint%2Cviewof+alpha%2Cviewof+eta%2CoptimalReached%2CMathJax%2Cstyles"&gt;&lt;/iframe&gt;</span>
<span id="cb78-201"><a href="#cb78-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-202"><a href="#cb78-202" aria-hidden="true" tabindex="-1"></a>In empirischen Anwendungen sind die zu lernenden Zusammenhänge komplex und damit die Anzahl der zu optimierenden Parameter eines NN häufig groß. Der oben erläuterte Algorithmus für Gradient Descent mit Momentum kann einfach auf Optimierungsprobleme mit $k$ Parametern generalisiert werden. Dann ist $\boldsymbol{w}_t$ ein Vektor mit $k$ Gewichten, $\boldsymbol{v}_{t+1}$ eine vektorwertige Funktion von $\boldsymbol{v}_t$ und $\nabla f(\boldsymbol{w}_t)$ mit Dimension $k$ und $f(\boldsymbol{w}_t)$ ist eine Oberfläche in einem $k+1$-dimensionalen Raum. </span>
<span id="cb78-203"><a href="#cb78-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-204"><a href="#cb78-204" aria-hidden="true" tabindex="-1"></a>Die nachfolgende interaktive Grafik illustriert Gradient Descent mit Momentum für $k=2$ zu optimierende Gewichte. Statt der Parameter des Algorithmus kann hier die Form der zu optimierenden Funktion manipuliert werden, sodass bis zu 6 Extremstellen vorliegen können. Der &lt;span style="color:red"&gt;rote Punkt&lt;/span&gt; zeigt den Verlauf der Optimierung von $\boldsymbol{w}_t$.</span>
<span id="cb78-205"><a href="#cb78-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-206"><a href="#cb78-206" aria-hidden="true" tabindex="-1"></a>Die Animation verdeutlicht, dass lokale Minima insbesondere in höheren Dimensionen herausfordernd für Optimierungsalgorithmen sind: Durch Variation der Extrema lassen sich leicht Funktionen $f(w_1,w_1)$ konstruieren, für die Gradient Descent mit den voreingestellten Parametern nicht gegen das globale Minimum konvergiert, sofern vorhanden. Ein günstiger Initialwert für $\boldsymbol{w}_t$ kann die Wahrscheinlichkeit von Stops in lokalen Minima verringern: *Grid Search Initialization* wertet die Funktion über ein gleichmäßiges Gitter von Werten für $\boldsymbol{w}_t$ aus und wählt als Startwert $\boldsymbol{w}_{0,\textup{init}}$ den Punkt mit dem minimalen Funktionswert von $f$ über alle Punkte im Gitter.</span>
<span id="cb78-207"><a href="#cb78-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-208"><a href="#cb78-208" aria-hidden="true" tabindex="-1"></a>&lt;iframe class="obs-soft-box-shadow" width="100%" height="1172" frameborder="0"</span>
<span id="cb78-209"><a href="#cb78-209" aria-hidden="true" tabindex="-1"></a>  src="https://observablehq.com/embed/@mca91/gradient-descent-in-3d-three-js?cells=renderer%2Cviewof+restart%2Cviewof+gridinit%2Cviewof+themin%2Cviewof+themin2%2Cviewof+themin3%2Cviewof+themin4%2Cviewof+themin5%2Cviewof+themin6%2Cscene%2Ccamera"&gt;&lt;/iframe&gt;</span>
<span id="cb78-210"><a href="#cb78-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-211"><a href="#cb78-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-212"><a href="#cb78-212" aria-hidden="true" tabindex="-1"></a><span class="fu">## Funktionale Zusammenhänge lernen: Regression</span></span>
<span id="cb78-213"><a href="#cb78-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-214"><a href="#cb78-214" aria-hidden="true" tabindex="-1"></a>Für einen leichten Einstieg in die Modellierung funktionaler Zusammenhänge durch NN mit statistischer Programmierung in R betrachten wir zunächst den einfachsten Zusammenhang zwischen einer Outcome-Variable $Y$ und einem Regressor $X$: Die einfache lineare Funktion</span>
<span id="cb78-215"><a href="#cb78-215" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb78-216"><a href="#cb78-216" aria-hidden="true" tabindex="-1"></a>  Y = w_1 X + b,</span>
<span id="cb78-217"><a href="#cb78-217" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb78-218"><a href="#cb78-218" aria-hidden="true" tabindex="-1"></a>wobei der Regressionskoeffizient $w_1$ den Einfluss von $X$ auf $Y$ misst und $b$ eine Konstante ist. Gemäß der Definitionen in @sec-nn-basics kann dieser Funktionale Zusammenhang als NN ohne Hidden Layer dargestellt werden, wobei $X$ ein Input-Neuron ist, dessen Information mit $w_1$ gewichtet an das Output Layer mit einem einzigen Neuron für $Y$ weitergegeben wird. Die Konstante $b$ ist ein *Bias*, der als von $X$ unabhängiger Einfluss von $Y$ behandelt wird, vgl. @fig-nn-lreg.</span>
<span id="cb78-219"><a href="#cb78-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-222"><a href="#cb78-222" aria-hidden="true" tabindex="-1"></a><span class="in">```{dot}</span></span>
<span id="cb78-223"><a href="#cb78-223" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-width: 6</span></span>
<span id="cb78-224"><a href="#cb78-224" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-height: 2</span></span>
<span id="cb78-225"><a href="#cb78-225" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-cap: "Neuronales Netzwerk: Lineare Regression mit einer Variable und Konstante"</span></span>
<span id="cb78-226"><a href="#cb78-226" aria-hidden="true" tabindex="-1"></a><span class="in">//| label: "fig-nn-lreg"</span></span>
<span id="cb78-227"><a href="#cb78-227" aria-hidden="true" tabindex="-1"></a><span class="in">digraph NEURALNET {</span></span>
<span id="cb78-228"><a href="#cb78-228" aria-hidden="true" tabindex="-1"></a><span class="in">    layout=neato</span></span>
<span id="cb78-229"><a href="#cb78-229" aria-hidden="true" tabindex="-1"></a><span class="in">    fontname="Helvetica,Arial,sans-serif"</span></span>
<span id="cb78-230"><a href="#cb78-230" aria-hidden="true" tabindex="-1"></a><span class="in">    node [fontname="Helvetica,Arial,sans-serif", shape="circle"]</span></span>
<span id="cb78-231"><a href="#cb78-231" aria-hidden="true" tabindex="-1"></a><span class="in">    edge [fontname="Helvetica,Arial,sans-serif"]</span></span>
<span id="cb78-232"><a href="#cb78-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-233"><a href="#cb78-233" aria-hidden="true" tabindex="-1"></a><span class="in">    X [label="X", pos="0,0!"];</span></span>
<span id="cb78-234"><a href="#cb78-234" aria-hidden="true" tabindex="-1"></a><span class="in">    Y [label="Y", pos="4,0!", style=filled, fillcolor=lightgreen];</span></span>
<span id="cb78-235"><a href="#cb78-235" aria-hidden="true" tabindex="-1"></a><span class="in">    B [label="1", pos="2,2!"];</span></span>
<span id="cb78-236"><a href="#cb78-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-237"><a href="#cb78-237" aria-hidden="true" tabindex="-1"></a><span class="in">    X -&gt; Y [headlabel = "w1", labeldistance=12.5, labelangle=10];</span></span>
<span id="cb78-238"><a href="#cb78-238" aria-hidden="true" tabindex="-1"></a><span class="in">    B -&gt; Y [headlabel = "Bias (b)", labeldistance=9, labelangle=-15];</span></span>
<span id="cb78-239"><a href="#cb78-239" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb78-240"><a href="#cb78-240" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-241"><a href="#cb78-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-242"><a href="#cb78-242" aria-hidden="true" tabindex="-1"></a>Für die Illustration der Schätzung des in @sec-nn-basics dargestellten NN verwenden wir $n=1000$ simulierte Datenpunkte gemäß der Vorschrift</span>
<span id="cb78-243"><a href="#cb78-243" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb78-244"><a href="#cb78-244" aria-hidden="true" tabindex="-1"></a>  Y = 5 + 3 \cdot X + u</span>
<span id="cb78-245"><a href="#cb78-245" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb78-246"><a href="#cb78-246" aria-hidden="true" tabindex="-1"></a>mit $X\sim U<span class="co">[</span><span class="ot">0,10</span><span class="co">]</span>$ und $u\sim N(0,1)$.</span>
<span id="cb78-247"><a href="#cb78-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-250"><a href="#cb78-250" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-251"><a href="#cb78-251" aria-hidden="true" tabindex="-1"></a><span class="co"># Daten simulieren</span></span>
<span id="cb78-252"><a href="#cb78-252" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb78-253"><a href="#cb78-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-254"><a href="#cb78-254" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb78-255"><a href="#cb78-255" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">10</span>)</span>
<span id="cb78-256"><a href="#cb78-256" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">5</span> <span class="sc">+</span> <span class="dv">3</span> <span class="sc">*</span> x <span class="sc">+</span> <span class="fu">rnorm</span>(n) </span>
<span id="cb78-257"><a href="#cb78-257" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-258"><a href="#cb78-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-259"><a href="#cb78-259" aria-hidden="true" tabindex="-1"></a>Für das Training von NN verwenden wir das Python-Paket <span class="co">[</span><span class="ot">keras</span><span class="co">](https://keras.io/)</span>. Hierzu muss lediglich eine lokale Python-Installation vorhanden sein.</span>
<span id="cb78-260"><a href="#cb78-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-261"><a href="#cb78-261" aria-hidden="true" tabindex="-1"></a>Die in diesem Kapitel betrachteten NN sind *sequentielle* NN. Solche Modelle können in <span class="in">`keras`</span> mit der Funktion <span class="in">`keras_model_sequential()`</span> definiert werden. Die Struktur des Modells kann über eine Verkettung von Funktionen für Layers (<span class="in">`keras::layer_dense()`</span>) und Aktivierungen (<span class="in">`keras::layer_activation()`</span>) definiert werden.</span>
<span id="cb78-262"><a href="#cb78-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-263"><a href="#cb78-263" aria-hidden="true" tabindex="-1"></a>Für die Implementierung des Modells in @fig-nn-lreg wählen wir mit <span class="in">`units = 1`</span> und <span class="in">`input_shape = 1`</span> ein Modell mit einem Neuron im Output Layer, das skalare Informationen verarbeitet. <span class="in">`activation = 'linear'`</span> in <span class="in">`layer_dense()`</span> führt zu der Aktivierungsfunktion $A(x) = x$, d.h. die Ausgabe des Input Layers ist die gewichtete Summe der Eingaben plus Bias, *ohne* eine zusätzliche Transformation.</span>
<span id="cb78-264"><a href="#cb78-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-267"><a href="#cb78-267" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-268"><a href="#cb78-268" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb78-269"><a href="#cb78-269" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb78-270"><a href="#cb78-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-271"><a href="#cb78-271" aria-hidden="true" tabindex="-1"></a><span class="co"># NN für einfache Regression</span></span>
<span id="cb78-272"><a href="#cb78-272" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span></span>
<span id="cb78-273"><a href="#cb78-273" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(</span>
<span id="cb78-274"><a href="#cb78-274" aria-hidden="true" tabindex="-1"></a>    <span class="at">units =</span> <span class="dv">1</span>, </span>
<span id="cb78-275"><a href="#cb78-275" aria-hidden="true" tabindex="-1"></a>    <span class="at">input_shape =</span> <span class="dv">1</span>, </span>
<span id="cb78-276"><a href="#cb78-276" aria-hidden="true" tabindex="-1"></a>    <span class="at">activation =</span> <span class="st">'linear'</span></span>
<span id="cb78-277"><a href="#cb78-277" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb78-278"><a href="#cb78-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-279"><a href="#cb78-279" aria-hidden="true" tabindex="-1"></a><span class="co"># Modell-Definition prüfen</span></span>
<span id="cb78-280"><a href="#cb78-280" aria-hidden="true" tabindex="-1"></a>model</span>
<span id="cb78-281"><a href="#cb78-281" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-282"><a href="#cb78-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-283"><a href="#cb78-283" aria-hidden="true" tabindex="-1"></a>Die Übersicht zeigt, dass <span class="in">`model`</span> aus einem Layer für skalare Inputs und Outputs sowie zwei trainierbaren Parameters ($w_1$ und $b$) besteht.</span>
<span id="cb78-284"><a href="#cb78-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-285"><a href="#cb78-285" aria-hidden="true" tabindex="-1"></a>Bevor das im Objekt <span class="in">`model`</span> definierte Modell trainiert werden kann, muss der Code *kompiliert* werden. Dieser Vorgang ist notwendig, da sämtliche Berechnungen in Python durchgeführt werden. Der Python-Code wird beim kompilieren in eine Zwischendarstellung (*Bytecode*) übersetzt, die dann von der Python-Interpreter-Laufzeitumgebung ausgeführt wird.^[Im Gegensatz zu Python ist R eine *interpretierte Programmiersprache*. Kompilierung von R-Ccode ist daher nicht notwendig.]</span>
<span id="cb78-286"><a href="#cb78-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-287"><a href="#cb78-287" aria-hidden="true" tabindex="-1"></a>Mit <span class="in">`keras::compile()`</span> kompilieren wir das Modell und wählen als Optimierungsfunktion Adam mit einer Lernrate von $.01$. Die Loss-Funktion wird über das Argument <span class="in">`loss`</span> festgelegt, hier der mittlere absolute Fehler,</span>
<span id="cb78-288"><a href="#cb78-288" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb78-289"><a href="#cb78-289" aria-hidden="true" tabindex="-1"></a>  \textup{MAE} = \frac{1}{n} \sum_{i=1}^{n} \lvert y_i - \widehat{y}_i\rvert.</span>
<span id="cb78-290"><a href="#cb78-290" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb78-291"><a href="#cb78-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-294"><a href="#cb78-294" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-295"><a href="#cb78-295" aria-hidden="true" tabindex="-1"></a><span class="co"># Modell kompilieren</span></span>
<span id="cb78-296"><a href="#cb78-296" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb78-297"><a href="#cb78-297" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(</span>
<span id="cb78-298"><a href="#cb78-298" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_adam</span>(<span class="at">learning_rate =</span> <span class="fl">0.01</span>),</span>
<span id="cb78-299"><a href="#cb78-299" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> <span class="st">'mean_absolute_error'</span></span>
<span id="cb78-300"><a href="#cb78-300" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-301"><a href="#cb78-301" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-302"><a href="#cb78-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-303"><a href="#cb78-303" aria-hidden="true" tabindex="-1"></a>Die Kompilierung erfolgt meist innerhalb von Sekundenbruchteilen und geschieht *in-place*: Eine Zuweisung des kompilierten Modells in `model` ist *nicht* notwendig.</span>
<span id="cb78-304"><a href="#cb78-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-305"><a href="#cb78-305" aria-hidden="true" tabindex="-1"></a>Um das Modell zu trainieren verwenden wir <span class="in">`keras::fit()`</span>. Neben den (simulierten) Daten übergeben wir die Anzahl der zudurchlaufenden Epochen <span class="in">`epocs`</span>. Über das Argument <span class="in">`validation_split`</span> legen wir fest, dass 20\% der Datensatzes zufällig ausgewählt und als Test-Datensatz für die Modell-Validierung während des Trainings genutzt werden sollen.</span>
<span id="cb78-306"><a href="#cb78-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-309"><a href="#cb78-309" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-310"><a href="#cb78-310" aria-hidden="true" tabindex="-1"></a><span class="co"># Modell trainieren</span></span>
<span id="cb78-311"><a href="#cb78-311" aria-hidden="true" tabindex="-1"></a>history_snn <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> </span>
<span id="cb78-312"><a href="#cb78-312" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb78-313"><a href="#cb78-313" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> x, </span>
<span id="cb78-314"><a href="#cb78-314" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> y, </span>
<span id="cb78-315"><a href="#cb78-315" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> <span class="dv">50</span>, </span>
<span id="cb78-316"><a href="#cb78-316" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> .<span class="dv">2</span></span>
<span id="cb78-317"><a href="#cb78-317" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-318"><a href="#cb78-318" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-319"><a href="#cb78-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-320"><a href="#cb78-320" aria-hidden="true" tabindex="-1"></a>Der Output zeigt die Enwicklung des Loss (MAE) für Vorhersagen des Trainingsdatensatzes (<span class="in">`loss`</span>) und für den Test-Datensatz (<span class="in">`val_loss`</span>) für alle 25 Epochen. Diese Informationen können mit <span class="in">`plot()`</span> einfach visualisiert werden.</span>
<span id="cb78-321"><a href="#cb78-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-324"><a href="#cb78-324" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-325"><a href="#cb78-325" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-snn-loss</span></span>
<span id="cb78-326"><a href="#cb78-326" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Einfaches lineares NN: Entwicklung des Loss für 25 Epochen"</span></span>
<span id="cb78-327"><a href="#cb78-327" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb78-328"><a href="#cb78-328" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cowplot)</span>
<span id="cb78-329"><a href="#cb78-329" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(purrr)</span>
<span id="cb78-330"><a href="#cb78-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-331"><a href="#cb78-331" aria-hidden="true" tabindex="-1"></a><span class="co"># Entwicklung des Loss über Epochen plotten</span></span>
<span id="cb78-332"><a href="#cb78-332" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(history_snn) <span class="sc">+</span></span>
<span id="cb78-333"><a href="#cb78-333" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb78-334"><a href="#cb78-334" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Epoche"</span>,</span>
<span id="cb78-335"><a href="#cb78-335" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Wert der Verlustfunktion"</span></span>
<span id="cb78-336"><a href="#cb78-336" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb78-337"><a href="#cb78-337" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_cowplot</span>() <span class="sc">+</span></span>
<span id="cb78-338"><a href="#cb78-338" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)</span>
<span id="cb78-339"><a href="#cb78-339" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-340"><a href="#cb78-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-341"><a href="#cb78-341" aria-hidden="true" tabindex="-1"></a>@fig-snn-loss zeigt, dass sich sowohl die Anpassung des NN auf dem Trainingsdatenstz als auch die Generalisierung auf dem Testdatensatz innerhalb der ersten Epochen dramatisch verbessert. Jenseits der 15. Epoche hingegen bewirken weitere Trainingszyklen keine weitere Verbesserung des Loss.</span>
<span id="cb78-342"><a href="#cb78-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-343"><a href="#cb78-343" aria-hidden="true" tabindex="-1"></a>Mit <span class="in">`keras::get_weights()`</span> können wir die optimierten Parameter aus dem Modell-Objekt auslesen.</span>
<span id="cb78-344"><a href="#cb78-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-347"><a href="#cb78-347" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-348"><a href="#cb78-348" aria-hidden="true" tabindex="-1"></a><span class="co"># Gewichtung und Bias des trainierten NN auslesen</span></span>
<span id="cb78-349"><a href="#cb78-349" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb78-350"><a href="#cb78-350" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">get_weights</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb78-351"><a href="#cb78-351" aria-hidden="true" tabindex="-1"></a>  <span class="fu">flatten_dbl</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb78-352"><a href="#cb78-352" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_names</span>(</span>
<span id="cb78-353"><a href="#cb78-353" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="st">"w_1"</span>, <span class="st">"bias"</span>)</span>
<span id="cb78-354"><a href="#cb78-354" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-355"><a href="#cb78-355" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-356"><a href="#cb78-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-357"><a href="#cb78-357" aria-hidden="true" tabindex="-1"></a>Das NN hat den funktionalen Zusammengang zwischen <span class="in">`x`</span> und <span class="in">`y`</span> erfolgreich gelernt: Die optimierten Parameter-Werte <span class="in">`bias`</span> und <span class="in">`w_1`</span> liegen nahe der wahren Parameter. Bei Parameter sind mit ihren KQ-Schätzungen vergleichbar.^<span class="co">[</span><span class="ot">Beachte, dass die KQ-Schätzung der Einfachheit halber hier den gesamten Datensatz nutzt und daher präziser sein kann als das NN.</span><span class="co">]</span></span>
<span id="cb78-358"><a href="#cb78-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-361"><a href="#cb78-361" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-362"><a href="#cb78-362" aria-hidden="true" tabindex="-1"></a><span class="co"># lineares Modell</span></span>
<span id="cb78-363"><a href="#cb78-363" aria-hidden="true" tabindex="-1"></a>lm_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(</span>
<span id="cb78-364"><a href="#cb78-364" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> y <span class="sc">~</span> x</span>
<span id="cb78-365"><a href="#cb78-365" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-366"><a href="#cb78-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-367"><a href="#cb78-367" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lm_model)</span>
<span id="cb78-368"><a href="#cb78-368" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-369"><a href="#cb78-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-372"><a href="#cb78-372" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-373"><a href="#cb78-373" aria-hidden="true" tabindex="-1"></a><span class="co"># Koeffizienten der KQ-Schätzung auslesen</span></span>
<span id="cb78-374"><a href="#cb78-374" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(lm_model)</span>
<span id="cb78-375"><a href="#cb78-375" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-376"><a href="#cb78-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-377"><a href="#cb78-377" aria-hidden="true" tabindex="-1"></a>Mit <span class="in">`predict()`</span> erhalten wir Vorhersagen des NN und können so beispielsweise die Residuen für den gesamten Datensatz mit denen der KQ-Schätzung vergleichen.</span>
<span id="cb78-378"><a href="#cb78-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-381"><a href="#cb78-381" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-382"><a href="#cb78-382" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Vergleich von Residuen für NN und KQ-Schätzung"</span></span>
<span id="cb78-383"><a href="#cb78-383" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-res-nn</span></span>
<span id="cb78-384"><a href="#cb78-384" aria-hidden="true" tabindex="-1"></a><span class="co"># Residuen vergleichen</span></span>
<span id="cb78-385"><a href="#cb78-385" aria-hidden="true" tabindex="-1"></a> <span class="fu">tibble</span>(</span>
<span id="cb78-386"><a href="#cb78-386" aria-hidden="true" tabindex="-1"></a>   <span class="at">NN =</span> y <span class="sc">-</span> model <span class="sc">%&gt;%</span> <span class="fu">predict</span>(x),</span>
<span id="cb78-387"><a href="#cb78-387" aria-hidden="true" tabindex="-1"></a>   <span class="at">lm =</span> lm_model<span class="sc">$</span>residuals</span>
<span id="cb78-388"><a href="#cb78-388" aria-hidden="true" tabindex="-1"></a> ) <span class="sc">%&gt;%</span></span>
<span id="cb78-389"><a href="#cb78-389" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb78-390"><a href="#cb78-390" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> NN, <span class="at">y =</span> lm)) <span class="sc">+</span></span>
<span id="cb78-391"><a href="#cb78-391" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> .<span class="dv">5</span>, <span class="at">color =</span> <span class="st">"steelblue"</span>) <span class="sc">+</span></span>
<span id="cb78-392"><a href="#cb78-392" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_cowplot</span>()</span>
<span id="cb78-393"><a href="#cb78-393" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-394"><a href="#cb78-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-395"><a href="#cb78-395" aria-hidden="true" tabindex="-1"></a>@fig-res-nn zeigt eine gute Korrespondenz zwischen der Anpassung des NN und der KQ-Schätzung des einfachen linearen Modells.</span>
<span id="cb78-396"><a href="#cb78-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-397"><a href="#cb78-397" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multiple Regression</span></span>
<span id="cb78-398"><a href="#cb78-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-399"><a href="#cb78-399" aria-hidden="true" tabindex="-1"></a>Ein neuronales Netz für multiple Regression kann als eine Erweiterung des Netzes für einfache Regression betrachtet werden. Das Netz enthält nun mehrere Input-Neuronen, von denen jedes eine der unabhängigen Variablen $X_1, X_2, \dots, X_k$ repräsentiert. Diese Input-Neuronen sind mit einem einzigen Output-Neuron verbunden, das die Vorhersage für $Y$  liefert. Jede dieser Verbindungen wird mit einem Gewicht $w_i$  multipliziert, das die Stärke des Einflusses der jeweiligen unabhängigen Variable  $X_i$  auf die abhängige Variable  $Y$  repräsentiert. Wie im einfachen Modell gibt es einen Bias-Term $b$, der ähnlich wie in der einen konstanten Einfluss darstellt.</span>
<span id="cb78-400"><a href="#cb78-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-401"><a href="#cb78-401" aria-hidden="true" tabindex="-1"></a>Die Struktur eines NN für multiple Regression ist in @fig-nn-mlreg dargestellt. In diesem Beispiel gibt es drei unabhängige Variablen $X_1$, $X_2$ und $X_3$, die jeweils ein eigenes Input-Neuron haben und mit dem Output-Neuron $Y$ verbunden sind. $Y$ ist eine Linear-Kombination der Inputs, gewichtet mit den jeweiligen Gewichten $w_1$, $w_2$ und $w_3$, sowie dem Bias $b$.</span>
<span id="cb78-402"><a href="#cb78-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-405"><a href="#cb78-405" aria-hidden="true" tabindex="-1"></a><span class="in">```{dot}</span></span>
<span id="cb78-406"><a href="#cb78-406" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-width: 6</span></span>
<span id="cb78-407"><a href="#cb78-407" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-height: 3</span></span>
<span id="cb78-408"><a href="#cb78-408" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-cap: "Neuronales Netzwerk: Multiple lineare Regression"</span></span>
<span id="cb78-409"><a href="#cb78-409" aria-hidden="true" tabindex="-1"></a><span class="in">//| label: "fig-nn-mlreg"</span></span>
<span id="cb78-410"><a href="#cb78-410" aria-hidden="true" tabindex="-1"></a><span class="in">digraph NEURALNET {</span></span>
<span id="cb78-411"><a href="#cb78-411" aria-hidden="true" tabindex="-1"></a><span class="in">    layout=neato</span></span>
<span id="cb78-412"><a href="#cb78-412" aria-hidden="true" tabindex="-1"></a><span class="in">    fontname="Helvetica,Arial,sans-serif"</span></span>
<span id="cb78-413"><a href="#cb78-413" aria-hidden="true" tabindex="-1"></a><span class="in">    node [fontname="Helvetica,Arial,sans-serif", shape="circle"]</span></span>
<span id="cb78-414"><a href="#cb78-414" aria-hidden="true" tabindex="-1"></a><span class="in">    edge [fontname="Helvetica,Arial,sans-serif"]</span></span>
<span id="cb78-415"><a href="#cb78-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-416"><a href="#cb78-416" aria-hidden="true" tabindex="-1"></a><span class="in">    // Eingangsneuronen</span></span>
<span id="cb78-417"><a href="#cb78-417" aria-hidden="true" tabindex="-1"></a><span class="in">    X1 [label="X1", pos="0,1!"];</span></span>
<span id="cb78-418"><a href="#cb78-418" aria-hidden="true" tabindex="-1"></a><span class="in">    X2 [label="X2", pos="0,0!"];</span></span>
<span id="cb78-419"><a href="#cb78-419" aria-hidden="true" tabindex="-1"></a><span class="in">    X3 [label="X3", pos="0,-1!"];</span></span>
<span id="cb78-420"><a href="#cb78-420" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb78-421"><a href="#cb78-421" aria-hidden="true" tabindex="-1"></a><span class="in">    // Summationsneuron</span></span>
<span id="cb78-422"><a href="#cb78-422" aria-hidden="true" tabindex="-1"></a><span class="in">    SUM [label="∑", shape="circle", pos="3,0!", width=0.5, height=0.5, style=filled, fillcolor=lightgray];</span></span>
<span id="cb78-423"><a href="#cb78-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-424"><a href="#cb78-424" aria-hidden="true" tabindex="-1"></a><span class="in">    // Ausgabeneuron</span></span>
<span id="cb78-425"><a href="#cb78-425" aria-hidden="true" tabindex="-1"></a><span class="in">    Y [label="Y", pos="5,0!", style=filled, fillcolor=lightgreen];</span></span>
<span id="cb78-426"><a href="#cb78-426" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb78-427"><a href="#cb78-427" aria-hidden="true" tabindex="-1"></a><span class="in">    // Bias</span></span>
<span id="cb78-428"><a href="#cb78-428" aria-hidden="true" tabindex="-1"></a><span class="in">    B [label="1", pos="3,2!", fontcolor=gray, style=filled, fillcolor=lightblue];</span></span>
<span id="cb78-429"><a href="#cb78-429" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb78-430"><a href="#cb78-430" aria-hidden="true" tabindex="-1"></a><span class="in">    // Verbindungen von Eingangsneuronen zur Summation</span></span>
<span id="cb78-431"><a href="#cb78-431" aria-hidden="true" tabindex="-1"></a><span class="in">    X1 -&gt; SUM [label = "w1"];</span></span>
<span id="cb78-432"><a href="#cb78-432" aria-hidden="true" tabindex="-1"></a><span class="in">    X2 -&gt; SUM [label = "w2"];</span></span>
<span id="cb78-433"><a href="#cb78-433" aria-hidden="true" tabindex="-1"></a><span class="in">    X3 -&gt; SUM [label = "w3"];</span></span>
<span id="cb78-434"><a href="#cb78-434" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb78-435"><a href="#cb78-435" aria-hidden="true" tabindex="-1"></a><span class="in">    // Verbindung vom Bias zur Summation</span></span>
<span id="cb78-436"><a href="#cb78-436" aria-hidden="true" tabindex="-1"></a><span class="in">    B -&gt; SUM [label = "b"];</span></span>
<span id="cb78-437"><a href="#cb78-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-438"><a href="#cb78-438" aria-hidden="true" tabindex="-1"></a><span class="in">    // Verbindung von der Summation zum Ausgabeneuron</span></span>
<span id="cb78-439"><a href="#cb78-439" aria-hidden="true" tabindex="-1"></a><span class="in">    SUM -&gt; Y [label = ""];</span></span>
<span id="cb78-440"><a href="#cb78-440" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb78-441"><a href="#cb78-441" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-442"><a href="#cb78-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-443"><a href="#cb78-443" aria-hidden="true" tabindex="-1"></a>Um die Vorgehensweise in R zu zeigen, generieren wir zunächst $n=250$ Datenpunkte gemäß der Vorschrift</span>
<span id="cb78-444"><a href="#cb78-444" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb78-445"><a href="#cb78-445" aria-hidden="true" tabindex="-1"></a>  Y = 5 + 3 \cdot X_1 + 2\cdot X_2 - 1.5 \cdot X_k + u</span>
<span id="cb78-446"><a href="#cb78-446" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb78-447"><a href="#cb78-447" aria-hidden="true" tabindex="-1"></a>mit $X_1,X_2,X_3 \sim\textup{u.i.v.} N(0, 1)$ und $u\sim N(0,1)$.</span>
<span id="cb78-448"><a href="#cb78-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-451"><a href="#cb78-451" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-452"><a href="#cb78-452" aria-hidden="true" tabindex="-1"></a><span class="co"># Erstellen von Trainingsdaten</span></span>
<span id="cb78-453"><a href="#cb78-453" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb78-454"><a href="#cb78-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-455"><a href="#cb78-455" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">250</span></span>
<span id="cb78-456"><a href="#cb78-456" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb78-457"><a href="#cb78-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-458"><a href="#cb78-458" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="at">n =</span> n <span class="sc">*</span> k), <span class="at">ncol =</span> k)</span>
<span id="cb78-459"><a href="#cb78-459" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">2</span>, <span class="sc">-</span><span class="fl">1.5</span>)</span>
<span id="cb78-460"><a href="#cb78-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-461"><a href="#cb78-461" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="dv">5</span> <span class="sc">+</span> X <span class="sc">%*%</span> w <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb78-462"><a href="#cb78-462" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-463"><a href="#cb78-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-464"><a href="#cb78-464" aria-hidden="true" tabindex="-1"></a>Anschließend definieren wir ein einfaches NN und fügen ein Layer hinzu. Da wir eine multiple Regression durchführen, wählen wir <span class="in">`input_shape = k`</span>, wobei <span class="in">`k`</span> die Anzahl der unabhängigen Variablen ist. Wie im einfachen Modell ist die Aktivierungsfunktion linear, da wir an der Anpassung von $Y$ mit einer linearen Kombination der Inputs interessiert sind.</span>
<span id="cb78-465"><a href="#cb78-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-468"><a href="#cb78-468" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-469"><a href="#cb78-469" aria-hidden="true" tabindex="-1"></a><span class="co"># Erstellen und Kompilieren des Modells</span></span>
<span id="cb78-470"><a href="#cb78-470" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span></span>
<span id="cb78-471"><a href="#cb78-471" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(</span>
<span id="cb78-472"><a href="#cb78-472" aria-hidden="true" tabindex="-1"></a>    <span class="at">units =</span> <span class="dv">1</span>, </span>
<span id="cb78-473"><a href="#cb78-473" aria-hidden="true" tabindex="-1"></a>    <span class="at">input_shape =</span> k, </span>
<span id="cb78-474"><a href="#cb78-474" aria-hidden="true" tabindex="-1"></a>    <span class="at">activation =</span> <span class="st">'linear'</span></span>
<span id="cb78-475"><a href="#cb78-475" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-476"><a href="#cb78-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-477"><a href="#cb78-477" aria-hidden="true" tabindex="-1"></a><span class="co"># Modelldefinition prüfen</span></span>
<span id="cb78-478"><a href="#cb78-478" aria-hidden="true" tabindex="-1"></a>model</span>
<span id="cb78-479"><a href="#cb78-479" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-480"><a href="#cb78-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-481"><a href="#cb78-481" aria-hidden="true" tabindex="-1"></a>Wir kompilieren das Modell mit dem mittleren quadratischen Fehler (mean squared error, MSE) und SGD als Loss-Funktion mit einer moderaten Lernrate.</span>
<span id="cb78-482"><a href="#cb78-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-485"><a href="#cb78-485" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-486"><a href="#cb78-486" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb78-487"><a href="#cb78-487" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(</span>
<span id="cb78-488"><a href="#cb78-488" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> <span class="st">'mean_squared_error'</span>,</span>
<span id="cb78-489"><a href="#cb78-489" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_sgd</span>(<span class="at">learning_rate =</span> <span class="fl">0.01</span>)</span>
<span id="cb78-490"><a href="#cb78-490" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-491"><a href="#cb78-491" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-492"><a href="#cb78-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-493"><a href="#cb78-493" aria-hidden="true" tabindex="-1"></a>Die Anpassung des Modells erfolgt wie bei einfacher Regression mit <span class="in">`keras::fit()`</span>.</span>
<span id="cb78-494"><a href="#cb78-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-497"><a href="#cb78-497" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-498"><a href="#cb78-498" aria-hidden="true" tabindex="-1"></a><span class="co"># Training des Modells</span></span>
<span id="cb78-499"><a href="#cb78-499" aria-hidden="true" tabindex="-1"></a>history_mnn <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> </span>
<span id="cb78-500"><a href="#cb78-500" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb78-501"><a href="#cb78-501" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> X, </span>
<span id="cb78-502"><a href="#cb78-502" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> Y, </span>
<span id="cb78-503"><a href="#cb78-503" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> .<span class="dv">2</span>,</span>
<span id="cb78-504"><a href="#cb78-504" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> <span class="dv">25</span></span>
<span id="cb78-505"><a href="#cb78-505" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-506"><a href="#cb78-506" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-507"><a href="#cb78-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-510"><a href="#cb78-510" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-511"><a href="#cb78-511" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-mnn-loss</span></span>
<span id="cb78-512"><a href="#cb78-512" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "NN für mult. Regression: Entwicklung des Loss für 25 Epochen"</span></span>
<span id="cb78-513"><a href="#cb78-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-514"><a href="#cb78-514" aria-hidden="true" tabindex="-1"></a><span class="co"># Entwicklung des Loss über Epochen plotten</span></span>
<span id="cb78-515"><a href="#cb78-515" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(history_mnn) <span class="sc">+</span></span>
<span id="cb78-516"><a href="#cb78-516" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb78-517"><a href="#cb78-517" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Epoche"</span>,</span>
<span id="cb78-518"><a href="#cb78-518" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Wert der Verlustfunktion"</span></span>
<span id="cb78-519"><a href="#cb78-519" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb78-520"><a href="#cb78-520" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_cowplot</span>() <span class="sc">+</span></span>
<span id="cb78-521"><a href="#cb78-521" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)</span>
<span id="cb78-522"><a href="#cb78-522" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-523"><a href="#cb78-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-524"><a href="#cb78-524" aria-hidden="true" tabindex="-1"></a>Wie bei der einfachen Regression zeigt ein Vergleich der angepassten Gewichte mit den KQ-Schätzungen eines entsprechenden linearen Regressionsmodells ähnliche Ergebnisse beider Ansätze.</span>
<span id="cb78-525"><a href="#cb78-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-528"><a href="#cb78-528" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-529"><a href="#cb78-529" aria-hidden="true" tabindex="-1"></a><span class="co"># Gewichtung und Bias des trainierten NN auslesen</span></span>
<span id="cb78-530"><a href="#cb78-530" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb78-531"><a href="#cb78-531" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">get_weights</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb78-532"><a href="#cb78-532" aria-hidden="true" tabindex="-1"></a>  <span class="fu">flatten_dbl</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb78-533"><a href="#cb78-533" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_names</span>(</span>
<span id="cb78-534"><a href="#cb78-534" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="st">"w_1"</span>, <span class="st">"w_2"</span>, <span class="st">"w_3"</span>, <span class="st">"bias"</span>)</span>
<span id="cb78-535"><a href="#cb78-535" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-536"><a href="#cb78-536" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-537"><a href="#cb78-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-540"><a href="#cb78-540" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-541"><a href="#cb78-541" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiples lineares Modell mit KQ schätzen</span></span>
<span id="cb78-542"><a href="#cb78-542" aria-hidden="true" tabindex="-1"></a>lm_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(</span>
<span id="cb78-543"><a href="#cb78-543" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> Y <span class="sc">~</span> X</span>
<span id="cb78-544"><a href="#cb78-544" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-545"><a href="#cb78-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-546"><a href="#cb78-546" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lm_model)</span>
<span id="cb78-547"><a href="#cb78-547" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-548"><a href="#cb78-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-549"><a href="#cb78-549" aria-hidden="true" tabindex="-1"></a><span class="fu">## Nicht-Lineare Zusammenhänge</span></span>
<span id="cb78-550"><a href="#cb78-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-551"><a href="#cb78-551" aria-hidden="true" tabindex="-1"></a>In diesem Abschnitt verwenden trainieren wir ein NN, um eine logistische Regression durchzuführen. Dieser Ansatz wird häufig verwendet, um eine binäre Outcome-Variablen $Y$ zu modellieren, also Variablen, die zwei mögliche Ausgänge haben (oft als 0 oder 1 dargestellt), siehe @sec-logreg für Details. Anstatt die Eingaben lediglich linear zu kombinieren, verwenden wir eine Sigmoid-Aktivierungsfunktion^<span class="co">[</span><span class="ot">Die Sigmoid-Aktivierungsfunktion entspricht der logistischen Funktion $\Lambda(z)$ aus @sec-logreg.</span><span class="co">]</span>, </span>
<span id="cb78-552"><a href="#cb78-552" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb78-553"><a href="#cb78-553" aria-hidden="true" tabindex="-1"></a>  \sigma(z) = \frac{1}{1 + \exp(-z)},</span>
<span id="cb78-554"><a href="#cb78-554" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb78-555"><a href="#cb78-555" aria-hidden="true" tabindex="-1"></a>welche die Ausgaben auf einen Wertebereich zwischen 0 und 1 abbildet. Dadurch kann das NN Wahrscheinlichkeiten $P(Y=1\vert \boldsymbol{X} = \boldsymbol{x})$ vorhersagen, die anschließend für die *Klassifikation* von Beobachtungen verwendet werden können.</span>
<span id="cb78-556"><a href="#cb78-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-557"><a href="#cb78-557" aria-hidden="true" tabindex="-1"></a>Für die Illustration der Schätzung mit <span class="in">`keras`</span> verwenden wir den DGP aus @sec-probitreg.</span>
<span id="cb78-558"><a href="#cb78-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-561"><a href="#cb78-561" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-562"><a href="#cb78-562" aria-hidden="true" tabindex="-1"></a><span class="co"># Erstellen von Trainingsdaten</span></span>
<span id="cb78-563"><a href="#cb78-563" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb78-564"><a href="#cb78-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-565"><a href="#cb78-565" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb78-566"><a href="#cb78-566" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">2</span>) <span class="co"># Regressor</span></span>
<span id="cb78-567"><a href="#cb78-567" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="dv">4</span> <span class="sc">+</span> <span class="fl">0.7</span> <span class="sc">*</span> X)</span>
<span id="cb78-568"><a href="#cb78-568" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">as.integer</span>(<span class="fu">runif</span>(n) <span class="sc">&lt;</span> P)</span>
<span id="cb78-569"><a href="#cb78-569" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-570"><a href="#cb78-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-571"><a href="#cb78-571" aria-hidden="true" tabindex="-1"></a>@fig-nn-log-reg zeigt ein einfaches NN für eine binäre Outcome-Variable.</span>
<span id="cb78-572"><a href="#cb78-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-575"><a href="#cb78-575" aria-hidden="true" tabindex="-1"></a><span class="in">```{dot}</span></span>
<span id="cb78-576"><a href="#cb78-576" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-width: 6</span></span>
<span id="cb78-577"><a href="#cb78-577" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-height: 4</span></span>
<span id="cb78-578"><a href="#cb78-578" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-cap: "Neuronales Netzwerk mit Sigmoid-Aktivierungsfunktion"</span></span>
<span id="cb78-579"><a href="#cb78-579" aria-hidden="true" tabindex="-1"></a><span class="in">//| label: "fig-nn-log-reg"</span></span>
<span id="cb78-580"><a href="#cb78-580" aria-hidden="true" tabindex="-1"></a><span class="in">digraph NNlogit {</span></span>
<span id="cb78-581"><a href="#cb78-581" aria-hidden="true" tabindex="-1"></a><span class="in">    layout=neato</span></span>
<span id="cb78-582"><a href="#cb78-582" aria-hidden="true" tabindex="-1"></a><span class="in">    fontname="Helvetica,Arial,sans-serif"</span></span>
<span id="cb78-583"><a href="#cb78-583" aria-hidden="true" tabindex="-1"></a><span class="in">    node [fontname="Helvetica,Arial,sans-serif", shape="circle"]</span></span>
<span id="cb78-584"><a href="#cb78-584" aria-hidden="true" tabindex="-1"></a><span class="in">    edge [fontname="Helvetica,Arial,sans-serif"]</span></span>
<span id="cb78-585"><a href="#cb78-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-586"><a href="#cb78-586" aria-hidden="true" tabindex="-1"></a><span class="in">    // Eingangsvariablen</span></span>
<span id="cb78-587"><a href="#cb78-587" aria-hidden="true" tabindex="-1"></a><span class="in">    X [label="X1", pos="0,0!"];</span></span>
<span id="cb78-588"><a href="#cb78-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-589"><a href="#cb78-589" aria-hidden="true" tabindex="-1"></a><span class="in">    // Summationsneuron</span></span>
<span id="cb78-590"><a href="#cb78-590" aria-hidden="true" tabindex="-1"></a><span class="in">    SUM [label="∑", shape="circle", pos="3,0!", width=0.5, height=0.5, style=filled];</span></span>
<span id="cb78-591"><a href="#cb78-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-592"><a href="#cb78-592" aria-hidden="true" tabindex="-1"></a><span class="in">    // Sigmoid-Aktivierungsfunktion</span></span>
<span id="cb78-593"><a href="#cb78-593" aria-hidden="true" tabindex="-1"></a><span class="in">    sigmoid [label="σ", pos="5,0!", style=filled, fillcolor=lightblue];</span></span>
<span id="cb78-594"><a href="#cb78-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-595"><a href="#cb78-595" aria-hidden="true" tabindex="-1"></a><span class="in">    // Output</span></span>
<span id="cb78-596"><a href="#cb78-596" aria-hidden="true" tabindex="-1"></a><span class="in">    Y [label="Y", pos="7,0!", style=filled, fillcolor=lightgreen];</span></span>
<span id="cb78-597"><a href="#cb78-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-598"><a href="#cb78-598" aria-hidden="true" tabindex="-1"></a><span class="in">    // Bias</span></span>
<span id="cb78-599"><a href="#cb78-599" aria-hidden="true" tabindex="-1"></a><span class="in">    B [label="1", pos="3,2!"];</span></span>
<span id="cb78-600"><a href="#cb78-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-601"><a href="#cb78-601" aria-hidden="true" tabindex="-1"></a><span class="in">    // Verbindungen von Eingangsneuronen zur Summation</span></span>
<span id="cb78-602"><a href="#cb78-602" aria-hidden="true" tabindex="-1"></a><span class="in">    X -&gt; SUM [label = "w1"];</span></span>
<span id="cb78-603"><a href="#cb78-603" aria-hidden="true" tabindex="-1"></a><span class="in">    B -&gt; SUM [label = "b"];</span></span>
<span id="cb78-604"><a href="#cb78-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-605"><a href="#cb78-605" aria-hidden="true" tabindex="-1"></a><span class="in">    // Verbindung von der Summation zur Sigmoid-Funktion</span></span>
<span id="cb78-606"><a href="#cb78-606" aria-hidden="true" tabindex="-1"></a><span class="in">    SUM -&gt; sigmoid [label = ""];</span></span>
<span id="cb78-607"><a href="#cb78-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-608"><a href="#cb78-608" aria-hidden="true" tabindex="-1"></a><span class="in">    // Verbindung von der Sigmoid-Funktion zum Output</span></span>
<span id="cb78-609"><a href="#cb78-609" aria-hidden="true" tabindex="-1"></a><span class="in">    sigmoid -&gt; Y [label = ""];</span></span>
<span id="cb78-610"><a href="#cb78-610" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb78-611"><a href="#cb78-611" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-612"><a href="#cb78-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-613"><a href="#cb78-613" aria-hidden="true" tabindex="-1"></a>Nach der Definition des NN wird das Modell mit dem Binary-Cross-Entropy-Loss (BCEL) und dem Adam-Optimierer kompiliert. BCEL ist für binäre Klassifikationsprobleme geeignet: Diese Loss-Funktion misst die die Unterschiede zwischen den vorhergesagten Wahrscheinlichkeiten $\widehat{p}_i$ und den tatsächlichen binären Zielen $y_i$,</span>
<span id="cb78-614"><a href="#cb78-614" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb78-615"><a href="#cb78-615" aria-hidden="true" tabindex="-1"></a>  \textup{BCEL} = -\frac{1}{N} \sum_{i=1}^{N} \left<span class="co">[</span><span class="ot"> y_i \cdot \log(\widehat{p}_i) + (1 - y_i) \cdot \log(1 - \widehat{p}_i) \right</span><span class="co">]</span>.</span>
<span id="cb78-616"><a href="#cb78-616" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb78-617"><a href="#cb78-617" aria-hidden="true" tabindex="-1"></a>Als weitere zu berechnende Metrik wählen wir $\textup{Accuracy}$, ein geläufiges Maß zur Bewertung der Leistung von Klassifikationsmodellen. $\textup{Accuracy}$ gibt an, wie oft das Modell korrekte Vorhersagen getroffen hat, ausgedrückt als Verhältnis der Anzahl der korrekten Vorhersagen zur Gesamtzahl der Vorhersagen,</span>
<span id="cb78-618"><a href="#cb78-618" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb78-619"><a href="#cb78-619" aria-hidden="true" tabindex="-1"></a>  \text{Accuracy} = \frac{\textup{TP} + \textup{TN} }{ \textup{TP} + \textup{TN} + \textup{FP} + \textup{FN} } = \frac{\textup{Anz. korrekte Vorhersagen}}{\textup{Anz. alle Vorhersagen}}.</span>
<span id="cb78-620"><a href="#cb78-620" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb78-621"><a href="#cb78-621" aria-hidden="true" tabindex="-1"></a>Hierbei sind $\textup{TP}$ und $\textup{FP}$ die Anazhl korrekter (*true positive*) und falscher (*false positiv*) Vorhersagen für Beobachtungen mit $y_i = 1$. $\textup{TN}$ und $\textup{FN}$ sind analog für Beobachtungen mit tatsächlichen Werten $y_i = 0$ definiert.</span>
<span id="cb78-622"><a href="#cb78-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-623"><a href="#cb78-623" aria-hidden="true" tabindex="-1"></a>Die Vorhersage von $y_i$ zur Berechnung von $\textup{Accuracy}$ erfolgt durch <span class="in">`keras::fit()`</span> standardmäßig nach der Regel</span>
<span id="cb78-624"><a href="#cb78-624" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb78-625"><a href="#cb78-625" aria-hidden="true" tabindex="-1"></a>  \hat{y}_i =</span>
<span id="cb78-626"><a href="#cb78-626" aria-hidden="true" tabindex="-1"></a>  \begin{cases}</span>
<span id="cb78-627"><a href="#cb78-627" aria-hidden="true" tabindex="-1"></a>    1 &amp; \text{wenn } \hat{p}_i \geq 0.5, <span class="sc">\\</span></span>
<span id="cb78-628"><a href="#cb78-628" aria-hidden="true" tabindex="-1"></a>    0 &amp; \text{wenn } \hat{p}_i &lt; 0.5.</span>
<span id="cb78-629"><a href="#cb78-629" aria-hidden="true" tabindex="-1"></a>  \end{cases}</span>
<span id="cb78-630"><a href="#cb78-630" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb78-631"><a href="#cb78-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-632"><a href="#cb78-632" aria-hidden="true" tabindex="-1"></a>Wir definieren nachchfolgend das Modell-Objekt und passen das NN über 150 Epochen an.</span>
<span id="cb78-633"><a href="#cb78-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-636"><a href="#cb78-636" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-637"><a href="#cb78-637" aria-hidden="true" tabindex="-1"></a><span class="co"># Erstellen und Kompilieren des Modells</span></span>
<span id="cb78-638"><a href="#cb78-638" aria-hidden="true" tabindex="-1"></a>model_nn_logit <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span></span>
<span id="cb78-639"><a href="#cb78-639" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(</span>
<span id="cb78-640"><a href="#cb78-640" aria-hidden="true" tabindex="-1"></a>    <span class="at">units =</span> <span class="dv">1</span>, </span>
<span id="cb78-641"><a href="#cb78-641" aria-hidden="true" tabindex="-1"></a>    <span class="at">input_shape =</span> <span class="dv">1</span>, </span>
<span id="cb78-642"><a href="#cb78-642" aria-hidden="true" tabindex="-1"></a>    <span class="at">activation =</span> <span class="st">'sigmoid'</span> <span class="co"># &lt;= für Logit-Modell</span></span>
<span id="cb78-643"><a href="#cb78-643" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-644"><a href="#cb78-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-645"><a href="#cb78-645" aria-hidden="true" tabindex="-1"></a>model_nn_logit</span>
<span id="cb78-646"><a href="#cb78-646" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-647"><a href="#cb78-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-650"><a href="#cb78-650" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-651"><a href="#cb78-651" aria-hidden="true" tabindex="-1"></a><span class="co"># Modell kompilieren</span></span>
<span id="cb78-652"><a href="#cb78-652" aria-hidden="true" tabindex="-1"></a>model_nn_logit <span class="sc">%&gt;%</span> </span>
<span id="cb78-653"><a href="#cb78-653" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(</span>
<span id="cb78-654"><a href="#cb78-654" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> <span class="st">'binary_crossentropy'</span>, <span class="co"># Für BCEL</span></span>
<span id="cb78-655"><a href="#cb78-655" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_adam</span>(<span class="at">learning_rate =</span> <span class="fl">0.01</span>),</span>
<span id="cb78-656"><a href="#cb78-656" aria-hidden="true" tabindex="-1"></a>    <span class="at">metrics =</span> <span class="st">'accuracy'</span></span>
<span id="cb78-657"><a href="#cb78-657" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-658"><a href="#cb78-658" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-659"><a href="#cb78-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-662"><a href="#cb78-662" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-663"><a href="#cb78-663" aria-hidden="true" tabindex="-1"></a><span class="co"># Anpassen des Modells</span></span>
<span id="cb78-664"><a href="#cb78-664" aria-hidden="true" tabindex="-1"></a>history_nn_logit <span class="ot">&lt;-</span> model_nn_logit <span class="sc">%&gt;%</span> </span>
<span id="cb78-665"><a href="#cb78-665" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb78-666"><a href="#cb78-666" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> X, </span>
<span id="cb78-667"><a href="#cb78-667" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> Y, </span>
<span id="cb78-668"><a href="#cb78-668" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> .<span class="dv">2</span>,</span>
<span id="cb78-669"><a href="#cb78-669" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> <span class="dv">150</span>,</span>
<span id="cb78-670"><a href="#cb78-670" aria-hidden="true" tabindex="-1"></a>    <span class="at">verbose =</span> F</span>
<span id="cb78-671"><a href="#cb78-671" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-672"><a href="#cb78-672" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-673"><a href="#cb78-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-674"><a href="#cb78-674" aria-hidden="true" tabindex="-1"></a>Die Zusammenfassung der Anpassung für die letzte Epoche in <span class="in">`history_nn_logit`</span> zeigt ergibt eine Genauigkeit von über 80\% auf dem Validierungsdatensatz.</span>
<span id="cb78-675"><a href="#cb78-675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-678"><a href="#cb78-678" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-679"><a href="#cb78-679" aria-hidden="true" tabindex="-1"></a>history_nn_logit</span>
<span id="cb78-680"><a href="#cb78-680" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-681"><a href="#cb78-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-684"><a href="#cb78-684" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-685"><a href="#cb78-685" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-mnn-logithist</span></span>
<span id="cb78-686"><a href="#cb78-686" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "NN für Logit-Regression: Entwicklung der Metriken für 25 Epochen"</span></span>
<span id="cb78-687"><a href="#cb78-687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-688"><a href="#cb78-688" aria-hidden="true" tabindex="-1"></a><span class="co"># Entwicklung des Loss über Epochen plotten</span></span>
<span id="cb78-689"><a href="#cb78-689" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(history_nn_logit) <span class="sc">+</span></span>
<span id="cb78-690"><a href="#cb78-690" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb78-691"><a href="#cb78-691" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Epoche"</span>,</span>
<span id="cb78-692"><a href="#cb78-692" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">""</span></span>
<span id="cb78-693"><a href="#cb78-693" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb78-694"><a href="#cb78-694" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_cowplot</span>() <span class="sc">+</span></span>
<span id="cb78-695"><a href="#cb78-695" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)</span>
<span id="cb78-696"><a href="#cb78-696" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-697"><a href="#cb78-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-698"><a href="#cb78-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-701"><a href="#cb78-701" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-702"><a href="#cb78-702" aria-hidden="true" tabindex="-1"></a><span class="co"># Gewicht und Bias extrahieren</span></span>
<span id="cb78-703"><a href="#cb78-703" aria-hidden="true" tabindex="-1"></a>model_nn_logit <span class="sc">%&gt;%</span> </span>
<span id="cb78-704"><a href="#cb78-704" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">get_weights</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb78-705"><a href="#cb78-705" aria-hidden="true" tabindex="-1"></a>  <span class="fu">flatten_dbl</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb78-706"><a href="#cb78-706" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_names</span>(</span>
<span id="cb78-707"><a href="#cb78-707" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="st">"w_1"</span>, <span class="st">"bias"</span>)</span>
<span id="cb78-708"><a href="#cb78-708" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-709"><a href="#cb78-709" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-710"><a href="#cb78-710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-711"><a href="#cb78-711" aria-hidden="true" tabindex="-1"></a>Für einen Vergleich der Vorhersagegüter mit logistischer Regression schätzen wir zunächst ein entsprechendes GLM mit <span class="in">`glm()`</span>. </span>
<span id="cb78-712"><a href="#cb78-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-715"><a href="#cb78-715" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-716"><a href="#cb78-716" aria-hidden="true" tabindex="-1"></a><span class="co"># Logistisches Modell mit glm() anpassen</span></span>
<span id="cb78-717"><a href="#cb78-717" aria-hidden="true" tabindex="-1"></a>glm_mod <span class="ot">&lt;-</span> <span class="fu">glm</span>(</span>
<span id="cb78-718"><a href="#cb78-718" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> Y <span class="sc">~</span> X, </span>
<span id="cb78-719"><a href="#cb78-719" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">"logit"</span>)</span>
<span id="cb78-720"><a href="#cb78-720" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-721"><a href="#cb78-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-722"><a href="#cb78-722" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glm_mod)</span>
<span id="cb78-723"><a href="#cb78-723" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-724"><a href="#cb78-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-725"><a href="#cb78-725" aria-hidden="true" tabindex="-1"></a>Wir erzeugen nun einen Testdatensatz mit 250 Beobachtungen gemäß des oben gewählten DGP.</span>
<span id="cb78-726"><a href="#cb78-726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-729"><a href="#cb78-729" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-730"><a href="#cb78-730" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4321</span>)</span>
<span id="cb78-731"><a href="#cb78-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-732"><a href="#cb78-732" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">250</span></span>
<span id="cb78-733"><a href="#cb78-733" aria-hidden="true" tabindex="-1"></a>data_new <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb78-734"><a href="#cb78-734" aria-hidden="true" tabindex="-1"></a>  <span class="at">X =</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">2</span>),</span>
<span id="cb78-735"><a href="#cb78-735" aria-hidden="true" tabindex="-1"></a>  <span class="at">P =</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="dv">4</span> <span class="sc">+</span> <span class="fl">0.7</span> <span class="sc">*</span> X),</span>
<span id="cb78-736"><a href="#cb78-736" aria-hidden="true" tabindex="-1"></a>  <span class="at">Y =</span> <span class="fu">as.integer</span>(<span class="fu">runif</span>(n) <span class="sc">&lt;</span> P)</span>
<span id="cb78-737"><a href="#cb78-737" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-738"><a href="#cb78-738" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-739"><a href="#cb78-739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-740"><a href="#cb78-740" aria-hidden="true" tabindex="-1"></a>Für die neuen Datenpunkte <span class="in">`data_new`</span> erzeugen wir Vorhersagen von $P(Y=1\vert X=x)$ mit <span class="in">`model_nn_logit`</span> und <span class="in">`glm_mod`</span> und erweitern <span class="in">`data_new`</span> um diese.</span>
<span id="cb78-741"><a href="#cb78-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-744"><a href="#cb78-744" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-745"><a href="#cb78-745" aria-hidden="true" tabindex="-1"></a><span class="co"># Vorhersagen für Trainingsdaten erstellen</span></span>
<span id="cb78-746"><a href="#cb78-746" aria-hidden="true" tabindex="-1"></a>predictions_nn_logit <span class="ot">&lt;-</span> model_nn_logit <span class="sc">%&gt;%</span> </span>
<span id="cb78-747"><a href="#cb78-747" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(data_new<span class="sc">$</span>X) <span class="sc">%&gt;%</span> </span>
<span id="cb78-748"><a href="#cb78-748" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>()</span>
<span id="cb78-749"><a href="#cb78-749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-750"><a href="#cb78-750" aria-hidden="true" tabindex="-1"></a>predictions_glm_logit <span class="ot">&lt;-</span> <span class="fu">predict</span>(</span>
<span id="cb78-751"><a href="#cb78-751" aria-hidden="true" tabindex="-1"></a>    glm_mod, </span>
<span id="cb78-752"><a href="#cb78-752" aria-hidden="true" tabindex="-1"></a>    <span class="at">newdata =</span> data_new, </span>
<span id="cb78-753"><a href="#cb78-753" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">"response"</span></span>
<span id="cb78-754"><a href="#cb78-754" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-755"><a href="#cb78-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-756"><a href="#cb78-756" aria-hidden="true" tabindex="-1"></a><span class="co"># Zusammenfassen</span></span>
<span id="cb78-757"><a href="#cb78-757" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> data_new <span class="sc">%&gt;%</span> </span>
<span id="cb78-758"><a href="#cb78-758" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb78-759"><a href="#cb78-759" aria-hidden="true" tabindex="-1"></a>    <span class="at">nn_logit =</span> predictions_nn_logit,</span>
<span id="cb78-760"><a href="#cb78-760" aria-hidden="true" tabindex="-1"></a>    <span class="at">glm_logit =</span> predictions_glm_logit</span>
<span id="cb78-761"><a href="#cb78-761" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-762"><a href="#cb78-762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-763"><a href="#cb78-763" aria-hidden="true" tabindex="-1"></a><span class="fu">slice_head</span>(results, <span class="at">n =</span> <span class="dv">10</span>)</span>
<span id="cb78-764"><a href="#cb78-764" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-765"><a href="#cb78-765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-766"><a href="#cb78-766" aria-hidden="true" tabindex="-1"></a>Für eine erste Beurteilung anhand der Vorhersagen auf dem Testdatensatz plotten wir die vorhergesagten Wahrscheinlichkeiten als Funktion von <span class="in">`X`</span> gemeinsam mit den tatsächlichen Ausprägungen der Outcome-Variable <span class="in">`Y`</span>.</span>
<span id="cb78-767"><a href="#cb78-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-770"><a href="#cb78-770" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-771"><a href="#cb78-771" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb78-772"><a href="#cb78-772" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cowplot)</span>
<span id="cb78-773"><a href="#cb78-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-774"><a href="#cb78-774" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot der tatsächlichen Werte gegen die vorhergesagten Wahrscheinlichkeiten</span></span>
<span id="cb78-775"><a href="#cb78-775" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(</span>
<span id="cb78-776"><a href="#cb78-776" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> results,</span>
<span id="cb78-777"><a href="#cb78-777" aria-hidden="true" tabindex="-1"></a>  <span class="at">mapping =</span>  <span class="fu">aes</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y)</span>
<span id="cb78-778"><a href="#cb78-778" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb78-779"><a href="#cb78-779" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(</span>
<span id="cb78-780"><a href="#cb78-780" aria-hidden="true" tabindex="-1"></a>    <span class="at">position =</span> <span class="fu">position_jitter</span>(<span class="at">height =</span> <span class="fl">0.05</span>), </span>
<span id="cb78-781"><a href="#cb78-781" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.5</span></span>
<span id="cb78-782"><a href="#cb78-782" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb78-783"><a href="#cb78-783" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(</span>
<span id="cb78-784"><a href="#cb78-784" aria-hidden="true" tabindex="-1"></a>     <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">y =</span> nn_logit),</span>
<span id="cb78-785"><a href="#cb78-785" aria-hidden="true" tabindex="-1"></a>    <span class="at">col =</span> <span class="st">"darkred"</span></span>
<span id="cb78-786"><a href="#cb78-786" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb78-787"><a href="#cb78-787" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(</span>
<span id="cb78-788"><a href="#cb78-788" aria-hidden="true" tabindex="-1"></a>    <span class="at">method =</span> <span class="st">"glm"</span>, </span>
<span id="cb78-789"><a href="#cb78-789" aria-hidden="true" tabindex="-1"></a>    <span class="at">method.args =</span> <span class="fu">list</span>(<span class="at">family =</span> <span class="st">"binomial"</span>), </span>
<span id="cb78-790"><a href="#cb78-790" aria-hidden="true" tabindex="-1"></a>    <span class="at">se =</span> <span class="cn">FALSE</span></span>
<span id="cb78-791"><a href="#cb78-791" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb78-792"><a href="#cb78-792" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb78-793"><a href="#cb78-793" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Logistische Regression vs. NN"</span>,</span>
<span id="cb78-794"><a href="#cb78-794" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"x"</span>,</span>
<span id="cb78-795"><a href="#cb78-795" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Schätzung v. P(Y=1|X=x)"</span></span>
<span id="cb78-796"><a href="#cb78-796" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb78-797"><a href="#cb78-797" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_cowplot</span>()</span>
<span id="cb78-798"><a href="#cb78-798" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-799"><a href="#cb78-799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-800"><a href="#cb78-800" aria-hidden="true" tabindex="-1"></a>Die geschätzten Wahrscheinlichkeitsfunktionen zeigen eine gute Übereinstimmung. Um die Vorhersagegüte von <span class="in">`model_nn_logit`</span> und <span class="in">`model_glm_logit`</span> genauer zu untersuchen, erstellen wir Plots der jeweilgen *Receiver Operating Characteristic* (ROC). ROC zeigt den Zusammenhang zwischen der *True Positive Rate* (TPR), dem Anteil korrekter Vorhersagen für $y_i=1$ (auch *Sensitivität* gennant) und der *False Positive Rate* (FPR), dem Anteil falscher Vorhersagen für $y_i=1$ in Abhängigkeit des Schwellenwerts von $\widehat{p}$ für die Klassifikation des Outcomes einer Beobachtung $y_i = 1$. Es gilt</span>
<span id="cb78-801"><a href="#cb78-801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-802"><a href="#cb78-802" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb78-803"><a href="#cb78-803" aria-hidden="true" tabindex="-1"></a>  TPR =&amp;\, \frac{TP}{TP + FN},<span class="sc">\\</span></span>
<span id="cb78-804"><a href="#cb78-804" aria-hidden="true" tabindex="-1"></a>  <span class="sc">\\</span></span>
<span id="cb78-805"><a href="#cb78-805" aria-hidden="true" tabindex="-1"></a>  FPR =&amp;\, \frac{FP}{FP + TN}.</span>
<span id="cb78-806"><a href="#cb78-806" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb78-807"><a href="#cb78-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-808"><a href="#cb78-808" aria-hidden="true" tabindex="-1"></a>Der Schwellenwert $\widehat{p}$ reguliert den Trade-Off zwischen $\textup{FPR}$ und $\textup{TPR}$: Kleine $\widehat{p}$ führen tendenziell zu großer $\textup{TPR}$ (gut), aber auch zu großer $\textup{FPR}$ (schlecht). Für ein Modell, das zufällig klassifiziert, entspricht die ROC-Kurve der Winkelhalbierenden. Wünschenwert ist ein verlauf der ROC-Kurve möglichst oberhalb der Winkelhalbierenden. </span>
<span id="cb78-809"><a href="#cb78-809" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-810"><a href="#cb78-810" aria-hidden="true" tabindex="-1"></a>Eine ROC-Kurve kann in R mit dem <span class="in">`plotROC`</span> anhand der Vorhergesagten und tatsächlichen Werte der Outcome-Varibale berechnet und geplottet werden. Hierzu transformieren wir <span class="in">`results`</span> in langes Format und verwenden <span class="in">`ggplot()`</span> mit dem Layer <span class="in">`geom_roc()`</span>.</span>
<span id="cb78-811"><a href="#cb78-811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-814"><a href="#cb78-814" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-815"><a href="#cb78-815" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-nnlogit-roc</span></span>
<span id="cb78-816"><a href="#cb78-816" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "ROC-Kurve für logistische Modelle"</span></span>
<span id="cb78-817"><a href="#cb78-817" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotROC)</span>
<span id="cb78-818"><a href="#cb78-818" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb78-819"><a href="#cb78-819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-820"><a href="#cb78-820" aria-hidden="true" tabindex="-1"></a>roc_data <span class="ot">&lt;-</span> results <span class="sc">%&gt;%</span></span>
<span id="cb78-821"><a href="#cb78-821" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(</span>
<span id="cb78-822"><a href="#cb78-822" aria-hidden="true" tabindex="-1"></a>    <span class="at">cols =</span> glm_logit<span class="sc">:</span>nn_logit,</span>
<span id="cb78-823"><a href="#cb78-823" aria-hidden="true" tabindex="-1"></a>    <span class="at">names_to =</span> <span class="st">"model"</span>, </span>
<span id="cb78-824"><a href="#cb78-824" aria-hidden="true" tabindex="-1"></a>    <span class="at">values_to =</span> <span class="st">"pp"</span></span>
<span id="cb78-825"><a href="#cb78-825" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb78-826"><a href="#cb78-826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-827"><a href="#cb78-827" aria-hidden="true" tabindex="-1"></a><span class="co"># ROC-Kurve plotten</span></span>
<span id="cb78-828"><a href="#cb78-828" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(</span>
<span id="cb78-829"><a href="#cb78-829" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> roc_data, </span>
<span id="cb78-830"><a href="#cb78-830" aria-hidden="true" tabindex="-1"></a>    <span class="at">mapping =</span> <span class="fu">aes</span>(</span>
<span id="cb78-831"><a href="#cb78-831" aria-hidden="true" tabindex="-1"></a>      <span class="at">m =</span> pp, </span>
<span id="cb78-832"><a href="#cb78-832" aria-hidden="true" tabindex="-1"></a>      <span class="at">d =</span> Y, </span>
<span id="cb78-833"><a href="#cb78-833" aria-hidden="true" tabindex="-1"></a>      <span class="at">colour =</span> model</span>
<span id="cb78-834"><a href="#cb78-834" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb78-835"><a href="#cb78-835" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb78-836"><a href="#cb78-836" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_roc</span>() <span class="sc">+</span></span>
<span id="cb78-837"><a href="#cb78-837" aria-hidden="true" tabindex="-1"></a>  <span class="fu">style_roc</span>() <span class="sc">+</span> </span>
<span id="cb78-838"><a href="#cb78-838" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> model) <span class="sc">+</span></span>
<span id="cb78-839"><a href="#cb78-839" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)</span>
<span id="cb78-840"><a href="#cb78-840" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-841"><a href="#cb78-841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-842"><a href="#cb78-842" aria-hidden="true" tabindex="-1"></a>@fig-nnlogit-roc zeigt sehr ähnliche ROC-Kurven für <span class="in">`model_nn_logit`</span> und <span class="in">`model_glm_logit`</span>.^<span class="co">[</span><span class="ot">Beide Plots enthalten Indikatoren des ROC für bestimmte Schwellenwerte $\widehat{p}$.</span><span class="co">]</span> Für die Quantifizierung der Vorhersageleistung wird *Area under the Curve* (AUC), die Fläche unterhalb der ROC-Kurve, herangezogen. Mit <span class="in">`plotROC::calc_auc()`</span> kann AUC aus dem <span class="in">`geom_roc()`</span>-Layer berechnet werden. Für ein geschätztes Modell $\widehat{M}$ gilt $0\leq\textup{AUC}(\widehat{M})\leq1$.^<span class="co">[</span><span class="ot">Ein geschätzes, dass nicht besser als raten ist, gilt $\textup{AUC}(\widehat{M})=.5$.</span><span class="co">]</span></span>
<span id="cb78-843"><a href="#cb78-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-846"><a href="#cb78-846" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-847"><a href="#cb78-847" aria-hidden="true" tabindex="-1"></a><span class="co"># AUC berechnen</span></span>
<span id="cb78-848"><a href="#cb78-848" aria-hidden="true" tabindex="-1"></a>roc_data <span class="sc">%&gt;%</span></span>
<span id="cb78-849"><a href="#cb78-849" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(model) <span class="sc">%&gt;%</span></span>
<span id="cb78-850"><a href="#cb78-850" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb78-851"><a href="#cb78-851" aria-hidden="true" tabindex="-1"></a>    <span class="at">AUC =</span> <span class="fu">calc_auc</span>(</span>
<span id="cb78-852"><a href="#cb78-852" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">m =</span> pp, <span class="at">d =</span> Y)) <span class="sc">+</span></span>
<span id="cb78-853"><a href="#cb78-853" aria-hidden="true" tabindex="-1"></a>        <span class="fu">geom_roc</span>()</span>
<span id="cb78-854"><a href="#cb78-854" aria-hidden="true" tabindex="-1"></a>    )<span class="sc">$</span>AUC</span>
<span id="cb78-855"><a href="#cb78-855" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-856"><a href="#cb78-856" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-857"><a href="#cb78-857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-858"><a href="#cb78-858" aria-hidden="true" tabindex="-1"></a>Der Vergleich der AUC-Statistiken beider Modelle für den Testdatensatz zeigt, dass das NN ähnlich gut klassifizert, wie das GLM mit logistischer Link-Funktion.</span>
<span id="cb78-859"><a href="#cb78-859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-860"><a href="#cb78-860" aria-hidden="true" tabindex="-1"></a><span class="fu">## Empirisches Beispiel: Boston Housing</span></span>
<span id="cb78-861"><a href="#cb78-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-862"><a href="#cb78-862" aria-hidden="true" tabindex="-1"></a>In diesem Beispiel illustrieren wir die Anwendung von (NN) für den Boston Housing-Datensatz <span class="in">`MASS::Boston`</span>. <span class="in">`Boston`</span> enthält enthält verschiedene Charakteristika von Häusern in Boston, wie z.B. Kriminalitätsrate, Anzahl der Räume und Alter der Gebäude. Ziel ist esm den Medianpreis der Häuser (<span class="in">`medv`</span>) vorherzusagen.</span>
<span id="cb78-863"><a href="#cb78-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-864"><a href="#cb78-864" aria-hidden="true" tabindex="-1"></a>Für die Analyse verwenden wir insbesondere die Pakete <span class="in">`tidymodels`</span> und <span class="in">`recipes`</span>. Das <span class="in">`recipes`</span>-Paket erlaubt eine automatisierte und leicht reproduzierbare Vorbereitung  von Datensätzen für statistische Modellierung mit <span class="in">`tidymodels`</span>. Es stellt Verben zur Konstruktion von Pipelines mit Schritten wie Skalierung, Kodierung und Handling fehlender Werte bereit. Diese Schritte werden mit einem Rezept (<span class="in">`recipe()`</span>) definiert, vorbereitet (<span class="in">`prep()`</span>) und dann auf Trainings- und/oder Testdaten angewendet (<span class="in">`bake()`</span>).</span>
<span id="cb78-865"><a href="#cb78-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-866"><a href="#cb78-866" aria-hidden="true" tabindex="-1"></a>Zunächst laden wir den Boston Housing-Datensatz und teilen <span class="in">`boston_tbl`</span> in Trainings- und Testdaten auf. Hierbei verwenden wir 80% der Daten für das Training und reservieren 20% zum Testen.</span>
<span id="cb78-867"><a href="#cb78-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-870"><a href="#cb78-870" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-871"><a href="#cb78-871" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb78-872"><a href="#cb78-872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-873"><a href="#cb78-873" aria-hidden="true" tabindex="-1"></a><span class="co"># Datensatz in tibble umwandeln </span></span>
<span id="cb78-874"><a href="#cb78-874" aria-hidden="true" tabindex="-1"></a>boston_tbl <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(MASS<span class="sc">::</span>Boston)</span>
<span id="cb78-875"><a href="#cb78-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-876"><a href="#cb78-876" aria-hidden="true" tabindex="-1"></a><span class="co"># Trainings- und Testdaten einteilen </span></span>
<span id="cb78-877"><a href="#cb78-877" aria-hidden="true" tabindex="-1"></a><span class="co"># (80% / 20%)</span></span>
<span id="cb78-878"><a href="#cb78-878" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb78-879"><a href="#cb78-879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-880"><a href="#cb78-880" aria-hidden="true" tabindex="-1"></a>split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(boston_tbl, <span class="at">prop =</span> <span class="fl">0.8</span>)</span>
<span id="cb78-881"><a href="#cb78-881" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> <span class="fu">training</span>(split)</span>
<span id="cb78-882"><a href="#cb78-882" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> <span class="fu">testing</span>(split)</span>
<span id="cb78-883"><a href="#cb78-883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-884"><a href="#cb78-884" aria-hidden="true" tabindex="-1"></a><span class="co"># Zielvariable und Prädiktoren aufteilen</span></span>
<span id="cb78-885"><a href="#cb78-885" aria-hidden="true" tabindex="-1"></a>train_x <span class="ot">&lt;-</span> <span class="fu">select</span>(train_data, <span class="sc">-</span>medv)</span>
<span id="cb78-886"><a href="#cb78-886" aria-hidden="true" tabindex="-1"></a>train_y <span class="ot">&lt;-</span> train_data<span class="sc">$</span>medv</span>
<span id="cb78-887"><a href="#cb78-887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-888"><a href="#cb78-888" aria-hidden="true" tabindex="-1"></a>test_x <span class="ot">&lt;-</span> <span class="fu">select</span>(test_data, <span class="sc">-</span>medv)</span>
<span id="cb78-889"><a href="#cb78-889" aria-hidden="true" tabindex="-1"></a>test_y <span class="ot">&lt;-</span> test_data<span class="sc">$</span>medv</span>
<span id="cb78-890"><a href="#cb78-890" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-891"><a href="#cb78-891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-892"><a href="#cb78-892" aria-hidden="true" tabindex="-1"></a>Da neuronale Netze empfindlich auf unterschiedlich skalierte Eingabedaten reagieren (ähnlich wie regularisierte Schätzer, vgl. @sec-regreg), normalisieren wir sämtliche (numerischen) Prädiktoren, ausgenommen <span class="in">`chas`</span> und <span class="in">`rad`</span>, mit <span class="in">`recipes::step_normalize()`</span>.</span>
<span id="cb78-893"><a href="#cb78-893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-896"><a href="#cb78-896" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-897"><a href="#cb78-897" aria-hidden="true" tabindex="-1"></a><span class="co"># Daten normalisieren</span></span>
<span id="cb78-898"><a href="#cb78-898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-899"><a href="#cb78-899" aria-hidden="true" tabindex="-1"></a><span class="co"># Rezept</span></span>
<span id="cb78-900"><a href="#cb78-900" aria-hidden="true" tabindex="-1"></a>recipe_obj <span class="ot">&lt;-</span> <span class="fu">recipe</span>(</span>
<span id="cb78-901"><a href="#cb78-901" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> medv <span class="sc">~</span> ., </span>
<span id="cb78-902"><a href="#cb78-902" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train_data</span>
<span id="cb78-903"><a href="#cb78-903" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb78-904"><a href="#cb78-904" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_normalize</span>(</span>
<span id="cb78-905"><a href="#cb78-905" aria-hidden="true" tabindex="-1"></a>    <span class="fu">all_predictors</span>(), <span class="sc">-</span>chas, <span class="sc">-</span>rad</span>
<span id="cb78-906"><a href="#cb78-906" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-907"><a href="#cb78-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-908"><a href="#cb78-908" aria-hidden="true" tabindex="-1"></a><span class="co"># Vorbreiten</span></span>
<span id="cb78-909"><a href="#cb78-909" aria-hidden="true" tabindex="-1"></a>data_prep <span class="ot">&lt;-</span> <span class="fu">prep</span>(</span>
<span id="cb78-910"><a href="#cb78-910" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> recipe_obj, </span>
<span id="cb78-911"><a href="#cb78-911" aria-hidden="true" tabindex="-1"></a>  <span class="at">training =</span> train_data</span>
<span id="cb78-912"><a href="#cb78-912" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-913"><a href="#cb78-913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-914"><a href="#cb78-914" aria-hidden="true" tabindex="-1"></a><span class="co"># Anwenden</span></span>
<span id="cb78-915"><a href="#cb78-915" aria-hidden="true" tabindex="-1"></a>train_x <span class="ot">&lt;-</span> <span class="fu">bake</span>(</span>
<span id="cb78-916"><a href="#cb78-916" aria-hidden="true" tabindex="-1"></a>  <span class="at">object =</span> data_prep, </span>
<span id="cb78-917"><a href="#cb78-917" aria-hidden="true" tabindex="-1"></a>  <span class="at">new_data =</span> train_data</span>
<span id="cb78-918"><a href="#cb78-918" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb78-919"><a href="#cb78-919" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>medv)</span>
<span id="cb78-920"><a href="#cb78-920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-921"><a href="#cb78-921" aria-hidden="true" tabindex="-1"></a>test_x <span class="ot">&lt;-</span> <span class="fu">bake</span>(</span>
<span id="cb78-922"><a href="#cb78-922" aria-hidden="true" tabindex="-1"></a>  <span class="at">object =</span> data_prep, </span>
<span id="cb78-923"><a href="#cb78-923" aria-hidden="true" tabindex="-1"></a>  <span class="at">new_data =</span> test_data) <span class="sc">%&gt;%</span> </span>
<span id="cb78-924"><a href="#cb78-924" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>medv)</span>
<span id="cb78-925"><a href="#cb78-925" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-926"><a href="#cb78-926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-927"><a href="#cb78-927" aria-hidden="true" tabindex="-1"></a>Zunächst führen wir eine KQ-Regression durch, um den Zusammenhang zwischen sämtlichen verfügbaren Prädiktoren und dem Zielwert <span class="in">`medv`</span> zu schätzen. Hierfür nutzen wir das linear_reg()-Modell aus tidymodels und passen es mit der Methode der kleinsten Quadrate (KQ) an.</span>
<span id="cb78-928"><a href="#cb78-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-931"><a href="#cb78-931" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-932"><a href="#cb78-932" aria-hidden="true" tabindex="-1"></a><span class="co"># Lineare Regression mit KQ</span></span>
<span id="cb78-933"><a href="#cb78-933" aria-hidden="true" tabindex="-1"></a>kq_spec <span class="ot">&lt;-</span> <span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span></span>
<span id="cb78-934"><a href="#cb78-934" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"lm"</span>)</span>
<span id="cb78-935"><a href="#cb78-935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-936"><a href="#cb78-936" aria-hidden="true" tabindex="-1"></a>kq_fit <span class="ot">&lt;-</span> <span class="fu">fit</span>(</span>
<span id="cb78-937"><a href="#cb78-937" aria-hidden="true" tabindex="-1"></a>  <span class="at">object =</span> kq_spec, </span>
<span id="cb78-938"><a href="#cb78-938" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> medv <span class="sc">~</span> ., </span>
<span id="cb78-939"><a href="#cb78-939" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train_data</span>
<span id="cb78-940"><a href="#cb78-940" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-941"><a href="#cb78-941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-942"><a href="#cb78-942" aria-hidden="true" tabindex="-1"></a><span class="co"># KQ-Vorhersagen für Testdaten</span></span>
<span id="cb78-943"><a href="#cb78-943" aria-hidden="true" tabindex="-1"></a>kq_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(</span>
<span id="cb78-944"><a href="#cb78-944" aria-hidden="true" tabindex="-1"></a>  <span class="at">object =</span> kq_fit, </span>
<span id="cb78-945"><a href="#cb78-945" aria-hidden="true" tabindex="-1"></a>  <span class="at">new_data =</span> test_data</span>
<span id="cb78-946"><a href="#cb78-946" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb78-947"><a href="#cb78-947" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(test_data) <span class="sc">%&gt;%</span></span>
<span id="cb78-948"><a href="#cb78-948" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">kq_pred =</span> .pred)</span>
<span id="cb78-949"><a href="#cb78-949" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-950"><a href="#cb78-950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-951"><a href="#cb78-951" aria-hidden="true" tabindex="-1"></a>Für das NN wählen wir eine Spezifikation mit zwei Hidden Layers, die jeweils 64 Neuronen haben. Mit <span class="in">`input_shape = ncol(train_x)`</span> verarbeitet das 1. Hidden Layer die Inputs sämtlicher Prädiktoren in <span class="in">`boston_tbl`</span>. Als Aktivierungsfunktion verwenden wir *Recified Linear Unit*,</span>
<span id="cb78-952"><a href="#cb78-952" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb78-953"><a href="#cb78-953" aria-hidden="true" tabindex="-1"></a>      \textup{ReLU}(z) \max(0, z).<span class="sc">\\</span></span>
<span id="cb78-954"><a href="#cb78-954" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb78-955"><a href="#cb78-955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-956"><a href="#cb78-956" aria-hidden="true" tabindex="-1"></a>Die ReLU-Aktivierungsfunktion setzt also negative Werte auf 0 und lässt positive Werte unverändert. In NN ermöglicht sie eine sparsame anpassung und ist numerisch leicht handhabbar bei der Berechnung des Gradienten: Die Verwendung von Layers mit ReLU verringert das *Vanishing-Gradient-Problem*.^<span class="co">[</span><span class="ot">Bei nicht-linearen Aktivierungsfunktionen kann der Gradient der Loss-Funktion extrem klein werden, was das Training von NN mit vielen Layers schwierig machen kann.</span><span class="co">]</span></span>
<span id="cb78-957"><a href="#cb78-957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-958"><a href="#cb78-958" aria-hidden="true" tabindex="-1"></a>Das Output Layer des Netzes besteht aus einem einzigen Neuron, dass einen numerischen Wert (den geschätzten Hauspreis) zurückgibt.</span>
<span id="cb78-959"><a href="#cb78-959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-962"><a href="#cb78-962" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-963"><a href="#cb78-963" aria-hidden="true" tabindex="-1"></a><span class="co"># NN mit Keras erstellen</span></span>
<span id="cb78-964"><a href="#cb78-964" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span></span>
<span id="cb78-965"><a href="#cb78-965" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Hidden Layer 1</span></span>
<span id="cb78-966"><a href="#cb78-966" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(</span>
<span id="cb78-967"><a href="#cb78-967" aria-hidden="true" tabindex="-1"></a>    <span class="at">units =</span> <span class="dv">64</span>, </span>
<span id="cb78-968"><a href="#cb78-968" aria-hidden="true" tabindex="-1"></a>    <span class="at">activation =</span> <span class="st">"relu"</span>, </span>
<span id="cb78-969"><a href="#cb78-969" aria-hidden="true" tabindex="-1"></a>    <span class="at">input_shape =</span> <span class="fu">ncol</span>(train_x)</span>
<span id="cb78-970"><a href="#cb78-970" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb78-971"><a href="#cb78-971" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Hidden Layer 2</span></span>
<span id="cb78-972"><a href="#cb78-972" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(</span>
<span id="cb78-973"><a href="#cb78-973" aria-hidden="true" tabindex="-1"></a>    <span class="at">units =</span> <span class="dv">64</span>, </span>
<span id="cb78-974"><a href="#cb78-974" aria-hidden="true" tabindex="-1"></a>    <span class="at">activation =</span> <span class="st">"relu"</span></span>
<span id="cb78-975"><a href="#cb78-975" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb78-976"><a href="#cb78-976" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Output Layer</span></span>
<span id="cb78-977"><a href="#cb78-977" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">1</span>)</span>
<span id="cb78-978"><a href="#cb78-978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-979"><a href="#cb78-979" aria-hidden="true" tabindex="-1"></a><span class="co"># Modell kompilieren</span></span>
<span id="cb78-980"><a href="#cb78-980" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb78-981"><a href="#cb78-981" aria-hidden="true" tabindex="-1"></a>  <span class="at">optimizer =</span> <span class="st">"rmsprop"</span>,</span>
<span id="cb78-982"><a href="#cb78-982" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss =</span> <span class="st">"mse"</span>,</span>
<span id="cb78-983"><a href="#cb78-983" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="st">"mae"</span></span>
<span id="cb78-984"><a href="#cb78-984" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-985"><a href="#cb78-985" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-986"><a href="#cb78-986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-987"><a href="#cb78-987" aria-hidden="true" tabindex="-1"></a>Wir trainieren das NN über 100 Epochen mit einem Batch-Größe von 32 Datenpunkten.</span>
<span id="cb78-988"><a href="#cb78-988" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-991"><a href="#cb78-991" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-992"><a href="#cb78-992" aria-hidden="true" tabindex="-1"></a><span class="co"># Modell trainieren</span></span>
<span id="cb78-993"><a href="#cb78-993" aria-hidden="true" tabindex="-1"></a>history <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> </span>
<span id="cb78-994"><a href="#cb78-994" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb78-995"><a href="#cb78-995" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">as.matrix</span>(train_x), </span>
<span id="cb78-996"><a href="#cb78-996" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> train_y,</span>
<span id="cb78-997"><a href="#cb78-997" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> <span class="dv">100</span>,</span>
<span id="cb78-998"><a href="#cb78-998" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size =</span> <span class="dv">32</span>,</span>
<span id="cb78-999"><a href="#cb78-999" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> <span class="fl">0.2</span>,</span>
<span id="cb78-1000"><a href="#cb78-1000" aria-hidden="true" tabindex="-1"></a>    <span class="at">verbose =</span> <span class="dv">0</span></span>
<span id="cb78-1001"><a href="#cb78-1001" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-1002"><a href="#cb78-1002" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-1003"><a href="#cb78-1003" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1004"><a href="#cb78-1004" aria-hidden="true" tabindex="-1"></a>Mit dem trainierten Nachdem das NN trainiert ist, verwenden wir <span class="in">`model`</span>, um Vorhersagen auf den Testdaten <span class="in">`test_data`</span> zu machen.</span>
<span id="cb78-1005"><a href="#cb78-1005" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1008"><a href="#cb78-1008" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-1009"><a href="#cb78-1009" aria-hidden="true" tabindex="-1"></a><span class="co"># Vorhersagen mit trainiertem NN</span></span>
<span id="cb78-1010"><a href="#cb78-1010" aria-hidden="true" tabindex="-1"></a>nn_pred <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> </span>
<span id="cb78-1011"><a href="#cb78-1011" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(<span class="fu">as.matrix</span>(test_x))</span>
<span id="cb78-1012"><a href="#cb78-1012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1013"><a href="#cb78-1013" aria-hidden="true" tabindex="-1"></a><span class="co"># Testdaten erweitern</span></span>
<span id="cb78-1014"><a href="#cb78-1014" aria-hidden="true" tabindex="-1"></a>nn_predictions <span class="ot">&lt;-</span> test_data <span class="sc">%&gt;%</span></span>
<span id="cb78-1015"><a href="#cb78-1015" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb78-1016"><a href="#cb78-1016" aria-hidden="true" tabindex="-1"></a>    <span class="at">nn_pred =</span> <span class="fu">c</span>(nn_pred)</span>
<span id="cb78-1017"><a href="#cb78-1017" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-1018"><a href="#cb78-1018" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-1019"><a href="#cb78-1019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1020"><a href="#cb78-1020" aria-hidden="true" tabindex="-1"></a>Um die Leistung der Modelle zu vergleichen, berechnen wir den MSE für beide Modelle.</span>
<span id="cb78-1021"><a href="#cb78-1021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1024"><a href="#cb78-1024" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-1025"><a href="#cb78-1025" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE berechnen</span></span>
<span id="cb78-1026"><a href="#cb78-1026" aria-hidden="true" tabindex="-1"></a>ols_mse <span class="ot">&lt;-</span> kq_predictions <span class="sc">%&gt;%</span></span>
<span id="cb78-1027"><a href="#cb78-1027" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">mse =</span> <span class="fu">mean</span>((medv <span class="sc">-</span> kq_pred)<span class="sc">^</span><span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb78-1028"><a href="#cb78-1028" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(mse)</span>
<span id="cb78-1029"><a href="#cb78-1029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1030"><a href="#cb78-1030" aria-hidden="true" tabindex="-1"></a>nn_mse <span class="ot">&lt;-</span> nn_predictions <span class="sc">%&gt;%</span></span>
<span id="cb78-1031"><a href="#cb78-1031" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">mse =</span> <span class="fu">mean</span>((medv <span class="sc">-</span> nn_pred)<span class="sc">^</span><span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb78-1032"><a href="#cb78-1032" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(mse)</span>
<span id="cb78-1033"><a href="#cb78-1033" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1034"><a href="#cb78-1034" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(</span>
<span id="cb78-1035"><a href="#cb78-1035" aria-hidden="true" tabindex="-1"></a>  <span class="st">"MSE KQ"</span> <span class="ot">=</span> ols_mse,</span>
<span id="cb78-1036"><a href="#cb78-1036" aria-hidden="true" tabindex="-1"></a>  <span class="st">"MSE NN"</span> <span class="ot">=</span> nn_mse</span>
<span id="cb78-1037"><a href="#cb78-1037" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-1038"><a href="#cb78-1038" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-1039"><a href="#cb78-1039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1040"><a href="#cb78-1040" aria-hidden="true" tabindex="-1"></a>Da das NN ist in der Lage ist, nicht-lineare Zusammenhänge zwischen den Prädiktoren und der Zielvariablen zu modellieren, liefert hat es eine höhere Vorhersagegenauigkeit auf dem Testdatensatz.</span>
<span id="cb78-1041"><a href="#cb78-1041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1042"><a href="#cb78-1042" aria-hidden="true" tabindex="-1"></a>Für eine Visualisierung der Vorhersagen tragen wir den wahren und die vorhergesagten Werte von <span class="in">`medv`</span> für beide Modelle in einem Punkteplot ab.</span>
<span id="cb78-1043"><a href="#cb78-1043" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1046"><a href="#cb78-1046" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-1047"><a href="#cb78-1047" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Boston Housing: KQ vs. NN"</span></span>
<span id="cb78-1048"><a href="#cb78-1048" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-bhkq-nn</span></span>
<span id="cb78-1049"><a href="#cb78-1049" aria-hidden="true" tabindex="-1"></a><span class="co"># KQ- und NN-Vorhersagen sammeln</span></span>
<span id="cb78-1050"><a href="#cb78-1050" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> kq_predictions <span class="sc">%&gt;%</span></span>
<span id="cb78-1051"><a href="#cb78-1051" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(medv, kq_pred) <span class="sc">%&gt;%</span></span>
<span id="cb78-1052"><a href="#cb78-1052" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">nn_pred =</span> nn_predictions<span class="sc">$</span>nn_pred)</span>
<span id="cb78-1053"><a href="#cb78-1053" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1054"><a href="#cb78-1054" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisierung der Ergebnisse mit ggplot2</span></span>
<span id="cb78-1055"><a href="#cb78-1055" aria-hidden="true" tabindex="-1"></a>preds <span class="sc">%&gt;%</span></span>
<span id="cb78-1056"><a href="#cb78-1056" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> medv)) <span class="sc">+</span></span>
<span id="cb78-1057"><a href="#cb78-1057" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> kq_pred, <span class="at">color =</span> <span class="st">"OLS"</span>), <span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb78-1058"><a href="#cb78-1058" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> nn_pred, <span class="at">color =</span> <span class="st">"Neuronales Netz"</span>), <span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb78-1059"><a href="#cb78-1059" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb78-1060"><a href="#cb78-1060" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb78-1061"><a href="#cb78-1061" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Wahre Werte (medv)"</span>,</span>
<span id="cb78-1062"><a href="#cb78-1062" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Vorhersagen"</span>,</span>
<span id="cb78-1063"><a href="#cb78-1063" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"Modell"</span></span>
<span id="cb78-1064"><a href="#cb78-1064" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb78-1065"><a href="#cb78-1065" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb78-1066"><a href="#cb78-1066" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb78-1067"><a href="#cb78-1067" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(</span>
<span id="cb78-1068"><a href="#cb78-1068" aria-hidden="true" tabindex="-1"></a>      <span class="st">"OLS"</span> <span class="ot">=</span> <span class="st">"red"</span>, </span>
<span id="cb78-1069"><a href="#cb78-1069" aria-hidden="true" tabindex="-1"></a>      <span class="st">"Neuronales Netz"</span> <span class="ot">=</span> <span class="st">"steelblue"</span></span>
<span id="cb78-1070"><a href="#cb78-1070" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb78-1071"><a href="#cb78-1071" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-1072"><a href="#cb78-1072" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-1073"><a href="#cb78-1073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1074"><a href="#cb78-1074" aria-hidden="true" tabindex="-1"></a>@fig-bhkq-nn zeigt, dass KQ und NN weitgehend vergleichbare Vorhersagen von <span class="in">`medv`</span> auf dem Testdatensatz liefern. Das NN scheint jedoch besser in der Vorhersage hoher Verkaufspreise zu sein -- möglicherweise weil extreme Preise auf nicht-lineare Beziehungen zwischen bestimmten Regressoren und <span class="in">`medv`</span> zurückzuführen sind, die in einer linearen KQ-Regression nicht erfasst werden können.</span>
<span id="cb78-1075"><a href="#cb78-1075" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1076"><a href="#cb78-1076" aria-hidden="true" tabindex="-1"></a><span class="fu">## Case Study: Vorhersage von Immobilienpreisen</span></span>
<span id="cb78-1077"><a href="#cb78-1077" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1080"><a href="#cb78-1080" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-1081"><a href="#cb78-1081" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AmesHousing)</span>
<span id="cb78-1082"><a href="#cb78-1082" aria-hidden="true" tabindex="-1"></a>housing <span class="ot">&lt;-</span> <span class="fu">make_ames</span>()</span>
<span id="cb78-1083"><a href="#cb78-1083" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-1084"><a href="#cb78-1084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1087"><a href="#cb78-1087" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-1088"><a href="#cb78-1088" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the necessary libraries</span></span>
<span id="cb78-1089"><a href="#cb78-1089" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb78-1090"><a href="#cb78-1090" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sf)</span>
<span id="cb78-1091"><a href="#cb78-1091" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tigris)</span>
<span id="cb78-1092"><a href="#cb78-1092" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1093"><a href="#cb78-1093" aria-hidden="true" tabindex="-1"></a><span class="co"># Retrieve basemap for Ames, Iowa using the tigris package</span></span>
<span id="cb78-1094"><a href="#cb78-1094" aria-hidden="true" tabindex="-1"></a>places_map <span class="ot">&lt;-</span> <span class="fu">places</span>(</span>
<span id="cb78-1095"><a href="#cb78-1095" aria-hidden="true" tabindex="-1"></a>  <span class="at">state =</span> <span class="st">'IA'</span>, </span>
<span id="cb78-1096"><a href="#cb78-1096" aria-hidden="true" tabindex="-1"></a>  <span class="at">cb =</span> <span class="cn">TRUE</span>, </span>
<span id="cb78-1097"><a href="#cb78-1097" aria-hidden="true" tabindex="-1"></a>  <span class="at">progress =</span> F</span>
<span id="cb78-1098"><a href="#cb78-1098" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb78-1099"><a href="#cb78-1099" aria-hidden="true" tabindex="-1"></a>  <span class="fu">st_as_sf</span>()</span>
<span id="cb78-1100"><a href="#cb78-1100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1101"><a href="#cb78-1101" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter for Ames city</span></span>
<span id="cb78-1102"><a href="#cb78-1102" aria-hidden="true" tabindex="-1"></a>ames_map <span class="ot">&lt;-</span> places_map <span class="sc">%&gt;%</span> </span>
<span id="cb78-1103"><a href="#cb78-1103" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(NAME <span class="sc">==</span> <span class="st">"Ames"</span>)</span>
<span id="cb78-1104"><a href="#cb78-1104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1105"><a href="#cb78-1105" aria-hidden="true" tabindex="-1"></a>houses <span class="ot">&lt;-</span> housing <span class="sc">%&gt;%</span></span>
<span id="cb78-1106"><a href="#cb78-1106" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(Latitude, Longitude, Sale_Price) <span class="sc">%&gt;%</span></span>
<span id="cb78-1107"><a href="#cb78-1107" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(</span>
<span id="cb78-1108"><a href="#cb78-1108" aria-hidden="true" tabindex="-1"></a>      <span class="at">Sale_Price =</span> <span class="fu">cut</span>(<span class="fu">log</span>(Sale_Price, <span class="at">base =</span> <span class="dv">2</span>), <span class="at">breaks =</span> <span class="dv">5</span>, <span class="at">labels =</span> <span class="cn">FALSE</span>)</span>
<span id="cb78-1109"><a href="#cb78-1109" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span></span>
<span id="cb78-1110"><a href="#cb78-1110" aria-hidden="true" tabindex="-1"></a>    <span class="fu">st_as_sf</span>(<span class="at">coords =</span> <span class="fu">c</span>(<span class="st">"Longitude"</span>, <span class="st">"Latitude"</span>), </span>
<span id="cb78-1111"><a href="#cb78-1111" aria-hidden="true" tabindex="-1"></a>             <span class="at">crs =</span> <span class="dv">4326</span>, <span class="at">agr =</span> <span class="st">"constant"</span>)</span>
<span id="cb78-1112"><a href="#cb78-1112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1113"><a href="#cb78-1113" aria-hidden="true" tabindex="-1"></a>rainbow_colors <span class="ot">&lt;-</span> <span class="fu">rainbow</span>(<span class="dv">5</span>, <span class="at">rev =</span> <span class="cn">TRUE</span>)</span>
<span id="cb78-1114"><a href="#cb78-1114" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-1115"><a href="#cb78-1115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1118"><a href="#cb78-1118" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-1119"><a href="#cb78-1119" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the map with just the outline of Ames</span></span>
<span id="cb78-1120"><a href="#cb78-1120" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb78-1121"><a href="#cb78-1121" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_sf</span>(<span class="at">data =</span> ames_map, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">fill =</span> <span class="fu">alpha</span>(<span class="st">"black"</span>, <span class="at">alpha =</span> <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb78-1122"><a href="#cb78-1122" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_sf</span>(<span class="at">data =</span> houses, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">color =</span> <span class="fu">factor</span>(Sale_Price)), <span class="at">size =</span> .<span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb78-1123"><a href="#cb78-1123" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_map</span>() <span class="sc">+</span></span>
<span id="cb78-1124"><a href="#cb78-1124" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb78-1125"><a href="#cb78-1125" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">"log(Verkaufspreis)"</span>, </span>
<span id="cb78-1126"><a href="#cb78-1126" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> rainbow_colors, </span>
<span id="cb78-1127"><a href="#cb78-1127" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">levels</span>(<span class="fu">factor</span>(houses<span class="sc">$</span>Sale_Price))</span>
<span id="cb78-1128"><a href="#cb78-1128" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb78-1129"><a href="#cb78-1129" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>, <span class="at">legend.direction =</span> <span class="st">"horizontal"</span>) <span class="sc">+</span></span>
<span id="cb78-1130"><a href="#cb78-1130" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Verkaufte Häuser in Ames, Iowa"</span>)</span>
<span id="cb78-1131"><a href="#cb78-1131" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-1132"><a href="#cb78-1132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1133"><a href="#cb78-1133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1136"><a href="#cb78-1136" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-1137"><a href="#cb78-1137" aria-hidden="true" tabindex="-1"></a>housing <span class="sc">%&gt;%</span></span>
<span id="cb78-1138"><a href="#cb78-1138" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> Year_Built, <span class="at">y =</span> Sale_Price)) <span class="sc">+</span></span>
<span id="cb78-1139"><a href="#cb78-1139" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> .<span class="dv">5</span>, <span class="at">fill =</span> <span class="st">"steelblue"</span>) <span class="sc">+</span></span>
<span id="cb78-1140"><a href="#cb78-1140" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_cowplot</span>()</span>
<span id="cb78-1141"><a href="#cb78-1141" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-1142"><a href="#cb78-1142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1145"><a href="#cb78-1145" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-1146"><a href="#cb78-1146" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb78-1147"><a href="#cb78-1147" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb78-1148"><a href="#cb78-1148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1149"><a href="#cb78-1149" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb78-1150"><a href="#cb78-1150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1151"><a href="#cb78-1151" aria-hidden="true" tabindex="-1"></a>split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(housing, <span class="at">prop =</span> <span class="fl">0.8</span>)</span>
<span id="cb78-1152"><a href="#cb78-1152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1153"><a href="#cb78-1153" aria-hidden="true" tabindex="-1"></a>housing_train <span class="ot">&lt;-</span> <span class="fu">training</span>(split)</span>
<span id="cb78-1154"><a href="#cb78-1154" aria-hidden="true" tabindex="-1"></a>housing_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(split)</span>
<span id="cb78-1155"><a href="#cb78-1155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1156"><a href="#cb78-1156" aria-hidden="true" tabindex="-1"></a><span class="co"># Separate the predictors and the outcome</span></span>
<span id="cb78-1157"><a href="#cb78-1157" aria-hidden="true" tabindex="-1"></a>housing_train_x <span class="ot">&lt;-</span> housing_train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Sale_Price)</span>
<span id="cb78-1158"><a href="#cb78-1158" aria-hidden="true" tabindex="-1"></a>housing_train_y <span class="ot">&lt;-</span> housing_train<span class="sc">$</span>Sale_Price</span>
<span id="cb78-1159"><a href="#cb78-1159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1160"><a href="#cb78-1160" aria-hidden="true" tabindex="-1"></a>housing_test_x <span class="ot">&lt;-</span> housing_test <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Sale_Price)</span>
<span id="cb78-1161"><a href="#cb78-1161" aria-hidden="true" tabindex="-1"></a>housing_test_y <span class="ot">&lt;-</span> housing_test<span class="sc">$</span>Sale_Price</span>
<span id="cb78-1162"><a href="#cb78-1162" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-1163"><a href="#cb78-1163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1166"><a href="#cb78-1166" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-1167"><a href="#cb78-1167" aria-hidden="true" tabindex="-1"></a>blueprint <span class="ot">&lt;-</span> <span class="fu">recipe</span>(</span>
<span id="cb78-1168"><a href="#cb78-1168" aria-hidden="true" tabindex="-1"></a>  Sale_Price <span class="sc">~</span> ., </span>
<span id="cb78-1169"><a href="#cb78-1169" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> housing_train) <span class="sc">%&gt;%</span></span>
<span id="cb78-1170"><a href="#cb78-1170" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_nzv</span>(<span class="fu">all_nominal</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb78-1171"><a href="#cb78-1171" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_other</span>(<span class="fu">all_nominal</span>(), <span class="at">threshold =</span> .<span class="dv">01</span>, <span class="at">other =</span> <span class="st">"other"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb78-1172"><a href="#cb78-1172" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_integer</span>(<span class="fu">matches</span>(<span class="st">"(Qual|Cond|QC|Qu)$"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb78-1173"><a href="#cb78-1173" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_YeoJohnson</span>(<span class="fu">all_numeric</span>(), <span class="sc">-</span><span class="fu">all_outcomes</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb78-1174"><a href="#cb78-1174" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_center</span>(<span class="fu">all_numeric</span>(), <span class="sc">-</span><span class="fu">all_outcomes</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb78-1175"><a href="#cb78-1175" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_scale</span>(<span class="fu">all_numeric</span>(), <span class="sc">-</span><span class="fu">all_outcomes</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb78-1176"><a href="#cb78-1176" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_dummy</span>(<span class="fu">all_nominal</span>(), <span class="sc">-</span><span class="fu">all_outcomes</span>(), <span class="at">one_hot =</span> <span class="cn">TRUE</span>)</span>
<span id="cb78-1177"><a href="#cb78-1177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1178"><a href="#cb78-1178" aria-hidden="true" tabindex="-1"></a>prepare <span class="ot">&lt;-</span> <span class="fu">prep</span>(blueprint, <span class="at">training =</span> housing_train)</span>
<span id="cb78-1179"><a href="#cb78-1179" aria-hidden="true" tabindex="-1"></a>prepare</span>
<span id="cb78-1180"><a href="#cb78-1180" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-1181"><a href="#cb78-1181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1184"><a href="#cb78-1184" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-1185"><a href="#cb78-1185" aria-hidden="true" tabindex="-1"></a>baked_train <span class="ot">&lt;-</span> <span class="fu">bake</span>(prepare, <span class="at">new_data =</span> housing_train)</span>
<span id="cb78-1186"><a href="#cb78-1186" aria-hidden="true" tabindex="-1"></a>baked_test <span class="ot">&lt;-</span> <span class="fu">bake</span>(prepare, <span class="at">new_data =</span> housing_test)</span>
<span id="cb78-1187"><a href="#cb78-1187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1188"><a href="#cb78-1188" aria-hidden="true" tabindex="-1"></a>baked_train</span>
<span id="cb78-1189"><a href="#cb78-1189" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-1190"><a href="#cb78-1190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1191"><a href="#cb78-1191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1192"><a href="#cb78-1192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1195"><a href="#cb78-1195" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-1196"><a href="#cb78-1196" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb78-1197"><a href="#cb78-1197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1198"><a href="#cb78-1198" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the data for glmnet (which requires matrices)</span></span>
<span id="cb78-1199"><a href="#cb78-1199" aria-hidden="true" tabindex="-1"></a>x_train_glmnet <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(baked_train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Sale_Price))</span>
<span id="cb78-1200"><a href="#cb78-1200" aria-hidden="true" tabindex="-1"></a>y_train_glmnet <span class="ot">&lt;-</span> <span class="fu">log10</span>(baked_train<span class="sc">$</span>Sale_Price)</span>
<span id="cb78-1201"><a href="#cb78-1201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1202"><a href="#cb78-1202" aria-hidden="true" tabindex="-1"></a>x_test_glmnet <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(baked_test <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Sale_Price))</span>
<span id="cb78-1203"><a href="#cb78-1203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1204"><a href="#cb78-1204" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a Ridge Regression model</span></span>
<span id="cb78-1205"><a href="#cb78-1205" aria-hidden="true" tabindex="-1"></a>ridge_model <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x_train_glmnet, y_train_glmnet, <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb78-1206"><a href="#cb78-1206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1207"><a href="#cb78-1207" aria-hidden="true" tabindex="-1"></a><span class="co"># Use cross-validation to find the optimal lambda</span></span>
<span id="cb78-1208"><a href="#cb78-1208" aria-hidden="true" tabindex="-1"></a>cv_ridge <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(x_train_glmnet, y_train_glmnet, <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb78-1209"><a href="#cb78-1209" aria-hidden="true" tabindex="-1"></a>best_lambda <span class="ot">&lt;-</span> cv_ridge<span class="sc">$</span>lambda.min</span>
<span id="cb78-1210"><a href="#cb78-1210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1211"><a href="#cb78-1211" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on the test set using the best lambda</span></span>
<span id="cb78-1212"><a href="#cb78-1212" aria-hidden="true" tabindex="-1"></a>ridge_preds_log <span class="ot">&lt;-</span> <span class="fu">predict</span>(cv_ridge, <span class="at">s =</span> best_lambda, <span class="at">newx =</span> x_test_glmnet)</span>
<span id="cb78-1213"><a href="#cb78-1213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1214"><a href="#cb78-1214" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert predictions back from log scale</span></span>
<span id="cb78-1215"><a href="#cb78-1215" aria-hidden="true" tabindex="-1"></a>ridge_preds <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="dv">10</span><span class="sc">^</span>ridge_preds_log)</span>
<span id="cb78-1216"><a href="#cb78-1216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1217"><a href="#cb78-1217" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the performance</span></span>
<span id="cb78-1218"><a href="#cb78-1218" aria-hidden="true" tabindex="-1"></a><span class="fu">mae_vec</span>(</span>
<span id="cb78-1219"><a href="#cb78-1219" aria-hidden="true" tabindex="-1"></a>  <span class="at">truth =</span> housing_test_y, </span>
<span id="cb78-1220"><a href="#cb78-1220" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> ridge_preds</span>
<span id="cb78-1221"><a href="#cb78-1221" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-1222"><a href="#cb78-1222" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-1223"><a href="#cb78-1223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1224"><a href="#cb78-1224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1227"><a href="#cb78-1227" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-1228"><a href="#cb78-1228" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb78-1229"><a href="#cb78-1229" aria-hidden="true" tabindex="-1"></a>x_train <span class="ot">&lt;-</span> <span class="fu">select</span>(baked_train, <span class="sc">-</span>Sale_Price) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb78-1230"><a href="#cb78-1230" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">&lt;-</span> baked_train <span class="sc">%&gt;%</span> <span class="fu">pull</span>(Sale_Price)</span>
<span id="cb78-1231"><a href="#cb78-1231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1232"><a href="#cb78-1232" aria-hidden="true" tabindex="-1"></a>x_test <span class="ot">&lt;-</span> <span class="fu">select</span>(baked_test, <span class="sc">-</span>Sale_Price) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb78-1233"><a href="#cb78-1233" aria-hidden="true" tabindex="-1"></a>y_test <span class="ot">&lt;-</span> baked_test <span class="sc">%&gt;%</span> <span class="fu">pull</span>(Sale_Price)</span>
<span id="cb78-1234"><a href="#cb78-1234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1235"><a href="#cb78-1235" aria-hidden="true" tabindex="-1"></a>network <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb78-1236"><a href="#cb78-1236" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">512</span>, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">input_shape =</span> <span class="fu">ncol</span>(x_train)) <span class="sc">%&gt;%</span></span>
<span id="cb78-1237"><a href="#cb78-1237" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">512</span>, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb78-1238"><a href="#cb78-1238" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">512</span>, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb78-1239"><a href="#cb78-1239" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">512</span>, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb78-1240"><a href="#cb78-1240" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">512</span>, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb78-1241"><a href="#cb78-1241" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">1</span>)</span>
<span id="cb78-1242"><a href="#cb78-1242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1243"><a href="#cb78-1243" aria-hidden="true" tabindex="-1"></a>network <span class="sc">%&gt;%</span></span>
<span id="cb78-1244"><a href="#cb78-1244" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(</span>
<span id="cb78-1245"><a href="#cb78-1245" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_rmsprop</span>(<span class="at">learning_rate =</span> <span class="fl">0.01</span>),</span>
<span id="cb78-1246"><a href="#cb78-1246" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> <span class="st">"msle"</span>,</span>
<span id="cb78-1247"><a href="#cb78-1247" aria-hidden="true" tabindex="-1"></a>    <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">"mae"</span>)</span>
<span id="cb78-1248"><a href="#cb78-1248" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-1249"><a href="#cb78-1249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1250"><a href="#cb78-1250" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb78-1251"><a href="#cb78-1251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1252"><a href="#cb78-1252" aria-hidden="true" tabindex="-1"></a>history <span class="ot">&lt;-</span> network <span class="sc">%&gt;%</span> <span class="fu">fit</span>(</span>
<span id="cb78-1253"><a href="#cb78-1253" aria-hidden="true" tabindex="-1"></a>  x_train,</span>
<span id="cb78-1254"><a href="#cb78-1254" aria-hidden="true" tabindex="-1"></a>  y_train,</span>
<span id="cb78-1255"><a href="#cb78-1255" aria-hidden="true" tabindex="-1"></a>  <span class="at">epochs =</span> <span class="dv">30</span>,</span>
<span id="cb78-1256"><a href="#cb78-1256" aria-hidden="true" tabindex="-1"></a>  <span class="at">batch_size =</span> <span class="dv">32</span>,</span>
<span id="cb78-1257"><a href="#cb78-1257" aria-hidden="true" tabindex="-1"></a>  <span class="at">validation_split =</span> <span class="fl">0.2</span>,</span>
<span id="cb78-1258"><a href="#cb78-1258" aria-hidden="true" tabindex="-1"></a>  <span class="at">callbacks =</span> <span class="fu">list</span>(</span>
<span id="cb78-1259"><a href="#cb78-1259" aria-hidden="true" tabindex="-1"></a>        <span class="fu">callback_early_stopping</span>(<span class="at">patience =</span> <span class="dv">10</span>, <span class="at">restore_best_weights =</span> <span class="cn">TRUE</span>),</span>
<span id="cb78-1260"><a href="#cb78-1260" aria-hidden="true" tabindex="-1"></a>        <span class="fu">callback_reduce_lr_on_plateau</span>(<span class="at">factor =</span> <span class="fl">0.2</span>, <span class="at">patience =</span> <span class="dv">4</span>)</span>
<span id="cb78-1261"><a href="#cb78-1261" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb78-1262"><a href="#cb78-1262" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-1263"><a href="#cb78-1263" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-1264"><a href="#cb78-1264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1267"><a href="#cb78-1267" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-1268"><a href="#cb78-1268" aria-hidden="true" tabindex="-1"></a>history</span>
<span id="cb78-1269"><a href="#cb78-1269" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb78-1270"><a href="#cb78-1270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-1273"><a href="#cb78-1273" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb78-1274"><a href="#cb78-1274" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(history) <span class="sc">+</span> </span>
<span id="cb78-1275"><a href="#cb78-1275" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_log10</span>() <span class="sc">+</span></span>
<span id="cb78-1276"><a href="#cb78-1276" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_cowplot</span>() <span class="sc">+</span></span>
<span id="cb78-1277"><a href="#cb78-1277" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)</span>
<span id="cb78-1278"><a href="#cb78-1278" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="In die Zwischenablage kopieren" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>