<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="de" xml:lang="de"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>13&nbsp; Neuronale Netzwerke – Kausalanalyse mit R</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ex.html" rel="next">
<link href="./RegReg.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/live-runtime/live-runtime.js" type="module"></script>
<link href="site_libs/quarto-contrib/live-runtime/live-runtime.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Keine Treffer",
    "search-matching-documents-text": "Treffer",
    "search-copy-link-title": "Link in die Suche kopieren",
    "search-hide-matches-text": "Zusätzliche Treffer verbergen",
    "search-more-match-text": "weitere Treffer in diesem Dokument",
    "search-more-matches-text": "weitere Treffer in diesem Dokument",
    "search-clear-button-title": "Zurücksetzen",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Abbrechen",
    "search-submit-button-title": "Abschicken",
    "search-label": "Suchen"
  }
}</script><script type="module" src="site_libs/quarto-ojs/quarto-ojs-runtime.js"></script><link href="site_libs/quarto-ojs/quarto-ojs.css" rel="stylesheet">
<meta name="robots" content="noindex">
<script>
  MathJax = {
    tex: {
      tags: 'ams'  // should be 'ams', 'none', or 'all'
    }
  };
</script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.js" integrity="sha512-aoZChv+8imY/U1O7KIHXvO87EOzCuKO0GhFtpD6G2Cyjo/xPeTgdf3/bchB10iB+AojMTDkMHDPLKNxPJVqDcw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css">
<style>
  .panel-tabset .tab-content {
    border: 0;
    padding: 1em 0 0 0;
  }
  
  .panel-tabset .nav-item a {
    border-radius: 5px 5px 0 0;
  }
  
  .scientific_borders {
    border: 0;
    border-top: 2px solid black !important; 
    border-bottom: 2px solid black !important;
  }
  .table:not(.gt_table) > :not(caption)>*>* {
    border-bottom-width: 0;
  }
  .table:not(.gt_table) > thead {
    border-bottom: 1px solid black;
  }
  .soft-box-shadow {
    border: 1px solid rgba(233,236,239,.9) !important;
    border-radius: .5rem !important;
    background-color: rgba(250,250,250,.9) !important;
    box-shadow: 0px 1px 2px rgba(0,0,0,.1),
                0px 3px 7px rgba(0,0,0,.1),
                0px 12px 30px rgba(0,0,0,.08);
    margin-top: 2rem !important;
    margin-bottom: 2.5rem !important;
    padding: .25rem !important;
  }
  .obs-soft-box-shadow {
    border: 1px solid rgba(233,236,239,.9) !important;
    border-radius: .5rem !important;
    background-color: white !important;
    box-shadow: 0px 1px 2px rgba(0,0,0,.1),
                0px 3px 7px rgba(0,0,0,.1),
                0px 12px 30px rgba(0,0,0,.08);
    margin-top: 2rem !important;
    margin-bottom: 2.5rem !important;
    padding: .25rem !important;
  }
  
</style>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    
    var gt_tables = document.querySelectorAll(".gt_table");
    gt_tables.forEach(function(table) {
      table.classList.remove("table-striped");
    });
    
    var tables = document.querySelectorAll("table.table:not(.gt_table)");
    tables.forEach(function(table) {
      table.classList.remove("table-striped");
      table.classList.add("scientific_borders");
    });
    
    document.querySelectorAll("div.sourceCode").forEach(function(block) {
      block.classList.add("soft-box-shadow");
    });
    
    document.querySelectorAll("div.bg-white").forEach(function(block) {
      block.classList.remove("bg-white");
    });
    
const elements = document.querySelectorAll('[id^="qwebr-interactive-area"]');

    elements.forEach(element => {
        element.classList.add('box-shadow');
    });
    
    document.querySelectorAll('[id^="webr"]').forEach(function(block) {
      block.classList.add("box-shadow");
    });
    
        document.querySelectorAll('.card-header').forEach(function(block) {
      block.classList.add("box-shadow");
    });
    
  });
</script><style>
.qwebr-code-output-stdout {background-color: powderblue;}

.qwebr-button-run {
 width = 100%; 
}

.centered-caption {
   text-align: center;
}
</style>
<script src="https://cdn.jsdelivr.net/npm/quizdown@latest/public/build/quizdown.js"></script><script>quizdown.init();</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script><link rel="stylesheet" href="custom_styles.css">
</head>
<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Seitenleiste umschalten" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./RegReg.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="./Machine Learning.html"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Neuronale Netzwerke</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Seitenleiste umschalten" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Suchen" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./"></a><a href="./index.html">Kausalanalyse mit R</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Lesemodus umschalten">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Suchen"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Einführung</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Grundlagen</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./R_Einfuehrung.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Statistische Programmierung mit R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Reg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Simulation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Simulation</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Kausale Inferenz</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Matching.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Matching</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./FixedEffects.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Panel-Daten</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./IV.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">IV-Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./DiD.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Difference-in-Differences</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./EventStudies.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Event Studies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./RDD.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Regression Discontiniuty Designs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./SyntheticControl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Synthetic Control</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./RegReg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Regularisierte Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Machine Learning.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Neuronale Netzwerke</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Übungsaufgaben</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Lineare Regression</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Literatur.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Literatur</span></a>
  </div>
</li>
    </ul>
</div>
    <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title"><a href="./index.html">Übersicht</a></h2>
   
  <ul>
<li>
<a href="#grundlagen-und-vokabeln" id="toc-grundlagen-und-vokabeln" class="nav-link active" data-scroll-target="#grundlagen-und-vokabeln"><span class="header-section-number">13.1</span> Grundlagen und Vokabeln</a>
  <ul>
<li><a href="#training-neuronaler-netze" id="toc-training-neuronaler-netze" class="nav-link" data-scroll-target="#training-neuronaler-netze"><span class="header-section-number">13.1.1</span> Training Neuronaler Netze</a></li>
  </ul>
</li>
  <li><a href="#optimierung-mit-gradient-descent" id="toc-optimierung-mit-gradient-descent" class="nav-link" data-scroll-target="#optimierung-mit-gradient-descent"><span class="header-section-number">13.2</span> Optimierung mit Gradient Descent</a></li>
  <li><a href="#funktionale-zusammenh%C3%A4nge-lernen-regression" id="toc-funktionale-zusammenhänge-lernen-regression" class="nav-link" data-scroll-target="#funktionale-zusammenh%C3%A4nge-lernen-regression"><span class="header-section-number">13.3</span> Funktionale Zusammenhänge lernen: Regression</a></li>
  <li><a href="#multiple-regression" id="toc-multiple-regression" class="nav-link" data-scroll-target="#multiple-regression"><span class="header-section-number">13.4</span> Multiple Regression</a></li>
  <li><a href="#nicht-lineare-zusammenh%C3%A4nge" id="toc-nicht-lineare-zusammenhänge" class="nav-link" data-scroll-target="#nicht-lineare-zusammenh%C3%A4nge"><span class="header-section-number">13.5</span> Nicht-Lineare Zusammenhänge</a></li>
  <li><a href="#case-study-immobilienpreise" id="toc-case-study-immobilienpreise" class="nav-link" data-scroll-target="#case-study-immobilienpreise"><span class="header-section-number">13.6</span> Case Study: Immobilienpreise</a></li>
  </ul></nav>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./RegReg.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="./Machine Learning.html"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Neuronale Netzwerke</span></a></li></ol></nav><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">
<span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Neuronale Netzwerke</span>
</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><p>Neuronale Netze sind leistungsstarke Modelle, die darauf spezialisiert sind, komplexe Muster in Daten zu erkennen und sind damit insbesondere ein hilfeiches Tool für Prognosen. Ein Nachteil neuronaler Netze ist die mangelnde Fähigkeit, kausale Zusammenhänge zu identifizieren und abzuleiten. Diese Limitation stellt eine signifikante Einschränkung dar, insbesondere für den Einsatz in empirischen Disziplinen, in denen das Verständnis kausaler Beziehungen von entscheidender Bedeutung ist. Während neuronale Netze effektiv komplizierte Strukturen abbilden können, sind sie nicht mit den notwendigen Mechanismen ausgestattet, um Kausalität zu modellieren oder gar zu identifizieren. Grund hierfür ist die fehlende explizite Berücksichtigung kausaler Beziehungen und des zugrunde liegenden datenerzeugenden Prozesses: Neuronale Netze lernen lediglich funktionale Zusammenhänge in den Trainingsdaten. Auch wenn hierdurch komplexeste Relationen abgebildet werden können, erlaubt ein angepasstes Netz keine Differenzierung zwischen einer Korrelation und einer tatsächlichen kausalen Beziehung zwischen Variablen.</p>
<p>In diesem Kapitel erläutern wir die Funktionsweise und Anpassung neuronaler Netze mit Keras und TensorFlow in R und diskutieren deren Anwendung zur Prognose von Zielvariablen in Datensätzen mit vielen Variablen und Beobachtungen.</p>
<section id="grundlagen-und-vokabeln" class="level2 page-columns page-full" data-number="13.1"><h2 data-number="13.1" class="anchored" data-anchor-id="grundlagen-und-vokabeln">
<span class="header-section-number">13.1</span> Grundlagen und Vokabeln</h2>
<p>Neuronale Netze (NN) bestehen aus einer (often großen) Anzahl so genannter <em>künstlicher Neuronen</em>. Ein Neuron ist eine mathematische Funktion, die mehrere Eingaben empfängt, diese unter Verwendung von Gewichten linear kombiniert und eine Ausgabe durch Verwendung einer Aktivierungsfunktion generiert.</p>
<p>Die Neuronen eines NN sind in Schichten (<em>Layers</em>) organisiert. Jedes Layer verarbeitet die Eingabedaten und gibt die Ergebnisse an das nächste Layer weiter, wobei die Neuronen verschiedener Layer miteinander verknüpft werden. Während das Eingabe-Layer (<em>Input</em>) die “Rohdaten” (bspw. beobachtete Regressorwerte) aufnimmt und sie an die erste versteckte Schicht (<em>Hidden Layer</em>) weiterleitet, ist die Hauptaufgabe der Neuronen in den Hidden Layers, komplexe Muster und Merkmale in den Daten zu erkennen und zu verarbeiten. Jedes Hidden Layer transformiert die empfangenen Daten anhand seiner Neuronen, bevor diese an das nächste Layer weitergeleitet werden. Das letzte Layer in einem neuronalen Netzwerk ist das Ausgabe-Layer (<em>Output Layer</em>), das die endgültige Vorhersage für die Outcome-Variable basierend auf den verarbeiteten Daten liefert.</p>
<p>Die Stärke der Verknüpfungen zwischen den Neuronen wird durch die Gewichte <span class="math inline">\(w\)</span> bestimmt, welche während des Trainingsprozesses angepasst werden, um das Modell hinsichtlich der (Vorhersage) einer Zielvariable zu optimieren. Die <span class="math inline">\(w\)</span> bestimmen, wie stark die Aktivierung eines Neurons in einer Schicht die Aktivierung der Neuronen in der nächsten Schicht beeinflusst. Das Netzwerk kann so tiefe und abstrakte Strukturen eines Datensatzes abbilden.</p>
<div class="cell page-columns page-full" data-fig-width="6" data-fig-height="4" data-layout-align="center">
<div class="cell-output-display page-columns page-full">
<div id="fig-nnex" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-nnex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="576" height="384" viewbox="0.00 0.00 497.95 361.62" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none"><g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 357.62)"><title>NNEX</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-357.62 493.95,-357.62 493.95,4 -4,4"></polygon><!-- X1 --><g id="node1" class="node"><title>X1</title>
<ellipse fill="lightblue" stroke="black" cx="25.14" cy="-248.81" rx="25.28" ry="25.28"></ellipse><text text-anchor="middle" x="25.14" y="-244.01" font-family="Helvetica,Arial,sans-serif" font-size="16.00">X1</text></g><!-- V1 --><g id="node3" class="node"><title>V1</title>
<ellipse fill="lightyellow" stroke="black" cx="241.14" cy="-320.81" rx="32.62" ry="32.62"></ellipse><text text-anchor="middle" x="241.14" y="-325.61" font-family="Helvetica,Arial,sans-serif" font-size="16.00">V1</text><text text-anchor="middle" x="241.14" y="-306.41" font-family="Helvetica,Arial,sans-serif" font-size="16.00">(A)</text></g><!-- X1&#45;&gt;V1 --><g id="edge1" class="edge"><title>X1-&gt;V1</title>
<path fill="none" stroke="black" d="M49.08,-256.79C85.54,-268.94 155.44,-292.24 200.1,-307.13"></path><polygon fill="black" stroke="black" points="199.18,-310.51 209.77,-310.35 201.39,-303.87 199.18,-310.51"></polygon><text text-anchor="middle" x="114.26" y="-285.56" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w11</text></g><!-- V2 --><g id="node4" class="node"><title>V2</title>
<ellipse fill="lightyellow" stroke="black" cx="241.14" cy="-176.81" rx="32.62" ry="32.62"></ellipse><text text-anchor="middle" x="241.14" y="-181.61" font-family="Helvetica,Arial,sans-serif" font-size="16.00">V2</text><text text-anchor="middle" x="241.14" y="-162.41" font-family="Helvetica,Arial,sans-serif" font-size="16.00">(A)</text></g><!-- X1&#45;&gt;V2 --><g id="edge2" class="edge"><title>X1-&gt;V2</title>
<path fill="none" stroke="black" d="M49.08,-240.83C85.54,-228.68 155.44,-205.38 200.1,-190.49"></path><polygon fill="black" stroke="black" points="201.39,-193.75 209.77,-187.27 199.18,-187.11 201.39,-193.75"></polygon><text text-anchor="middle" x="114.26" y="-219.26" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w12</text></g><!-- V3 --><g id="node5" class="node"><title>V3</title>
<ellipse fill="lightyellow" stroke="black" cx="241.14" cy="-32.81" rx="32.62" ry="32.62"></ellipse><text text-anchor="middle" x="241.14" y="-37.61" font-family="Helvetica,Arial,sans-serif" font-size="16.00">V3</text><text text-anchor="middle" x="241.14" y="-18.41" font-family="Helvetica,Arial,sans-serif" font-size="16.00">(A)</text></g><!-- X1&#45;&gt;V3 --><g id="edge3" class="edge"><title>X1-&gt;V3</title>
<path fill="none" stroke="black" d="M43.19,-230.77C80.16,-193.79 164.9,-109.05 210.6,-63.35"></path><polygon fill="black" stroke="black" points="213.25,-65.65 217.85,-56.1 208.3,-60.7 213.25,-65.65"></polygon><text text-anchor="middle" x="116.56" y="-150.66" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w13</text></g><!-- X2 --><g id="node2" class="node"><title>X2</title>
<ellipse fill="lightblue" stroke="black" cx="25.14" cy="-104.81" rx="25.28" ry="25.28"></ellipse><text text-anchor="middle" x="25.14" y="-100.01" font-family="Helvetica,Arial,sans-serif" font-size="16.00">X2</text></g><!-- X2&#45;&gt;V1 --><g id="edge4" class="edge"><title>X2-&gt;V1</title>
<path fill="none" stroke="black" d="M43.19,-122.85C80.16,-159.83 164.9,-244.57 210.6,-290.26"></path><polygon fill="black" stroke="black" points="208.3,-292.92 217.85,-297.52 213.25,-287.97 208.3,-292.92"></polygon><text text-anchor="middle" x="116.56" y="-195.76" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w21</text></g><!-- X2&#45;&gt;V2 --><g id="edge5" class="edge"><title>X2-&gt;V2</title>
<path fill="none" stroke="black" d="M49.08,-112.79C85.54,-124.94 155.44,-148.24 200.1,-163.13"></path><polygon fill="black" stroke="black" points="199.18,-166.51 209.77,-166.35 201.39,-159.87 199.18,-166.51"></polygon><text text-anchor="middle" x="114.26" y="-127.16" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w22</text></g><!-- X2&#45;&gt;V3 --><g id="edge6" class="edge"><title>X2-&gt;V3</title>
<path fill="none" stroke="black" d="M49.08,-96.83C85.54,-84.68 155.44,-61.38 200.1,-46.49"></path><polygon fill="black" stroke="black" points="201.39,-49.75 209.77,-43.27 199.18,-43.11 201.39,-49.75"></polygon><text text-anchor="middle" x="114.26" y="-75.26" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w23</text></g><!-- Y --><g id="node6" class="node"><title>Y</title>
<ellipse fill="lightgreen" stroke="black" cx="457.14" cy="-176.81" rx="32.62" ry="32.62"></ellipse><text text-anchor="middle" x="457.14" y="-181.61" font-family="Helvetica,Arial,sans-serif" font-size="16.00">Y</text><text text-anchor="middle" x="457.14" y="-162.41" font-family="Helvetica,Arial,sans-serif" font-size="16.00">(A)</text></g><!-- V1&#45;&gt;Y --><g id="edge7" class="edge"><title>V1-&gt;Y</title>
<path fill="none" stroke="black" d="M268.5,-302.57C307.26,-276.73 378.23,-229.42 421.2,-200.77"></path><polygon fill="black" stroke="black" points="423.29,-203.59 429.67,-195.13 419.4,-197.76 423.29,-203.59"></polygon><text text-anchor="middle" x="334.52" y="-255.27" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w31</text></g><!-- V2&#45;&gt;Y --><g id="edge8" class="edge"><title>V2-&gt;Y</title>
<path fill="none" stroke="black" d="M274.42,-176.81C311.87,-176.81 372.83,-176.81 413.93,-176.81"></path><polygon fill="black" stroke="black" points="414.18,-180.31 424.18,-176.81 414.18,-173.31 414.18,-180.31"></polygon><text text-anchor="middle" x="333.84" y="-180.41" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w32</text></g><!-- V3&#45;&gt;Y --><g id="edge9" class="edge"><title>V3-&gt;Y</title>
<path fill="none" stroke="black" d="M268.5,-51.05C307.26,-76.89 378.23,-124.2 421.2,-152.85"></path><polygon fill="black" stroke="black" points="419.4,-155.86 429.67,-158.49 423.29,-150.03 419.4,-155.86"></polygon><text text-anchor="middle" x="334.52" y="-105.55" font-family="Helvetica,Arial,sans-serif" font-size="12.00">w33</text></g></g></svg>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-nnex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;13.1: Neuronales Netzwerk mit einem Hidden Layer
</figcaption></figure>
</div>
</div>
</div>
<p>Angenommen wir interessieren uns für die Vorhersage einer Outcome-Variable <span class="math inline">\(Y\)</span> mit den Regressoren <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span>. <a href="#fig-nnex" class="quarto-xref">Abbildung&nbsp;<span>13.1</span></a> zeigt ein mögliches NN mit 3 Neuronen <span class="math inline">\(V_1\)</span>, <span class="math inline">\(V_2\)</span>, <span class="math inline">\(V_3\)</span> in einem Hidden Layer. Die Neuronen im Hidden Layer empfangen Eingaben aus dem Input Layer, bestehend aus Beobachtungen der Variablen <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span>, und gewichten diese Informationen gemäß der Vorschrift</p>
<p><span class="math display">\[\begin{align*}
  h_i = A\left(\sum_{j=1}^{2} w_{ji} \cdot x_j + b_i\right) \quad \text{für } i = 1, 2, 3.
\end{align*}\]</span></p>
<p>Hierbei sind <span class="math inline">\(w_{ji}\)</span> die Gewichte der Verbindung von Input <span class="math inline">\(j\)</span> zu Neuron <span class="math inline">\(i\)</span> und <span class="math inline">\(b_i\)</span> ist ein <em>Bias</em>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> <span class="math inline">\(A(\cdot)\)</span> ist eine Aktivierungsfunktion, die in Abhängigkeit der zu modellierenden Daten gewählt wird.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Der Bias ist analog zur Konstante in einer Regression.</p></div></div><p>Das Ausgabe-Neuron für <span class="math inline">\(Y\)</span> verarbeitet die Informationen aus dem Hidden Layer ebenfalls anhand einer Linearkombination, die mit einer Aktivierungsfunktion transformiert wird,</p>
<p><span class="math display">\[\begin{align*}
  y = A\left(\sum_{i=1}^{3} w_{i} \cdot h_i + b_y\right).
\end{align*}\]</span></p>
<p>Ein solches NN “lernt” Relationen zwischen <span class="math inline">\(Y\)</span> und den Regressoren <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span>, indem die Gewichte anhand eines Algorithmus derart gewählt werden, dass der Fehler zwischen den vorhergesagten und den tatsächlichen Werten von <span class="math inline">\(Y\)</span> — gemessen mit einer Verlustfunktion (<em>Loss-Funktion</em>) — minimiert wird. Dieser Lernprozess erfolgt unter Verwendung numerischer Optimierungsverfahren wie <em>Gradientenabstieg</em> (<em>Gradient Descent</em>).</p>
<section id="training-neuronaler-netze" class="level3 page-columns page-full" data-number="13.1.1"><h3 data-number="13.1.1" class="anchored" data-anchor-id="training-neuronaler-netze">
<span class="header-section-number">13.1.1</span> Training Neuronaler Netze</h3>
<p>Der Anpassungsprozess eines NN an einen Datensatz (<em>Training</em>) wird grob durch folgende Schritte bestimmt:</p>
<ol type="1">
<li><p>Das Netz (Gewichte) wird initialisiert.</p></li>
<li><p>Die Inputs jeder Beobachtung im Trainingsdatensatz werden durch das neuronale Netz geleitet (<em>Forward Pass</em>): Jedes Layer transformiert die Daten mit Hilfe von Gewichten und Aktivierungsfunktionen, um eine Vorhersage von <span class="math inline">\(Y\)</span> zu erzeugen.</p></li>
<li><p>Der Loss wird berechnet, indem die Vorhersage von <span class="math inline">\(Y\)</span> mit dem tatsächlichen Wert verglichen wird. Die Verlustfunktion wird entsprechend der Definition von <span class="math inline">\(Y\)</span> gewählt. Typische Verlustfunktionen sind <em>Quadratic Loss</em> (analog zur Schätzung von linearen Regressionsmodellen mit KQ) oder <em>Logistic Loss</em> (analog zu logistischer Regression).</p></li>
<li>
<p>Zur Anpassung der Gewichte wird der Gradient<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> der Verlustfunktion hinsichtlich der Gewichte des NN ermittelt.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> Ein Gradient-Descent-Algorithmus bestimmt, in welche Richtung die Gewichte verändert werden müssen, um den Vorhersagefehler zu verringern.</p>
<p>Für diese Berechnung wird ein <em>Backward Pass</em> (auch <em>Backpropagation</em> genannt) genutzt. Hierbei wird der anhand des Ausgabelayers ermittelte Loss rückwärts durch das Netzwerk propagiert, um die Gewichte so anzupassen, dass der Fehler bei der Vorhersage von <span class="math inline">\(Y\)</span> minimiert wird.</p>
</li>
<li>
<p>Die Gewichte werden in kleinen Schritten, die durch die so genannte <em>Lernrate</em> bestimmt werden, in Richtung des negativen Gradienten angepasst. Dies bewirkt, dass die Gewichte so verändert werden, dass der Loss im Vergleich zur letzten Iteration verringert wird.</p>
<p>Um den Lernprozess effizienter und stabiler zu machen, nutzen moderne Algorithmen weitere Schritte, bspw. eine Kombination von Gradientenabstieg mit <em>Momentum</em>. Dies beschleunigt die Anpassung der Gewichte und stabilisiert den Lernprozess. Fortgeschrittene Methoden verwenden adaptiven Lernraten, die die Schrittgröße für jedes Gewicht individuell anpassen können.</p>
</li>
</ol>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Der Gradient einer Funktion <span class="math inline">\(f(\boldsymbol{x}) = f(x_1, x_2, \ldots, x_k)\)</span> ist der Vektor der partiellen Ableitungen: <span class="math inline">\(\nabla f = \left( \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \ldots, \frac{\partial f}{\partial x_k} \right)\)</span>. <span class="math inline">\(\nabla f(\boldsymbol{x})\)</span> zeigt die Richtung und Stärke der steilsten Änderung von <span class="math inline">\(f\)</span> am Punkt <span class="math inline">\(\boldsymbol{x}\)</span> an.</p></div><div id="fn3"><p><sup>3</sup>&nbsp;<span class="math inline">\(\nabla f\)</span> ist in NN grundsätzlich unbekannt. Gradient-Desenct-Algorithmen verwenden numerische Verfahren, um den Gradienten anhand von <span class="math inline">\(f\)</span> zu approximieren.</p></div></div><p>Die Schritte 4 und 5 werden wiederholt, bis ein Abbruchkriterium erfüllt ist: Der Fehler ist ausreichend klein, oder weitere Iterationen bewirken keine signifikante Änderung des Gradienten.</p>
<p><strong>Epochen und Iterationen</strong></p>
<p>Der Gesamte Prozess wird für mehrere Epochen (<em>Epocs</em>) durchlaufen, in denen jeweils der gesamte Trainingsdatensatz durch das NN geleitet wird. Um das Training auch für große Datensätze durchführen zu können, werden die Trainingsdaten hierbei üblicherweise in zufällig zusammengesetzen, kleineren Datensätzen (<em>Batches</em>) gruppiert. In jeder Epoche erfolgt die Anpassung der Gewichte für jedes durch das Netz geleitete Batch (jede <em>Iteration</em>):</p>
<ol type="1">
<li>
<p><strong>Epoche</strong></p>
<ol type="1">
<li>
<p><strong>Batch</strong></p>
<p><em>Forward Pass</em> <span class="math inline">\(\rightarrow\)</span> <em>Loss-Berechnung</em> <span class="math inline">\(\rightarrow\)</span> <em>Backpropagation</em> <span class="math inline">\(\rightarrow\)</span> <em>Gradient-Descent-Update</em></p>
</li>
<li>
<p><strong>Batch</strong></p>
<p><em>Forward Pass</em> <span class="math inline">\(\rightarrow\)</span> <em>Loss-Berechnung</em> <span class="math inline">\(\rightarrow\)</span> <em>Backpropagation</em> <span class="math inline">\(\rightarrow\)</span> <em>Gradient-Descent-Update</em></p>
<p>…</p>
</li>
</ol>
</li>
<li>
<p><strong>Epoche</strong></p>
<pre><code>     ...</code></pre>
<p>…</p>
</li>
</ol>
<p>Für das Training eines NN sind mehrere Epochen notwendig, weil ein einzelner Durchlauf der Daten oft nicht ausreicht, um die zugrundeliegenden Muster zu lernen. Durch Anpassung über mehrere Epochen können die Gewichte des Modells verfeinert werden, was insbesondere die Fähigkeit zur Generalisierung für ungesehene Daten verbessert. Die zufällige Einteilung der Daten in Batches zu Beginn jeder Epoche verhindert unter anderem, dass das NN lediglich die Reihenfolge der durchgeleiteten Datenpunkte lernt.</p>
<p>Die Anzahl an zu durchlaufender Epochen ist ein Tuning-Parameter: Zu wenige Epochen führen zu einer schlechten Anpassung an die Daten, während zu viele Epochen das Risiko von Overfitting erhöhen. Um den Vorhersagefehler für ungesehene Daten einzuschätzen, wird ein Testdatensatz vorbehalten. Dieser Datensatz wird während des Trainings nicht zum Anpassen der Gewichte genutzt, sondern erst nach Abschluss einer Epoche für die Berechnung der Vorhersagequalität herangezogen. So kann jeweils nach dem Durchlauf einer Epoche beurteilt werden, wie gut das Modell auf neue, unbekannte Daten generalisiert. Hierbei können ein hoher Vorhersagefehler für den Testdatensatz und ein (viel) geringerer Fehler für den Trainingsdatensatz nach mehreren Epochen auf Overfitting hinweisen. Im empirischen Teil dieses Kapitels diskutieren wir (grafische) Methoden zur Beurteilung der Anpassung des Modells.</p>
<p>Beim Training von NN können sogenannte <em>Callback-Funktionen</em> eingesetzt werden, um den Anpassungsprozess unter Einbezug von Zwischenergebnissen zu bestimmten Zeitpunkten während des Trainingsprozesses, z. B. am Ende jeder Epoche oder nach einer bestimmten Anzahl von Iterationen, zu evaluieren. Callbacks werden verwendet, um bestimmte Aktionen auszuführen, wie das Anpassen der Lernrate oder das Überwachen der Trainingsleistung: Ein Callback kann das Training automatisch stoppen (<em>Early Stopping</em>), wenn Anzeichen von Overfitting erkannt werden, beispielsweise wenn die Vorhersagegüte auf dem Test-Datensatz über mehrere Epochen hinweg stagniert. Dadurch wird ein unnötiges Fortsetzen des Trainings vermieden und ein Verlust der Generalisierungsfähigkeit auf neuen Daten verhindert.</p>
<p>Wir fassen die wichtigsten Begriffe für die Beschreibung von NN nachfolgend kurz zusammen.</p>
<p><strong>Wesentliche Definitionen</strong></p>
<ul>
<li><p><strong>Layer</strong>: Eine Ebene von Neuronen im neuronalen Netzwerk. Es gibt das Eingabe-Layer, versteckte Layers (Hidden Layers) und das Ausgabe-Layer. Jedes Layer verarbeitet Informationen aus dem vorangegangenen Layer und gibt die Ergebnisse an das nächste Layer weiter.</p></li>
<li><p><strong>Input</strong>: Die Eingangsdaten oder Merkmale, die in das NN eingespeist werden. Jeder Input wird durch ein oder mehrere Neuronen im Eingabe-Layer repräsentiert.</p></li>
<li><p><strong>Output</strong>: Das Ergebnis, welches das NN nach der Verarbeitung der Inputs liefert. Der Output wird durch die Neuronen im Output-Layer des NN erstellt.</p></li>
<li><p><strong>Neuron</strong>: Die kleinste Komponente eines NN. Jedes Neuron empfängt Inputs, multipliziert sie mit Gewichten, addiert einen Bias und gibt das Ergebnis nach Anwendung einer Aktivierungsfunktion weiter: Ein Neuron ist also eine <em>mathematische Funktion</em>, die Inputs aus dem vorherigen Layer mit einer transformierten Linearkombination verarbeitet und das Ergebnis das nächste Layers weiterleitet.</p></li>
<li><p><strong>Forward Pass</strong>: Leitung der Trainingsdaten durch das NN und Berechnung der Vorhersage des Outcomes.</p></li>
<li><p><strong>Loss-Funktion</strong>: Mathematische Funktion, welche die Güte der Vorhersage des NN für das Outcome quantifiziert. Der Loss ist eine Funktion der zu trainierenden Parameter des NN.</p></li>
<li><p><strong>Backward Pass / Backpropagation</strong>: Ermittlung des Gradienten der Loss-Funktion durch Verkettung des Effekts der Gewichte über die Layers des NN.</p></li>
<li>
<p><strong>Aktivierungsfunktion</strong>: Eine mathematische Funktion, die auf die gewichtete Summe der Eingaben eines Neurons angewendet wird. Die Aktivierungsfunktion bestimmt, ob ein Neuron aktiviert wird. Beispiele sind</p>
<p><span class="math display">\[\begin{align*}
    \text{ReLU}(z) =&amp; \max(0, z), \\[.5ex]
    \sigma(z) =&amp;\, \frac{1}{1 + e^{-z}}, \\[.5ex]
    \tanh(z) =&amp;\, \frac{e^z - e^{-z}}{e^z + e^{-z}}.
  \end{align*}\]</span></p>
</li>
<li><p><strong>Epoche</strong>: Ein Trainingszyklus, bei dem der gesamte Trainingsdatensatz, aufgeteilt in Batches, das NN durchläuft.</p></li>
<li><p><strong>Batches</strong>: Zufällig eingeteilte Teilmengen der Beobachtungen des Trainingsdatensatzes.</p></li>
<li><p><strong>Callback</strong>: Eine Funktion, die im Zuge der Überwachung des des Trainings-Prozesses automatisch ausgeführt wird, um Aktionen wie Lernratenanpassung oder Trainingsstopp zu auszulösen.</p></li>
</ul>
<p>Im nächsten Abschnitt erläutern wir die Optimierung der Gewichte mit Gradient Descent beispielhaft anhand interaktiver Visualisierungen.</p>
</section></section><section id="optimierung-mit-gradient-descent" class="level2 page-columns page-full" data-number="13.2"><h2 data-number="13.2" class="anchored" data-anchor-id="optimierung-mit-gradient-descent">
<span class="header-section-number">13.2</span> Optimierung mit Gradient Descent</h2>
<p>Gradient Descent ist ein iteratives Optimierungsverfahren zur Minimierung einer differenzierbaren Zielfunktion <span class="math inline">\(f(w)\)</span>. Ausgehend von einem Startwert <span class="math inline">\(w_0\)</span> aktualisiert der Algorithmus die Variable <span class="math inline">\(w\)</span> schrittweise gemäß einer Lernrate <span class="math inline">\(\eta\)</span> in die entgegengesetzte Richtung des Gradienten <span class="math inline">\(\nabla f(w)\)</span> der Funktion an der aktuellen <span class="math inline">\(w\)</span>. Mit <span class="math inline">\(\nabla f(w)\)</span> wird mathematisch die Richtung des <em>steilsten Anstiegs</em> von <span class="math inline">\(f(w)\)</span> im Punkt <span class="math inline">\(w\)</span> ermittelt. Der Algorithmus vollzieht eine Veränderung von <span class="math inline">\(w\)</span> in die entgegengesetzten Richtung – die Richtung mit dem schnellsten <em>Abstieg</em> (Descent) der Zielfunktion.</p>
<p>Der folgende Algorithmus zeigt die grundlegende Vorgehensweise des Gradientenabstiegsverfahrens für einen einziegen zu optimierenden Parameter <span class="math inline">\(w\)</span> unter Einbeziehung eines Momentum-Terms <span class="math inline">\(v_t\)</span>.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> Der Momentum-Term dient dazu, das Konvergenzverhalten zu verbessern und lokale Minima effektiver zu überwinden. Die Stärke des Momentums <span class="math inline">\(v_t\)</span> wird durch den Momentum-Faktor <span class="math inline">\(\alpha \in [0,1)\)</span> bestimmt.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;In der Literatur wird <span class="math inline">\(v_t\)</span> häufig auch als <em>Velocity</em> bezeichnet.</p></div></div><p><span class="math display">\[\begin{align*}
  \small
  &amp; \textbf{Algorithmus: Gradientenabstiegsverfahren mit Momentum} \\
  &amp; \textup{Initialisiere: }\\[.5ex]
  &amp; \quad w_0 \text{ (Startpunkt) }\\
  &amp; \quad \eta \text{ (Lernrate) }\\
  &amp; \quad \alpha \text{ (Momentum-Faktor) }\\
  &amp; \quad v_0 = 0 \text{ (Anfangsmomentum) } \\[1em]
  &amp; \text{Iteriere für } t = 0, 1, 2, \dots \text{ bis Konvergenz:} \\[.5ex]
  &amp; \quad \text{1. Berechne den Gradienten: } \nabla f(w_t) \\
  &amp; \quad \text{2. Aktualisiere den Momentum-Term: } v_{t+1} = \alpha v_t - \eta \nabla f(w_t) \\
  &amp; \quad \text{3. Aktualisiere die Position: } w_{t+1} = w_t + v_{t+1} \\
  &amp; \quad \text{4. Überprüfe das Abbruchkriterium } |\nabla f(w_t)| &lt; \epsilon\text{ (für ein kleines $\epsilon&gt;0$)} \\
\end{align*}\]</span></p>
<p>In der nachfolgenden interaktiven Visualisierung illustrieren wir die Minimierung einer univariaten Funktion <span class="math inline">\(\color{blue}{f(w_t)}\)</span> nach <span class="math inline">\(w_t\)</span> anhand des obigen Algorithmus mit Lernrate <span class="math inline">\(\eta = .001\)</span> und Momentum-Faktor <span class="math inline">\(\alpha = .925\)</span>.</p>
<p>Der <span style="color:orange">Gradient</span><span class="math inline">\(\color{orange}{\nabla f(w_t)}\)</span> ist hier die 1. Ableitung von <span class="math inline">\(\color{blue}{f(w_t)}\)</span> nach <span class="math inline">\(w_t\)</span>. Die Richtung der Änderung von <span class="math inline">\(\color{blue}{f(w_t)}\)</span> in <span class="math inline">\(w_t\)</span> wird durch den <span style="color:orange">orangenen Pfeil</span> angezeigt. Beachte, wie sich der Gradient bei Variation des Start-Punkts mit dem Slider ändert. Während die Animation der Optimierung mit Gradient Descent läuft, zeigt der <span style="color:purple">lilane Pfeil</span> das <span style="color:purple">Momentum</span> (<span style="color:purple">Velocity <span class="math inline">\(v_t\)</span></span>) für Schirtt <span class="math inline">\(t\)</span> an.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> Der Algorithmus iteriert die Schritte 1. bis 3. solange, bis das Abbruchkriterium <span class="math inline">\(|\textcolor{orange}{\nabla f(w_t)}| &lt; \epsilon = 0.001\)</span> erreicht ist, die Änderung in <span class="math inline">\(\color{orange}{\nabla f(w_t)}\)</span> also hinreichend klein ist, dass ein Parameterwert <span class="math inline">\(w_t\)</span> mit <span class="math inline">\(\color{blue}{f(w_t)}\)</span> nahe des (globalen) Minimums von <span class="math inline">\(f\)</span> plausibel ist.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;Unterschiedliche Längen der Pfeile zeigen hier nicht Änderungen der tatsächlichen Beträge, sondern dienen lediglich der Interpretierbakeit der Grafik.</p></div></div><p>Folgende Eigenschaften der Optimierung mit Gradient Descent können anhand der Parameter geprüft werden:</p>
<ul>
<li>
<p>Für Startpunkte mit großen Werten des Gradienten beginnt der Algorithmus mit einem starken Momentum: Der Abstieg in Richtung des negativen Gradients erfolgt also in großen Schritten, sodass die Optimierung schneller erfolgt als für Startpunkte in flachen Regionen von <span class="math inline">\(\color{blue}{f}\)</span>.</p>
<p>Dieser Effekt des Momentum auf den Pfad der zu optimierenden Parameter bei Gradient Descent ist vergleichbar mit dem Effekt der Schwerkraft auf eine Murmel, die auf einer hügeligen Oberfläche rollt: Anfangs gewinnt die Murmel an Geschwindigkeit und bewegt sich beschleunigt in Richtung des steilsten Gefälles. In flacheren Regionen wird die Bewegung langsamer und die Murmel kann in Tälern stecken bleiben, ähnlich wie der Optimierungsprozess in flachen Regionen von <span class="math inline">\(\color{blue}{f}\)</span> langsamer verläuft oder gar stoppt, weil ein Abbruchkriterium erfüllt ist (geringe Änderung des Gradienten). Das Momentum hilft, auch in solchen flachen Bereichen weiter voranzukommen, indem es dem Parameterpfad eine gewisse “Trägheit” verleiht, die es ermöglicht, flache Stellen schneller zu durchqueren und die Optimierung effizienter zu gestalten.</p>
</li>
<li><p>Bei ungünstiger Wahl der Parameter konvergiert der Algorithmus nicht zum globalen Minimum, sondern stoppt im lokalen Minimum bei <span class="math inline">\(w = -0.5\)</span>. Dies unterstreicht die Notwendigkeit, die Hyperparameter Lernrate <span class="math inline">\(\eta\)</span> und Momentum-Faktor <span class="math inline">\(\alpha\)</span> sorgfältig zu wählen, beispielsweise indem die Modellgüte nach erfolgter Anpassung für verschiedene Parameter-Kombinationen verglichen wird.</p></li>
</ul>
<p>In empirischen Anwendungen ist es für eine hohe Modellgüte eines neuronalen Netzwerks nicht unbedingt erforderlich, das globale Minimum zu finden: Viele Optimierungsprobleme weisen zahlreiche lokale Minima auf, die eine ausreichend gute Annäherung an das Optimum bieten können. Besonders bei hochdimensionalen Optimierungsproblemen mit komplexen Loss-Funktionen können diese lokalen Minima zufriedenstellende Lösungen darstellen. In einigen Fällen existiert möglicherweise kein globales Minimum, und der Algorithmus konvergiert zwangsläufig zu einem stabilen lokalen Minimum, das dennoch eine gute Performance gewährleistet. Daher kann es sinnvoller sein, Algorithmen zu verwenden, die das Erreichen einer robusten Lösung legen, anstatt strikt nach dem globalen Minimum zu suchen.</p>
<p>In Software-Implementierungen für Machine und Deep Learning wie <code>tensorflow</code> und <code>keras</code> werden fortgeschrittene Techniken wie Momentum Tuning oder Stochastic <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Gradient Descent</a> (SGD) eingesetzt, um die Wahrscheinlichkeit zu erhöhen, dass der Algorithmus nicht in einem (ungünstigen) lokalen Minimum endet. Ein für die Anpassung von NN häufig verwendeter Algorithmus, der SGD verwendet, ist <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam">Adaptive Moment Estimation (Adam)</a>. Wir verwenden u.a. den Adam-Optimizer in den empirischen Beispielen.</p>
<iframe class="obs-soft-box-shadow" width="100%" height="761" frameborder="0" src="https://observablehq.com/embed/@mca91/gradient-descent-in-2d?cells=plot%2Cviewof+startAnimation%2Cviewof+startPoint%2Cviewof+alpha%2Cviewof+eta%2CoptimalReached%2CMathJax%2Cstyles">
</iframe>
<p>In empirischen Anwendungen sind die zu lernenden Zusammenhänge komplex und damit die Anzahl der zu optimierenden Parameter eines NN häufig groß. Der oben erläuterte Algorithmus für Gradient Descent mit Momentum kann einfach auf Optimierungsprobleme mit <span class="math inline">\(k\)</span> Parametern generalisiert werden. Dann ist <span class="math inline">\(\boldsymbol{w}_t\)</span> ein Vektor mit <span class="math inline">\(k\)</span> Gewichten, <span class="math inline">\(\boldsymbol{v}_{t+1}\)</span> eine vektorwertige Funktion von <span class="math inline">\(\boldsymbol{v}_t\)</span> und <span class="math inline">\(\nabla f(\boldsymbol{w}_t)\)</span> mit Dimension <span class="math inline">\(k\)</span> und <span class="math inline">\(f(\boldsymbol{w}_t)\)</span> ist eine Oberfläche in einem <span class="math inline">\(k+1\)</span>-dimensionalen Raum.</p>
<p>Die nachfolgende interaktive Grafik illustriert Gradient Descent mit Momentum für <span class="math inline">\(k=2\)</span> zu optimierende Gewichte. Statt der Parameter des Algorithmus kann hier die Form der zu optimierenden Funktion manipuliert werden, sodass bis zu 6 Extremstellen vorliegen können. Der <span style="color:red">rote Punkt</span> zeigt den Verlauf der Optimierung von <span class="math inline">\(\boldsymbol{w}_t\)</span>.</p>
<p>Die Animation verdeutlicht, dass lokale Minima insbesondere in höheren Dimensionen herausfordernd für Optimierungsalgorithmen sind: Durch Variation der Extrema lassen sich leicht Funktionen <span class="math inline">\(f(w_1,w_1)\)</span> konstruieren, für die Gradient Descent mit den voreingestellten Parametern nicht gegen das globale Minimum konvergiert, sofern vorhanden. Ein günstiger Initialwert für <span class="math inline">\(\boldsymbol{w}_t\)</span> kann die Wahrscheinlichkeit von Stops in lokalen Minima verringern: <em>Grid Search Initialization</em> wertet die Funktion über ein gleichmäßiges Gitter von Werten für <span class="math inline">\(\boldsymbol{w}_t\)</span> aus und wählt als Startwert <span class="math inline">\(\boldsymbol{w}_{0,\textup{init}}\)</span> den Punkt mit dem minimalen Funktionswert von <span class="math inline">\(f\)</span> über alle Punkte im Gitter.</p>
<iframe class="obs-soft-box-shadow" width="100%" height="1172" frameborder="0" src="https://observablehq.com/embed/@mca91/gradient-descent-in-3d-three-js?cells=renderer%2Cviewof+restart%2Cviewof+gridinit%2Cviewof+themin%2Cviewof+themin2%2Cviewof+themin3%2Cviewof+themin4%2Cviewof+themin5%2Cviewof+themin6%2Cscene%2Ccamera">
</iframe>
</section><section id="funktionale-zusammenhänge-lernen-regression" class="level2 page-columns page-full" data-number="13.3"><h2 data-number="13.3" class="anchored" data-anchor-id="funktionale-zusammenhänge-lernen-regression">
<span class="header-section-number">13.3</span> Funktionale Zusammenhänge lernen: Regression</h2>
<p><span class="math display">\[\begin{align*}
  Y = w_1 X + b
\end{align*}\]</span></p>
<div class="cell page-columns page-full" data-fig-width="6" data-fig-height="2" data-layout-align="default">
<div class="cell-output-display page-columns page-full">
<div id="fig-nn-lreg" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-nn-lreg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="576" height="192" viewbox="0.00 0.00 332.02 200.11" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none"><g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 196.11)"><title>NEURALNET</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-196.11 328.02,-196.11 328.02,4 -4,4"></polygon><!-- X --><g id="node1" class="node"><title>X</title>
<ellipse fill="none" stroke="black" cx="18.01" cy="-30.11" rx="18.02" ry="18.02"></ellipse><text text-anchor="middle" x="18.01" y="-25.91" font-family="Helvetica,Arial,sans-serif" font-size="14.00">X</text></g><!-- Y --><g id="node2" class="node"><title>Y</title>
<ellipse fill="lightgreen" stroke="black" cx="306.01" cy="-30.11" rx="18.02" ry="18.02"></ellipse><text text-anchor="middle" x="306.01" y="-25.91" font-family="Helvetica,Arial,sans-serif" font-size="14.00">Y</text></g><!-- X&#45;&gt;Y --><g id="edge1" class="edge"><title>X-&gt;Y</title>
<path fill="none" stroke="black" d="M36.03,-30.11C84.6,-30.11 218.57,-30.11 277.53,-30.11"></path><polygon fill="black" stroke="black" points="277.63,-33.61 287.63,-30.11 277.63,-26.61 277.63,-33.61"></polygon><text text-anchor="middle" x="164.53" y="-4.2" font-family="Helvetica,Arial,sans-serif" font-size="14.00">w1</text></g><!-- B --><g id="node3" class="node"><title>B</title>
<ellipse fill="none" stroke="black" cx="162.01" cy="-174.11" rx="18" ry="18"></ellipse><text text-anchor="middle" x="162.01" y="-169.91" font-family="Helvetica,Arial,sans-serif" font-size="14.00" fill="gray">1</text></g><!-- B&#45;&gt;Y --><g id="edge2" class="edge"><title>B-&gt;Y</title>
<path fill="none" stroke="gray" d="M174.79,-161.33C199.81,-136.31 255.45,-80.67 285.62,-50.5"></path><polygon fill="gray" stroke="gray" points="288.46,-52.61 293.05,-43.06 283.51,-47.66 288.46,-52.61"></polygon><text text-anchor="middle" x="248.05" y="-116.81" font-family="Helvetica,Arial,sans-serif" font-size="14.00">bias (b)</text></g></g></svg>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-nn-lreg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;13.2: Neuronales Netzwerk: Lineare Regression mit einer Variable und Bias
</figcaption></figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://wilkelab.org/cowplot/">cowplot</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tensorflow">tensorflow</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tensorflow.rstudio.com/">keras</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">1000</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">n</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">5</span> <span class="op">+</span> <span class="fl">3</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span> </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span></span>
<span>    units <span class="op">=</span> <span class="fl">1</span>, </span>
<span>    input_shape <span class="op">=</span> <span class="fl">1</span>, </span>
<span>    activation <span class="op">=</span> <span class="st">'linear'</span></span>
<span>    <span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># kompilieren</span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span></span>
<span>  optimizer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/optimizer_adam.html">optimizer_adam</a></span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span>,</span>
<span>  loss <span class="op">=</span> <span class="st">'mean_absolute_error'</span></span>
<span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Modell trainieren</span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span></span>
<span>  x <span class="op">=</span> <span class="va">x</span>, </span>
<span>  y <span class="op">=</span> <span class="va">y</span>, </span>
<span>  epochs <span class="op">=</span> <span class="fl">100</span>, </span>
<span>  verbose <span class="op">=</span> <span class="fl">0</span>, </span>
<span>  validation_split <span class="op">=</span> <span class="fl">.2</span></span>
<span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># lineares Modell</span></span>
<span><span class="va">lm_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lm_model</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.8431 -0.7007  0.0136  0.6558  3.4072 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  5.04094    0.06333    79.6   &lt;2e-16 ***
x            2.99417    0.01103   271.6   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.002 on 998 degrees of freedom
Multiple R-squared:  0.9866,    Adjusted R-squared:  0.9866 
F-statistic: 7.374e+04 on 1 and 998 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Koeffizienten der linearen Regression</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">lm_model</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)           x 
   5.040943    2.994166 </code></pre>
</div>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Gewichtung und Bias des neuronalen Netzwerks</span></span>
<span><span class="va">weights</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/get_weights.html">get_weights</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">weights</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>  <span class="co"># Gewichtung</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          [,1]
[1,] 0.4906718</code></pre>
</div>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">weights</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>  <span class="co"># Bias</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0</code></pre>
</div>
</div>
</section><section id="multiple-regression" class="level2 page-columns page-full" data-number="13.4"><h2 data-number="13.4" class="anchored" data-anchor-id="multiple-regression">
<span class="header-section-number">13.4</span> Multiple Regression</h2>
<div class="cell page-columns page-full" data-fig-width="6" data-fig-height="3" data-layout-align="default">
<div class="cell-output-display page-columns page-full">
<div id="fig-nn-mlreg" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-nn-mlreg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="576" height="288" viewbox="0.00 0.00 408.85 264.84" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none"><g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 260.84)"><title>NEURALNET</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-260.84 404.85,-260.84 404.85,4 -4,4"></polygon><!-- X1 --><g id="node1" class="node"><title>X1</title>
<ellipse fill="none" stroke="black" cx="22.84" cy="-166.84" rx="22.68" ry="22.68"></ellipse><text text-anchor="middle" x="22.84" y="-162.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">X1</text></g><!-- Y --><g id="node4" class="node"><title>Y</title>
<ellipse fill="none" stroke="black" cx="382.84" cy="-94.84" rx="18.02" ry="18.02"></ellipse><text text-anchor="middle" x="382.84" y="-90.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">Y</text></g><!-- X1&#45;&gt;Y --><g id="edge1" class="edge"><title>X1-&gt;Y</title>
<path fill="none" stroke="black" d="M45.36,-162.33C108.33,-149.74 286.14,-114.18 355.06,-100.39"></path><polygon fill="black" stroke="black" points="356.03,-103.77 365.15,-98.38 354.66,-96.91 356.03,-103.77"></polygon><text text-anchor="middle" x="192.4" y="-144.73" font-family="Helvetica,Arial,sans-serif" font-size="14.00">w1</text></g><!-- X2 --><g id="node2" class="node"><title>X2</title>
<ellipse fill="none" stroke="black" cx="22.84" cy="-94.84" rx="22.68" ry="22.68"></ellipse><text text-anchor="middle" x="22.84" y="-90.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">X2</text></g><!-- X2&#45;&gt;Y --><g id="edge2" class="edge"><title>X2-&gt;Y</title>
<path fill="none" stroke="black" d="M45.91,-94.84C109.25,-94.84 285.73,-94.84 354.7,-94.84"></path><polygon fill="black" stroke="black" points="354.82,-98.34 364.82,-94.84 354.82,-91.34 354.82,-98.34"></polygon><text text-anchor="middle" x="185.5" y="-106.33" font-family="Helvetica,Arial,sans-serif" font-size="14.00">w2</text></g><!-- X3 --><g id="node3" class="node"><title>X3</title>
<ellipse fill="none" stroke="black" cx="22.84" cy="-22.84" rx="22.68" ry="22.68"></ellipse><text text-anchor="middle" x="22.84" y="-18.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">X3</text></g><!-- X3&#45;&gt;Y --><g id="edge3" class="edge"><title>X3-&gt;Y</title>
<path fill="none" stroke="black" d="M45.36,-27.34C108.33,-39.94 286.14,-75.5 355.06,-89.28"></path><polygon fill="black" stroke="black" points="354.66,-92.77 365.15,-91.3 356.03,-85.91 354.66,-92.77"></polygon><text text-anchor="middle" x="186.24" y="-67.32" font-family="Helvetica,Arial,sans-serif" font-size="14.00">w3</text></g><!-- B --><g id="node5" class="node"><title>B</title>
<ellipse fill="none" stroke="black" cx="22.84" cy="-238.84" rx="18" ry="18"></ellipse><text text-anchor="middle" x="22.84" y="-234.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00" fill="gray">1</text></g><!-- B&#45;&gt;Y --><g id="edge4" class="edge"><title>B-&gt;Y</title>
<path fill="none" stroke="black" d="M39.72,-232.09C97.35,-209.03 286.65,-133.32 356.57,-105.35"></path><polygon fill="black" stroke="black" points="358.01,-108.54 365.99,-101.58 355.41,-102.04 358.01,-108.54"></polygon><text text-anchor="middle" x="209.8" y="-186.84" font-family="Helvetica,Arial,sans-serif" font-size="14.00">bias (b)</text></g></g></svg>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-nn-mlreg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;13.3: Neuronales Netzwerk: Multiple lineare Regression
</figcaption></figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Erstellen von Trainingsdaten</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">250</span></span>
<span><span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">3</span></span>
<span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span> <span class="op">*</span> <span class="va">k</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="va">k</span><span class="op">)</span></span>
<span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">2</span>, <span class="op">-</span><span class="fl">1.5</span><span class="op">)</span></span>
<span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="fl">5</span> <span class="op">+</span> <span class="va">X</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">w</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Erstellen und Kompilieren des Modells</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span></span>
<span>    units <span class="op">=</span> <span class="fl">1</span>, </span>
<span>    input_shape <span class="op">=</span> <span class="va">k</span>, </span>
<span>    activation <span class="op">=</span> <span class="st">'linear'</span></span>
<span>  <span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span></span>
<span>  loss <span class="op">=</span> <span class="st">'mean_squared_error'</span>,</span>
<span>  optimizer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/optimizer_sgd.html">optimizer_sgd</a></span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Training des Modells</span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span></span>
<span>  x <span class="op">=</span> <span class="va">X</span>, </span>
<span>  y <span class="op">=</span> <span class="va">Y</span>, </span>
<span>  epochs <span class="op">=</span> <span class="fl">100</span>, </span>
<span>  verbose <span class="op">=</span> <span class="fl">0</span></span>
<span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Gewichte und Bias extrahieren</span></span>
<span><span class="va">weights</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/get_weights.html">get_weights</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">weights</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>  <span class="co"># Gewicht für jede Variablen</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           [,1]
[1,] -0.4610112
[2,]  0.7993697
[3,]  0.4530224</code></pre>
</div>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">weights</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>  <span class="co"># Bias-Term</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># lineares Modell</span></span>
<span><span class="va">lm_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">X</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lm_model</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Y ~ X)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.3129 -0.7286  0.0900  0.7439  3.4086 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  5.01583    0.06843   73.30   &lt;2e-16 ***
X1           2.97449    0.07028   42.32   &lt;2e-16 ***
X2           1.94345    0.07061   27.52   &lt;2e-16 ***
X3          -1.47278    0.06914  -21.30   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.079 on 246 degrees of freedom
Multiple R-squared:  0.9271,    Adjusted R-squared:  0.9262 
F-statistic:  1042 on 3 and 246 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
</section><section id="nicht-lineare-zusammenhänge" class="level2 page-columns page-full" data-number="13.5"><h2 data-number="13.5" class="anchored" data-anchor-id="nicht-lineare-zusammenhänge">
<span class="header-section-number">13.5</span> Nicht-Lineare Zusammenhänge</h2>
<div class="cell">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Erstellen von Trainingsdaten</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">500</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mean <span class="op">=</span> <span class="fl">5</span>, sd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="co"># Regressor</span></span>
<span><span class="va">P</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="op">-</span><span class="fl">4</span> <span class="op">+</span> <span class="fl">0.7</span> <span class="op">*</span> <span class="va">X</span><span class="op">)</span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span> <span class="op">&lt;</span> <span class="va">P</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell page-columns page-full" data-fig-width="6" data-fig-height="4" data-layout-align="default">
<div class="cell-output-display page-columns page-full">
<div id="fig-neuralnet-logistic-regression" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-neuralnet-logistic-regression-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="576" height="384" viewbox="0.00 0.00 480.85 264.84" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none"><g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 260.84)"><title>NEURALNET</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-260.84 476.85,-260.84 476.85,4 -4,4"></polygon><!-- X1 --><g id="node1" class="node"><title>X1</title>
<ellipse fill="none" stroke="black" cx="22.84" cy="-166.84" rx="22.68" ry="22.68"></ellipse><text text-anchor="middle" x="22.84" y="-162.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">X1</text></g><!-- sigmoid --><g id="node5" class="node"><title>sigmoid</title>
<ellipse fill="lightblue" stroke="black" cx="310.84" cy="-94.84" rx="27" ry="18"></ellipse><text text-anchor="middle" x="310.84" y="-90.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">σ</text></g><!-- X1&#45;&gt;sigmoid --><g id="edge1" class="edge"><title>X1-&gt;sigmoid</title>
<path fill="none" stroke="black" d="M45.44,-161.19C95.45,-148.69 215.81,-118.6 275.73,-103.62"></path><polygon fill="black" stroke="black" points="276.64,-107 285.49,-101.18 274.94,-100.21 276.64,-107"></polygon><text text-anchor="middle" x="171.33" y="-147.89" font-family="Helvetica,Arial,sans-serif" font-size="14.00">w1</text></g><!-- X2 --><g id="node2" class="node"><title>X2</title>
<ellipse fill="none" stroke="black" cx="22.84" cy="-94.84" rx="22.68" ry="22.68"></ellipse><text text-anchor="middle" x="22.84" y="-90.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">X2</text></g><!-- X2&#45;&gt;sigmoid --><g id="edge2" class="edge"><title>X2-&gt;sigmoid</title>
<path fill="none" stroke="black" d="M45.92,-94.84C95.53,-94.84 212.72,-94.84 273.23,-94.84"></path><polygon fill="black" stroke="black" points="273.49,-98.34 283.49,-94.84 273.49,-91.34 273.49,-98.34"></polygon><text text-anchor="middle" x="160.39" y="-112.34" font-family="Helvetica,Arial,sans-serif" font-size="14.00">w2</text></g><!-- X3 --><g id="node3" class="node"><title>X3</title>
<ellipse fill="none" stroke="black" cx="22.84" cy="-22.84" rx="22.68" ry="22.68"></ellipse><text text-anchor="middle" x="22.84" y="-18.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">X3</text></g><!-- X3&#45;&gt;sigmoid --><g id="edge3" class="edge"><title>X3-&gt;sigmoid</title>
<path fill="none" stroke="black" d="M45.44,-28.49C95.45,-40.99 215.81,-71.08 275.73,-86.06"></path><polygon fill="black" stroke="black" points="274.94,-89.47 285.49,-88.5 276.64,-82.68 274.94,-89.47"></polygon><text text-anchor="middle" x="160.8" y="-75.5" font-family="Helvetica,Arial,sans-serif" font-size="14.00">w3</text></g><!-- Y --><g id="node4" class="node"><title>Y</title>
<ellipse fill="lightgreen" stroke="black" cx="454.84" cy="-94.84" rx="18.02" ry="18.02"></ellipse><text text-anchor="middle" x="454.84" y="-90.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00">Y</text></g><!-- sigmoid&#45;&gt;Y --><g id="edge5" class="edge"><title>sigmoid-&gt;Y</title>
<path fill="none" stroke="black" d="M337.92,-94.84C363.16,-94.84 400.65,-94.84 426.34,-94.84"></path><polygon fill="black" stroke="black" points="426.55,-98.34 436.55,-94.84 426.55,-91.34 426.55,-98.34"></polygon></g><!-- B --><g id="node6" class="node"><title>B</title>
<ellipse fill="none" stroke="black" cx="22.84" cy="-238.84" rx="18" ry="18"></ellipse><text text-anchor="middle" x="22.84" y="-234.64" font-family="Helvetica,Arial,sans-serif" font-size="14.00" fill="gray">1</text></g><!-- B&#45;&gt;sigmoid --><g id="edge4" class="edge"><title>B-&gt;sigmoid</title>
<path fill="none" stroke="gray" d="M39.15,-230.68C85.57,-207.47 218.99,-140.76 279.88,-110.32"></path><polygon fill="gray" stroke="gray" points="281.62,-113.36 289,-105.76 278.49,-107.1 281.62,-113.36"></polygon><text text-anchor="middle" x="188.6" y="-176.02" font-family="Helvetica,Arial,sans-serif" font-size="14.00">bias (b)</text></g></g></svg>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-neuralnet-logistic-regression-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;13.4: Neuronales Netzwerk mit Sigmoid-Aktivierungsfunktion
</figcaption></figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Erstellen und Kompilieren des Modells</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">1</span>, input_shape <span class="op">=</span> <span class="fl">1</span>, activation <span class="op">=</span> <span class="st">'sigmoid'</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span></span>
<span>  loss <span class="op">=</span> <span class="st">'binary_crossentropy'</span>,</span>
<span>  optimizer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/optimizer_adam.html">optimizer_adam</a></span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span>,</span>
<span>  metrics <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'accuracy'</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Training des Modells</span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">Y</span>, epochs <span class="op">=</span> <span class="fl">200</span>, verbose <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Gewichte und Bias extrahieren</span></span>
<span><span class="va">weights</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/get_weights.html">get_weights</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">w</span> <span class="op">&lt;-</span> <span class="va">weights</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>  <span class="co"># Gewicht für jede der 5 Variablen</span></span>
<span><span class="va">bias</span> <span class="op">&lt;-</span> <span class="va">weights</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>  <span class="co"># Bias-Term</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Ergebnisse anzeigen</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">w</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           [,1]
[1,] -0.6519682</code></pre>
</div>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">bias</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">X</span>, family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:  glm(formula = Y ~ X, family = binomial(link = "logit"))

Coefficients:
(Intercept)            X  
     -8.572        1.527  

Degrees of Freedom: 499 Total (i.e. Null);  498 Residual
Null Deviance:      663.1 
Residual Deviance: 347.1    AIC: 351.1</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Vorhersagen auf den Trainingsdaten erstellen</span></span>
<span><span class="va">predictions</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>16/16 - 0s - 92ms/epoch - 6ms/step</code></pre>
</div>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># In einen DataFrame zusammenfassen</span></span>
<span><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  Regressor <span class="op">=</span> <span class="va">X</span>,</span>
<span>  Actual <span class="op">=</span> <span class="va">Y</span>,</span>
<span>  Predicted_Probability <span class="op">=</span> <span class="va">predictions</span></span>
<span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot der tatsächlichen Werte gegen die vorhergesagten Wahrscheinlichkeiten</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">results</span>,</span>
<span>  mapping <span class="op">=</span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">X</span>, y <span class="op">=</span> <span class="va">Actual</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span></span>
<span>    position <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/position_jitter.html">position_jitter</a></span><span class="op">(</span>height <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span>, </span>
<span>    alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span></span>
<span>     mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">Predicted_Probability</span><span class="op">)</span>,</span>
<span>    col <span class="op">=</span> <span class="st">"darkred"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span></span>
<span>    method <span class="op">=</span> <span class="st">"glm"</span>, </span>
<span>    method.args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span>, </span>
<span>    se <span class="op">=</span> <span class="cn">FALSE</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"Logistische Regression vs. NN"</span>,</span>
<span>       x <span class="op">=</span> <span class="st">"x"</span>,</span>
<span>       y <span class="op">=</span> <span class="st">"Schätzung P(Y=1|X=x)"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="Machine-Learning_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section><section id="case-study-immobilienpreise" class="level2" data-number="13.6"><h2 data-number="13.6" class="anchored" data-anchor-id="case-study-immobilienpreise">
<span class="header-section-number">13.6</span> Case Study: Immobilienpreise</h2>
<div class="cell">
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/topepo/AmesHousing">AmesHousing</a></span><span class="op">)</span></span>
<span><span class="va">housing</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/AmesHousing/man/make_ames.html">make_ames</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load the necessary libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-spatial.github.io/sf/">sf</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/walkerke/tigris">tigris</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Retrieve basemap for Ames, Iowa using the tigris package</span></span>
<span><span class="va">places_map</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/tigris/man/places.html">places</a></span><span class="op">(</span></span>
<span>  state <span class="op">=</span> <span class="st">'IA'</span>, </span>
<span>  cb <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>  progress <span class="op">=</span> <span class="cn">F</span></span>
<span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://r-spatial.github.io/sf/reference/st_as_sf.html">st_as_sf</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Filter for Ames city</span></span>
<span><span class="va">ames_map</span> <span class="op">&lt;-</span> <span class="va">places_map</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">NAME</span> <span class="op">==</span> <span class="st">"Ames"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">houses</span> <span class="op">&lt;-</span> <span class="va">housing</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">Latitude</span>, <span class="va">Longitude</span>, <span class="va">Sale_Price</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span></span>
<span>      Sale_Price <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cut.html">cut</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">Sale_Price</span>, base <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>, breaks <span class="op">=</span> <span class="fl">5</span>, labels <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>    <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://r-spatial.github.io/sf/reference/st_as_sf.html">st_as_sf</a></span><span class="op">(</span>coords <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Longitude"</span>, <span class="st">"Latitude"</span><span class="op">)</span>, </span>
<span>             crs <span class="op">=</span> <span class="fl">4326</span>, agr <span class="op">=</span> <span class="st">"constant"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">rainbow_colors</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/palettes.html">rainbow</a></span><span class="op">(</span><span class="fl">5</span>, rev <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Plot the map with just the outline of Ames</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggsf.html">geom_sf</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">ames_map</span>, color <span class="op">=</span> <span class="st">"black"</span>, fill <span class="op">=</span> <span class="fu"><a href="https://scales.r-lib.org/reference/alpha.html">alpha</a></span><span class="op">(</span><span class="st">"black"</span>, alpha <span class="op">=</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggsf.html">geom_sf</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">houses</span>, mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">Sale_Price</span><span class="op">)</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://wilkelab.org/cowplot/reference/theme_map.html">theme_map</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_color_manual</a></span><span class="op">(</span></span>
<span>    name <span class="op">=</span> <span class="st">"log(Verkaufspreis)"</span>, </span>
<span>    values <span class="op">=</span> <span class="va">rainbow_colors</span>, </span>
<span>    labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">houses</span><span class="op">$</span><span class="va">Sale_Price</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"bottom"</span>, legend.direction <span class="op">=</span> <span class="st">"horizontal"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"Verkaufte Häuser in Ames, Iowa"</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="Machine-Learning_files/figure-html/unnamed-chunk-28-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">housing</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Year_Built</span>, y <span class="op">=</span> <span class="va">Sale_Price</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">.5</span>, fill <span class="op">=</span> <span class="st">"steelblue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://wilkelab.org/cowplot/reference/theme_cowplot.html">theme_cowplot</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="Machine-Learning_files/figure-html/unnamed-chunk-29-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Split the data into training and testing sets</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidymodels.tidymodels.org">tidymodels</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">split</span> <span class="op">&lt;-</span> <span class="fu">initial_split</span><span class="op">(</span><span class="va">housing</span>, prop <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span></span>
<span></span>
<span><span class="va">housing_train</span> <span class="op">&lt;-</span> <span class="fu">training</span><span class="op">(</span><span class="va">split</span><span class="op">)</span></span>
<span><span class="va">housing_test</span> <span class="op">&lt;-</span> <span class="fu">testing</span><span class="op">(</span><span class="va">split</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Separate the predictors and the outcome</span></span>
<span><span class="va">housing_train_x</span> <span class="op">&lt;-</span> <span class="va">housing_train</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">Sale_Price</span><span class="op">)</span></span>
<span><span class="va">housing_train_y</span> <span class="op">&lt;-</span> <span class="va">housing_train</span><span class="op">$</span><span class="va">Sale_Price</span></span>
<span></span>
<span><span class="va">housing_test_x</span> <span class="op">&lt;-</span> <span class="va">housing_test</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">Sale_Price</span><span class="op">)</span></span>
<span><span class="va">housing_test_y</span> <span class="op">&lt;-</span> <span class="va">housing_test</span><span class="op">$</span><span class="va">Sale_Price</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">blueprint</span> <span class="op">&lt;-</span> <span class="fu">recipe</span><span class="op">(</span><span class="va">Sale_Price</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">housing_train</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">step_nzv</span><span class="op">(</span><span class="fu">all_nominal</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">step_other</span><span class="op">(</span><span class="fu">all_nominal</span><span class="op">(</span><span class="op">)</span>, threshold <span class="op">=</span> <span class="fl">.01</span>, other <span class="op">=</span> <span class="st">"other"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">step_integer</span><span class="op">(</span><span class="fu"><a href="https://tidyselect.r-lib.org/reference/starts_with.html">matches</a></span><span class="op">(</span><span class="st">"(Qual|Cond|QC|Qu)$"</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">step_YeoJohnson</span><span class="op">(</span><span class="fu">all_numeric</span><span class="op">(</span><span class="op">)</span>, <span class="op">-</span><span class="fu">all_outcomes</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">step_center</span><span class="op">(</span><span class="fu">all_numeric</span><span class="op">(</span><span class="op">)</span>, <span class="op">-</span><span class="fu">all_outcomes</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">step_scale</span><span class="op">(</span><span class="fu">all_numeric</span><span class="op">(</span><span class="op">)</span>, <span class="op">-</span><span class="fu">all_outcomes</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">step_dummy</span><span class="op">(</span><span class="fu">all_nominal</span><span class="op">(</span><span class="op">)</span>, <span class="op">-</span><span class="fu">all_outcomes</span><span class="op">(</span><span class="op">)</span>, one_hot <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">prepare</span> <span class="op">&lt;-</span> <span class="fu">prep</span><span class="op">(</span><span class="va">blueprint</span>, training <span class="op">=</span> <span class="va">housing_train</span><span class="op">)</span></span>
<span><span class="va">prepare</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">baked_train</span> <span class="op">&lt;-</span> <span class="fu">bake</span><span class="op">(</span><span class="va">prepare</span>, new_data <span class="op">=</span> <span class="va">housing_train</span><span class="op">)</span></span>
<span><span class="va">baked_test</span> <span class="op">&lt;-</span> <span class="fu">bake</span><span class="op">(</span><span class="va">prepare</span>, new_data <span class="op">=</span> <span class="va">housing_test</span><span class="op">)</span></span>
<span></span>
<span><span class="va">baked_train</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2,344 × 190
   Lot_Frontage  Lot_Area Overall_Qual Overall_Cond Year_Built Year_Remod_Add
          &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;
 1       1.15    0.350         -0.0340       -0.487     0.843           0.654
 2       0.277  -0.0336        -0.800        -0.487    -0.155          -0.839
 3      -0.129  -0.0213        -0.800        -1.76     -1.75           -1.66 
 4      -0.909  -3.19          -0.0340        0.479     0.277           0.365
 5       0.407  -0.223         -1.68          1.26     -0.0554         -0.694
 6      -1.88    0.0595         1.28         -0.487     1.01            0.847
 7       0.407   0.000506       0.655        -0.487     0.943           0.750
 8       0.144  -0.377         -0.0340       -0.487     0.910           0.895
 9      -0.0461 -1.52          -0.0340       -0.487     0.111          -0.453
10       1.98    0.501          1.28         -0.487     0.876           0.654
# ℹ 2,334 more rows
# ℹ 184 more variables: Mas_Vnr_Area &lt;dbl&gt;, Exter_Qual &lt;dbl&gt;, Exter_Cond &lt;dbl&gt;,
#   Bsmt_Qual &lt;dbl&gt;, BsmtFin_SF_1 &lt;dbl&gt;, BsmtFin_SF_2 &lt;dbl&gt;, Bsmt_Unf_SF &lt;dbl&gt;,
#   Total_Bsmt_SF &lt;dbl&gt;, Heating_QC &lt;dbl&gt;, First_Flr_SF &lt;dbl&gt;,
#   Second_Flr_SF &lt;dbl&gt;, Low_Qual_Fin_SF &lt;dbl&gt;, Gr_Liv_Area &lt;dbl&gt;,
#   Bsmt_Full_Bath &lt;dbl&gt;, Bsmt_Half_Bath &lt;dbl&gt;, Full_Bath &lt;dbl&gt;,
#   Half_Bath &lt;dbl&gt;, Bedroom_AbvGr &lt;dbl&gt;, Kitchen_AbvGr &lt;dbl&gt;, …</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://glmnet.stanford.edu">glmnet</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Prepare the data for glmnet (which requires matrices)</span></span>
<span><span class="va">x_train_glmnet</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">baked_train</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">Sale_Price</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">y_train_glmnet</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log10</a></span><span class="op">(</span><span class="va">baked_train</span><span class="op">$</span><span class="va">Sale_Price</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x_test_glmnet</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">baked_test</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">Sale_Price</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit a Ridge Regression model</span></span>
<span><span class="va">ridge_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/glmnet.html">glmnet</a></span><span class="op">(</span><span class="va">x_train_glmnet</span>, <span class="va">y_train_glmnet</span>, alpha <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Use cross-validation to find the optimal lambda</span></span>
<span><span class="va">cv_ridge</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">x_train_glmnet</span>, <span class="va">y_train_glmnet</span>, alpha <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">best_lambda</span> <span class="op">&lt;-</span> <span class="va">cv_ridge</span><span class="op">$</span><span class="va">lambda.min</span></span>
<span></span>
<span><span class="co"># Predict on the test set using the best lambda</span></span>
<span><span class="va">ridge_preds_log</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">cv_ridge</span>, s <span class="op">=</span> <span class="va">best_lambda</span>, newx <span class="op">=</span> <span class="va">x_test_glmnet</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Convert predictions back from log scale</span></span>
<span><span class="va">ridge_preds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fl">10</span><span class="op">^</span><span class="va">ridge_preds_log</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Evaluate the performance</span></span>
<span><span class="fu">mae_vec</span><span class="op">(</span></span>
<span>  truth <span class="op">=</span> <span class="va">housing_test_y</span>, </span>
<span>  estimate <span class="op">=</span> <span class="va">ridge_preds</span></span>
<span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14695.86</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">x_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">baked_train</span>, <span class="op">-</span><span class="va">Sale_Price</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">y_train</span> <span class="op">&lt;-</span> <span class="va">baked_train</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">Sale_Price</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">baked_test</span>, <span class="op">-</span><span class="va">Sale_Price</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">y_test</span> <span class="op">&lt;-</span> <span class="va">baked_test</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">Sale_Price</span><span class="op">)</span></span>
<span></span>
<span><span class="va">network</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">512</span>, activation <span class="op">=</span> <span class="st">"relu"</span>, input_shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">x_train</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">512</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">512</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">512</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">512</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">network</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span></span>
<span>    optimizer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/optimizer_rmsprop.html">optimizer_rmsprop</a></span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span>,</span>
<span>    loss <span class="op">=</span> <span class="st">"msle"</span>,</span>
<span>    metrics <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"mae"</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">history</span> <span class="op">&lt;-</span> <span class="va">network</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span></span>
<span>  <span class="va">x_train</span>,</span>
<span>  <span class="va">y_train</span>,</span>
<span>  epochs <span class="op">=</span> <span class="fl">30</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="fl">32</span>,</span>
<span>  validation_split <span class="op">=</span> <span class="fl">0.2</span>,</span>
<span>  callbacks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/pkg/keras/man/callback_early_stopping.html">callback_early_stopping</a></span><span class="op">(</span>patience <span class="op">=</span> <span class="fl">10</span>, restore_best_weights <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>        <span class="fu"><a href="https://rdrr.io/pkg/keras/man/callback_reduce_lr_on_plateau.html">callback_reduce_lr_on_plateau</a></span><span class="op">(</span>factor <span class="op">=</span> <span class="fl">0.2</span>, patience <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/30
59/59 - 2s - loss: 2.6759 - mae: 69141.8359 - val_loss: 0.3388 - val_mae: 125313.5078 - lr: 0.0100 - 2s/epoch - 31ms/step
Epoch 2/30
59/59 - 1s - loss: 0.3292 - mae: 102071.5703 - val_loss: 0.1209 - val_mae: 50366.2930 - lr: 0.0100 - 524ms/epoch - 9ms/step
Epoch 3/30
59/59 - 0s - loss: 0.2236 - mae: 80215.3750 - val_loss: 0.2176 - val_mae: 101830.4766 - lr: 0.0100 - 487ms/epoch - 8ms/step
Epoch 4/30
59/59 - 0s - loss: 0.1667 - mae: 69142.9531 - val_loss: 0.1528 - val_mae: 59499.3945 - lr: 0.0100 - 485ms/epoch - 8ms/step
Epoch 5/30
59/59 - 0s - loss: 0.1381 - mae: 61069.4180 - val_loss: 0.1368 - val_mae: 74134.7188 - lr: 0.0100 - 481ms/epoch - 8ms/step
Epoch 6/30
59/59 - 0s - loss: 0.1057 - mae: 50187.8789 - val_loss: 0.0588 - val_mae: 33784.0391 - lr: 0.0100 - 488ms/epoch - 8ms/step
Epoch 7/30
59/59 - 0s - loss: 0.0853 - mae: 45312.9102 - val_loss: 0.0427 - val_mae: 26335.1621 - lr: 0.0100 - 483ms/epoch - 8ms/step
Epoch 8/30
59/59 - 0s - loss: 0.0801 - mae: 43236.3398 - val_loss: 0.1033 - val_mae: 48533.3750 - lr: 0.0100 - 478ms/epoch - 8ms/step
Epoch 9/30
59/59 - 0s - loss: 0.0707 - mae: 41985.2188 - val_loss: 0.0621 - val_mae: 36053.5000 - lr: 0.0100 - 479ms/epoch - 8ms/step
Epoch 10/30
59/59 - 0s - loss: 0.0624 - mae: 37421.0820 - val_loss: 0.0213 - val_mae: 18885.2949 - lr: 0.0100 - 484ms/epoch - 8ms/step
Epoch 11/30
59/59 - 0s - loss: 0.0521 - mae: 34274.8047 - val_loss: 0.1811 - val_mae: 65037.4883 - lr: 0.0100 - 475ms/epoch - 8ms/step
Epoch 12/30
59/59 - 0s - loss: 0.0515 - mae: 33666.2422 - val_loss: 0.1039 - val_mae: 60014.6602 - lr: 0.0100 - 476ms/epoch - 8ms/step
Epoch 13/30
59/59 - 0s - loss: 0.0449 - mae: 28975.7910 - val_loss: 0.0819 - val_mae: 55129.4492 - lr: 0.0100 - 482ms/epoch - 8ms/step
Epoch 14/30
59/59 - 1s - loss: 0.0456 - mae: 32409.0820 - val_loss: 0.0196 - val_mae: 15696.7275 - lr: 0.0100 - 518ms/epoch - 9ms/step
Epoch 15/30
59/59 - 0s - loss: 0.0412 - mae: 29795.2422 - val_loss: 0.0838 - val_mae: 44143.0898 - lr: 0.0100 - 495ms/epoch - 8ms/step
Epoch 16/30
59/59 - 0s - loss: 0.0442 - mae: 31179.7930 - val_loss: 0.0199 - val_mae: 16013.7881 - lr: 0.0100 - 487ms/epoch - 8ms/step
Epoch 17/30
59/59 - 0s - loss: 0.0326 - mae: 24831.5898 - val_loss: 0.0644 - val_mae: 39009.3086 - lr: 0.0100 - 485ms/epoch - 8ms/step
Epoch 18/30
59/59 - 0s - loss: 0.0361 - mae: 28841.9512 - val_loss: 0.0236 - val_mae: 20014.9492 - lr: 0.0100 - 488ms/epoch - 8ms/step
Epoch 19/30
59/59 - 0s - loss: 0.0091 - mae: 11926.6846 - val_loss: 0.0186 - val_mae: 14730.9482 - lr: 0.0020 - 493ms/epoch - 8ms/step
Epoch 20/30
59/59 - 0s - loss: 0.0077 - mae: 11491.7871 - val_loss: 0.0193 - val_mae: 14735.4531 - lr: 0.0020 - 492ms/epoch - 8ms/step
Epoch 21/30
59/59 - 0s - loss: 0.0071 - mae: 11067.1553 - val_loss: 0.0205 - val_mae: 15961.4180 - lr: 0.0020 - 485ms/epoch - 8ms/step
Epoch 22/30
59/59 - 0s - loss: 0.0066 - mae: 10707.5098 - val_loss: 0.0193 - val_mae: 15110.8096 - lr: 0.0020 - 480ms/epoch - 8ms/step
Epoch 23/30
59/59 - 0s - loss: 0.0063 - mae: 10519.0166 - val_loss: 0.0187 - val_mae: 14614.5020 - lr: 0.0020 - 488ms/epoch - 8ms/step
Epoch 24/30
59/59 - 0s - loss: 0.0047 - mae: 8918.0469 - val_loss: 0.0186 - val_mae: 14453.5859 - lr: 4.0000e-04 - 485ms/epoch - 8ms/step
Epoch 25/30
59/59 - 0s - loss: 0.0047 - mae: 8805.7842 - val_loss: 0.0186 - val_mae: 14472.5566 - lr: 4.0000e-04 - 483ms/epoch - 8ms/step
Epoch 26/30
59/59 - 0s - loss: 0.0045 - mae: 8704.9229 - val_loss: 0.0191 - val_mae: 14654.7793 - lr: 4.0000e-04 - 483ms/epoch - 8ms/step
Epoch 27/30
59/59 - 0s - loss: 0.0045 - mae: 8670.8203 - val_loss: 0.0189 - val_mae: 14690.8467 - lr: 4.0000e-04 - 484ms/epoch - 8ms/step
Epoch 28/30
59/59 - 0s - loss: 0.0043 - mae: 8390.0723 - val_loss: 0.0188 - val_mae: 14496.3291 - lr: 8.0000e-05 - 483ms/epoch - 8ms/step
Epoch 29/30
59/59 - 0s - loss: 0.0043 - mae: 8390.3545 - val_loss: 0.0188 - val_mae: 14543.1641 - lr: 8.0000e-05 - 489ms/epoch - 8ms/step</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">history</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Final epoch (plot to see history):
    loss: 0.004258
     mae: 8,390
val_loss: 0.01875
 val_mae: 14,543
      lr: 0.00008 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">history</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_log10</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://wilkelab.org/cowplot/reference/theme_cowplot.html">theme_cowplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"top"</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="Machine-Learning_files/figure-html/unnamed-chunk-36-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>


<!-- -->

<script type="ojs-module-contents">
eyJjb250ZW50cyI6W119
</script><div id="exercise-loading-indicator" class="exercise-loading-indicator d-none d-flex align-items-center gap-2">
<div id="exercise-loading-status" class="d-flex gap-2">

</div>
<div class="spinner-grow spinner-grow-sm">

</div>
</div>
<script type="vfs-file">
W10=
</script></section></main><!-- /main --><script type="ojs-module-contents">
eyJjb250ZW50cyI6W119
</script><script type="module">
if (window.location.protocol === "file:") { alert("The OJS runtime does not work with file:// URLs. Please use a web server to view this document."); }
window._ojs.paths.runtimeToDoc = "../..";
window._ojs.paths.runtimeToRoot = "../..";
window._ojs.paths.docToRoot = "";
window._ojs.selfContained = false;
window._ojs.runtime.interpretFromScriptTags();
</script><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Kopiert");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Kopiert");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./RegReg.html" class="pagination-link" aria-label="Regularisierte Regression">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Regularisierte Regression</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./ex.html" class="pagination-link" aria-label="Lineare Regression">
        <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Lineare Regression</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Quellcode</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb54" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> live-html</span></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="an">engine:</span><span class="co"> knitr</span></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a><span class="fu"># Neuronale Netzwerke</span></span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a>Neuronale Netze (NN) sind leistungsstarke Modelle, die darauf spezialisiert sind, komplexe Muster in Daten zu erkennen und sind damit insbesondere ein hilfeiches Tool für Prognosen. Ein Nachteil neuronaler Netze ist die mangelnde Fähigkeit, kausale Zusammenhänge zu identifizieren und abzuleiten. Diese Limitation stellt eine signifikante Einschränkung dar, insbesondere für den Einsatz in empirischen Disziplinen, in denen das Verständnis kausaler Beziehungen von entscheidender Bedeutung ist. Während NN effektiv komplizierte Strukturen abbilden können, sind sie nicht mit den notwendigen Mechanismen ausgestattet, um Kausalität zu modellieren oder gar zu identifizieren. Grund hierfür ist die fehlende explizite Berücksichtigung kausaler Beziehungen und des zugrunde liegenden datenerzeugenden Prozesses: NN lernen lediglich funktionale Zusammenhänge in den Trainingsdaten. Auch wenn hierdurch komplexeste Relationen abgebildet werden können, erlaubt ein angepasstes Netz keine Differenzierung zwischen einer Korrelation und einer tatsächlichen kausalen Beziehung zwischen Variablen.</span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>In diesem Kapitel erläutern wir die Funktionsweise und Anpassung neuronaler Netze mit Keras und TensorFlow in R und diskutieren deren Anwendung zur Prognose von Zielvariablen in Datensätzen mit vielen Variablen und Beobachtungen. Die hier erläuterten Grundlagen basieren  auf den einleitenden Kapiteln in @Bishop2007 und @Goodfellowetal2016. Für ausführliche Erläuterungen der R-API <span class="in">`keras`</span> für die gleichnamige Python-Bibliothek empfehlen wir @Allaire2018.</span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a><span class="fu">## Grundlagen und Vokabeln {#sec-nn-basics}</span></span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a>NN bestehen aus einer (often großen) Anzahl so genannter *künstlicher Neuronen*. Ein Neuron ist eine mathematische Funktion, die mehrere Eingaben empfängt, diese unter Verwendung von Gewichten linear kombiniert und eine Ausgabe durch Verwendung einer Aktivierungsfunktion generiert.</span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a>Die Neuronen eines NN sind in Schichten (*Layers*) organisiert. Jedes Layer verarbeitet die Eingabedaten und gibt die Ergebnisse an das nächste Layer weiter, wobei die Neuronen verschiedener Layer miteinander verknüpft werden. Während das Eingabe-Layer (*Input*) die "Rohdaten" (bspw. beobachtete Regressorwerte) aufnimmt und sie an die erste versteckte Schicht (*Hidden Layer*) weiterleitet, ist die Hauptaufgabe der Neuronen in den Hidden Layers, komplexe Muster und Merkmale in den Daten zu erkennen und zu verarbeiten. Jedes Hidden Layer transformiert die empfangenen Daten anhand seiner Neuronen, bevor diese an das nächste Layer weitergeleitet werden. Das letzte Layer in einem neuronalen Netzwerk ist das Ausgabe-Layer (*Output Layer*), das die endgültige Vorhersage für die Outcome-Variable basierend auf den verarbeiteten Daten liefert.</span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a>Die Stärke der Verknüpfungen zwischen den Neuronen wird durch die Gewichte $w$ bestimmt, welche während des Trainingsprozesses angepasst werden, um das Modell hinsichtlich der (Vorhersage) einer Zielvariable zu optimieren. Die $w$ bestimmen, wie stark die Aktivierung eines Neurons in einer Schicht die Aktivierung der Neuronen in der nächsten Schicht beeinflusst. Das Netzwerk kann so tiefe und abstrakte Strukturen eines Datensatzes abbilden. </span>
<span id="cb54-19"><a href="#cb54-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-22"><a href="#cb54-22" aria-hidden="true" tabindex="-1"></a><span class="in">```{dot}</span></span>
<span id="cb54-23"><a href="#cb54-23" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-width: 6</span></span>
<span id="cb54-24"><a href="#cb54-24" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-height: 4</span></span>
<span id="cb54-25"><a href="#cb54-25" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-align: 'center'</span></span>
<span id="cb54-26"><a href="#cb54-26" aria-hidden="true" tabindex="-1"></a><span class="in">//| label: fig-nnex</span></span>
<span id="cb54-27"><a href="#cb54-27" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-cap: "Neuronales Netzwerk mit einem Hidden Layer"</span></span>
<span id="cb54-28"><a href="#cb54-28" aria-hidden="true" tabindex="-1"></a><span class="in">digraph NNEX {</span></span>
<span id="cb54-29"><a href="#cb54-29" aria-hidden="true" tabindex="-1"></a><span class="in">    layout=neato;</span></span>
<span id="cb54-30"><a href="#cb54-30" aria-hidden="true" tabindex="-1"></a><span class="in">    fontname="Helvetica,Arial,sans-serif";</span></span>
<span id="cb54-31"><a href="#cb54-31" aria-hidden="true" tabindex="-1"></a><span class="in">    node [fontname="Helvetica,Arial,sans-serif", shape="circle", style=filled, fontsize=16];</span></span>
<span id="cb54-32"><a href="#cb54-32" aria-hidden="true" tabindex="-1"></a><span class="in">    edge [fontname="Helvetica,Arial,sans-serif", fontsize=12];</span></span>
<span id="cb54-33"><a href="#cb54-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-34"><a href="#cb54-34" aria-hidden="true" tabindex="-1"></a><span class="in">    // Eingabeschicht</span></span>
<span id="cb54-35"><a href="#cb54-35" aria-hidden="true" tabindex="-1"></a><span class="in">    X1 [label="X1", pos="0,1!", fillcolor=lightblue];</span></span>
<span id="cb54-36"><a href="#cb54-36" aria-hidden="true" tabindex="-1"></a><span class="in">    X2 [label="X2", pos="0,-1!", fillcolor=lightblue];</span></span>
<span id="cb54-37"><a href="#cb54-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-38"><a href="#cb54-38" aria-hidden="true" tabindex="-1"></a><span class="in">    // Versteckte Schicht</span></span>
<span id="cb54-39"><a href="#cb54-39" aria-hidden="true" tabindex="-1"></a><span class="in">    V1 [label="V1\n(A)", pos="3,2!", fillcolor=lightyellow];</span></span>
<span id="cb54-40"><a href="#cb54-40" aria-hidden="true" tabindex="-1"></a><span class="in">    V2 [label="V2\n(A)", pos="3,0!", fillcolor=lightyellow];</span></span>
<span id="cb54-41"><a href="#cb54-41" aria-hidden="true" tabindex="-1"></a><span class="in">    V3 [label="V3\n(A)", pos="3,-2!", fillcolor=lightyellow];</span></span>
<span id="cb54-42"><a href="#cb54-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-43"><a href="#cb54-43" aria-hidden="true" tabindex="-1"></a><span class="in">    // Ausgabeneuron</span></span>
<span id="cb54-44"><a href="#cb54-44" aria-hidden="true" tabindex="-1"></a><span class="in">    Y [label="Y\n(A)", pos="6,0!", fillcolor=lightgreen];</span></span>
<span id="cb54-45"><a href="#cb54-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-46"><a href="#cb54-46" aria-hidden="true" tabindex="-1"></a><span class="in">    // Kanten von Eingabeschicht zur versteckten Schicht</span></span>
<span id="cb54-47"><a href="#cb54-47" aria-hidden="true" tabindex="-1"></a><span class="in">    X1 -&gt; V1 [label="w11"];</span></span>
<span id="cb54-48"><a href="#cb54-48" aria-hidden="true" tabindex="-1"></a><span class="in">    X1 -&gt; V2 [label="w12"];</span></span>
<span id="cb54-49"><a href="#cb54-49" aria-hidden="true" tabindex="-1"></a><span class="in">    X1 -&gt; V3 [label="w13"];</span></span>
<span id="cb54-50"><a href="#cb54-50" aria-hidden="true" tabindex="-1"></a><span class="in">    X2 -&gt; V1 [label="w21"];</span></span>
<span id="cb54-51"><a href="#cb54-51" aria-hidden="true" tabindex="-1"></a><span class="in">    X2 -&gt; V2 [label="w22"];</span></span>
<span id="cb54-52"><a href="#cb54-52" aria-hidden="true" tabindex="-1"></a><span class="in">    X2 -&gt; V3 [label="w23"];</span></span>
<span id="cb54-53"><a href="#cb54-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-54"><a href="#cb54-54" aria-hidden="true" tabindex="-1"></a><span class="in">    // Kanten von der versteckten Schicht zur Ausgabeschicht</span></span>
<span id="cb54-55"><a href="#cb54-55" aria-hidden="true" tabindex="-1"></a><span class="in">    V1 -&gt; Y [label="w31"];</span></span>
<span id="cb54-56"><a href="#cb54-56" aria-hidden="true" tabindex="-1"></a><span class="in">    V2 -&gt; Y [label="w32"];</span></span>
<span id="cb54-57"><a href="#cb54-57" aria-hidden="true" tabindex="-1"></a><span class="in">    V3 -&gt; Y [label="w33"];</span></span>
<span id="cb54-58"><a href="#cb54-58" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb54-59"><a href="#cb54-59" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-60"><a href="#cb54-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-61"><a href="#cb54-61" aria-hidden="true" tabindex="-1"></a>Angenommen wir interessieren uns für die Vorhersage einer Outcome-Variable $Y$ mit den Regressoren $X_1$ und $X_2$. @fig-nnex zeigt ein mögliches NN mit 3 Neuronen $V_1$, $V_2$, $V_3$ in einem Hidden Layer. Die Neuronen im Hidden Layer empfangen Eingaben aus dem Input Layer, bestehend aus Beobachtungen der Variablen $X_1$ und $X_2$, und gewichten diese Informationen gemäß der Vorschrift</span>
<span id="cb54-62"><a href="#cb54-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-63"><a href="#cb54-63" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb54-64"><a href="#cb54-64" aria-hidden="true" tabindex="-1"></a>  h_i = A\left(\sum_{j=1}^{2} w_{ji} \cdot x_j + b_i\right) \quad \text{für } i = 1, 2, 3.</span>
<span id="cb54-65"><a href="#cb54-65" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb54-66"><a href="#cb54-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-67"><a href="#cb54-67" aria-hidden="true" tabindex="-1"></a>Hierbei sind $w_{ji}$ die Gewichte der Verbindung von Input $j$ zu Neuron $i$ und $b_i$ ist ein *Bias*.^<span class="co">[</span><span class="ot">Der Bias ist analog zur Konstante in einer Regression.</span><span class="co">]</span> $A(\cdot)$ ist eine Aktivierungsfunktion, die in Abhängigkeit der zu modellierenden Daten gewählt wird.</span>
<span id="cb54-68"><a href="#cb54-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-69"><a href="#cb54-69" aria-hidden="true" tabindex="-1"></a>Das Ausgabe-Neuron für $Y$ verarbeitet die Informationen aus dem Hidden Layer ebenfalls anhand einer Linearkombination, die mit einer Aktivierungsfunktion transformiert wird,</span>
<span id="cb54-70"><a href="#cb54-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-71"><a href="#cb54-71" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb54-72"><a href="#cb54-72" aria-hidden="true" tabindex="-1"></a>  y = A\left(\sum_{i=1}^{3} w_{i} \cdot h_i + b_y\right).</span>
<span id="cb54-73"><a href="#cb54-73" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb54-74"><a href="#cb54-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-75"><a href="#cb54-75" aria-hidden="true" tabindex="-1"></a>Ein solches NN "lernt" Relationen zwischen $Y$ und den Regressoren $X_1$ und $X_2$, indem die Gewichte anhand eines Algorithmus derart gewählt werden, dass der Fehler zwischen den vorhergesagten und den tatsächlichen Werten von $Y$ --- gemessen mit einer Verlustfunktion (*Loss-Funktion*) --- minimiert wird. Dieser Lernprozess erfolgt unter Verwendung numerischer Optimierungsverfahren wie *Gradientenabstieg* (*Gradient Descent*).</span>
<span id="cb54-76"><a href="#cb54-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-77"><a href="#cb54-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-78"><a href="#cb54-78" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training Neuronaler Netze</span></span>
<span id="cb54-79"><a href="#cb54-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-80"><a href="#cb54-80" aria-hidden="true" tabindex="-1"></a>Der Anpassungsprozess eines NN an einen Datensatz (*Training*) wird grob durch folgende Schritte bestimmt:</span>
<span id="cb54-81"><a href="#cb54-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-82"><a href="#cb54-82" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Das Netz (Gewichte) wird initialisiert. </span>
<span id="cb54-83"><a href="#cb54-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-84"><a href="#cb54-84" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Die Inputs jeder Beobachtung im Trainingsdatensatz werden durch das NN geleitet (*Forward Pass*): Jedes Layer transformiert die Daten mit Hilfe von Gewichten und Aktivierungsfunktionen, um eine Vorhersage von $Y$ zu erzeugen.</span>
<span id="cb54-85"><a href="#cb54-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-86"><a href="#cb54-86" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Der Loss wird berechnet, indem die Vorhersage von $Y$ mit dem tatsächlichen Wert verglichen wird. Die Verlustfunktion wird entsprechend der Definition von $Y$ gewählt. Typische Verlustfunktionen sind *Quadratic Loss* (analog zur Schätzung von linearen Regressionsmodellen mit KQ) oder *Logistic Loss* (analog zu logistischer Regression).</span>
<span id="cb54-87"><a href="#cb54-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-88"><a href="#cb54-88" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Zur Anpassung der Gewichte wird der Gradient^<span class="co">[</span><span class="ot">Der Gradient einer Funktion $f(\boldsymbol{x}) = f(x_1, x_2, \ldots, x_k)$ ist der Vektor der partiellen Ableitungen: $\nabla f = \left( \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \ldots, \frac{\partial f}{\partial x_k} \right)$. $\nabla f(\boldsymbol{x})$ zeigt die Richtung und Stärke der steilsten Änderung von $f$ am Punkt $\boldsymbol{x}$ an.</span><span class="co">]</span> der Verlustfunktion hinsichtlich der Gewichte des NN ermittelt.^<span class="co">[</span><span class="ot">$\nabla f$ ist in NN grundsätzlich unbekannt. Gradient-Desenct-Algorithmen verwenden numerische Verfahren, um den Gradienten anhand von $f$ zu approximieren.</span><span class="co">]</span> Ein Gradient-Descent-Algorithmus bestimmt, in welche Richtung die Gewichte verändert werden müssen, um den Vorhersagefehler zu verringern.</span>
<span id="cb54-89"><a href="#cb54-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-90"><a href="#cb54-90" aria-hidden="true" tabindex="-1"></a>    Für diese Berechnung wird ein *Backward Pass* (auch *Backpropagation* genannt) genutzt. Hierbei wird der anhand des Ausgabelayers ermittelte Loss rückwärts durch das Netzwerk propagiert, um die Gewichte so anzupassen, dass der Fehler bei der Vorhersage von $Y$ minimiert wird.</span>
<span id="cb54-91"><a href="#cb54-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-92"><a href="#cb54-92" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Die Gewichte werden in kleinen Schritten, die durch die so genannte *Lernrate* bestimmt werden, in Richtung des negativen Gradienten angepasst. Dies bewirkt, dass die Gewichte so verändert werden, dass der Loss im Vergleich zur letzten Iteration verringert wird.</span>
<span id="cb54-93"><a href="#cb54-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-94"><a href="#cb54-94" aria-hidden="true" tabindex="-1"></a>    Um den Lernprozess effizienter und stabiler zu machen, nutzen moderne Algorithmen weitere Schritte, bspw. eine Kombination von Gradientenabstieg mit *Momentum*. Dies beschleunigt die Anpassung der Gewichte und stabilisiert den Lernprozess. Fortgeschrittene Methoden verwenden adaptiven Lernraten, die die Schrittgröße für jedes Gewicht individuell anpassen können.</span>
<span id="cb54-95"><a href="#cb54-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-96"><a href="#cb54-96" aria-hidden="true" tabindex="-1"></a>Die Schritte 4 und 5 werden wiederholt, bis ein Abbruchkriterium erfüllt ist: Der Fehler ist ausreichend klein, oder weitere Iterationen bewirken keine signifikante Änderung des Gradienten. </span>
<span id="cb54-97"><a href="#cb54-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-98"><a href="#cb54-98" aria-hidden="true" tabindex="-1"></a>**Epochen und Iterationen**</span>
<span id="cb54-99"><a href="#cb54-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-100"><a href="#cb54-100" aria-hidden="true" tabindex="-1"></a>Der Gesamte Prozess wird für mehrere Epochen (*Epocs*) durchlaufen, in denen jeweils der gesamte Trainingsdatensatz durch das NN geleitet wird. Um das Training auch für große Datensätze durchführen zu können, werden die Trainingsdaten hierbei üblicherweise in zufällig zusammengesetzen, kleineren Datensätzen (*Batches*) gruppiert. In jeder Epoche erfolgt die Anpassung der Gewichte für jedes durch das Netz geleitete Batch (jede *Iteration*):</span>
<span id="cb54-101"><a href="#cb54-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-102"><a href="#cb54-102" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Epoche**</span>
<span id="cb54-103"><a href="#cb54-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-104"><a href="#cb54-104" aria-hidden="true" tabindex="-1"></a><span class="ss">    1. </span>**Batch**</span>
<span id="cb54-105"><a href="#cb54-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-106"><a href="#cb54-106" aria-hidden="true" tabindex="-1"></a>        *Forward Pass* $\rightarrow$ *Loss-Berechnung* $\rightarrow$ *Backpropagation* $\rightarrow$ *Gradient-Descent-Update*</span>
<span id="cb54-107"><a href="#cb54-107" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb54-108"><a href="#cb54-108" aria-hidden="true" tabindex="-1"></a><span class="ss">    2. </span>**Batch**</span>
<span id="cb54-109"><a href="#cb54-109" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb54-110"><a href="#cb54-110" aria-hidden="true" tabindex="-1"></a>        *Forward Pass* $\rightarrow$ *Loss-Berechnung* $\rightarrow$ *Backpropagation* $\rightarrow$ *Gradient-Descent-Update*</span>
<span id="cb54-111"><a href="#cb54-111" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb54-112"><a href="#cb54-112" aria-hidden="true" tabindex="-1"></a>        ...</span>
<span id="cb54-113"><a href="#cb54-113" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb54-114"><a href="#cb54-114" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Epoche**</span>
<span id="cb54-115"><a href="#cb54-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-116"><a href="#cb54-116" aria-hidden="true" tabindex="-1"></a><span class="in">            ...</span></span>
<span id="cb54-117"><a href="#cb54-117" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb54-118"><a href="#cb54-118" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb54-119"><a href="#cb54-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-120"><a href="#cb54-120" aria-hidden="true" tabindex="-1"></a>Für das Training eines NN sind mehrere Epochen notwendig, weil ein einzelner Durchlauf der Daten oft nicht ausreicht, um die zugrundeliegenden Muster zu lernen. Durch Anpassung über mehrere Epochen können die Gewichte des Modells verfeinert werden, was insbesondere die Fähigkeit zur Generalisierung für ungesehene Daten verbessert. Die zufällige Einteilung der Daten in Batches zu Beginn jeder Epoche verhindert unter anderem, dass das NN lediglich die Reihenfolge der durchgeleiteten Datenpunkte lernt. </span>
<span id="cb54-121"><a href="#cb54-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-122"><a href="#cb54-122" aria-hidden="true" tabindex="-1"></a>Die Anzahl an zu durchlaufender Epochen ist ein Tuning-Parameter: Zu wenige Epochen führen zu einer schlechten Anpassung an die Daten, während zu viele Epochen das Risiko von Overfitting erhöhen. Um den Vorhersagefehler für ungesehene Daten einzuschätzen, wird ein Testdatensatz vorbehalten. Dieser Datensatz wird während des Trainings nicht zum Anpassen der Gewichte genutzt, sondern erst nach Abschluss einer Epoche für die Berechnung der Vorhersagequalität herangezogen. So kann jeweils nach dem Durchlauf einer Epoche beurteilt werden, wie gut das Modell auf neue, unbekannte Daten generalisiert. Hierbei können ein hoher Vorhersagefehler für den Testdatensatz und ein (viel) geringerer Fehler für den Trainingsdatensatz nach mehreren Epochen auf Overfitting hinweisen. Im empirischen Teil dieses Kapitels diskutieren wir (grafische) Methoden zur Beurteilung der Anpassung des Modells.</span>
<span id="cb54-123"><a href="#cb54-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-124"><a href="#cb54-124" aria-hidden="true" tabindex="-1"></a>Beim Training von NN können sogenannte *Callback-Funktionen* eingesetzt werden, um den Anpassungsprozess unter Einbezug von Zwischenergebnissen zu bestimmten Zeitpunkten während des Trainingsprozesses, z. B. am Ende jeder Epoche oder nach einer bestimmten Anzahl von Iterationen, zu evaluieren. Callbacks werden verwendet, um bestimmte Aktionen auszuführen, wie das Anpassen der Lernrate oder das Überwachen der Trainingsleistung: Ein Callback kann das Training automatisch stoppen (*Early Stopping*), wenn Anzeichen von Overfitting erkannt werden, beispielsweise wenn die Vorhersagegüte auf dem Test-Datensatz über mehrere Epochen hinweg stagniert. Dadurch wird ein unnötiges Fortsetzen des Trainings vermieden und ein Verlust der Generalisierungsfähigkeit auf neuen Daten verhindert.</span>
<span id="cb54-125"><a href="#cb54-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-126"><a href="#cb54-126" aria-hidden="true" tabindex="-1"></a>Wir fassen die wichtigsten Begriffe für die Beschreibung von NN nachfolgend kurz zusammen.</span>
<span id="cb54-127"><a href="#cb54-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-128"><a href="#cb54-128" aria-hidden="true" tabindex="-1"></a>**Wesentliche Definitionen**</span>
<span id="cb54-129"><a href="#cb54-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-130"><a href="#cb54-130" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Layer**: Eine Ebene von Neuronen im neuronalen Netzwerk. Es gibt das Eingabe-Layer, versteckte Layers (Hidden Layers) und das Ausgabe-Layer. Jedes Layer verarbeitet Informationen aus dem vorangegangenen Layer und gibt die Ergebnisse an das nächste Layer weiter.</span>
<span id="cb54-131"><a href="#cb54-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-132"><a href="#cb54-132" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Input**: Die Eingangsdaten oder Merkmale, die in das NN eingespeist werden. Jeder Input wird durch ein oder mehrere Neuronen im Eingabe-Layer repräsentiert.</span>
<span id="cb54-133"><a href="#cb54-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-134"><a href="#cb54-134" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Output**: Das Ergebnis, welches das NN nach der Verarbeitung der Inputs liefert. Der Output wird durch die Neuronen im Output-Layer des NN erstellt.</span>
<span id="cb54-135"><a href="#cb54-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-136"><a href="#cb54-136" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Neuron**: Die kleinste Komponente eines NN. Jedes Neuron empfängt Inputs, multipliziert sie mit Gewichten, addiert einen Bias und gibt das Ergebnis nach Anwendung einer Aktivierungsfunktion weiter: Ein Neuron ist also eine *mathematische Funktion*, die Inputs aus dem vorherigen Layer mit einer transformierten Linearkombination verarbeitet und das Ergebnis das nächste Layers weiterleitet. </span>
<span id="cb54-137"><a href="#cb54-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-138"><a href="#cb54-138" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Forward Pass**: Leitung der Trainingsdaten durch das NN und Berechnung der Vorhersage des Outcomes.</span>
<span id="cb54-139"><a href="#cb54-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-140"><a href="#cb54-140" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Loss-Funktion**: Mathematische Funktion, welche die Güte der Vorhersage des NN für das Outcome quantifiziert. Der Loss ist eine Funktion der zu trainierenden Parameter des NN.</span>
<span id="cb54-141"><a href="#cb54-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-142"><a href="#cb54-142" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Backward Pass / Backpropagation**: Ermittlung des Gradienten der Loss-Funktion durch Verkettung des Effekts der Gewichte über die Layers des NN.</span>
<span id="cb54-143"><a href="#cb54-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-144"><a href="#cb54-144" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Aktivierungsfunktion**: Eine mathematische Funktion, die auf die gewichtete Summe der Eingaben eines Neurons angewendet wird. Die Aktivierungsfunktion bestimmt, ob ein Neuron aktiviert wird. Beispiele sind </span>
<span id="cb54-145"><a href="#cb54-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-146"><a href="#cb54-146" aria-hidden="true" tabindex="-1"></a>    \begin{align*}</span>
<span id="cb54-147"><a href="#cb54-147" aria-hidden="true" tabindex="-1"></a>      \text{ReLU}(z) =&amp; \max(0, z), <span class="sc">\\</span><span class="co">[</span><span class="ot">.5ex</span><span class="co">]</span></span>
<span id="cb54-148"><a href="#cb54-148" aria-hidden="true" tabindex="-1"></a>      \sigma(z) =&amp;\, \frac{1}{1 + e^{-z}}, <span class="sc">\\</span><span class="co">[</span><span class="ot">.5ex</span><span class="co">]</span></span>
<span id="cb54-149"><a href="#cb54-149" aria-hidden="true" tabindex="-1"></a>      \tanh(z) =&amp;\, \frac{e^z - e^{-z}}{e^z + e^{-z}}.</span>
<span id="cb54-150"><a href="#cb54-150" aria-hidden="true" tabindex="-1"></a>    \end{align*}</span>
<span id="cb54-151"><a href="#cb54-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-152"><a href="#cb54-152" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Epoche**: Ein Trainingszyklus, bei dem der gesamte Trainingsdatensatz, aufgeteilt in Batches, das NN durchläuft.</span>
<span id="cb54-153"><a href="#cb54-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-154"><a href="#cb54-154" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Batches**: Zufällig eingeteilte Teilmengen der Beobachtungen des Trainingsdatensatzes.</span>
<span id="cb54-155"><a href="#cb54-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-156"><a href="#cb54-156" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Callback**: Eine Funktion, die im Zuge der Überwachung des des Trainings-Prozesses automatisch ausgeführt wird, um Aktionen wie Lernratenanpassung oder Trainingsstopp zu auszulösen.</span>
<span id="cb54-157"><a href="#cb54-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-158"><a href="#cb54-158" aria-hidden="true" tabindex="-1"></a>Im nächsten Abschnitt erläutern wir die Optimierung der Gewichte mit Gradient Descent beispielhaft anhand interaktiver Visualisierungen.</span>
<span id="cb54-159"><a href="#cb54-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-160"><a href="#cb54-160" aria-hidden="true" tabindex="-1"></a><span class="fu">## Optimierung mit Gradient Descent</span></span>
<span id="cb54-161"><a href="#cb54-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-162"><a href="#cb54-162" aria-hidden="true" tabindex="-1"></a>Gradient Descent ist ein iteratives Optimierungsverfahren zur Minimierung einer differenzierbaren Zielfunktion $f(w)$. Ausgehend von einem Startwert $w_0$ aktualisiert der Algorithmus die Variable $w$ schrittweise gemäß einer Lernrate $\eta$ in die entgegengesetzte Richtung des Gradienten $\nabla f(w)$ der Funktion an der aktuellen $w$. Mit $\nabla f(w)$ wird mathematisch die Richtung des *steilsten Anstiegs* von $f(w)$ im Punkt $w$ ermittelt. Der Algorithmus vollzieht eine Veränderung von $w$ in die entgegengesetzten Richtung -- die Richtung mit dem schnellsten *Abstieg* (Descent) der Zielfunktion.</span>
<span id="cb54-163"><a href="#cb54-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-164"><a href="#cb54-164" aria-hidden="true" tabindex="-1"></a>Der folgende Algorithmus zeigt die grundlegende Vorgehensweise des Gradientenabstiegsverfahrens für einen einziegen zu optimierenden Parameter $w$ unter Einbeziehung eines Momentum-Terms $v_t$.^<span class="co">[</span><span class="ot">In der Literatur wird $v_t$ häufig auch als *Velocity* bezeichnet.</span><span class="co">]</span> Der Momentum-Term dient dazu, das Konvergenzverhalten zu verbessern und lokale Minima effektiver zu überwinden. Die Stärke des Momentums $v_t$ wird durch den Momentum-Faktor $\alpha \in [0,1)$ bestimmt. </span>
<span id="cb54-165"><a href="#cb54-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-166"><a href="#cb54-166" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb54-167"><a href="#cb54-167" aria-hidden="true" tabindex="-1"></a>  \small</span>
<span id="cb54-168"><a href="#cb54-168" aria-hidden="true" tabindex="-1"></a>  &amp; \textbf{Algorithmus: Gradientenabstiegsverfahren mit Momentum} <span class="sc">\\</span></span>
<span id="cb54-169"><a href="#cb54-169" aria-hidden="true" tabindex="-1"></a>  &amp; \textup{Initialisiere: }<span class="sc">\\</span><span class="co">[</span><span class="ot">.5ex</span><span class="co">]</span></span>
<span id="cb54-170"><a href="#cb54-170" aria-hidden="true" tabindex="-1"></a>  &amp; \quad w_0 \text{ (Startpunkt) }<span class="sc">\\</span></span>
<span id="cb54-171"><a href="#cb54-171" aria-hidden="true" tabindex="-1"></a>  &amp; \quad \eta \text{ (Lernrate) }<span class="sc">\\</span></span>
<span id="cb54-172"><a href="#cb54-172" aria-hidden="true" tabindex="-1"></a>  &amp; \quad \alpha \text{ (Momentum-Faktor) }<span class="sc">\\</span> </span>
<span id="cb54-173"><a href="#cb54-173" aria-hidden="true" tabindex="-1"></a>  &amp; \quad v_0 = 0 \text{ (Anfangsmomentum) } <span class="sc">\\</span><span class="co">[</span><span class="ot">1em</span><span class="co">]</span></span>
<span id="cb54-174"><a href="#cb54-174" aria-hidden="true" tabindex="-1"></a>  &amp; \text{Iteriere für } t = 0, 1, 2, \dots \text{ bis Konvergenz:} <span class="sc">\\</span><span class="co">[</span><span class="ot">.5ex</span><span class="co">]</span></span>
<span id="cb54-175"><a href="#cb54-175" aria-hidden="true" tabindex="-1"></a>  &amp; \quad \text{1. Berechne den Gradienten: } \nabla f(w_t) <span class="sc">\\</span></span>
<span id="cb54-176"><a href="#cb54-176" aria-hidden="true" tabindex="-1"></a>  &amp; \quad \text{2. Aktualisiere den Momentum-Term: } v_{t+1} = \alpha v_t - \eta \nabla f(w_t) <span class="sc">\\</span></span>
<span id="cb54-177"><a href="#cb54-177" aria-hidden="true" tabindex="-1"></a>  &amp; \quad \text{3. Aktualisiere die Position: } w_{t+1} = w_t + v_{t+1} <span class="sc">\\</span></span>
<span id="cb54-178"><a href="#cb54-178" aria-hidden="true" tabindex="-1"></a>  &amp; \quad \text{4. Überprüfe das Abbruchkriterium } |\nabla f(w_t)| &lt; \epsilon\text{ (für ein kleines $\epsilon&gt;0$)} <span class="sc">\\</span></span>
<span id="cb54-179"><a href="#cb54-179" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb54-180"><a href="#cb54-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-181"><a href="#cb54-181" aria-hidden="true" tabindex="-1"></a>In der nachfolgenden interaktiven Visualisierung illustrieren wir die Minimierung einer univariaten Funktion $\color{blue}{f(w_t)}$ über $w_t$ anhand des obigen Algorithmus mit Lernrate $\eta = .001$ und Momentum-Faktor $\alpha = .925$.</span>
<span id="cb54-182"><a href="#cb54-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-183"><a href="#cb54-183" aria-hidden="true" tabindex="-1"></a>Der &lt;span style="color:orange"&gt;Gradient&lt;/span&gt;$\color{orange}{\nabla f(w_t)}$ ist hier die 1. Ableitung von $\color{blue}{f(w_t)}$ nach $w_t$. Die Richtung der Änderung von $\color{blue}{f(w_t)}$ in $w_t$ wird durch den &lt;span style="color:orange"&gt;orangenen Pfeil&lt;/span&gt; angezeigt. Beachte, wie sich der Gradient bei Variation des Start-Punkts mit dem Slider ändert. Während die Animation der Optimierung mit Gradient Descent läuft, zeigt der  &lt;span style="color:purple"&gt;lilane Pfeil&lt;/span&gt; das &lt;span style="color:purple"&gt;Momentum&lt;/span&gt; (&lt;span style="color:purple"&gt;Velocity $v_t$&lt;/span&gt;) für Schirtt $t$ an.^<span class="co">[</span><span class="ot">Unterschiedliche Längen der Pfeile zeigen hier nicht Änderungen der tatsächlichen Beträge, sondern dienen lediglich der Interpretierbakeit der Grafik.</span><span class="co">]</span> Der Algorithmus iteriert die Schritte 1. bis 3. solange, bis das Abbruchkriterium $|\textcolor{orange}{\nabla f(w_t)}| &lt; \epsilon = 0.001$ erreicht ist, die Änderung in $\color{orange}{\nabla f(w_t)}$ also hinreichend klein ist, dass ein Parameterwert $w_t$ mit $\color{blue}{f(w_t)}$ nahe des (globalen) Minimums von $f$ plausibel ist.</span>
<span id="cb54-184"><a href="#cb54-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-185"><a href="#cb54-185" aria-hidden="true" tabindex="-1"></a>Folgende Eigenschaften der Optimierung mit Gradient Descent können anhand der Parameter geprüft werden:</span>
<span id="cb54-186"><a href="#cb54-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-187"><a href="#cb54-187" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Für Startpunkte mit großen Werten des Gradienten beginnt der Algorithmus mit einem starken Momentum: Der Abstieg in Richtung des negativen Gradients erfolgt also in großen Schritten, sodass die Optimierung schneller erfolgt als für Startpunkte in flachen Regionen von $\color{blue}{f}$.</span>
<span id="cb54-188"><a href="#cb54-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-189"><a href="#cb54-189" aria-hidden="true" tabindex="-1"></a>    Dieser Effekt des Momentum auf den Pfad der zu optimierenden Parameter bei Gradient Descent ist vergleichbar mit dem Effekt der Schwerkraft auf eine Murmel, die auf einer hügeligen Oberfläche rollt: Anfangs gewinnt die Murmel an Geschwindigkeit und bewegt sich beschleunigt in Richtung des steilsten Gefälles. In flacheren Regionen wird die Bewegung langsamer und die Murmel kann in Tälern stecken bleiben, ähnlich wie der Optimierungsprozess in flachen Regionen von $\color{blue}{f}$ langsamer verläuft oder gar stoppt, weil ein Abbruchkriterium erfüllt ist (geringe Änderung des Gradienten). Das Momentum hilft, auch in solchen flachen Bereichen weiter voranzukommen, indem es dem Parameterpfad eine gewisse "Trägheit" verleiht, die es ermöglicht, flache Stellen schneller zu durchqueren und die Optimierung effizienter zu gestalten.</span>
<span id="cb54-190"><a href="#cb54-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-191"><a href="#cb54-191" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Bei ungünstiger Wahl der Parameter konvergiert der Algorithmus nicht zum globalen Minimum, sondern stoppt im lokalen Minimum bei $w = -0.5$. Dies unterstreicht die Notwendigkeit, die Hyperparameter Lernrate $\eta$ und Momentum-Faktor $\alpha$ sorgfältig zu wählen, beispielsweise indem die Modellgüte nach erfolgter Anpassung für verschiedene Parameter-Kombinationen verglichen wird. </span>
<span id="cb54-192"><a href="#cb54-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-193"><a href="#cb54-193" aria-hidden="true" tabindex="-1"></a>In empirischen Anwendungen ist es für eine hohe Modellgüte eines neuronalen Netzwerks nicht unbedingt erforderlich, das globale Minimum zu finden: Viele Optimierungsprobleme weisen zahlreiche lokale Minima auf, die eine ausreichend gute Annäherung an das Optimum bieten können. Besonders bei hochdimensionalen Optimierungsproblemen mit komplexen Loss-Funktionen können diese lokalen Minima zufriedenstellende Lösungen darstellen. In einigen Fällen existiert möglicherweise kein globales Minimum, und der Algorithmus konvergiert zwangsläufig zu einem stabilen lokalen Minimum, das dennoch eine gute Performance gewährleistet. Daher kann es sinnvoller sein, Algorithmen zu verwenden, die das Erreichen einer robusten Lösung legen, anstatt strikt nach dem globalen Minimum zu suchen.</span>
<span id="cb54-194"><a href="#cb54-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-195"><a href="#cb54-195" aria-hidden="true" tabindex="-1"></a>In Software-Implementierungen für Machine und Deep Learning wie <span class="in">`tensorflow`</span> und <span class="in">`keras`</span> werden fortgeschrittene Techniken wie Momentum Tuning oder Stochastic <span class="co">[</span><span class="ot">Gradient Descent</span><span class="co">](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)</span> (SGD) eingesetzt, um die Wahrscheinlichkeit zu erhöhen, dass der Algorithmus nicht in einem (ungünstigen) lokalen Minimum endet. Ein für die Anpassung von NN häufig verwendeter Algorithmus, der SGD verwendet, ist <span class="co">[</span><span class="ot">Adaptive Moment Estimation (Adam)</span><span class="co">](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam)</span>. Wir verwenden u.a. den Adam-Optimizer in den empirischen Beispielen. </span>
<span id="cb54-196"><a href="#cb54-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-197"><a href="#cb54-197" aria-hidden="true" tabindex="-1"></a>&lt;iframe class="obs-soft-box-shadow" width="100%" height="761" frameborder="0"</span>
<span id="cb54-198"><a href="#cb54-198" aria-hidden="true" tabindex="-1"></a>  src="https://observablehq.com/embed/@mca91/gradient-descent-in-2d?cells=plot%2Cviewof+startAnimation%2Cviewof+startPoint%2Cviewof+alpha%2Cviewof+eta%2CoptimalReached%2CMathJax%2Cstyles"&gt;&lt;/iframe&gt;</span>
<span id="cb54-199"><a href="#cb54-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-200"><a href="#cb54-200" aria-hidden="true" tabindex="-1"></a>In empirischen Anwendungen sind die zu lernenden Zusammenhänge komplex und damit die Anzahl der zu optimierenden Parameter eines NN häufig groß. Der oben erläuterte Algorithmus für Gradient Descent mit Momentum kann einfach auf Optimierungsprobleme mit $k$ Parametern generalisiert werden. Dann ist $\boldsymbol{w}_t$ ein Vektor mit $k$ Gewichten, $\boldsymbol{v}_{t+1}$ eine vektorwertige Funktion von $\boldsymbol{v}_t$ und $\nabla f(\boldsymbol{w}_t)$ mit Dimension $k$ und $f(\boldsymbol{w}_t)$ ist eine Oberfläche in einem $k+1$-dimensionalen Raum. </span>
<span id="cb54-201"><a href="#cb54-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-202"><a href="#cb54-202" aria-hidden="true" tabindex="-1"></a>Die nachfolgende interaktive Grafik illustriert Gradient Descent mit Momentum für $k=2$ zu optimierende Gewichte. Statt der Parameter des Algorithmus kann hier die Form der zu optimierenden Funktion manipuliert werden, sodass bis zu 6 Extremstellen vorliegen können. Der &lt;span style="color:red"&gt;rote Punkt&lt;/span&gt; zeigt den Verlauf der Optimierung von $\boldsymbol{w}_t$.</span>
<span id="cb54-203"><a href="#cb54-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-204"><a href="#cb54-204" aria-hidden="true" tabindex="-1"></a>Die Animation verdeutlicht, dass lokale Minima insbesondere in höheren Dimensionen herausfordernd für Optimierungsalgorithmen sind: Durch Variation der Extrema lassen sich leicht Funktionen $f(w_1,w_1)$ konstruieren, für die Gradient Descent mit den voreingestellten Parametern nicht gegen das globale Minimum konvergiert, sofern vorhanden. Ein günstiger Initialwert für $\boldsymbol{w}_t$ kann die Wahrscheinlichkeit von Stops in lokalen Minima verringern: *Grid Search Initialization* wertet die Funktion über ein gleichmäßiges Gitter von Werten für $\boldsymbol{w}_t$ aus und wählt als Startwert $\boldsymbol{w}_{0,\textup{init}}$ den Punkt mit dem minimalen Funktionswert von $f$ über alle Punkte im Gitter.</span>
<span id="cb54-205"><a href="#cb54-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-206"><a href="#cb54-206" aria-hidden="true" tabindex="-1"></a>&lt;iframe class="obs-soft-box-shadow" width="100%" height="1172" frameborder="0"</span>
<span id="cb54-207"><a href="#cb54-207" aria-hidden="true" tabindex="-1"></a>  src="https://observablehq.com/embed/@mca91/gradient-descent-in-3d-three-js?cells=renderer%2Cviewof+restart%2Cviewof+gridinit%2Cviewof+themin%2Cviewof+themin2%2Cviewof+themin3%2Cviewof+themin4%2Cviewof+themin5%2Cviewof+themin6%2Cscene%2Ccamera"&gt;&lt;/iframe&gt;</span>
<span id="cb54-208"><a href="#cb54-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-209"><a href="#cb54-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-210"><a href="#cb54-210" aria-hidden="true" tabindex="-1"></a><span class="fu">## Funktionale Zusammenhänge lernen: Regression</span></span>
<span id="cb54-211"><a href="#cb54-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-212"><a href="#cb54-212" aria-hidden="true" tabindex="-1"></a>Für einen leichten Einstieg in die Modellierung funktionaler Zusammenhänge durch NN mit statistischer Programmierung in R betrachten wir zunächst den einfachsten Zusammenhang zwischen einer Outcome-Variable $Y$ und einem Regressor $X$: Die einfache lineare Funktion</span>
<span id="cb54-213"><a href="#cb54-213" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb54-214"><a href="#cb54-214" aria-hidden="true" tabindex="-1"></a>  Y = w_1 X + b,</span>
<span id="cb54-215"><a href="#cb54-215" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb54-216"><a href="#cb54-216" aria-hidden="true" tabindex="-1"></a>wobei der Regressionskoeffizient $w_1$ den Einfluss von $X$ auf $Y$ misst und $b$ eine Konstante ist. Gemäß der Definitionen in @sec-nn-basics kann dieser Funktionale Zusammenhang als NN ohne Hidden Layer dargestellt werden, wobei $X$ ein Input-Neuron ist, dessen Information mit $w_1$ gewichtet an das Output Layer mit einem einzigen Neuron für $Y$ weitergegeben wird. Die Konstante $b$ ist ein *Bias*, der als von $X$ unabhängiger Einfluss von $Y$ behandelt wird, vgl. @fig-nn-lreg.</span>
<span id="cb54-217"><a href="#cb54-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-220"><a href="#cb54-220" aria-hidden="true" tabindex="-1"></a><span class="in">```{dot}</span></span>
<span id="cb54-221"><a href="#cb54-221" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-width: 6</span></span>
<span id="cb54-222"><a href="#cb54-222" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-height: 2</span></span>
<span id="cb54-223"><a href="#cb54-223" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-cap: "Neuronales Netzwerk: Lineare Regression mit einer Variable und Konstante"</span></span>
<span id="cb54-224"><a href="#cb54-224" aria-hidden="true" tabindex="-1"></a><span class="in">//| label: "fig-nn-lreg"</span></span>
<span id="cb54-225"><a href="#cb54-225" aria-hidden="true" tabindex="-1"></a><span class="in">digraph NEURALNET {</span></span>
<span id="cb54-226"><a href="#cb54-226" aria-hidden="true" tabindex="-1"></a><span class="in">    layout=neato</span></span>
<span id="cb54-227"><a href="#cb54-227" aria-hidden="true" tabindex="-1"></a><span class="in">    fontname="Helvetica,Arial,sans-serif"</span></span>
<span id="cb54-228"><a href="#cb54-228" aria-hidden="true" tabindex="-1"></a><span class="in">    node [fontname="Helvetica,Arial,sans-serif", shape="circle"]</span></span>
<span id="cb54-229"><a href="#cb54-229" aria-hidden="true" tabindex="-1"></a><span class="in">    edge [fontname="Helvetica,Arial,sans-serif"]</span></span>
<span id="cb54-230"><a href="#cb54-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-231"><a href="#cb54-231" aria-hidden="true" tabindex="-1"></a><span class="in">    X [label="X", pos="0,0!"];</span></span>
<span id="cb54-232"><a href="#cb54-232" aria-hidden="true" tabindex="-1"></a><span class="in">    Y [label="Y", pos="4,0!", style=filled, fillcolor=lightgreen];</span></span>
<span id="cb54-233"><a href="#cb54-233" aria-hidden="true" tabindex="-1"></a><span class="in">    B [label="1", pos="2,2!"];</span></span>
<span id="cb54-234"><a href="#cb54-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-235"><a href="#cb54-235" aria-hidden="true" tabindex="-1"></a><span class="in">    X -&gt; Y [headlabel = "w1", labeldistance=12.5, labelangle=10];</span></span>
<span id="cb54-236"><a href="#cb54-236" aria-hidden="true" tabindex="-1"></a><span class="in">    B -&gt; Y [headlabel = "Bias (b)", labeldistance=9, labelangle=-15];</span></span>
<span id="cb54-237"><a href="#cb54-237" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb54-238"><a href="#cb54-238" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-239"><a href="#cb54-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-240"><a href="#cb54-240" aria-hidden="true" tabindex="-1"></a>Für die Illustration der Schätzung des in @sec-nn-basics dargestellten NN verwenden wir $n=1000$ simulierte Datenpunkte gemäß der Vorschrift</span>
<span id="cb54-241"><a href="#cb54-241" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb54-242"><a href="#cb54-242" aria-hidden="true" tabindex="-1"></a>  Y = 5 + 3 \cdot X + u</span>
<span id="cb54-243"><a href="#cb54-243" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb54-244"><a href="#cb54-244" aria-hidden="true" tabindex="-1"></a>mit $X\sim U<span class="co">[</span><span class="ot">0,10</span><span class="co">]</span>$ und $u\sim N(0,1)$.</span>
<span id="cb54-245"><a href="#cb54-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-248"><a href="#cb54-248" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-249"><a href="#cb54-249" aria-hidden="true" tabindex="-1"></a><span class="co"># Daten simulieren</span></span>
<span id="cb54-250"><a href="#cb54-250" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb54-251"><a href="#cb54-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-252"><a href="#cb54-252" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb54-253"><a href="#cb54-253" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">10</span>)</span>
<span id="cb54-254"><a href="#cb54-254" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">5</span> <span class="sc">+</span> <span class="dv">3</span> <span class="sc">*</span> x <span class="sc">+</span> <span class="fu">rnorm</span>(n) </span>
<span id="cb54-255"><a href="#cb54-255" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-256"><a href="#cb54-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-257"><a href="#cb54-257" aria-hidden="true" tabindex="-1"></a>Für das Training von NN verwenden wir das Python-Paket <span class="co">[</span><span class="ot">keras</span><span class="co">](https://keras.io/)</span>. Hierzu muss lediglich eine lokale Python-Installation vorhanden sein.</span>
<span id="cb54-258"><a href="#cb54-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-259"><a href="#cb54-259" aria-hidden="true" tabindex="-1"></a>Die in diesem Kapitel betrachteten NN sind *sequentielle* NN. Solche Modelle können in <span class="in">`keras`</span> mit der Funktion <span class="in">`keras_model_sequential()`</span> definiert werden. Die Struktur des Modells kann über eine Verkettung von Funktionen für Layers (<span class="in">`keras::layer_dense()`</span>) und Aktivierungen (<span class="in">`keras::layer_activation()`</span>) definiert werden.</span>
<span id="cb54-260"><a href="#cb54-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-261"><a href="#cb54-261" aria-hidden="true" tabindex="-1"></a>Für die Implementierung des Modells in @fig-nn-lreg wählen wir mit <span class="in">`units = 1`</span> und <span class="in">`input_shape = 1`</span> ein Modell mit einem Neuron im Output Layer, das skalare Informationen verarbeitet. <span class="in">`activation = 'linear'`</span> in <span class="in">`layer_dense()`</span> führt zu der Aktivierungsfunktion $A(x) = x$, d.h. die Ausgabe des Input Layers ist die gewichtete Summe der Eingaben plus Bias, *ohne* eine zusätzliche Transformation.</span>
<span id="cb54-262"><a href="#cb54-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-265"><a href="#cb54-265" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-266"><a href="#cb54-266" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb54-267"><a href="#cb54-267" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb54-268"><a href="#cb54-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-269"><a href="#cb54-269" aria-hidden="true" tabindex="-1"></a><span class="co"># NN für einfache Regression</span></span>
<span id="cb54-270"><a href="#cb54-270" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span></span>
<span id="cb54-271"><a href="#cb54-271" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(</span>
<span id="cb54-272"><a href="#cb54-272" aria-hidden="true" tabindex="-1"></a>    <span class="at">units =</span> <span class="dv">1</span>, </span>
<span id="cb54-273"><a href="#cb54-273" aria-hidden="true" tabindex="-1"></a>    <span class="at">input_shape =</span> <span class="dv">1</span>, </span>
<span id="cb54-274"><a href="#cb54-274" aria-hidden="true" tabindex="-1"></a>    <span class="at">activation =</span> <span class="st">'linear'</span></span>
<span id="cb54-275"><a href="#cb54-275" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb54-276"><a href="#cb54-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-277"><a href="#cb54-277" aria-hidden="true" tabindex="-1"></a><span class="co"># Modell-Definition prüfen</span></span>
<span id="cb54-278"><a href="#cb54-278" aria-hidden="true" tabindex="-1"></a>model</span>
<span id="cb54-279"><a href="#cb54-279" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-280"><a href="#cb54-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-281"><a href="#cb54-281" aria-hidden="true" tabindex="-1"></a>Die Übersicht zeigt, dass <span class="in">`model`</span> aus einem Layer für skalare Inputs und Outputs sowie zwei trainierbaren Parameters ($w_1$ und $b$) besteht.</span>
<span id="cb54-282"><a href="#cb54-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-283"><a href="#cb54-283" aria-hidden="true" tabindex="-1"></a>Bevor das im Objekt <span class="in">`model`</span> definierte Modell trainiert werden kann, muss der Code *kompiliert* werden. Dieser Vorgang ist notwendig, da sämtliche Berechnungen in Python durchgeführt werden. Der Python-Code wird beim kompilieren in eine Zwischendarstellung (*Bytecode*) übersetzt, die dann von der Python-Interpreter-Laufzeitumgebung ausgeführt wird.^[Im Gegensatz zu Python ist R eine *interpretierte Programmiersprache*. Kompilierung von R-Ccode ist daher nicht notwendig.]</span>
<span id="cb54-284"><a href="#cb54-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-285"><a href="#cb54-285" aria-hidden="true" tabindex="-1"></a>Mit <span class="in">`keras::compile()`</span> kompilieren wir das Modell und wählen als Optimierungsfunktion Adam mit einer Lernrate von $.01$. Die Loss-Funktion wird über das Argument <span class="in">`loss`</span> festgelegt, hier der mittlere absolute Fehler,</span>
<span id="cb54-286"><a href="#cb54-286" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb54-287"><a href="#cb54-287" aria-hidden="true" tabindex="-1"></a>  \textup{MAE} = \frac{1}{n} \sum_{i=1}^{n} \lvert y_i - \widehat{y}_i\rvert.</span>
<span id="cb54-288"><a href="#cb54-288" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb54-289"><a href="#cb54-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-292"><a href="#cb54-292" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-293"><a href="#cb54-293" aria-hidden="true" tabindex="-1"></a><span class="co"># Modell kompilieren</span></span>
<span id="cb54-294"><a href="#cb54-294" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb54-295"><a href="#cb54-295" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(</span>
<span id="cb54-296"><a href="#cb54-296" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_adam</span>(<span class="at">learning_rate =</span> <span class="fl">0.01</span>),</span>
<span id="cb54-297"><a href="#cb54-297" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> <span class="st">'mean_absolute_error'</span></span>
<span id="cb54-298"><a href="#cb54-298" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb54-299"><a href="#cb54-299" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-300"><a href="#cb54-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-301"><a href="#cb54-301" aria-hidden="true" tabindex="-1"></a>Die Kompilierung erfolgt meist innerhalb von Sekundenbruchteilen und geschieht *in-place*: Eine Zuweisung des kompilierten Modells in `model` ist *nicht* notwendig.</span>
<span id="cb54-302"><a href="#cb54-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-303"><a href="#cb54-303" aria-hidden="true" tabindex="-1"></a>Um das Modell zu trainieren verwenden wir <span class="in">`keras::fit()`</span>. Neben den (simulierten) Daten übergeben wir die Anzahl der zudurchlaufenden Epochen <span class="in">`epocs`</span>. Über das Argument <span class="in">`validation_split`</span> legen wir fest, dass 20\% der Datensatzes zufällig ausgewählt und als Test-Datensatz für die Modell-Validierung während des Trainings genutzt werden sollen.</span>
<span id="cb54-304"><a href="#cb54-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-307"><a href="#cb54-307" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-308"><a href="#cb54-308" aria-hidden="true" tabindex="-1"></a><span class="co"># Modell trainieren</span></span>
<span id="cb54-309"><a href="#cb54-309" aria-hidden="true" tabindex="-1"></a>history_snn <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> </span>
<span id="cb54-310"><a href="#cb54-310" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb54-311"><a href="#cb54-311" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> x, </span>
<span id="cb54-312"><a href="#cb54-312" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> y, </span>
<span id="cb54-313"><a href="#cb54-313" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> <span class="dv">50</span>, </span>
<span id="cb54-314"><a href="#cb54-314" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> .<span class="dv">2</span></span>
<span id="cb54-315"><a href="#cb54-315" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb54-316"><a href="#cb54-316" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-317"><a href="#cb54-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-318"><a href="#cb54-318" aria-hidden="true" tabindex="-1"></a>Der Output zeigt die Enwicklung des Loss (MAE) für Vorhersagen des Trainingsdatensatzes (<span class="in">`loss`</span>) und für den Test-Datensatz (<span class="in">`val_loss`</span>) für alle 25 Epochen. Diese Informationen können mit <span class="in">`plot()`</span> einfach visualisiert werden.</span>
<span id="cb54-319"><a href="#cb54-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-322"><a href="#cb54-322" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-323"><a href="#cb54-323" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-snn-loss</span></span>
<span id="cb54-324"><a href="#cb54-324" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Einfaches lineares NN: Entwicklung des Loss für 25 Epochen"</span></span>
<span id="cb54-325"><a href="#cb54-325" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb54-326"><a href="#cb54-326" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cowplot)</span>
<span id="cb54-327"><a href="#cb54-327" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(purrr)</span>
<span id="cb54-328"><a href="#cb54-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-329"><a href="#cb54-329" aria-hidden="true" tabindex="-1"></a><span class="co"># Entwicklung des Loss über Epochen plotten</span></span>
<span id="cb54-330"><a href="#cb54-330" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(history_snn) <span class="sc">+</span></span>
<span id="cb54-331"><a href="#cb54-331" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb54-332"><a href="#cb54-332" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Epoche"</span>,</span>
<span id="cb54-333"><a href="#cb54-333" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Wert der Verlustfunktion"</span></span>
<span id="cb54-334"><a href="#cb54-334" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb54-335"><a href="#cb54-335" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_cowplot</span>() <span class="sc">+</span></span>
<span id="cb54-336"><a href="#cb54-336" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)</span>
<span id="cb54-337"><a href="#cb54-337" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-338"><a href="#cb54-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-339"><a href="#cb54-339" aria-hidden="true" tabindex="-1"></a>@fig-snn-loss zeigt, dass sich sowohl die Anpassung des NN auf dem Trainingsdatenstz als auch die Generalisierung auf dem Testdatensatz innerhalb der ersten Epochen dramatisch verbessert. Jenseits der 15. Epoche hingegen bewirken weitere Trainingszyklen keine weitere Verbesserung des Loss.</span>
<span id="cb54-340"><a href="#cb54-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-341"><a href="#cb54-341" aria-hidden="true" tabindex="-1"></a>Mit <span class="in">`keras::get_weights()`</span> können wir die optimierten Parameter aus dem Modell-Objekt auslesen.</span>
<span id="cb54-342"><a href="#cb54-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-345"><a href="#cb54-345" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-346"><a href="#cb54-346" aria-hidden="true" tabindex="-1"></a><span class="co"># Gewichtung und Bias des trainierten NN auslesen</span></span>
<span id="cb54-347"><a href="#cb54-347" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb54-348"><a href="#cb54-348" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">get_weights</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb54-349"><a href="#cb54-349" aria-hidden="true" tabindex="-1"></a>  <span class="fu">flatten_dbl</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb54-350"><a href="#cb54-350" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_names</span>(</span>
<span id="cb54-351"><a href="#cb54-351" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="st">"w_1"</span>, <span class="st">"bias"</span>)</span>
<span id="cb54-352"><a href="#cb54-352" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb54-353"><a href="#cb54-353" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-354"><a href="#cb54-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-355"><a href="#cb54-355" aria-hidden="true" tabindex="-1"></a>Das NN hat den funktionalen Zusammengang zwischen <span class="in">`x`</span> und <span class="in">`y`</span> erfolgreich gelernt: Die optimierten Parameter-Werte <span class="in">`bias`</span> und <span class="in">`w_1`</span> liegen nahe der wahren Parameter. Bei Parameter sind mit ihren KQ-Schätzungen vergleichbar.^<span class="co">[</span><span class="ot">Beachte, dass die KQ-Schätzung der Einfachheit halber hier den gesamten Datensatz nutzt und daher präziser sein kann als das NN.</span><span class="co">]</span></span>
<span id="cb54-356"><a href="#cb54-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-359"><a href="#cb54-359" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-360"><a href="#cb54-360" aria-hidden="true" tabindex="-1"></a><span class="co"># lineares Modell</span></span>
<span id="cb54-361"><a href="#cb54-361" aria-hidden="true" tabindex="-1"></a>lm_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb54-362"><a href="#cb54-362" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lm_model)</span>
<span id="cb54-363"><a href="#cb54-363" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-364"><a href="#cb54-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-367"><a href="#cb54-367" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-368"><a href="#cb54-368" aria-hidden="true" tabindex="-1"></a><span class="co"># Koeffizienten der KQ-Schätzung auslesen</span></span>
<span id="cb54-369"><a href="#cb54-369" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(lm_model)</span>
<span id="cb54-370"><a href="#cb54-370" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-371"><a href="#cb54-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-372"><a href="#cb54-372" aria-hidden="true" tabindex="-1"></a>Mit <span class="in">`predict()`</span> erhalten wir Vorhersagen des NN und können so beispielsweise die Residuen für den gesamten Datensatz mit denen der KQ-Schätzung vergleichen.</span>
<span id="cb54-373"><a href="#cb54-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-376"><a href="#cb54-376" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-377"><a href="#cb54-377" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Vergleich von Residuen für NN und KQ-Schätzung"</span></span>
<span id="cb54-378"><a href="#cb54-378" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-res-nn</span></span>
<span id="cb54-379"><a href="#cb54-379" aria-hidden="true" tabindex="-1"></a><span class="co"># Residuen vergleichen</span></span>
<span id="cb54-380"><a href="#cb54-380" aria-hidden="true" tabindex="-1"></a> <span class="fu">tibble</span>(</span>
<span id="cb54-381"><a href="#cb54-381" aria-hidden="true" tabindex="-1"></a>   <span class="at">NN =</span> y <span class="sc">-</span> model <span class="sc">%&gt;%</span> <span class="fu">predict</span>(x),</span>
<span id="cb54-382"><a href="#cb54-382" aria-hidden="true" tabindex="-1"></a>   <span class="at">lm =</span> lm_model<span class="sc">$</span>residuals</span>
<span id="cb54-383"><a href="#cb54-383" aria-hidden="true" tabindex="-1"></a> ) <span class="sc">%&gt;%</span></span>
<span id="cb54-384"><a href="#cb54-384" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb54-385"><a href="#cb54-385" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> NN, <span class="at">y =</span> lm)) <span class="sc">+</span></span>
<span id="cb54-386"><a href="#cb54-386" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> .<span class="dv">5</span>, <span class="at">color =</span> <span class="st">"steelblue"</span>) <span class="sc">+</span></span>
<span id="cb54-387"><a href="#cb54-387" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_cowplot</span>()</span>
<span id="cb54-388"><a href="#cb54-388" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-389"><a href="#cb54-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-390"><a href="#cb54-390" aria-hidden="true" tabindex="-1"></a>@fig-res-nn zeigt eine gute Korrespondenz der Anpassung des NN mit der Anpassung des linearen, mit KQ geschätzten Modells.</span>
<span id="cb54-391"><a href="#cb54-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-392"><a href="#cb54-392" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multiple Regression</span></span>
<span id="cb54-393"><a href="#cb54-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-394"><a href="#cb54-394" aria-hidden="true" tabindex="-1"></a>Ein neuronales Netz für multiple Regression kann als eine Erweiterung des Netzes für einfache Regression betrachtet werden. Das Netz enthält nun mehrere Input-Neuronen, von denen jedes eine der unabhängigen Variablen $X_1, X_2, \dots, X_k$ repräsentiert. Diese Input-Neuronen sind mit einem einzigen Output-Neuron verbunden, das die Vorhersage für $Y$  liefert. Jede dieser Verbindungen wird mit einem Gewicht $w_i$  multipliziert, das die Stärke des Einflusses der jeweiligen unabhängigen Variable  $X_i$  auf die abhängige Variable  $Y$  repräsentiert. Wie im einfachen Modell gibt es einen Bias-Term $b$, der ähnlich wie in der einen konstanten Einfluss darstellt.</span>
<span id="cb54-395"><a href="#cb54-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-396"><a href="#cb54-396" aria-hidden="true" tabindex="-1"></a>Die Struktur eines NN für multiple Regression ist in @fig-nn-mlreg dargestellt. In diesem Beispiel gibt es drei unabhängige Variablen $X_1$, $X_2$ und $X_3$, die jeweils ein eigenes Input-Neuron haben und mit dem Output-Neuron $Y$ verbunden sind. $Y$ ist eine Linear-Kombination der Inputs, gewichtet mit den jeweiligen Gewichten $w_1$, $w_2$ und $w_3$, sowie dem Bias $b$.</span>
<span id="cb54-397"><a href="#cb54-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-400"><a href="#cb54-400" aria-hidden="true" tabindex="-1"></a><span class="in">```{dot}</span></span>
<span id="cb54-401"><a href="#cb54-401" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-width: 6</span></span>
<span id="cb54-402"><a href="#cb54-402" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-height: 3</span></span>
<span id="cb54-403"><a href="#cb54-403" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-cap: "Neuronales Netzwerk: Multiple lineare Regression"</span></span>
<span id="cb54-404"><a href="#cb54-404" aria-hidden="true" tabindex="-1"></a><span class="in">//| label: "fig-nn-mlreg"</span></span>
<span id="cb54-405"><a href="#cb54-405" aria-hidden="true" tabindex="-1"></a><span class="in">digraph NEURALNET {</span></span>
<span id="cb54-406"><a href="#cb54-406" aria-hidden="true" tabindex="-1"></a><span class="in">    layout=neato</span></span>
<span id="cb54-407"><a href="#cb54-407" aria-hidden="true" tabindex="-1"></a><span class="in">    fontname="Helvetica,Arial,sans-serif"</span></span>
<span id="cb54-408"><a href="#cb54-408" aria-hidden="true" tabindex="-1"></a><span class="in">    node [fontname="Helvetica,Arial,sans-serif", shape="circle"]</span></span>
<span id="cb54-409"><a href="#cb54-409" aria-hidden="true" tabindex="-1"></a><span class="in">    edge [fontname="Helvetica,Arial,sans-serif"]</span></span>
<span id="cb54-410"><a href="#cb54-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-411"><a href="#cb54-411" aria-hidden="true" tabindex="-1"></a><span class="in">    // Eingangsneuronen</span></span>
<span id="cb54-412"><a href="#cb54-412" aria-hidden="true" tabindex="-1"></a><span class="in">    X1 [label="X1", pos="0,1!"];</span></span>
<span id="cb54-413"><a href="#cb54-413" aria-hidden="true" tabindex="-1"></a><span class="in">    X2 [label="X2", pos="0,0!"];</span></span>
<span id="cb54-414"><a href="#cb54-414" aria-hidden="true" tabindex="-1"></a><span class="in">    X3 [label="X3", pos="0,-1!"];</span></span>
<span id="cb54-415"><a href="#cb54-415" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb54-416"><a href="#cb54-416" aria-hidden="true" tabindex="-1"></a><span class="in">    // Summationsneuron</span></span>
<span id="cb54-417"><a href="#cb54-417" aria-hidden="true" tabindex="-1"></a><span class="in">    SUM [label="∑", shape="circle", pos="3,0!", width=0.5, height=0.5, style=filled, fillcolor=lightgray];</span></span>
<span id="cb54-418"><a href="#cb54-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-419"><a href="#cb54-419" aria-hidden="true" tabindex="-1"></a><span class="in">    // Ausgabeneuron</span></span>
<span id="cb54-420"><a href="#cb54-420" aria-hidden="true" tabindex="-1"></a><span class="in">    Y [label="Y", pos="5,0!", style=filled, fillcolor=lightgreen];</span></span>
<span id="cb54-421"><a href="#cb54-421" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb54-422"><a href="#cb54-422" aria-hidden="true" tabindex="-1"></a><span class="in">    // Bias</span></span>
<span id="cb54-423"><a href="#cb54-423" aria-hidden="true" tabindex="-1"></a><span class="in">    B [label="1", pos="3,2!", fontcolor=gray, style=filled, fillcolor=lightblue];</span></span>
<span id="cb54-424"><a href="#cb54-424" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb54-425"><a href="#cb54-425" aria-hidden="true" tabindex="-1"></a><span class="in">    // Verbindungen von Eingangsneuronen zur Summation</span></span>
<span id="cb54-426"><a href="#cb54-426" aria-hidden="true" tabindex="-1"></a><span class="in">    X1 -&gt; SUM [label = "w1"];</span></span>
<span id="cb54-427"><a href="#cb54-427" aria-hidden="true" tabindex="-1"></a><span class="in">    X2 -&gt; SUM [label = "w2"];</span></span>
<span id="cb54-428"><a href="#cb54-428" aria-hidden="true" tabindex="-1"></a><span class="in">    X3 -&gt; SUM [label = "w3"];</span></span>
<span id="cb54-429"><a href="#cb54-429" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb54-430"><a href="#cb54-430" aria-hidden="true" tabindex="-1"></a><span class="in">    // Verbindung vom Bias zur Summation</span></span>
<span id="cb54-431"><a href="#cb54-431" aria-hidden="true" tabindex="-1"></a><span class="in">    B -&gt; SUM [label = "b"];</span></span>
<span id="cb54-432"><a href="#cb54-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-433"><a href="#cb54-433" aria-hidden="true" tabindex="-1"></a><span class="in">    // Verbindung von der Summation zum Ausgabeneuron</span></span>
<span id="cb54-434"><a href="#cb54-434" aria-hidden="true" tabindex="-1"></a><span class="in">    SUM -&gt; Y [label = ""];</span></span>
<span id="cb54-435"><a href="#cb54-435" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb54-436"><a href="#cb54-436" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-437"><a href="#cb54-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-438"><a href="#cb54-438" aria-hidden="true" tabindex="-1"></a>Um die Vorgehensweise in R zu zeigen, generieren wir zunächst $n=250$ Datenpunkte gemäß der Vorschrift</span>
<span id="cb54-439"><a href="#cb54-439" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb54-440"><a href="#cb54-440" aria-hidden="true" tabindex="-1"></a>  Y = 5 + 3 \cdot X_1 + 2\cdot X_2 - 1.5 \cdot X_k + u</span>
<span id="cb54-441"><a href="#cb54-441" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb54-442"><a href="#cb54-442" aria-hidden="true" tabindex="-1"></a>mit $X_1,X_2,X_3 \sim\textup{u.i.v.} N(0, 1)$ und $u\sim N(0,1)$.</span>
<span id="cb54-443"><a href="#cb54-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-446"><a href="#cb54-446" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-447"><a href="#cb54-447" aria-hidden="true" tabindex="-1"></a><span class="co"># Erstellen von Trainingsdaten</span></span>
<span id="cb54-448"><a href="#cb54-448" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb54-449"><a href="#cb54-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-450"><a href="#cb54-450" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">250</span></span>
<span id="cb54-451"><a href="#cb54-451" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb54-452"><a href="#cb54-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-453"><a href="#cb54-453" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="at">n =</span> n <span class="sc">*</span> k), <span class="at">ncol =</span> k)</span>
<span id="cb54-454"><a href="#cb54-454" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">2</span>, <span class="sc">-</span><span class="fl">1.5</span>)</span>
<span id="cb54-455"><a href="#cb54-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-456"><a href="#cb54-456" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="dv">5</span> <span class="sc">+</span> X <span class="sc">%*%</span> w <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb54-457"><a href="#cb54-457" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-458"><a href="#cb54-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-459"><a href="#cb54-459" aria-hidden="true" tabindex="-1"></a>Anschließend definieren wir ein einfaches NN und fügen ein Layer hinzu. Da wir eine multiple Regression durchführen, wählen wir <span class="in">`input_shape = k`</span>, wobei <span class="in">`k`</span> die Anzahl der unabhängigen Variablen ist. Wie im einfachen Modell ist die Aktivierungsfunktion linear, da wir an der Anpassung von $Y$ mit einer linearen Kombination der Inputs interessiert sind.</span>
<span id="cb54-460"><a href="#cb54-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-463"><a href="#cb54-463" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-464"><a href="#cb54-464" aria-hidden="true" tabindex="-1"></a><span class="co"># Erstellen und Kompilieren des Modells</span></span>
<span id="cb54-465"><a href="#cb54-465" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span></span>
<span id="cb54-466"><a href="#cb54-466" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(</span>
<span id="cb54-467"><a href="#cb54-467" aria-hidden="true" tabindex="-1"></a>    <span class="at">units =</span> <span class="dv">1</span>, </span>
<span id="cb54-468"><a href="#cb54-468" aria-hidden="true" tabindex="-1"></a>    <span class="at">input_shape =</span> k, </span>
<span id="cb54-469"><a href="#cb54-469" aria-hidden="true" tabindex="-1"></a>    <span class="at">activation =</span> <span class="st">'linear'</span></span>
<span id="cb54-470"><a href="#cb54-470" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb54-471"><a href="#cb54-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-472"><a href="#cb54-472" aria-hidden="true" tabindex="-1"></a><span class="co"># Modelldefinition prüfen</span></span>
<span id="cb54-473"><a href="#cb54-473" aria-hidden="true" tabindex="-1"></a>model</span>
<span id="cb54-474"><a href="#cb54-474" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-475"><a href="#cb54-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-476"><a href="#cb54-476" aria-hidden="true" tabindex="-1"></a>Wir kompilieren das Modell mit dem mittleren quadratischen Fehler (mean squared error, MSE) und SGD als Loss-Funktion mit einer moderaten Lernrate.</span>
<span id="cb54-477"><a href="#cb54-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-480"><a href="#cb54-480" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-481"><a href="#cb54-481" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb54-482"><a href="#cb54-482" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(</span>
<span id="cb54-483"><a href="#cb54-483" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> <span class="st">'mean_squared_error'</span>,</span>
<span id="cb54-484"><a href="#cb54-484" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_sgd</span>(<span class="at">learning_rate =</span> <span class="fl">0.01</span>)</span>
<span id="cb54-485"><a href="#cb54-485" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb54-486"><a href="#cb54-486" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-487"><a href="#cb54-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-488"><a href="#cb54-488" aria-hidden="true" tabindex="-1"></a>Die Anpassung des Modells erfolgt wie bei einfacher Regression mit <span class="in">`keras::fit()`</span>.</span>
<span id="cb54-489"><a href="#cb54-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-492"><a href="#cb54-492" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-493"><a href="#cb54-493" aria-hidden="true" tabindex="-1"></a><span class="co"># Training des Modells</span></span>
<span id="cb54-494"><a href="#cb54-494" aria-hidden="true" tabindex="-1"></a>history_mnn <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> </span>
<span id="cb54-495"><a href="#cb54-495" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb54-496"><a href="#cb54-496" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> X, </span>
<span id="cb54-497"><a href="#cb54-497" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> Y, </span>
<span id="cb54-498"><a href="#cb54-498" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> .<span class="dv">2</span>,</span>
<span id="cb54-499"><a href="#cb54-499" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> <span class="dv">25</span></span>
<span id="cb54-500"><a href="#cb54-500" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb54-501"><a href="#cb54-501" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-502"><a href="#cb54-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-505"><a href="#cb54-505" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-506"><a href="#cb54-506" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-mnn-loss</span></span>
<span id="cb54-507"><a href="#cb54-507" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "NN für mult. Regression: Entwicklung des Loss für 25 Epochen"</span></span>
<span id="cb54-508"><a href="#cb54-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-509"><a href="#cb54-509" aria-hidden="true" tabindex="-1"></a><span class="co"># Entwicklung des Loss über Epochen plotten</span></span>
<span id="cb54-510"><a href="#cb54-510" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(history_mnn) <span class="sc">+</span></span>
<span id="cb54-511"><a href="#cb54-511" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb54-512"><a href="#cb54-512" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Epoche"</span>,</span>
<span id="cb54-513"><a href="#cb54-513" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Wert der Verlustfunktion"</span></span>
<span id="cb54-514"><a href="#cb54-514" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb54-515"><a href="#cb54-515" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_cowplot</span>() <span class="sc">+</span></span>
<span id="cb54-516"><a href="#cb54-516" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)</span>
<span id="cb54-517"><a href="#cb54-517" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-518"><a href="#cb54-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-519"><a href="#cb54-519" aria-hidden="true" tabindex="-1"></a>Wie bei der einfachen Regression können wir die angepassten Gewichte auslesen und mit ihren KQ-Schätzungen vergleichen.</span>
<span id="cb54-520"><a href="#cb54-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-523"><a href="#cb54-523" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-524"><a href="#cb54-524" aria-hidden="true" tabindex="-1"></a><span class="co"># Gewichte und Bias extrahieren</span></span>
<span id="cb54-525"><a href="#cb54-525" aria-hidden="true" tabindex="-1"></a>weights <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> </span>
<span id="cb54-526"><a href="#cb54-526" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">get_weights</span>()</span>
<span id="cb54-527"><a href="#cb54-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-528"><a href="#cb54-528" aria-hidden="true" tabindex="-1"></a>weights[[<span class="dv">1</span>]]  <span class="co"># Gewicht für die Regressoren</span></span>
<span id="cb54-529"><a href="#cb54-529" aria-hidden="true" tabindex="-1"></a>weights[[<span class="dv">2</span>]]  <span class="co"># Bias-Term</span></span>
<span id="cb54-530"><a href="#cb54-530" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-531"><a href="#cb54-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-534"><a href="#cb54-534" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-535"><a href="#cb54-535" aria-hidden="true" tabindex="-1"></a><span class="co"># lineares Modell</span></span>
<span id="cb54-536"><a href="#cb54-536" aria-hidden="true" tabindex="-1"></a>lm_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X)</span>
<span id="cb54-537"><a href="#cb54-537" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lm_model)</span>
<span id="cb54-538"><a href="#cb54-538" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-539"><a href="#cb54-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-540"><a href="#cb54-540" aria-hidden="true" tabindex="-1"></a><span class="fu">## Nicht-Lineare Zusammenhänge</span></span>
<span id="cb54-541"><a href="#cb54-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-542"><a href="#cb54-542" aria-hidden="true" tabindex="-1"></a>In diesem Abschnitt verwenden trainieren wir ein NN, um eine logistische Regression durchzuführen. Dieser Ansatz wird häufig verwendet, um eine binäre Outcome-Variablen $Y$ zu modellieren, also Variablen, die zwei mögliche Ausgänge haben (oft als 0 oder 1 dargestellt), siehe @sec-logreg für Details. Anstatt die Eingaben lediglich linear zu kombinieren, verwenden wir eine Sigmoid-Aktivierungsfunktion^<span class="co">[</span><span class="ot">Die Sigmoid-Aktivierungsfunktion entspricht der logistischen Funktion $\Lambda(z)$ aus @sec-logreg.</span><span class="co">]</span>, welche die Ausgaben auf einen Wertebereich zwischen 0 und 1 abbildet. Dadurch kann das NN Wahrscheinlichkeiten $P(Y=1\vert \boldsymbol{X} = \boldsymbol{x})$ vorhersagen, die für die *Klassifikation* von Beobachtungen verwendet werden können.</span>
<span id="cb54-543"><a href="#cb54-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-544"><a href="#cb54-544" aria-hidden="true" tabindex="-1"></a>Für die Illustration der Schätzung mit <span class="in">`keras`</span> verwenden wir den DGP aus @sec-probitreg.</span>
<span id="cb54-545"><a href="#cb54-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-548"><a href="#cb54-548" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-549"><a href="#cb54-549" aria-hidden="true" tabindex="-1"></a><span class="co"># Erstellen von Trainingsdaten</span></span>
<span id="cb54-550"><a href="#cb54-550" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb54-551"><a href="#cb54-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-552"><a href="#cb54-552" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb54-553"><a href="#cb54-553" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">2</span>) <span class="co"># Regressor</span></span>
<span id="cb54-554"><a href="#cb54-554" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="dv">4</span> <span class="sc">+</span> <span class="fl">0.7</span> <span class="sc">*</span> X)</span>
<span id="cb54-555"><a href="#cb54-555" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">as.integer</span>(<span class="fu">runif</span>(n) <span class="sc">&lt;</span> P)</span>
<span id="cb54-556"><a href="#cb54-556" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-557"><a href="#cb54-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-558"><a href="#cb54-558" aria-hidden="true" tabindex="-1"></a>@fig-nn-log-reg zeigt ein einfaches NN für eine binäre Outcome-Variable.</span>
<span id="cb54-559"><a href="#cb54-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-562"><a href="#cb54-562" aria-hidden="true" tabindex="-1"></a><span class="in">```{dot}</span></span>
<span id="cb54-563"><a href="#cb54-563" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-width: 6</span></span>
<span id="cb54-564"><a href="#cb54-564" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-height: 4</span></span>
<span id="cb54-565"><a href="#cb54-565" aria-hidden="true" tabindex="-1"></a><span class="in">//| fig-cap: "Neuronales Netzwerk mit Sigmoid-Aktivierungsfunktion"</span></span>
<span id="cb54-566"><a href="#cb54-566" aria-hidden="true" tabindex="-1"></a><span class="in">//| label: "fig-nn-log-reg"</span></span>
<span id="cb54-567"><a href="#cb54-567" aria-hidden="true" tabindex="-1"></a><span class="in">digraph NNlogit {</span></span>
<span id="cb54-568"><a href="#cb54-568" aria-hidden="true" tabindex="-1"></a><span class="in">    layout=neato</span></span>
<span id="cb54-569"><a href="#cb54-569" aria-hidden="true" tabindex="-1"></a><span class="in">    fontname="Helvetica,Arial,sans-serif"</span></span>
<span id="cb54-570"><a href="#cb54-570" aria-hidden="true" tabindex="-1"></a><span class="in">    node [fontname="Helvetica,Arial,sans-serif", shape="circle"]</span></span>
<span id="cb54-571"><a href="#cb54-571" aria-hidden="true" tabindex="-1"></a><span class="in">    edge [fontname="Helvetica,Arial,sans-serif"]</span></span>
<span id="cb54-572"><a href="#cb54-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-573"><a href="#cb54-573" aria-hidden="true" tabindex="-1"></a><span class="in">    // Eingangsvariablen</span></span>
<span id="cb54-574"><a href="#cb54-574" aria-hidden="true" tabindex="-1"></a><span class="in">    X [label="X1", pos="0,0!"];</span></span>
<span id="cb54-575"><a href="#cb54-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-576"><a href="#cb54-576" aria-hidden="true" tabindex="-1"></a><span class="in">    // Summationsneuron</span></span>
<span id="cb54-577"><a href="#cb54-577" aria-hidden="true" tabindex="-1"></a><span class="in">    SUM [label="∑", shape="circle", pos="3,0!", width=0.5, height=0.5, style=filled];</span></span>
<span id="cb54-578"><a href="#cb54-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-579"><a href="#cb54-579" aria-hidden="true" tabindex="-1"></a><span class="in">    // Sigmoid-Aktivierungsfunktion</span></span>
<span id="cb54-580"><a href="#cb54-580" aria-hidden="true" tabindex="-1"></a><span class="in">    sigmoid [label="σ", pos="5,0!", style=filled, fillcolor=lightblue];</span></span>
<span id="cb54-581"><a href="#cb54-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-582"><a href="#cb54-582" aria-hidden="true" tabindex="-1"></a><span class="in">    // Output</span></span>
<span id="cb54-583"><a href="#cb54-583" aria-hidden="true" tabindex="-1"></a><span class="in">    Y [label="Y", pos="7,0!", style=filled, fillcolor=lightgreen];</span></span>
<span id="cb54-584"><a href="#cb54-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-585"><a href="#cb54-585" aria-hidden="true" tabindex="-1"></a><span class="in">    // Bias</span></span>
<span id="cb54-586"><a href="#cb54-586" aria-hidden="true" tabindex="-1"></a><span class="in">    B [label="1", pos="3,2!"];</span></span>
<span id="cb54-587"><a href="#cb54-587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-588"><a href="#cb54-588" aria-hidden="true" tabindex="-1"></a><span class="in">    // Verbindungen von Eingangsneuronen zur Summation</span></span>
<span id="cb54-589"><a href="#cb54-589" aria-hidden="true" tabindex="-1"></a><span class="in">    X -&gt; SUM [label = "w1"];</span></span>
<span id="cb54-590"><a href="#cb54-590" aria-hidden="true" tabindex="-1"></a><span class="in">    B -&gt; SUM [label = "b"];</span></span>
<span id="cb54-591"><a href="#cb54-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-592"><a href="#cb54-592" aria-hidden="true" tabindex="-1"></a><span class="in">    // Verbindung von der Summation zur Sigmoid-Funktion</span></span>
<span id="cb54-593"><a href="#cb54-593" aria-hidden="true" tabindex="-1"></a><span class="in">    SUM -&gt; sigmoid [label = ""];</span></span>
<span id="cb54-594"><a href="#cb54-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-595"><a href="#cb54-595" aria-hidden="true" tabindex="-1"></a><span class="in">    // Verbindung von der Sigmoid-Funktion zum Output</span></span>
<span id="cb54-596"><a href="#cb54-596" aria-hidden="true" tabindex="-1"></a><span class="in">    sigmoid -&gt; Y [label = ""];</span></span>
<span id="cb54-597"><a href="#cb54-597" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb54-598"><a href="#cb54-598" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-599"><a href="#cb54-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-600"><a href="#cb54-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-601"><a href="#cb54-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-604"><a href="#cb54-604" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-605"><a href="#cb54-605" aria-hidden="true" tabindex="-1"></a><span class="co"># Erstellen und Kompilieren des Modells</span></span>
<span id="cb54-606"><a href="#cb54-606" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span></span>
<span id="cb54-607"><a href="#cb54-607" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(</span>
<span id="cb54-608"><a href="#cb54-608" aria-hidden="true" tabindex="-1"></a>    <span class="at">units =</span> <span class="dv">1</span>, </span>
<span id="cb54-609"><a href="#cb54-609" aria-hidden="true" tabindex="-1"></a>    <span class="at">input_shape =</span> <span class="dv">1</span>, </span>
<span id="cb54-610"><a href="#cb54-610" aria-hidden="true" tabindex="-1"></a>    <span class="at">activation =</span> <span class="st">'sigmoid'</span> <span class="co"># &lt;= für Logit-Modell</span></span>
<span id="cb54-611"><a href="#cb54-611" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb54-612"><a href="#cb54-612" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-613"><a href="#cb54-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-614"><a href="#cb54-614" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb54-615"><a href="#cb54-615" aria-hidden="true" tabindex="-1"></a>  \textup{Binary Crossentropy} = -\frac{1}{N} \sum_{i=1}^{N} \left<span class="co">[</span><span class="ot"> y_i \cdot \log(\widehat{y}_i) + (1 - y_i) \cdot \log(1 - \widehat{y}_i) \right</span><span class="co">]</span></span>
<span id="cb54-616"><a href="#cb54-616" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb54-617"><a href="#cb54-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-620"><a href="#cb54-620" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-621"><a href="#cb54-621" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb54-622"><a href="#cb54-622" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss =</span> <span class="st">'binary_crossentropy'</span>,</span>
<span id="cb54-623"><a href="#cb54-623" aria-hidden="true" tabindex="-1"></a>  <span class="at">optimizer =</span> <span class="fu">optimizer_adam</span>(<span class="at">learning_rate =</span> <span class="fl">0.01</span>),</span>
<span id="cb54-624"><a href="#cb54-624" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">'accuracy'</span>)</span>
<span id="cb54-625"><a href="#cb54-625" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb54-626"><a href="#cb54-626" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-627"><a href="#cb54-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-628"><a href="#cb54-628" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, cache=TRUE}</span></span>
<span id="cb54-629"><a href="#cb54-629" aria-hidden="true" tabindex="-1"></a><span class="in"># Training des Modells</span></span>
<span id="cb54-630"><a href="#cb54-630" aria-hidden="true" tabindex="-1"></a><span class="in">model %&gt;% </span></span>
<span id="cb54-631"><a href="#cb54-631" aria-hidden="true" tabindex="-1"></a><span class="in">  fit(X, Y, epochs = 200, verbose = 0)</span></span>
<span id="cb54-632"><a href="#cb54-632" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-633"><a href="#cb54-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-636"><a href="#cb54-636" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-637"><a href="#cb54-637" aria-hidden="true" tabindex="-1"></a><span class="co"># Gewichte und Bias extrahieren</span></span>
<span id="cb54-638"><a href="#cb54-638" aria-hidden="true" tabindex="-1"></a>weights <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> </span>
<span id="cb54-639"><a href="#cb54-639" aria-hidden="true" tabindex="-1"></a>  <span class="fu">get_weights</span>()</span>
<span id="cb54-640"><a href="#cb54-640" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> weights[[<span class="dv">1</span>]]  <span class="co"># Gewicht für jede der 5 Variablen</span></span>
<span id="cb54-641"><a href="#cb54-641" aria-hidden="true" tabindex="-1"></a>bias <span class="ot">&lt;-</span> weights[[<span class="dv">2</span>]]  <span class="co"># Bias-Term</span></span>
<span id="cb54-642"><a href="#cb54-642" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-643"><a href="#cb54-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-646"><a href="#cb54-646" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-647"><a href="#cb54-647" aria-hidden="true" tabindex="-1"></a><span class="co"># Ergebnisse anzeigen</span></span>
<span id="cb54-648"><a href="#cb54-648" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(w)</span>
<span id="cb54-649"><a href="#cb54-649" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(bias)</span>
<span id="cb54-650"><a href="#cb54-650" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-651"><a href="#cb54-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-654"><a href="#cb54-654" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-655"><a href="#cb54-655" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(Y <span class="sc">~</span> X, <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">"logit"</span>))</span>
<span id="cb54-656"><a href="#cb54-656" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-657"><a href="#cb54-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-660"><a href="#cb54-660" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-661"><a href="#cb54-661" aria-hidden="true" tabindex="-1"></a><span class="co"># Vorhersagen auf den Trainingsdaten erstellen</span></span>
<span id="cb54-662"><a href="#cb54-662" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> </span>
<span id="cb54-663"><a href="#cb54-663" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(X)</span>
<span id="cb54-664"><a href="#cb54-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-665"><a href="#cb54-665" aria-hidden="true" tabindex="-1"></a><span class="co"># In einen DataFrame zusammenfassen</span></span>
<span id="cb54-666"><a href="#cb54-666" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb54-667"><a href="#cb54-667" aria-hidden="true" tabindex="-1"></a>  <span class="at">Regressor =</span> X,</span>
<span id="cb54-668"><a href="#cb54-668" aria-hidden="true" tabindex="-1"></a>  <span class="at">Actual =</span> Y,</span>
<span id="cb54-669"><a href="#cb54-669" aria-hidden="true" tabindex="-1"></a>  <span class="at">Predicted_Probability =</span> predictions</span>
<span id="cb54-670"><a href="#cb54-670" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb54-671"><a href="#cb54-671" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-672"><a href="#cb54-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-675"><a href="#cb54-675" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-676"><a href="#cb54-676" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb54-677"><a href="#cb54-677" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cowplot)</span>
<span id="cb54-678"><a href="#cb54-678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-679"><a href="#cb54-679" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot der tatsächlichen Werte gegen die vorhergesagten Wahrscheinlichkeiten</span></span>
<span id="cb54-680"><a href="#cb54-680" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(</span>
<span id="cb54-681"><a href="#cb54-681" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> results,</span>
<span id="cb54-682"><a href="#cb54-682" aria-hidden="true" tabindex="-1"></a>  <span class="at">mapping =</span>  <span class="fu">aes</span>(<span class="at">x =</span> X, <span class="at">y =</span> Actual)</span>
<span id="cb54-683"><a href="#cb54-683" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb54-684"><a href="#cb54-684" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(</span>
<span id="cb54-685"><a href="#cb54-685" aria-hidden="true" tabindex="-1"></a>    <span class="at">position =</span> <span class="fu">position_jitter</span>(<span class="at">height =</span> <span class="fl">0.05</span>), </span>
<span id="cb54-686"><a href="#cb54-686" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb54-687"><a href="#cb54-687" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(</span>
<span id="cb54-688"><a href="#cb54-688" aria-hidden="true" tabindex="-1"></a>     <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">y =</span> Predicted_Probability),</span>
<span id="cb54-689"><a href="#cb54-689" aria-hidden="true" tabindex="-1"></a>    <span class="at">col =</span> <span class="st">"darkred"</span></span>
<span id="cb54-690"><a href="#cb54-690" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb54-691"><a href="#cb54-691" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(</span>
<span id="cb54-692"><a href="#cb54-692" aria-hidden="true" tabindex="-1"></a>    <span class="at">method =</span> <span class="st">"glm"</span>, </span>
<span id="cb54-693"><a href="#cb54-693" aria-hidden="true" tabindex="-1"></a>    <span class="at">method.args =</span> <span class="fu">list</span>(<span class="at">family =</span> <span class="st">"binomial"</span>), </span>
<span id="cb54-694"><a href="#cb54-694" aria-hidden="true" tabindex="-1"></a>    <span class="at">se =</span> <span class="cn">FALSE</span></span>
<span id="cb54-695"><a href="#cb54-695" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb54-696"><a href="#cb54-696" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb54-697"><a href="#cb54-697" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Logistische Regression vs. NN"</span>,</span>
<span id="cb54-698"><a href="#cb54-698" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"x"</span>,</span>
<span id="cb54-699"><a href="#cb54-699" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Schätzung P(Y=1|X=x)"</span></span>
<span id="cb54-700"><a href="#cb54-700" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb54-701"><a href="#cb54-701" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb54-702"><a href="#cb54-702" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-703"><a href="#cb54-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-704"><a href="#cb54-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-705"><a href="#cb54-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-706"><a href="#cb54-706" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb54-707"><a href="#cb54-707" aria-hidden="true" tabindex="-1"></a><span class="fu">## Case Study: Immobilienpreise</span></span>
<span id="cb54-708"><a href="#cb54-708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-711"><a href="#cb54-711" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-712"><a href="#cb54-712" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AmesHousing)</span>
<span id="cb54-713"><a href="#cb54-713" aria-hidden="true" tabindex="-1"></a>housing <span class="ot">&lt;-</span> <span class="fu">make_ames</span>()</span>
<span id="cb54-714"><a href="#cb54-714" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-715"><a href="#cb54-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-718"><a href="#cb54-718" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-719"><a href="#cb54-719" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the necessary libraries</span></span>
<span id="cb54-720"><a href="#cb54-720" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb54-721"><a href="#cb54-721" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sf)</span>
<span id="cb54-722"><a href="#cb54-722" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tigris)</span>
<span id="cb54-723"><a href="#cb54-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-724"><a href="#cb54-724" aria-hidden="true" tabindex="-1"></a><span class="co"># Retrieve basemap for Ames, Iowa using the tigris package</span></span>
<span id="cb54-725"><a href="#cb54-725" aria-hidden="true" tabindex="-1"></a>places_map <span class="ot">&lt;-</span> <span class="fu">places</span>(</span>
<span id="cb54-726"><a href="#cb54-726" aria-hidden="true" tabindex="-1"></a>  <span class="at">state =</span> <span class="st">'IA'</span>, </span>
<span id="cb54-727"><a href="#cb54-727" aria-hidden="true" tabindex="-1"></a>  <span class="at">cb =</span> <span class="cn">TRUE</span>, </span>
<span id="cb54-728"><a href="#cb54-728" aria-hidden="true" tabindex="-1"></a>  <span class="at">progress =</span> F</span>
<span id="cb54-729"><a href="#cb54-729" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb54-730"><a href="#cb54-730" aria-hidden="true" tabindex="-1"></a>  <span class="fu">st_as_sf</span>()</span>
<span id="cb54-731"><a href="#cb54-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-732"><a href="#cb54-732" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter for Ames city</span></span>
<span id="cb54-733"><a href="#cb54-733" aria-hidden="true" tabindex="-1"></a>ames_map <span class="ot">&lt;-</span> places_map <span class="sc">%&gt;%</span> </span>
<span id="cb54-734"><a href="#cb54-734" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(NAME <span class="sc">==</span> <span class="st">"Ames"</span>)</span>
<span id="cb54-735"><a href="#cb54-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-736"><a href="#cb54-736" aria-hidden="true" tabindex="-1"></a>houses <span class="ot">&lt;-</span> housing <span class="sc">%&gt;%</span></span>
<span id="cb54-737"><a href="#cb54-737" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(Latitude, Longitude, Sale_Price) <span class="sc">%&gt;%</span></span>
<span id="cb54-738"><a href="#cb54-738" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(</span>
<span id="cb54-739"><a href="#cb54-739" aria-hidden="true" tabindex="-1"></a>      <span class="at">Sale_Price =</span> <span class="fu">cut</span>(<span class="fu">log</span>(Sale_Price, <span class="at">base =</span> <span class="dv">2</span>), <span class="at">breaks =</span> <span class="dv">5</span>, <span class="at">labels =</span> <span class="cn">FALSE</span>)</span>
<span id="cb54-740"><a href="#cb54-740" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span></span>
<span id="cb54-741"><a href="#cb54-741" aria-hidden="true" tabindex="-1"></a>    <span class="fu">st_as_sf</span>(<span class="at">coords =</span> <span class="fu">c</span>(<span class="st">"Longitude"</span>, <span class="st">"Latitude"</span>), </span>
<span id="cb54-742"><a href="#cb54-742" aria-hidden="true" tabindex="-1"></a>             <span class="at">crs =</span> <span class="dv">4326</span>, <span class="at">agr =</span> <span class="st">"constant"</span>)</span>
<span id="cb54-743"><a href="#cb54-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-744"><a href="#cb54-744" aria-hidden="true" tabindex="-1"></a>rainbow_colors <span class="ot">&lt;-</span> <span class="fu">rainbow</span>(<span class="dv">5</span>, <span class="at">rev =</span> <span class="cn">TRUE</span>)</span>
<span id="cb54-745"><a href="#cb54-745" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-746"><a href="#cb54-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-749"><a href="#cb54-749" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-750"><a href="#cb54-750" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the map with just the outline of Ames</span></span>
<span id="cb54-751"><a href="#cb54-751" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb54-752"><a href="#cb54-752" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_sf</span>(<span class="at">data =</span> ames_map, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">fill =</span> <span class="fu">alpha</span>(<span class="st">"black"</span>, <span class="at">alpha =</span> <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb54-753"><a href="#cb54-753" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_sf</span>(<span class="at">data =</span> houses, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">color =</span> <span class="fu">factor</span>(Sale_Price)), <span class="at">size =</span> .<span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb54-754"><a href="#cb54-754" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_map</span>() <span class="sc">+</span></span>
<span id="cb54-755"><a href="#cb54-755" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb54-756"><a href="#cb54-756" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">"log(Verkaufspreis)"</span>, </span>
<span id="cb54-757"><a href="#cb54-757" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> rainbow_colors, </span>
<span id="cb54-758"><a href="#cb54-758" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">levels</span>(<span class="fu">factor</span>(houses<span class="sc">$</span>Sale_Price))</span>
<span id="cb54-759"><a href="#cb54-759" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb54-760"><a href="#cb54-760" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>, <span class="at">legend.direction =</span> <span class="st">"horizontal"</span>) <span class="sc">+</span></span>
<span id="cb54-761"><a href="#cb54-761" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Verkaufte Häuser in Ames, Iowa"</span>)</span>
<span id="cb54-762"><a href="#cb54-762" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-763"><a href="#cb54-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-764"><a href="#cb54-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-767"><a href="#cb54-767" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-768"><a href="#cb54-768" aria-hidden="true" tabindex="-1"></a>housing <span class="sc">%&gt;%</span></span>
<span id="cb54-769"><a href="#cb54-769" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> Year_Built, <span class="at">y =</span> Sale_Price)) <span class="sc">+</span></span>
<span id="cb54-770"><a href="#cb54-770" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> .<span class="dv">5</span>, <span class="at">fill =</span> <span class="st">"steelblue"</span>) <span class="sc">+</span></span>
<span id="cb54-771"><a href="#cb54-771" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_cowplot</span>()</span>
<span id="cb54-772"><a href="#cb54-772" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-773"><a href="#cb54-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-776"><a href="#cb54-776" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-777"><a href="#cb54-777" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb54-778"><a href="#cb54-778" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb54-779"><a href="#cb54-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-780"><a href="#cb54-780" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb54-781"><a href="#cb54-781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-782"><a href="#cb54-782" aria-hidden="true" tabindex="-1"></a>split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(housing, <span class="at">prop =</span> <span class="fl">0.8</span>)</span>
<span id="cb54-783"><a href="#cb54-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-784"><a href="#cb54-784" aria-hidden="true" tabindex="-1"></a>housing_train <span class="ot">&lt;-</span> <span class="fu">training</span>(split)</span>
<span id="cb54-785"><a href="#cb54-785" aria-hidden="true" tabindex="-1"></a>housing_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(split)</span>
<span id="cb54-786"><a href="#cb54-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-787"><a href="#cb54-787" aria-hidden="true" tabindex="-1"></a><span class="co"># Separate the predictors and the outcome</span></span>
<span id="cb54-788"><a href="#cb54-788" aria-hidden="true" tabindex="-1"></a>housing_train_x <span class="ot">&lt;-</span> housing_train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Sale_Price)</span>
<span id="cb54-789"><a href="#cb54-789" aria-hidden="true" tabindex="-1"></a>housing_train_y <span class="ot">&lt;-</span> housing_train<span class="sc">$</span>Sale_Price</span>
<span id="cb54-790"><a href="#cb54-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-791"><a href="#cb54-791" aria-hidden="true" tabindex="-1"></a>housing_test_x <span class="ot">&lt;-</span> housing_test <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Sale_Price)</span>
<span id="cb54-792"><a href="#cb54-792" aria-hidden="true" tabindex="-1"></a>housing_test_y <span class="ot">&lt;-</span> housing_test<span class="sc">$</span>Sale_Price</span>
<span id="cb54-793"><a href="#cb54-793" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-794"><a href="#cb54-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-797"><a href="#cb54-797" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-798"><a href="#cb54-798" aria-hidden="true" tabindex="-1"></a>blueprint <span class="ot">&lt;-</span> <span class="fu">recipe</span>(Sale_Price <span class="sc">~</span> ., <span class="at">data =</span> housing_train) <span class="sc">%&gt;%</span></span>
<span id="cb54-799"><a href="#cb54-799" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_nzv</span>(<span class="fu">all_nominal</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb54-800"><a href="#cb54-800" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_other</span>(<span class="fu">all_nominal</span>(), <span class="at">threshold =</span> .<span class="dv">01</span>, <span class="at">other =</span> <span class="st">"other"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb54-801"><a href="#cb54-801" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_integer</span>(<span class="fu">matches</span>(<span class="st">"(Qual|Cond|QC|Qu)$"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb54-802"><a href="#cb54-802" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_YeoJohnson</span>(<span class="fu">all_numeric</span>(), <span class="sc">-</span><span class="fu">all_outcomes</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb54-803"><a href="#cb54-803" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_center</span>(<span class="fu">all_numeric</span>(), <span class="sc">-</span><span class="fu">all_outcomes</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb54-804"><a href="#cb54-804" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_scale</span>(<span class="fu">all_numeric</span>(), <span class="sc">-</span><span class="fu">all_outcomes</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb54-805"><a href="#cb54-805" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_dummy</span>(<span class="fu">all_nominal</span>(), <span class="sc">-</span><span class="fu">all_outcomes</span>(), <span class="at">one_hot =</span> <span class="cn">TRUE</span>)</span>
<span id="cb54-806"><a href="#cb54-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-807"><a href="#cb54-807" aria-hidden="true" tabindex="-1"></a>prepare <span class="ot">&lt;-</span> <span class="fu">prep</span>(blueprint, <span class="at">training =</span> housing_train)</span>
<span id="cb54-808"><a href="#cb54-808" aria-hidden="true" tabindex="-1"></a>prepare</span>
<span id="cb54-809"><a href="#cb54-809" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-810"><a href="#cb54-810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-813"><a href="#cb54-813" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-814"><a href="#cb54-814" aria-hidden="true" tabindex="-1"></a>baked_train <span class="ot">&lt;-</span> <span class="fu">bake</span>(prepare, <span class="at">new_data =</span> housing_train)</span>
<span id="cb54-815"><a href="#cb54-815" aria-hidden="true" tabindex="-1"></a>baked_test <span class="ot">&lt;-</span> <span class="fu">bake</span>(prepare, <span class="at">new_data =</span> housing_test)</span>
<span id="cb54-816"><a href="#cb54-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-817"><a href="#cb54-817" aria-hidden="true" tabindex="-1"></a>baked_train</span>
<span id="cb54-818"><a href="#cb54-818" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-819"><a href="#cb54-819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-820"><a href="#cb54-820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-821"><a href="#cb54-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-824"><a href="#cb54-824" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-825"><a href="#cb54-825" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb54-826"><a href="#cb54-826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-827"><a href="#cb54-827" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the data for glmnet (which requires matrices)</span></span>
<span id="cb54-828"><a href="#cb54-828" aria-hidden="true" tabindex="-1"></a>x_train_glmnet <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(baked_train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Sale_Price))</span>
<span id="cb54-829"><a href="#cb54-829" aria-hidden="true" tabindex="-1"></a>y_train_glmnet <span class="ot">&lt;-</span> <span class="fu">log10</span>(baked_train<span class="sc">$</span>Sale_Price)</span>
<span id="cb54-830"><a href="#cb54-830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-831"><a href="#cb54-831" aria-hidden="true" tabindex="-1"></a>x_test_glmnet <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(baked_test <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Sale_Price))</span>
<span id="cb54-832"><a href="#cb54-832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-833"><a href="#cb54-833" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a Ridge Regression model</span></span>
<span id="cb54-834"><a href="#cb54-834" aria-hidden="true" tabindex="-1"></a>ridge_model <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x_train_glmnet, y_train_glmnet, <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb54-835"><a href="#cb54-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-836"><a href="#cb54-836" aria-hidden="true" tabindex="-1"></a><span class="co"># Use cross-validation to find the optimal lambda</span></span>
<span id="cb54-837"><a href="#cb54-837" aria-hidden="true" tabindex="-1"></a>cv_ridge <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(x_train_glmnet, y_train_glmnet, <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb54-838"><a href="#cb54-838" aria-hidden="true" tabindex="-1"></a>best_lambda <span class="ot">&lt;-</span> cv_ridge<span class="sc">$</span>lambda.min</span>
<span id="cb54-839"><a href="#cb54-839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-840"><a href="#cb54-840" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on the test set using the best lambda</span></span>
<span id="cb54-841"><a href="#cb54-841" aria-hidden="true" tabindex="-1"></a>ridge_preds_log <span class="ot">&lt;-</span> <span class="fu">predict</span>(cv_ridge, <span class="at">s =</span> best_lambda, <span class="at">newx =</span> x_test_glmnet)</span>
<span id="cb54-842"><a href="#cb54-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-843"><a href="#cb54-843" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert predictions back from log scale</span></span>
<span id="cb54-844"><a href="#cb54-844" aria-hidden="true" tabindex="-1"></a>ridge_preds <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="dv">10</span><span class="sc">^</span>ridge_preds_log)</span>
<span id="cb54-845"><a href="#cb54-845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-846"><a href="#cb54-846" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the performance</span></span>
<span id="cb54-847"><a href="#cb54-847" aria-hidden="true" tabindex="-1"></a><span class="fu">mae_vec</span>(</span>
<span id="cb54-848"><a href="#cb54-848" aria-hidden="true" tabindex="-1"></a>  <span class="at">truth =</span> housing_test_y, </span>
<span id="cb54-849"><a href="#cb54-849" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> ridge_preds</span>
<span id="cb54-850"><a href="#cb54-850" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb54-851"><a href="#cb54-851" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-852"><a href="#cb54-852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-853"><a href="#cb54-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-856"><a href="#cb54-856" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-857"><a href="#cb54-857" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb54-858"><a href="#cb54-858" aria-hidden="true" tabindex="-1"></a>x_train <span class="ot">&lt;-</span> <span class="fu">select</span>(baked_train, <span class="sc">-</span>Sale_Price) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb54-859"><a href="#cb54-859" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">&lt;-</span> baked_train <span class="sc">%&gt;%</span> <span class="fu">pull</span>(Sale_Price)</span>
<span id="cb54-860"><a href="#cb54-860" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-861"><a href="#cb54-861" aria-hidden="true" tabindex="-1"></a>x_test <span class="ot">&lt;-</span> <span class="fu">select</span>(baked_test, <span class="sc">-</span>Sale_Price) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb54-862"><a href="#cb54-862" aria-hidden="true" tabindex="-1"></a>y_test <span class="ot">&lt;-</span> baked_test <span class="sc">%&gt;%</span> <span class="fu">pull</span>(Sale_Price)</span>
<span id="cb54-863"><a href="#cb54-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-864"><a href="#cb54-864" aria-hidden="true" tabindex="-1"></a>network <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb54-865"><a href="#cb54-865" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">512</span>, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">input_shape =</span> <span class="fu">ncol</span>(x_train)) <span class="sc">%&gt;%</span></span>
<span id="cb54-866"><a href="#cb54-866" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">512</span>, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb54-867"><a href="#cb54-867" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">512</span>, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb54-868"><a href="#cb54-868" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">512</span>, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb54-869"><a href="#cb54-869" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">512</span>, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb54-870"><a href="#cb54-870" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">1</span>)</span>
<span id="cb54-871"><a href="#cb54-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-872"><a href="#cb54-872" aria-hidden="true" tabindex="-1"></a>network <span class="sc">%&gt;%</span></span>
<span id="cb54-873"><a href="#cb54-873" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(</span>
<span id="cb54-874"><a href="#cb54-874" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_rmsprop</span>(<span class="at">learning_rate =</span> <span class="fl">0.01</span>),</span>
<span id="cb54-875"><a href="#cb54-875" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> <span class="st">"msle"</span>,</span>
<span id="cb54-876"><a href="#cb54-876" aria-hidden="true" tabindex="-1"></a>    <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">"mae"</span>)</span>
<span id="cb54-877"><a href="#cb54-877" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb54-878"><a href="#cb54-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-879"><a href="#cb54-879" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb54-880"><a href="#cb54-880" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-881"><a href="#cb54-881" aria-hidden="true" tabindex="-1"></a>history <span class="ot">&lt;-</span> network <span class="sc">%&gt;%</span> <span class="fu">fit</span>(</span>
<span id="cb54-882"><a href="#cb54-882" aria-hidden="true" tabindex="-1"></a>  x_train,</span>
<span id="cb54-883"><a href="#cb54-883" aria-hidden="true" tabindex="-1"></a>  y_train,</span>
<span id="cb54-884"><a href="#cb54-884" aria-hidden="true" tabindex="-1"></a>  <span class="at">epochs =</span> <span class="dv">30</span>,</span>
<span id="cb54-885"><a href="#cb54-885" aria-hidden="true" tabindex="-1"></a>  <span class="at">batch_size =</span> <span class="dv">32</span>,</span>
<span id="cb54-886"><a href="#cb54-886" aria-hidden="true" tabindex="-1"></a>  <span class="at">validation_split =</span> <span class="fl">0.2</span>,</span>
<span id="cb54-887"><a href="#cb54-887" aria-hidden="true" tabindex="-1"></a>  <span class="at">callbacks =</span> <span class="fu">list</span>(</span>
<span id="cb54-888"><a href="#cb54-888" aria-hidden="true" tabindex="-1"></a>        <span class="fu">callback_early_stopping</span>(<span class="at">patience =</span> <span class="dv">10</span>, <span class="at">restore_best_weights =</span> <span class="cn">TRUE</span>),</span>
<span id="cb54-889"><a href="#cb54-889" aria-hidden="true" tabindex="-1"></a>        <span class="fu">callback_reduce_lr_on_plateau</span>(<span class="at">factor =</span> <span class="fl">0.2</span>, <span class="at">patience =</span> <span class="dv">4</span>)</span>
<span id="cb54-890"><a href="#cb54-890" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb54-891"><a href="#cb54-891" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb54-892"><a href="#cb54-892" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-893"><a href="#cb54-893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-896"><a href="#cb54-896" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-897"><a href="#cb54-897" aria-hidden="true" tabindex="-1"></a>history</span>
<span id="cb54-898"><a href="#cb54-898" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb54-899"><a href="#cb54-899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-902"><a href="#cb54-902" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb54-903"><a href="#cb54-903" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(history) <span class="sc">+</span> </span>
<span id="cb54-904"><a href="#cb54-904" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_log10</span>() <span class="sc">+</span></span>
<span id="cb54-905"><a href="#cb54-905" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_cowplot</span>() <span class="sc">+</span></span>
<span id="cb54-906"><a href="#cb54-906" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)</span>
<span id="cb54-907"><a href="#cb54-907" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="In die Zwischenablage kopieren" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>