<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="de" xml:lang="de"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="description" content="Kausalanalyse und Maschinelles Lernen mit R (KMLR) ist ein innovatives Online-Lehrbuch, das Studierende der Wirtschaftswissenschaften in moderne statistische Methoden und deren ökonometrische Anwendungen einführt. Das interaktive Kompendium für quantitative Lehrveranstaltungen verbindet theoretische Grundlagen mit praktischer Anwendung durch die Möglichkeit, R-Code direkt im Browser auszuführen. Von den statistischen Grundlagen über fortgeschrittene Methoden der Kausalanalyse bis hin zu Machine Learning-Techniken bietet das Buch einen umfassenden Einblick in fortschrittliche quantitative Forschungsmethoden. Besonders wertvoll für Studierende sind die zahlreichen interaktiven Visualisierungen und praxisnahen Fallstudien mit wirtschaftswissenschaftlichem Fokus, die ein tiefes Verständnis der ökonometrischen Methoden fördern und Kompetenzen in reproduzierbarer Forschung mit dem R-Ökosystem vermitteln.">
<title>4&nbsp; Regression – Kausalanalyse und maschinelles Lernen mit R</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Simulation.html" rel="next">
<link href="./RR.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/live-runtime/live-runtime.js" type="module"></script>
<link href="site_libs/quarto-contrib/live-runtime/live-runtime.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Keine Treffer",
    "search-matching-documents-text": "Treffer",
    "search-copy-link-title": "Link in die Suche kopieren",
    "search-hide-matches-text": "Zusätzliche Treffer verbergen",
    "search-more-match-text": "weitere Treffer in diesem Dokument",
    "search-more-matches-text": "weitere Treffer in diesem Dokument",
    "search-clear-button-title": "Zurücksetzen",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Abbrechen",
    "search-submit-button-title": "Abschicken",
    "search-label": "Suchen"
  }
}</script><script type="module" src="site_libs/quarto-ojs/quarto-ojs-runtime.js"></script><link href="site_libs/quarto-ojs/quarto-ojs.css" rel="stylesheet">
<script>
  MathJax = {
    tex: {
      tags: 'ams'  // should be 'ams', 'none', or 'all'
    }
  };
</script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.js" integrity="sha512-aoZChv+8imY/U1O7KIHXvO87EOzCuKO0GhFtpD6G2Cyjo/xPeTgdf3/bchB10iB+AojMTDkMHDPLKNxPJVqDcw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css">
<style>

  .panel-tabset .tab-content {
    border: 0;
    padding: 1em 0 0 0;
  }
  
  .panel-tabset .nav-item a {
    border-radius: 5px 5px 0 0;
  }
  
  .scientific_borders {
    border: 0;
    border-top: 2px solid black !important; 
    border-bottom: 2px solid black !important;
  }
  .table:not(.gt_table) > :not(caption)>*>* {
    border-bottom-width: 0;
  }
  .table:not(.gt_table) > thead {
    border-bottom: 1px solid black;
  }
  .soft-box-shadow {
    border: 1px solid rgba(233,236,239,.9) !important;
    border-radius: .5rem !important;
    background-color: rgba(250,250,250,.9) !important;
    box-shadow: 0px 1px 2px rgba(0,0,0,.1),
                0px 3px 7px rgba(0,0,0,.1),
                0px 12px 30px rgba(0,0,0,.08);
    margin-top: 2rem !important;
    margin-bottom: 2.5rem !important;
    padding: .25rem !important;
  }
  .obs-soft-box-shadow {
    border: 1px solid rgba(233,236,239,.9) !important;
    border-radius: .5rem !important;
    background-color: white !important;
    box-shadow: 0px 1px 2px rgba(0,0,0,.1),
                0px 3px 7px rgba(0,0,0,.1),
                0px 12px 30px rgba(0,0,0,.08);
    margin-top: 2rem !important;
    margin-bottom: 2.5rem !important;
    padding: .25rem !important;
  }
  
</style>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    
    var gt_tables = document.querySelectorAll(".gt_table");
    gt_tables.forEach(function(table) {
      table.classList.remove("table-striped");
    });
    
    var tables = document.querySelectorAll("table.table:not(.gt_table)");
    tables.forEach(function(table) {
      table.classList.remove("table-striped");
      table.classList.add("scientific_borders");
    });
    
    document.querySelectorAll("div.sourceCode").forEach(function(block) {
      block.classList.add("soft-box-shadow");
    });
    
    document.querySelectorAll("div.bg-white").forEach(function(block) {
      block.classList.remove("bg-white");
    });
    
const elements = document.querySelectorAll('[id^="qwebr-interactive-area"]');

    elements.forEach(element => {
        element.classList.add('box-shadow');
    });
    
    document.querySelectorAll('[id^="webr"]').forEach(function(block) {
      block.classList.add("box-shadow");
    });
    
        document.querySelectorAll('.card-header').forEach(function(block) {
      block.classList.add("box-shadow");
    });
    
  });
</script><style>
.qwebr-code-output-stdout {background-color: powderblue;}

.qwebr-button-run {
 width = 100%; 
}

.centered-caption {
   text-align: center;
}
</style>
<script src="https://cdn.jsdelivr.net/npm/quizdown@latest/public/build/quizdown.js"></script><script>quizdown.init();</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script><link rel="stylesheet" href="custom_styles.css">
<meta name="twitter:title" content="4&nbsp; Regression – Kausalanalyse und maschinelles Lernen mit R">
<meta name="twitter:description" content="Kausalanalyse und Maschinelles Lernen mit R (KMLR) ist ein innovatives Online-Lehrbuch, das Studierende der Wirtschaftswissenschaften in moderne statistische Methoden und deren ökonometrische Anwendungen einführt. Das interaktive Kompendium für quantitative Lehrveranstaltungen verbindet theoretische Grundlagen mit praktischer Anwendung durch die Möglichkeit, R-Code direkt im Browser auszuführen. Von den statistischen Grundlagen über fortgeschrittene Methoden der Kausalanalyse bis hin zu Machine Learning-Techniken bietet das Buch einen umfassenden Einblick in fortschrittliche quantitative Forschungsmethoden. Besonders wertvoll für Studierende sind die zahlreichen interaktiven Visualisierungen und praxisnahen Fallstudien mit wirtschaftswissenschaftlichem Fokus, die ein tiefes Verständnis der ökonometrischen Methoden fördern und Kompetenzen in reproduzierbarer Forschung mit dem R-Ökosystem vermitteln.">
<meta name="twitter:card" content="summary">
<meta name="citation_title" content="[[4]{.chapter-number}&nbsp; [Regression]{.chapter-title}]{#sec-regression .quarto-section-identifier}">
<meta name="citation_language" content="de">
<meta name="citation_reference" content="citation_title=The credibility revolution in empirical economics: How better research design is taking the con out of econometrics;,citation_author=Joshua D Angrist;,citation_author=Jörn-Steffen Pischke;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=2;,citation_volume=24;,citation_journal_title=Journal of economic perspectives;,citation_publisher=American Economic Association;">
<meta name="citation_reference" content="citation_title=A new data set of educational attainment in the world, 1950–2010;,citation_author=Robert J. Barro;,citation_author=Jong Wha Lee;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S0304387812000855;,citation_doi=https://doi.org/10.1016/j.jdeveco.2012.10.001;,citation_issn=0304-3878;,citation_volume=104;,citation_journal_title=Journal of Development Economics;">
<meta name="citation_reference" content="citation_title=Beyond work ethic: Religion, individual, and political preferences;,citation_author=Christoph Basten;,citation_author=Frank Betz;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=3;,citation_volume=5;,citation_journal_title=American Economic Journal: Economic Policy;,citation_publisher=American Economic Association;">
<meta name="citation_reference" content="citation_title=The effect of alcohol consumption on mortality: Regression discontinuity evidence from the minimum drinking age;,citation_author=Christopher Carpenter;,citation_author=Carlos Dobkin;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=1;,citation_volume=1;,citation_journal_title=American Economic Journal: Applied Economics;,citation_publisher=American Economic Association;">
<meta name="citation_reference" content="citation_title=Optimal bandwidth choice for the regression discontinuity estimator;,citation_author=Guido Imbens;,citation_author=Karthik Kalyanaraman;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=3;,citation_volume=79;,citation_journal_title=The Review of economic studies;,citation_publisher=Oxford University Press;">
<meta name="citation_reference" content="citation_title=Regression discontinuity designs: A guide to practice;,citation_author=G. W. Imbens;,citation_author=Thomas Lemieux;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=2;,citation_volume=142;,citation_journal_title=Journal of econometrics;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Why high-order polynomials should not be used in regression discontinuity designs;,citation_author=Andrew Gelman;,citation_author=Guido Imbens;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=3;,citation_volume=37;,citation_journal_title=Journal of Business &amp;amp;amp; Economic Statistics;,citation_publisher=Taylor &amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Randomized experiments from non-random selection in US house elections;,citation_author=David S Lee;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=2;,citation_volume=142;,citation_journal_title=Journal of Econometrics;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Die protestantische ethik und der geist des kapitalismus;,citation_author=Max Weber;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_volume=1614;">
<meta name="citation_reference" content="citation_title=Regularization and confounding in linear regression for treatment effect estimation;,citation_author=P Richard Hahn;,citation_author=Carlos M Carvalho;,citation_author=David Puelz;,citation_author=Jingyu He;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Regression shrinkage and selection via the lasso;,citation_author=Robert Tibshirani;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_issue=1;,citation_volume=58;,citation_journal_title=Journal of the Royal Statistical Society Series B: Statistical Methodology;,citation_publisher=Oxford University Press;">
<meta name="citation_reference" content="citation_title=Least angle regression;,citation_author=Bradley Efron;,citation_author=Trevor Hastie;,citation_author=Iain Johnstone;,citation_author=Robert Tibshirani;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;">
<meta name="citation_reference" content="citation_title=Sparse models and methods for optimal instruments with an application to eminent domain;,citation_author=Alexandre Belloni;,citation_author=Daniel Chen;,citation_author=Victor Chernozhukov;,citation_author=Christian Hansen;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=6;,citation_volume=80;,citation_journal_title=Econometrica;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Least squares after model selection in high-dimensional sparse models;,citation_author=Alexandre Belloni;,citation_author=Victor Chernozhukov;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_journal_title=Bernoulli;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=High-dimensional methods and inference on structural and treatment effects;,citation_author=Alexandre Belloni;,citation_author=Victor Chernozhukov;,citation_author=Christian Hansen;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=2;,citation_volume=28;,citation_journal_title=Journal of Economic Perspectives;,citation_publisher=American Economic Association 2014 Broadway, Suite 305, Nashville, TN 37203-2418;">
<meta name="citation_reference" content="citation_title=Ridge regression: Biased estimation for nonorthogonal problems;,citation_author=Arthur E Hoerl;,citation_author=Robert W Kennard;,citation_publication_date=1970;,citation_cover_date=1970;,citation_year=1970;,citation_issue=1;,citation_volume=12;,citation_journal_title=Technometrics;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Using data mining to predict secondary school student performance;,citation_author=Paulo Cortez;,citation_author=Alice Maria Gonçalves Silva;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_publisher=EUROSIS-ETI;">
<meta name="citation_reference" content="citation_title=Manipulation of the running variable in the regression discontinuity design: A density test;,citation_author=Justin McCrary;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=2;,citation_volume=142;,citation_journal_title=Journal of Econometrics;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Simple local polynomial density estimators;,citation_author=Matias D Cattaneo;,citation_author=Michael Jansson;,citation_author=Xinwei Ma;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=531;,citation_volume=115;,citation_journal_title=Journal of the American Statistical Association;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=An introduction to propensity score methods for reducing the effects of confounding in observational studies;,citation_author=P. Austin;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=3;,citation_doi=10.1080/00273171.2011.568786;,citation_issn=0027-3171;,citation_pmid=21818162;,citation_volume=46;,citation_journal_title=Multivariate Behavioral Research;,citation_publisher=Informa UK Limited;">
<meta name="citation_reference" content="citation_title=The central role of the propensity score in observational studies for causal effects;,citation_author=Paul R. Rosenbaum;,citation_author=Donald R. Rubin;,citation_publication_date=1983;,citation_cover_date=1983;,citation_year=1983;,citation_issue=1;,citation_doi=10.1017/cbo9780511810725.016;,citation_issn=0006-3444;,citation_volume=70;,citation_journal_title=Biometrika;,citation_publisher=Cambridge University Press;">
<meta name="citation_reference" content="citation_title=Efficient estimation of average treatment effects using the estimated propensity score.;,citation_author=Keisuke Hirano;,citation_author=Guido Imbens;,citation_author=Geert Ridder;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=4;,citation_doi=10.1111/1468-0262.00442;,citation_volume=71;,citation_journal_title=Econometrica;,citation_publisher=The Econometric Society;">
<meta name="citation_reference" content="citation_title=Comment on “an essay on the logical foundations of survey sampling” by basu, d;,citation_author=J Hájek;,citation_publication_date=1971;,citation_cover_date=1971;,citation_year=1971;,citation_volume=236;,citation_journal_title=Foundations of Statistical Inference;">
<meta name="citation_reference" content="citation_title=Graphical display of covariate balance;,citation_author=Thomas Love;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_publisher=Presentation;">
<meta name="citation_reference" content="citation_title=The use of bootstrapping when using propensity-score matching without replacement: A simulation study.;,citation_author=Peter C. Austin;,citation_author=Dylan S. Small;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=24;,citation_doi=10.1002/sim.6276;,citation_issn=0277-6715;,citation_volume=33;,citation_journal_title=Statistics in Medicine;,citation_publisher=Wiley;">
<meta name="citation_reference" content="citation_title=Robust post-matching inference.;,citation_author=Alberto Abadie;,citation_author=Jann Spiess;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issue=538;,citation_doi=10.1080/01621459.2020.1840383;,citation_issn=0162-1459;,citation_volume=117;,citation_journal_title=Journal of the American Statistical Association;,citation_publisher=Informa UK Limited;">
<meta name="citation_reference" content="citation_title=Matching on the estimated propensity score.;,citation_author=undefined Imbens;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=2;,citation_doi=10.3982/ecta11293;,citation_issn=0012-9682;,citation_volume=84;,citation_journal_title=Econometrica;,citation_publisher=The Econometric Society;">
<meta name="citation_reference" content="citation_title=The finite sample performance of inference methods for propensity score matching and weighting estimators.;,citation_author=Hugo Bodory;,citation_author=Lorenzo Camponovo;,citation_author=Martin Huber;,citation_author=Michael Lechner;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_doi=10.2139/ssrn.2731969;,citation_issn=1556-5068;,citation_journal_title=Journal of Business &amp;amp;amp; Economic Statistics;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Interval estimation for treatment effects using propensity score matching. Statistics in medicine;,citation_author=Jennifer Hill;,citation_author=Jerome P. Reiter;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=13;,citation_doi=10.1002/sim.2277;,citation_issn=0277-6715;,citation_volume=25;,citation_journal_title=Statistics in Medicine;,citation_publisher=Wiley;">
<meta name="citation_reference" content="citation_title=On the failure of the bootstrap for matching estimators.;,citation_author=Alberto Abadie;,citation_author=Guido W. Imbens;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=6;,citation_doi=10.3982/ECTA6474;,citation_issn=0012-9682,1468-0262;,citation_volume=76;,citation_journal_title=Econometrica. Journal of the Econometric Society;">
<meta name="citation_reference" content="citation_title=Estimating the effect of treatment on binary outcomes using full matching on the propensity score.;,citation_author=Peter C. Austin;,citation_author=Elizabeth A. Stuart;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=6;,citation_doi=10.1177/0962280215601134;,citation_issn=0962-2802,1477-0334;,citation_volume=26;,citation_journal_title=Statistical Methods in Medical Research;">
<meta name="citation_reference" content="citation_title=Entropy balancing for causal effects: A multivariate reweighting method to produce balanced samples in observational studies;,citation_author=Jens Hainmueller;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_doi=10.1093/pan/mpr025;,citation_issn=1047-1987;,citation_volume=20;,citation_journal_title=Political Analysis;,citation_publisher=Cambridge University Press (CUP);">
<meta name="citation_reference" content="citation_title=Econometric analysis of cross section and panel data;,citation_author=Jeffrey Wooldridge;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_isbn=9780262232586;">
<meta name="citation_reference" content="citation_title=Statistical inference;,citation_author=George Casella;,citation_author=Roger L. Berger;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_isbn=9780534243128;">
<meta name="citation_reference" content="citation_title=Synthetic control methods for comparative case studies: Estimating the effect of california’s tobacco control program.;,citation_author=Alexis Diamond Abadie;,citation_author=Jens Hainmueller;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=490;,citation_doi=10.1198/jasa.2009.ap08746;,citation_volume=105;,citation_journal_title=Journal of the American Statistical Association;,citation_publisher=Informa UK Limited;">
<meta name="citation_reference" content="citation_title=Comparative politics and the synthetic control method: COMPARATIVE POLITICS AND THE SYNTHETIC CONTROL METHOD;,citation_author=Alberto Abadie;,citation_author=Alexis Diamond;,citation_author=Jens Hainmueller;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=2;,citation_doi=10.1111/ajps.12116;,citation_volume=59;,citation_journal_title=American Journal of Political Science;,citation_publisher=Wiley;">
<meta name="citation_reference" content="citation_title=The costs of economic nationalism: Evidence from the brexit experiment*;,citation_author=Benjamin Born;,citation_author=Gernot J Müller;,citation_author=Moritz Schularick;,citation_author=Petr Sedláček;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=623;,citation_doi=10.1093/ej/uez020;,citation_volume=129;,citation_journal_title=The Economic Journal;,citation_publisher=Oxford University Press (OUP);">
<meta name="citation_reference" content="citation_title=End-of-sample instability tests;,citation_author=D. W. K. Andrews;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=6;,citation_doi=10.1111/1468-0262.00466;,citation_volume=71;,citation_journal_title=Econometrica;,citation_publisher=The Econometric Society;">
<meta name="citation_reference" content="citation_title=The effects of the 1993 earned income tax credit expansion on the labor supply of unmarried women;,citation_author=Kampon Adireksombat;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=1;,citation_doi=https://doi.org/10.1177/1091142109358626;,citation_issn=1552-7530;,citation_volume=38;,citation_journal_title=Public Finance Review;,citation_publisher=SAGE Publications;">
<meta name="citation_reference" content="citation_title=Labor supply response to the earned income tax credit;,citation_author=N. Eissa;,citation_author=J. B. Liebman;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_issue=2;,citation_doi=10.2307/2946689;,citation_issn=1531-4650;,citation_volume=111;,citation_journal_title=The Quarterly Journal of Economics;,citation_publisher=Oxford University Press (OUP);">
<meta name="citation_reference" content="citation_title=Difference-in-differences with multiple time periods.;,citation_author=Brantly Callaway;,citation_author=Pedro H. C. Sant’Anna;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=2;,citation_doi=10.1016/j.jeconom.2020.12.001;,citation_volume=225;,citation_journal_title=Journal of Econometrics;">
<meta name="citation_reference" content="citation_title=Difference-in-differences with variation in treatment timing.;,citation_author=Andrew Goodman-Bacon;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=2;,citation_doi=10.1016/j.jeconom.2021.03.014;,citation_volume=225;,citation_journal_title=Journal of Econometrics;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Do police reduce crime? Estimates using the allocation of police forces after a terrorist attack;,citation_author=Rafael Di Tella;,citation_author=Ernesto Schargrodsky;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=1;,citation_doi=10.1257/000282804322970733;,citation_volume=94;,citation_journal_title=American Economic Review;,citation_publisher=American Economic Association;">
<meta name="citation_reference" content="citation_title=Economic shocks and civil conflict: An instrumental variables approach;,citation_author=Edward Miguel;,citation_author=Shanker Satyanath;,citation_author=Ernest Sergenti;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=4;,citation_doi=10.1086/421174;,citation_volume=112;,citation_journal_title=Journal of Political Economy;,citation_publisher=University of Chicago Press;">
<meta name="citation_reference" content="citation_title=Ethnicity, insurgency, and civil war.;,citation_author=undefined Fearon;,citation_author=David D. Laitin;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=01;,citation_doi=10.1017/s0003055403000534;,citation_volume=97;,citation_journal_title=American Political Science Review;,citation_publisher=Cambridge University Press (CUP);">
<meta name="citation_reference" content="citation_title=Weak states: Causes and consequences of the sicilian mafia;,citation_author=Daron Acemoglu;,citation_author=Giuseppe De Feo;,citation_author=Giacomo Davide De Luca;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_doi=10.1093/restud/rdz009;,citation_journal_title=The Review of Economic Studies;,citation_publisher=Oxford University Press (OUP);">
<meta name="citation_reference" content="citation_title=Income and democracy;,citation_author=Daron Acemoglu;,citation_author=Simon Johnson;,citation_author=James A. Robinson;,citation_author=Pierre Yared;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=3;,citation_doi=10.1257/aer.98.3.808;,citation_volume=98;,citation_journal_title=American Economic Review;,citation_publisher=American Economic Association;">
<meta name="citation_reference" content="citation_title=Polyarchy: Participation and opposition: Participation and opposition;,citation_author=Robert Alan Dahl;,citation_publication_date=1971;,citation_cover_date=1971;,citation_year=1971;,citation_isbn=0300015658;">
<meta name="citation_reference" content="citation_title=The third wave: Democratization in the late twentieth century: Democratization in the late twentieth century;,citation_author=Samuel P. Huntington;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_isbn=0-8061-2516-0;">
<meta name="citation_reference" content="citation_title=Capitalist development and democracy;,citation_author=Dietrich Rueschemeyer;,citation_author=Evelyne H. Stephens;,citation_author=John D. Stephens;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_isbn=074560398X;">
<meta name="citation_reference" content="citation_title=The effect: An introduction to research design and causality;,citation_author=Nick Huntington-Klein;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_doi=10.1201/9781003226055;,citation_isbn=9781003226055;">
<meta name="citation_reference" content="citation_title=Synth: An r package for synthetic control methods in comparative case studies;,citation_author=Jens Hainmueller;,citation_author=Alexis Diamond;,citation_author=Alberto Abadie;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=https://www.jstatsoft.org/v42/i13/;,citation_issue=13;,citation_volume=42;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=Replication data for: Income and democracy;,citation_author=Daron Acemoglu;,citation_author=Simon Johnson;,citation_author=James A. Robinson;,citation_author=Pierre Yared;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_doi=10.3886/E113251V1;,citation_publisher=ICPSR - Interuniversity Consortium for Political; Social Research;">
<meta name="citation_reference" content="citation_title=Biases in dynamic models with fixed effects;,citation_author=Stephen Nickell;,citation_publication_date=1981;,citation_cover_date=1981;,citation_year=1981;,citation_issue=6;,citation_doi=10.2307/1911408;,citation_volume=49;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Mostly harmless econometrics: An empiricist’s companion;,citation_author=J. Angrist;,citation_author=Jörn-Steffen Pischke;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_isbn=9780691120355;">
<meta name="citation_reference" content="citation_title=Some tests of specification for panel data: Monte carlo evidence and an application to employment equations;,citation_author=Manuel Arellano;,citation_author=Stephen Bond;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_issue=2;,citation_doi=10.2307/2297968;,citation_volume=58;,citation_journal_title=The Review of Economic Studies;,citation_publisher=Oxford University Press (OUP);">
<meta name="citation_reference" content="citation_title=Estimation of dynamic models with error components;,citation_author=T. W. Anderson;,citation_author=Cheng Hsiao;,citation_publication_date=1981;,citation_cover_date=1981;,citation_year=1981;,citation_issue=375;,citation_doi=10.2307/2287517;,citation_volume=76;,citation_journal_title=Journal of the American Statistical Association;,citation_publisher=Informa UK Limited;">
<meta name="citation_reference" content="citation_title=The estimation of economic relationships using instrumental variables;,citation_author=J. D. Sargan;,citation_publication_date=1958;,citation_cover_date=1958;,citation_year=1958;,citation_issue=3;,citation_doi=10.2307/1907619;,citation_volume=26;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Large sample properties of generalized method of moments estimators;,citation_author=Lars Peter Hansen;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;,citation_issue=4;,citation_doi=10.2307/1912775;,citation_volume=50;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Bootstrap procedures under some non-i.i.d. models;,citation_author=Regina Y. Liu;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;,citation_issue=4;,citation_doi=10.1214/aos/1176351062;,citation_volume=16;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Bootstrap-based improvements for inference with clustered errors;,citation_author=A. Colin Cameron;,citation_author=Jonah B. Gelbach;,citation_author=Douglas L. Miller;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=3;,citation_doi=10.1162/rest.90.3.414;,citation_volume=90;,citation_journal_title=Review of Economics and Statistics;,citation_publisher=MIT Press - Journals;">
<meta name="citation_reference" content="citation_title=Robust inference with multiway clustering;,citation_author=A. Colin Cameron;,citation_author=Jonah B. Gelbach;,citation_author=Douglas L. Miller;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=2;,citation_doi=10.1198/jbes.2010.07136;,citation_volume=29;,citation_journal_title=Journal of Business &amp;amp;amp;amp; Economic Statistics;,citation_publisher=Informa UK Limited;">
<meta name="citation_reference" content="citation_title=La Mafia E I Mafiosi;,citation_author=Antonino Cutrera;,citation_publication_date=1900;,citation_cover_date=1900;,citation_year=1900;">
<meta name="citation_reference" content="citation_title=Estimating the deterrent effect of incarceration using sentencing enhancements;,citation_author=David S Abrams;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=4;,citation_doi=10.1257/app.4.4.32;,citation_volume=4;,citation_journal_title=American Economic Journal: Applied Economics;,citation_publisher=American Economic Association;">
<meta name="citation_reference" content="citation_title=Replication data for: Estimating the deterrent effect of incarceration using sentencing enhancements;,citation_author=David S. Abrams;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_doi=10.3886/E113838V1;,citation_publisher=ICPSR - Interuniversity Consortium for Political; Social Research;">
<meta name="citation_reference" content="citation_title=Earnings losses of displaced workers;,citation_author=Louis S. Jacobson;,citation_author=Robert J. LaLonde;,citation_author=Daniel G. Sullivan;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;,citation_fulltext_html_url=http://www.jstor.org/stable/2117574;,citation_issue=4;,citation_volume=83;,citation_journal_title=The American Economic Review;,citation_publisher=American Economic Association;">
<meta name="citation_reference" content="citation_title=Bootstrap methods: Another look at the jackknife;,citation_author=B. Efron;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=1;,citation_doi=10.1214/aos/1176344552;,citation_volume=7;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Pattern recognition and machine learning;,citation_author=Christopher M. Bishop;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_isbn=9780387310732;,citation_series_title=Information science and statistics;">
<meta name="citation_reference" content="citation_title=Deep learning;,citation_author=Ian Goodfellow;,citation_author=Yoshua Bengio;,citation_author=Aaron Courville;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=Deep learning with r;,citation_author=Francois Chollet;,citation_author=J. J. Allaire;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_isbn=9781617295546;">
<meta name="citation_reference" content="citation_title=Classification and regression trees;,citation_author=L. Breiman;,citation_author=J. Friedman;,citation_author=C. J. Stone;,citation_author=R. A. Olshen;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_isbn=9780412048418;">
<meta name="citation_reference" content="citation_title=The elements of statistical learning: Data mining, inference, and prediction;,citation_author=T. Hastie;,citation_author=R. Tibshirani;,citation_author=J. Friedman;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_isbn=9780387216065;,citation_series_title=Springer series in statistics;">
<meta name="citation_reference" content="citation_title=ISLR: Data for an introduction to statistical learning with applications in r;,citation_author=Gareth James;,citation_author=Daniela Witten;,citation_author=Trevor Hastie;,citation_author=Rob Tibshirani;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://CRAN.R-project.org/package=ISLR;">
<meta name="citation_reference" content="citation_title=An introduction to statistical learning: With applications in r;,citation_author=Gareth James;,citation_author=Daniela Witten;,citation_author=Trevor Hastie;,citation_author=Robert Tibshirani;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_isbn=9781461471370;,citation_series_title=Springer texts in statistics;">
<meta name="citation_reference" content="citation_title=R markdown: The definitive guide: The definitive guide;,citation_author=Yihui Xie;,citation_author=J. J. Allaire;,citation_author=Garrett Grolemund;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_doi=10.1201/9781138359444;">
<meta name="citation_reference" content="citation_title=R markdown cookbook;,citation_author=Yihui Xie;,citation_author=Christophe Dervieux;,citation_author=Emily Riederer;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://bookdown.org/yihui/rmarkdown-cookbook;,citation_isbn=9780367563837;">
<meta name="citation_reference" content="citation_title=Shiny: Web application framework for r;,citation_author=Winston Chang;,citation_author=Joe Cheng;,citation_author=JJ Allaire;,citation_author=Carson Sievert;,citation_author=Barret Schloerke;,citation_author=Yihui Xie;,citation_author=Jeff Allen;,citation_author=Jonathan McPherson;,citation_author=Alan Dipert;,citation_author=Barbara Borges;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=shiny;">
<meta name="citation_reference" content="citation_title=Rmarkdown: Dynamic documents for r;,citation_author=JJ Allaire;,citation_author=Yihui Xie;,citation_author=Christophe Dervieux;,citation_author=Jonathan McPherson;,citation_author=Javier Luraschi;,citation_author=Kevin Ushey;,citation_author=Aron Atkins;,citation_author=Hadley Wickham;,citation_author=Joe Cheng;,citation_author=Winston Chang;,citation_author=Richard Iannone;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://github.com/rstudio/rmarkdown;">
<meta name="citation_reference" content="citation_title=Mastering shiny;,citation_author=H. Wickham;,citation_author=an O’Reilly Media Company Safari;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://books.google.de/books?id=ha1CzgEACAAJ;,citation_isbn=9781492047377;">
<meta name="citation_reference" content="citation_title=Recursive partitioning for heterogeneous causal effects;,citation_author=Susan Athey;,citation_author=Guido Imbens;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=27;,citation_doi=10.1073/pnas.1510489113;,citation_volume=113;,citation_journal_title=Proceedings of the National Academy of Sciences;,citation_publisher=Proceedings of the National Academy of Sciences;">
<meta name="citation_reference" content="citation_title=Grf: Generalized random forests;,citation_author=Julie Tibshirani;,citation_author=Susan Athey;,citation_author=Erik Sverdrup;,citation_author=Stefan Wager;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=grf;">
<meta name="citation_reference" content="citation_title=Statistical inference in two-sample summary-data mendelian randomization using robust adjusted profile score;,citation_author=Qingyuan Zhao;,citation_author=Jingshu Wang;,citation_author=Gibran Hemani;,citation_author=Jack Bowden;,citation_author=Dylan S. Small;,citation_publication_date=2020-06;,citation_cover_date=2020-06;,citation_year=2020;,citation_issue=3;,citation_doi=0.1214/18-AOS1709;,citation_issn=0090-5364;,citation_volume=48;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Generalized random forests;,citation_author=Susan Athey;,citation_author=Julie Tibshirani;,citation_author=Stefan Wager;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=2;,citation_doi=10.1214/18-aos1709;,citation_volume=47;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
</head>
<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="navbar navbar-expand-lg " data-bs-theme="dark"><div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Kausalanalyse und maschinelles Lernen mit R</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-wide tools-end">
    <a href="https://github.com/mca91/kasa_book" title="Quellcode" class="quarto-navigation-tool px-1" aria-label="Quellcode"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
<li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://twitter.com/intent/tweet?url=%7Curl%7C">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://www.facebook.com/sharer/sharer.php?u=%7Curl%7C">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://www.linkedin.com/sharing/share-offsite/?url=%7Curl%7C">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
</div>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Lesemodus umschalten">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          <div id="quarto-search" class="" title="Suchen"></div>
      </div> <!-- /container-fluid -->
    </nav><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Seitenleiste umschalten" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./R_Einfuehrung.html">Grundlagen</a></li><li class="breadcrumb-item"><a href="./Reg.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regression</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Seitenleiste umschalten" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Einleitung</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Grundlagen</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./R_Einfuehrung.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Statistische Programmierung mit R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./RR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Reproduzierbarkeit</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Reg.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Simulation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Simulation</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Kausale Inferenz</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Matching.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Matching</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./FixedEffects.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Panel-Daten</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./IV.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">IV-Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./DiD.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Difference-in-Differences</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./EventStudies.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Event Studies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./RDD.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Regression Discontinuity Designs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./SyntheticControl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Synthetic Control</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./RegReg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Regularisierte Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./svm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Support Vector Machines</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./trees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Baum-basierte Methoden</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Machine Learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Neuronale Netzwerke</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Literatur.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Literatur</span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title"><a href="./index.html">Übersicht</a></h2>
   
  <ul>
<li><a href="#regression-schlie%C3%9Ft-backdoors-frisch-waugh-lovell-theorem" id="toc-regression-schließt-backdoors-frisch-waugh-lovell-theorem" class="nav-link active" data-scroll-target="#regression-schlie%C3%9Ft-backdoors-frisch-waugh-lovell-theorem"><span class="header-section-number">4.1</span> Regression schließt Backdoors: Frisch-Waugh-Lovell-Theorem</a></li>
  <li>
<a href="#sec-bov" id="toc-sec-bov" class="nav-link" data-scroll-target="#sec-bov"><span class="header-section-number">4.2</span> Binäre Outcome-Variable</a>
  <ul>
<li><a href="#sec-lpm" id="toc-sec-lpm" class="nav-link" data-scroll-target="#sec-lpm"><span class="header-section-number">4.2.1</span> Das lineare Wahrscheinlichkeitsmodell</a></li>
  <li>
<a href="#sec-probitreg" id="toc-sec-probitreg" class="nav-link" data-scroll-target="#sec-probitreg"><span class="header-section-number">4.2.2</span> Probit-Regression</a>
  <ul class="collapse">
<li><a href="#sch%C3%A4tzung" id="toc-schätzung" class="nav-link" data-scroll-target="#sch%C3%A4tzung"><span class="header-section-number">4.2.2.1</span> Schätzung</a></li>
  </ul>
</li>
  <li><a href="#sec-logreg" id="toc-sec-logreg" class="nav-link" data-scroll-target="#sec-logreg"><span class="header-section-number">4.2.3</span> Logistische Regression</a></li>
  <li><a href="#sch%C3%A4tzung-1" id="toc-schätzung-1" class="nav-link" data-scroll-target="#sch%C3%A4tzung-1"><span class="header-section-number">4.2.4</span> Schätzung</a></li>
  <li><a href="#modellg%C3%BCte" id="toc-modellgüte" class="nav-link" data-scroll-target="#modellg%C3%BCte"><span class="header-section-number">4.2.5</span> Modellgüte</a></li>
  <li><a href="#beispiel-klassifikation-von-palmer-piniguinen" id="toc-beispiel-klassifikation-von-palmer-piniguinen" class="nav-link" data-scroll-target="#beispiel-klassifikation-von-palmer-piniguinen"><span class="header-section-number">4.2.6</span> Beispiel: Klassifikation von Palmer-Piniguinen</a></li>
  </ul>
</li>
  <li>
<a href="#sec-poissonreg" id="toc-sec-poissonreg" class="nav-link" data-scroll-target="#sec-poissonreg"><span class="header-section-number">4.3</span> Modellierung von Zählvariablen</a>
  <ul>
<li><a href="#poisson-verteilung" id="toc-poisson-verteilung" class="nav-link" data-scroll-target="#poisson-verteilung"><span class="header-section-number">4.3.1</span> Poisson-Verteilung</a></li>
  <li><a href="#poisson-regression" id="toc-poisson-regression" class="nav-link" data-scroll-target="#poisson-regression"><span class="header-section-number">4.3.2</span> Poisson-Regression</a></li>
  <li><a href="#sch%C3%A4tzung-2" id="toc-schätzung-2" class="nav-link" data-scroll-target="#sch%C3%A4tzung-2"><span class="header-section-number">4.3.3</span> Schätzung</a></li>
  <li><a href="#interpretation-der-koeffizienten" id="toc-interpretation-der-koeffizienten" class="nav-link" data-scroll-target="#interpretation-der-koeffizienten"><span class="header-section-number">4.3.4</span> Interpretation der Koeffizienten</a></li>
  </ul>
</li>
  <li><a href="#zusammenfassung" id="toc-zusammenfassung" class="nav-link" data-scroll-target="#zusammenfassung"><span class="header-section-number">4.4</span> Zusammenfassung</a></li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/mca91/kasa_book/edit/main/Reg.qmd" class="toc-action"><i class="bi bi-github"></i>Seite editieren</a></li><li><a href="https://github.com/mca91/kasa_book/issues/new" class="toc-action"><i class="bi empty"></i>Problem melden</a></li><li><a href="https://github.com/mca91/kasa_book/blob/main/Reg.qmd" class="toc-action"><i class="bi empty"></i>Quellcode anzeigen</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./R_Einfuehrung.html">Grundlagen</a></li><li class="breadcrumb-item"><a href="./Reg.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regression</span></a></li></ol></nav><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-regression" class="quarto-section-identifier"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regression</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<p><i class="callout-icon"></i></p>
</div>
<div class="callout-body-container">
<p>
<strong>Hinweis</strong>
</p>
<p>
Für eine optimale technische Stabilität empfehlen wir, dieses Online-Lehrbuch auf einem Notebook oder Desktop-Computer zu nutzen. Die interaktiven Komponente, insbesondere die R-Konsole (WebR), sind rechenintensiv und funktionieren auf mobilen Geräten nur eingeschränkt.
</p>
</div>
</div>
</div>
</div>
</div><p>Viele der in diesem Companion behandelten Methoden basiert auf dem Konzept der Schätzung kausaler Effekte mit <em>Regression</em>. Als Regressionsansatz bezeichnet man eine Methode, welche die Beziehungen zwischen Variablen durch einen funktionalen Zusammenhang beschreibt und die Parameter der gewählten funktionalen Form anhand von beobachteten Daten schätzt. <em>Lineare Regression</em> nimmt eine lineare funktionale Form der Beziehung zwischen einer abhängigen Variable (Outcome-Variable) und erklärenden Variablen (Regressoren) an. <em>Nicht-lineare Regressionsmethoden</em> modellieren die Beziehung etwa durch Polynome höherer Ordnung, exponentielle Funktionen oder andere komplexere Formen. Die Wahl der funktionalen Form hängt von der Natur des datenerzeugenden Prozesses (DGP) und somit stets von der spezifischen Beziehung ab, die untersucht wird.</p>
<p>Regressionsansätze gehören zu den am häufigsten verwendeten Methoden für Kausalanalysen, da mit Regression in vielen Forschungsdesigns kausale Effekte identifiziert werden können, indem Backdoors geschlossen werden: Regression kann die durch die Behandlungsvariable verursachte Variation in der Outcome-Variable isolieren, indem für gemeinsame Einflussfaktoren von Behandlungs- <em>und</em> Outcome-Variable kontrolliert wird. In diesem Kapitel erläutern wir Erweiterungen der Spezifikation und Schätzung von Regressionsansätzen, die für spätere Kapitel relevant sind. Neben einer Motivation der Schätzung kausaler Effekte mit multipler Regression betrachten wir Modelle für verschiedene Kategorien von Outcome-Variablen und diskutieren deren Implementierung mit R.</p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.5.1     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.1
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</code></pre>
</div>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://wilkelab.org/cowplot/">cowplot</a></span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'cowplot'

The following object is masked from 'package:lubridate':

    stamp</code></pre>
</div>
</div>
<section id="regression-schließt-backdoors-frisch-waugh-lovell-theorem" class="level2 page-columns page-full" data-number="4.1"><h2 data-number="4.1" class="anchored" data-anchor-id="regression-schließt-backdoors-frisch-waugh-lovell-theorem">
<span class="header-section-number">4.1</span> Regression schließt Backdoors: Frisch-Waugh-Lovell-Theorem</h2>
<p>Das Frisch-Waugh-Lovell-Theorem (FWL) besagt, dass die geschätzten Koeffizienten für eine interessierende Teilmenge der Regressoren in einer multiplen linearen Regression numerisch identisch mit den Koeffizientenschätzungen aus folgenden Schritten sind:</p>
<ol type="1">
<li><p>Rechne die Effekte der übrigen Regressoren auf (a) die Outcome-Variable und (b) die interessierende Teilmenge der Regressoren mit Regression heraus.</p></li>
<li><p>Regressiere anschließend die Residuen von Schritt (a) auf die Residuen aus Schritt (b).</p></li>
</ol>
<p>In einem multiplen Modell mit zwei Regressoren <span class="math inline">\(X_1,\ X_2\)</span>, <span class="math display">\[\begin{align}
  Y = \beta_0 + \beta_1 X + \beta_2 X_2 + \epsilon \label{eq:fwlfullreg}
\end{align}\]</span> kann der Effekt von <span class="math inline">\(X_1\)</span> auf <span class="math inline">\(Y\)</span> also mit der Regression <span class="math display">\[\begin{align*}
  \widehat{u}_{Y,X_2} = \beta_1 \widehat{u}_{X_1,X_2} + e \label{eq:fwl2reg}
\end{align*}\]</span> geschätzt werden, wobei <span class="math inline">\(\widehat{u}_{Y,X_2}\)</span> und <span class="math inline">\(\widehat{u}_{X_1,X_2}\)</span> die Residuen der Regression von <span class="math inline">\(Y\)</span> auf <span class="math inline">\(X_2\)</span> und von <span class="math inline">\(X_1\)</span> auf <span class="math inline">\(X_2\)</span> sind.</p>
<p>FWL ermöglicht daher eine Vereinfachung der Schätzung komplexer Modelle durch die Zerlegung der Schätzung in Teilschritte.</p>
<p>Für das Verständnis der Schätzung kausaler Effekte mit linearer Regression ist FWL hilfreich, denn es zeigt, wie sowohl die Variation in der Outcome-Variable (<span class="math inline">\(\widehat{u}_{Y,X_2}\)</span>) als auch die Variation in der Behandlungsvariable (<span class="math inline">\(\widehat{u}_{X_1,X_2}\)</span>), die jeweils <em>nicht</em> durch Kovariablen (<span class="math inline">\(X_2\)</span>) verursacht wird, mit multipler Regression isoliert werden kann, sodass Backdoors geschlossen werden.</p>
<p>Wir illustrieren dieses Konzept anhand einer multiplen Regression für das Gewicht (<code>body_mass</code>) von Pinguinen aus dem Datensatz <code><a href="https://allisonhorst.github.io/palmerpenguins/reference/penguins.html">palmerpenguins::penguins</a></code>,</p>
<p><span class="math display">\[\begin{align}
  \textup{body\_mass} = \beta_0 + \beta_1\cdot\textup{bill\_length} + \beta_2\cdot \textup{flipper\_length} + \epsilon,\label{eq:billdepthmodel}
\end{align}\]</span> unter der Annahme, dass <span class="math inline">\(\beta_1\)</span> der interessierende Effekt ist: Die erwartete Änderung des Gewichts eines Pinguins (in Gramm) für eine Änderung der Schnabel-Länge um 1mm.</p>
<p>Vor der Schätzung von Modell <span class="math inline">\(\eqref{eq:billdepthmodel}\)</span> lesen wir den Datensatz ein und erstellen eine bereinigte Variante <code>penguins_cleaned</code>, analog zur Vorgehensweise in <a href="R_Einfuehrung.html#sec-pp" class="quarto-xref"><span>Kapitel 2.1.2</span></a>.</p>
<div class="cell">
<div>
<div id="webr-1">

</div>
<script type="webr-1-contents">
eyJjb2RlIjoibGlicmFyeShwYWxtZXJwZW5ndWlucylcbmRhdGEocGVuZ3VpbnMpXG5cbiMgRGF0ZW5zYXR6IGJlcmVpbmlnZW5cbnBlbmd1aW5zX2NsZWFuZWQgPC0gcGVuZ3VpbnMgJT4lIFxuICByZW5hbWUoXG4gICAgYmlsbF9kZXB0aCA9IGJpbGxfZGVwdGhfbW0sXG4gICAgYmlsbF9sZW5ndGggPSBiaWxsX2xlbmd0aF9tbSxcbiAgICBmbGlwcGVyX2xlbmd0aCA9IGZsaXBwZXJfbGVuZ3RoX21tLFxuICAgIGJvZHlfbWFzcyA9IGJvZHlfbWFzc19nXG4gICkgJT4lIFxuICBkcm9wX25hKCkgJT4lIFxuICBmaWx0ZXIoXG4gICAgYm9keV9tYXNzIDwgcXVhbnRpbGUoYm9keV9tYXNzLCAuOTUpXG4gIClcblxuIyDDnGJlcmJsaWNrXG5zbGljZV9oZWFkKHBlbmd1aW5zX2NsZWFuZWQsIG4gPSAxMCkiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWV9fQ==
</script>
</div>
</div>
<p>Wir schätzen nun Modell <span class="math inline">\(\eqref{eq:billdepthmodel}\)</span> mit <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> und erhalten eine Zusammenfassung der geschätzten Koeffizienten mit <code><a href="https://generics.r-lib.org/reference/tidy.html">broom::tidy()</a></code>.</p>
<div class="cell">
<div>
<div id="webr-2">

</div>
<script type="webr-2-contents">
eyJjb2RlIjoibGlicmFyeShicm9vbSlcblxuIyBcIkdyb8OfZXNcIiBNb2RlbGwgc2Now6R0emVuXG5sbShcbiAgZm9ybXVsYSA9IGJvZHlfbWFzcyB+IGJpbGxfbGVuZ3RoICsgZmxpcHBlcl9sZW5ndGgsIFxuICBkYXRhID0gcGVuZ3VpbnNfY2xlYW5lZFxuKSAlPiVcbiAgdGlkeSgpIiwiYXR0ciI6eyJldmFsIjp0cnVlLCJlZGl0Ijp0cnVlfX0=
</script>
</div>
</div>
<p>Das Ergebnis der Schätzung ist <span class="math inline">\(\widehat{\beta}_1\approx3.80\)</span>. Der nächste Code-Block berechnet die Residuen aus den Regressionen <span class="math display">\[\begin{align*}
  \textup{body\_mass} =&amp;\, \alpha_0 + \alpha_1 \textup{flipper\_length} + u_{\textup{body\_mass},\,\textup{flipper\_length}},\\
  \textup{bill\_length} =&amp;\, \delta_0 + \delta_1 \textup{flipper\_length} + u_{\textup{bill\_length},\,\textup{flipper\_length}},
\end{align*}\]</span></p>
<p>und speichert diese in <code>body_mass_res</code> und <code>bill_length_res</code>.</p>
<div class="cell">
<div>
<div id="webr-3">

</div>
<script type="webr-3-contents">
eyJjb2RlIjoiIyBGV0wtU2Nocml0dCAxIChhKVxucGVuZ19tb2RfZndsMWEgPC0gbG0oXG4gIGZvcm11bGEgPSBib2R5X21hc3MgfiBmbGlwcGVyX2xlbmd0aCwgXG4gIGRhdGEgPSBwZW5ndWluc19jbGVhbmVkXG4pXG5cbmJvZHlfbWFzc19yZXMgPC0gcmVzaWR1YWxzKHBlbmdfbW9kX2Z3bDFhKVxuXG5oZWFkKGJvZHlfbWFzc19yZXMsIG4gPSAxMCkiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWV9fQ==
</script>
</div>
</div>
<div class="cell">
<div>
<div id="webr-4">

</div>
<script type="webr-4-contents">
eyJjb2RlIjoiIyBGV0wtU2Nocml0dCAxIChiKVxucGVuZ19tb2RfZndsMWIgPC0gbG0oXG4gIGZvcm11bGEgPSBiaWxsX2xlbmd0aCB+IGZsaXBwZXJfbGVuZ3RoLCBcbiAgZGF0YSA9IHBlbmd1aW5zX2NsZWFuZWRcbilcblxuYmlsbF9sZW5ndGhfcmVzIDwtIHJlc2lkdWFscyhwZW5nX21vZF9md2wxYilcblxuaGVhZChiaWxsX2xlbmd0aF9yZXMsIG4gPSAxMCkiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWV9fQ==
</script>
</div>
</div>
<p>Für den zweiten Schritt regressieren wir <code>body_mass_res</code> auf <code>bill_length_res</code>.</p>
<div class="cell">
<div>
<div id="webr-5">

</div>
<script type="webr-5-contents">
eyJjb2RlIjoiIyBGV0wtU2Nocml0dCAyXG5sbShmb3JtdWxhID0gYm9keV9tYXNzX3JlcyB+IGJpbGxfbGVuZ3RoX3JlcyAtIDEpICU+JSBcbiAgdGlkeSgpIiwiYXR0ciI6eyJldmFsIjp0cnVlLCJlZGl0Ijp0cnVlfX0=
</script>
</div>
</div>
<p>Der geschätzte Koeffizient aus der Regression der Residuen stimmt mit dem geschätzten Koeffizienten von <code>bill_length</code> aus der großen Regression <span class="math inline">\(\eqref{eq:billdepthmodel}\)</span> überein.</p>
<p>Wir können den Effekt der Kontrolle für <code>flipper_length</code> visualisieren. Wir plotten hierzu:</p>
<ul>
<li><p>Die originalen Datenpunkte für <code>bill_length</code> und <code>body_mass</code><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> gemeinsam mit der geschätzten Regressionslinie für das Modell <span class="math display">\[ \textup{body\_mass} = \beta_0 + \beta_1\textup{bill\_length} + u \]</span> (keine Kontrolle für <code>flipper_length</code>!)<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p></li>
<li><p>Die um <code>flipper_length</code> bereinigten Datenpunkte und die zugehörige geschätzte Regressionslinie.</p></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Für eine bessere Lesbarkeit der Grafik zentrieren wir beide Variablen um den jeweiligen Stichprobenmittelwert.</p></div><div id="fn2"><p><sup>2</sup>&nbsp;Der R-Befehl für diese Regression ist <code>lm(I(body_mass - mean(body_mass)) ~ I(bill_length - mean(bill_length)) - 1, data = penguins_cleaned)</code>.</p></div></div><div class="cell">
<div>
<div id="webr-6">

</div>
<script type="webr-6-contents">
eyJjb2RlIjoiIyBSZXNpZHVlbiBpbiB0aWJibGUgc2FtbWVsblxucCA8LSB0aWJibGUoXG4gIGJvZHlfbWFzc19yZXMsIFxuICBiaWxsX2xlbmd0aF9yZXNcbikgJT4lXG4gIFxuICBnZ3Bsb3QoKSArXG4gICMgQmVyZWluaWd0ZSBEYXRlbnB1bmt0ZSBwbG90dGVuXG4gIGdlb21fcG9pbnQoXG4gICAgbWFwcGluZyA9IGFlcyhcbiAgICAgIHggPSBiaWxsX2xlbmd0aF9yZXMsIFxuICAgICAgeSA9IGJvZHlfbWFzc19yZXMsXG4gICAgICBjb2xvciA9IFwiVW0gZmxpcHBlcl9sZW5ndGggYmVyZWluaWd0ZSBEYXRlblwiXG4gICAgKVxuICApICtcbiAgIyBSZWdyZXNzaW9uc2xpbmllIGbDvHIgYmVyZWluaWd0ZSBEYXRlbnB1bmt0ZVxuICBnZW9tX3Ntb290aChcbiAgICBtYXBwaW5nID0gYWVzKHggPSBiaWxsX2xlbmd0aF9yZXMsIHkgPSBib2R5X21hc3NfcmVzKSxcbiAgICBtZXRob2QgPSBcImxtXCIsIFxuICAgIGZvcm11bGEgPSBcInkgfiB4IC0gMVwiLFxuICAgIHNlID0gRixcbiAgICBjb2wgPSBcInB1cnBsZVwiXG4gICkgK1xuICBzY2FsZV9jb2xvcl9tYW51YWwoXG4gICAgbmFtZSA9IFwiXCIsXG4gICAgdmFsdWVzID0gYyhcbiAgICAgIFwiVW0gZmxpcHBlcl9sZW5ndGggYmVyZWluaWd0ZSBEYXRlblwiID0gXCJwdXJwbGVcIixcbiAgICAgIFwiVXJzcHLDvG5nbGljaGUgRGF0ZW5wdW5rdGVcIiA9IFwiYmxhY2tcIlxuICAgIClcbiAgKSArXG4gIGxhYnMoXG4gICAgdGl0bGUgPSBcIlBlbmd1aW5zOiBBbndlbmR1bmcgdm9uIEZXTFwiLFxuICAgIHggPSBcImJpbGxfbGVuZ3RoXCIsXG4gICAgeSA9IFwiYm9keV9tYXNzXCJcbiAgKSArXG4gIHRoZW1lX2Nvd3Bsb3QoKSArXG4gIHRoZW1lKGxlZ2VuZC5wb3NpdGlvbiA9IFwidG9wXCIpXG5cbnAiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWV9fQ==
</script>
</div>
</div>
<p>Wir erweitern <code>p</code> um die ursprünglichen Datenpunkte und die zugehörige Regressionslinie.</p>
<div class="cell">
<div>
<div id="webr-7">

</div>
<script type="webr-7-contents">
eyJjb2RlIjoiIyBVcnNwcsO8bmdsaWNoZSBEYXRlbnB1bmt0ZSBoaW56dWbDvGdlblxucCArIGdlb21fcG9pbnQoXG4gICAgZGF0YSA9IHBlbmd1aW5zX2NsZWFuZWQsIFxuICAgIG1hcHBpbmcgPSBhZXMoXG4gICAgICB4ID0gYmlsbF9sZW5ndGggLSBtZWFuKGJpbGxfbGVuZ3RoKSwgXG4gICAgICB5ID0gYm9keV9tYXNzIC0gbWVhbihib2R5X21hc3MpLFxuICAgICAgY29sb3IgPSBcIlVyc3Byw7xuZ2xpY2hlIERhdGVucHVua3RlXCJcbiAgICApLFxuICAgIGFscGhhID0gLjUsXG4gICkgK1xuICAjIFJlZ3Jlc3Npb25zbGluaWUgZsO8ciB1cnNwcsO8bmdsaWNoZSBEYXRlbnB1bmt0ZVxuICBnZW9tX3Ntb290aChcbiAgICBkYXRhID0gcGVuZ3VpbnNfY2xlYW5lZCwgXG4gICAgbWFwcGluZyA9IGFlcyhcbiAgICAgIHggPSBiaWxsX2xlbmd0aCAtIG1lYW4oYmlsbF9sZW5ndGgpLCBcbiAgICAgIHkgPSBib2R5X21hc3MgLSBtZWFuKGJvZHlfbWFzcylcbiAgICApLFxuICAgIG1ldGhvZCA9IFwibG1cIiwgXG4gICAgZm9ybXVsYSA9IFwieSB+IHggLSAxXCIsXG4gICAgc2UgPSBGLFxuICAgIGNvbCA9IGFscGhhKFwiYmxhY2tcIiwgLjUpXG4gICkiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWV9fQ==
</script>
</div>
</div>
<p>Der grafische Vergleich beider Vorgehensweisen zeigt den Effekt der Kontrolle für <code>flipper_length</code>: Die geschätzte (schwarze) Regressionslinie für die bereinigten Daten hat eine deutlich geringere Steigung als die anhand der ursprünglichen Daten geschätzte (lilane) Linie. Der Effekt von <code>bill_length</code> auf <code>body_mass</code> wird mit der einfachen Regression <code>lm(body_mass ~ bill_length)</code> vermutlich <em>überschätzt</em>, weil es andere Faktoren (wie <code>flipper_length</code> gibt, die mit <code>bill_length</code> und <code>body_mass</code> korrelieren. Kontrollieren für <code>flipper_length</code> in der multiplen Regression <code>lm(body_mass ~ bill_length + flipper_length)</code> schließt die Backdoor durch <code>flipper_length</code>. Die Konsequenz ist eine deutlich geringere Steigung der lilanen Regressionslinie.</p>
</section><section id="sec-bov" class="level2 page-columns page-full" data-number="4.2"><h2 data-number="4.2" class="anchored" data-anchor-id="sec-bov">
<span class="header-section-number">4.2</span> Binäre Outcome-Variable</h2>
<p>Eine binäre Variable, auch als dichotome Variable oder Indikator-Variable bezeichnet, ist eine Variable, die nur zwei Ausprägungen annehmen kann. Diese beiden Ausprägungen werden typischerweise durch die Werte 0 und 1 repräsentiert und dienen dazu, zwei verschiedene Zustände oder Kategorien zu unterscheiden. Formal kann eine binäre Variable <span class="math inline">\(B\)</span> wie folgt definiert werden:</p>
<p><span class="math display">\[\begin{align}
  B = \begin{cases}
  1, &amp; \text{Eigenschaft trifft zu,} \\
  0, &amp; \text{Eigenschaft trifft nicht zu.}
  \end{cases}
\end{align}\]</span></p>
<p>Ein in späteren Kapiteln dieses Companions verwendeter <em>binärer Regressor</em> ist der Indikator für die Zuordnung von Beobachtungen zur Behandlungs- oder Kontrollgruppe (1 = Behandlungsgruppe, 0 = Kontrollgruppe).</p>
<p>Für viele ökonomische Forschungsfragen ist es hilfreich, eine <em>binäre Outcome-Variable</em> mit Regression zu modellieren. Hierzu gibt es verschiedene Ansätze, die wir nachfolgend zusammenfassen und ihre Anwendung mit R zeigen.</p>
<section id="sec-lpm" class="level3" data-number="4.2.1"><h3 data-number="4.2.1" class="anchored" data-anchor-id="sec-lpm">
<span class="header-section-number">4.2.1</span> Das lineare Wahrscheinlichkeitsmodell</h3>
<p>Das lineare Regressionsmodell</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1 X_{1} + \beta_2 X_{2} + \dots + \beta_k X_{k} + u\]</span> mit einer binären abhängigen Variablen <span class="math inline">\(Y_i\in\{0,1\}\)</span> wird als <em>lineares Wahrscheinlichkeitsmodell</em> bezeichnet. Wie üblich modellieren wir den Erwartungswert der abhängigen Variable gegeben der Regressoren <span class="math inline">\(X_1,\dots,X_k\)</span> als lineare Funktion,</p>
<p><span class="math display">\[E(Y\vert X_1,X_2,\dots,X_k) = P(Y=1\vert X_1, X_2,\dots, X_3).\]</span> Da <span class="math inline">\(Y\)</span> eine binäre Variable ist, gilt hier</p>
<p><span class="math display">\[ P(Y = 1 \vert X_1, X_2, \dots, X_k) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_k X_k.\]</span></p>
<p>Das lineare Wahrscheinlichkeitsmodell beschreibt also die <em>Wahrscheinlichkeit</em>, dass <span class="math inline">\(Y=1\)</span> als lineare Funktion der Regressoren: <span class="math inline">\(\beta_j\)</span> misst die Änderung in der Wahrscheinlichkeit für das Ereignis <span class="math inline">\(Y_i=1\)</span>, unter der Bedingung, dass die anderen <span class="math inline">\(k-1\)</span> Regressoren konstant gehalten werden. Genau wie bei multipler Regression mit einer kontinuierlichen abhängigen Variablen können die <span class="math inline">\(\beta_j\)</span> mit der KQ-Methode geschätzt werden.</p>
<p>Aufgrund der Beschränktheit der <span class="math inline">\(Y_i\)</span> auf <span class="math inline">\(\{0,1\}\)</span> ist <span class="math inline">\(u_i\)</span> heteroskedastisch. Folglich sollten Inferenzstatistiken mit robusten Standardfehlern berechnet werden. Weiterhin ist zu beachten, dass <span class="math inline">\(R^2\)</span> in den meisten Anwendungen von linearen Wahrscheinlichkeitsmodellen keine hilfreiche Interpretation hat, da das geschätzte Modell die Daten nicht perfekt erklären kann, wenn die abhängige Variable binär, aber die Regressoren kontinuierlich verteilt sind.</p>
<p>Das lineare Wahrscheinlichkeitsmodell hat einen wesentlichen Nachteil: Das Modell nimmt an, dass die bedingte Wahrscheinlichkeitsfunktion linear ist und <span class="math inline">\(P(Y=1\vert X_1,\dots,X_k)\)</span> über das für Wahrscheinlichkeiten definierte Intervall <span class="math inline">\([0,1]\)</span> hinausgehen kann. Ein angepasstes Modell hat dann für Regressorwerte, die zu Vorhersagen von <span class="math inline">\(Y\)</span> jenseits von <span class="math inline">\([0,1]\)</span> führen keine sinnvolle Interpretation.</p>
<p>Dieser Umstand verlangt nach Regressionsansätzen, die <span class="math inline">\(P(Y=1)\)</span> durch eine auf <span class="math inline">\([0,1]\)</span> beschränkte (nicht-lineare) Funktion der Regressoren modellieren. Häufig verwendete Methoden sind Probit- und Logit-Regression.</p>
<p>Ein lineares Wahrscheinlichkeitsmodell kann mit <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> geschätzt werden, wobei die abhängige Variable den Typ <code>numeric</code> oder <code>integer</code> haben muss.</p>
</section><section id="sec-probitreg" class="level3 page-columns page-full" data-number="4.2.2"><h3 data-number="4.2.2" class="anchored" data-anchor-id="sec-probitreg">
<span class="header-section-number">4.2.2</span> Probit-Regression</h3>
<p>Bei der Probit-Regression wird die Standardnormalverteilungsfunktion <span class="math inline">\(\Phi(\cdot)\)</span> verwendet, um die Regressionsfunktion einer binären abhängigen Variable zu modellieren. Wir nehmen an, dass <span class="math display">\[\begin{align}
  E(Y\vert X) = P(Y=1\vert X) = \Phi(\beta_0 + \beta_1 X), \label{eq:probitmodel}
\end{align}\]</span> sodass der mit der Verknüpfungsfunktion (Link-Funktion) <span class="math display">\[\textup{probit}(\cdot) = \Phi^{-1}(\cdot)\]</span> transformierte Erwartungswert <span class="math inline">\(P(Y=1\vert X)\)</span> dem linearen Prädiktor <span class="math inline">\(z=\beta_0 + \beta_1 X\)</span> entspricht, <span class="math display">\[\begin{align*}
  \Phi^{-1}\big[P(Y=1\vert X)\big] = \beta_0 + \beta_1 X.
\end{align*}\]</span></p>
<p><span class="math inline">\(z=\beta_0 + \beta_1 X\)</span> in <span class="math inline">\(\eqref{eq:probitmodel}\)</span> modelliert hier also ein <em>Quantil</em> der Standardnormalverteilung, <span class="math display">\[\begin{align*}
\Phi(z) = P(Z \leq z) \ , \ Z \sim \mathcal{N}(0,1).
\end{align*}\]</span> Der Koeffizient <span class="math inline">\(\beta_1\)</span> in <span class="math inline">\(\eqref{eq:probitmodel}\)</span> misst die Änderung in <span class="math inline">\(z\)</span>, die mit einer Änderung von <span class="math inline">\(X\)</span> um eine Einheit verbunden ist. Obwohl der Effekt einer Änderung in <span class="math inline">\(X\)</span> auf <span class="math inline">\(z\)</span> linear ist, ist der Zusammenhang zwischen <span class="math inline">\(z\)</span> und <span class="math inline">\(\textup{E}(Y\vert X) = P(Y=1\vert X)\)</span> <em>nicht linear</em>, denn <span class="math inline">\(\Phi(\cdot)\)</span> ist eine nicht-lineare Funktion von <span class="math inline">\(X\)</span>.</p>
<div class="cell">
<div>
<div id="webr-8">

</div>
<script type="webr-8-contents">
eyJjb2RlIjoiIyBOKDAsMSktUXVhbnRpbHNmdW5rdGlvbiAvIFByb2JpdC1MaW5rXG5nZ3Bsb3QoKSArXG4gIGdlb21fZnVuY3Rpb24oZnVuID0gcW5vcm0pICtcbiAgc2NhbGVfeF9jb250aW51b3VzKFxuICAgIG5hbWUgPSBcInpcIiwgXG4gICAgbGltaXRzID0gYygwLCAxKVxuICApICtcbiAgc2NhbGVfeV9jb250aW51b3VzKG5hbWUgPSBcIlF1YW50aWxcIikgK1xuICBsYWJzKHRpdGxlID0gXCJQcm9iaXQtRnVua3Rpb25cIikgK1xuICB0aGVtZV9jb3dwbG90KCkiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWV9fQ==
</script>
</div>
</div>
<p>Aufgrund der Nicht-Linearität der Link-Funktion hat der Koeffizient von <span class="math inline">\(X\)</span> keine einfache Interpretation hinsichtlich des Effekts auf <span class="math inline">\(P(Y=1\vert X)\)</span>. Die Änderung in der Wahrscheinlichkeit, dass <span class="math inline">\(Y=1\)</span> ist, durch eine Änderung in <span class="math inline">\(X\)</span> (partieller Effekt von <span class="math inline">\(X\)</span>) kann berechnet werden als:</p>
<p><span class="math display">\[\begin{align*}
  \frac{\partial\textup{E}(Y\vert X)}{\partial X} = \frac{\partial\textup{P}(Y=1\vert X)}{\partial X} = \frac{\partial\Phi(\beta_0 + \beta_1 X)}{\partial X} = \phi(\beta_0 + \beta_1 X) \beta_1,
\end{align*}\]</span> wobei <span class="math inline">\(\phi(\cdot)\)</span> die Dichtefunktion der Standardnormalverteilung ist. In empirischen Anwendungen wird der partielle Effekt häufig als Differenz in geschätzten Wahrscheinlichkeiten angegeben:</p>
<ol type="1">
<li>Berechne die geschätzte Wahrscheinlichkeit, dass <span class="math inline">\(Y=1\)</span> für einen Bezugswert <span class="math inline">\(X\)</span>.</li>
<li>Berechne die geschätzte Wahrscheinlichkeit, dass <span class="math inline">\(Y=1\)</span> für <span class="math inline">\(X + \Delta X\)</span>.</li>
<li>Berechne die Differenz zwischen der geschätzten Wahrscheinlichkeiten.</li>
</ol>
<p>Wie im linearen Wahrscheinlichkeitsmodell kann das Modell <span class="math inline">\(\eqref{eq:probitmodel}\)</span> auf eine Probit-Regression mit <span class="math inline">\(k+1\)</span> Regressoren <span class="math inline">\(\boldsymbol{X} := (1, X_1, \dots, X_k)\)</span> verallgemeinert werden, um das Risiko einer Verzerrung durch ausgelassene Variablen zu mindern. Die Schritte 1 bis 3 für die Berechnung des partiellen Effekts einer Änderung in <span class="math inline">\(X_j\)</span> erfolgen dann unter der Annahme, dass die übrigen <span class="math inline">\(k-1\)</span> Regressoren konstant gehalten werden, wobei der partielle Effekt von den jeweiligen Regressorwerten abhängt. Im nächsten Abschnitt erläutern wir die Schätzung von Probit-Modellen mit <span class="math inline">\(k+1\)</span> Regressoren.</p>
<section id="schätzung" class="level4 page-columns page-full" data-number="4.2.2.1"><h4 data-number="4.2.2.1" class="anchored" data-anchor-id="schätzung">
<span class="header-section-number">4.2.2.1</span> Schätzung</h4>
<p>Die Likelihood-Funktion für Probit-Regression ist</p>
<p><span class="math display">\[\begin{align*}
  L(\boldsymbol{\beta}) = \prod_{i=1}^n \Phi(\mathbf{X}_i^\top \boldsymbol{\beta})^{y_i} \left[1 - \Phi(\mathbf{X}_i^\top \boldsymbol{\beta})\right]^{1-y_i}
\end{align*}\]</span></p>
<p>Hierbei ist <span class="math inline">\(\Phi(\mathbf{X}_i^\top \boldsymbol{\beta})\)</span> die Wahrscheinlichkeit, dass <span class="math inline">\(Y_i = 1\)</span> ist und <span class="math inline">\(1 - \Phi(\mathbf{X}_i^\top \boldsymbol{\beta})\)</span> ist die Wahrscheinlichkeit, dass <span class="math inline">\(Y_i = 0\)</span> ist.</p>
<p>Die Log-Likelihood-Funktion ergibt sich als</p>
<p><span class="math display">\[\begin{align*}
  \mathcal{L}(\boldsymbol{\beta}) = \sum_{i=1}^n \left[ y_i \log \Phi(\mathbf{X}_i^\top \boldsymbol{\beta}) + (1 - y_i) \log \left(1 - \Phi(\mathbf{X}_i^\top \boldsymbol{\beta})\right) \right]
\end{align*}\]</span></p>
<p>Um den Maximum-Likelihood-Schätzer <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span> zu finden, muss die Log-Likelihood-Funktion <span class="math inline">\(\mathcal{L}(\boldsymbol{\beta})\)</span> maximiert werden. In der Praxis erfolgt dies häufig durch numerische Optimierung, da die Log-Likelihood-Funktion der Probit-Regression im Allgemeinen keine geschlossene Form hat, sodass eine analytische Lösung nicht möglich ist.</p>
<p>Für eine Anwendung in R und einen Vergleich mit dem linearen Wahrscheinlichkeitsmodell erzeugen wir einen Beispieldatensatz <code>simdata</code> für einen datenerzeugenden Prozess (DGP)<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> mit einem normalverteilten Regressor <span class="math inline">\(X\sim N(5,2^2)\)</span> und <span class="math display">\[\begin{align*}
  P(Y=1\vert X) = \Phi(z), \quad z = -4 + 0.7 X.
\end{align*}\]</span></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;Siehe <a href="Simulation.html" class="quarto-xref"><span>Kapitel 5</span></a> für Erläuterungen von Simulationsmethoden in R.</p></div></div><div class="cell">
<div>
<div id="webr-9">

</div>
<script type="webr-9-contents">
eyJjb2RlIjoiIyBEYXRlbiBzaW11bGllcmVuXG5zZXQuc2VlZCgxMjM0KVxuXG4jIFN0aWNocHJvYmVuZ3LDtsOfZVxubiA8LSA1MDAgXG5cbnNpbWRhdGEgPC0gdGliYmxlKFxuICBYID0gcm5vcm0obiA9IG4sIG1lYW4gPSA1LCBzZCA9IDIpLCAjIFJlZ3Jlc3NvclxuICBQID0gcG5vcm0oLTQgKyAwLjcgKiBYKSxcbilcblxuIyBCaW7DpHJlIE91dGNvbWUtVmFyaWFibGUgaGluenVmw7xnZW5cbnNpbWRhdGEgPC0gc2ltZGF0YSAlPiVcbiAgbXV0YXRlKFxuICAgIFkgPSBhcy5pbnRlZ2VyKHJ1bmlmKG4pIDwgUClcbiAgKVxuXG4jIMOcYmVyYmxpY2tcbnNsaWNlX2hlYWQoc2ltZGF0YSwgbiA9IDEwKSIsImF0dHIiOnsiZXZhbCI6dHJ1ZSwiZWRpdCI6dHJ1ZX19
</script>
</div>
</div>
<p>Das lineare Wahrscheinlichkeitsmodell schätzen wir wie gewohnt mit <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> und berechnen robuste Standardfehler mit <code><a href="https://rdrr.io/pkg/lmtest/man/coeftest.html">lmtest::coeftest()</a></code>.</p>
<div class="cell">
<div>
<div id="webr-10">

</div>
<script type="webr-10-contents">
eyJjb2RlIjoiIyBsaW5lYXJlcyBXYWhyc2NoZWlubGljaGtlaXRzbW9kZWxsIHNjaMOkdHplblxubW9kX2xwIDwtIGxtKFxuICBmb3JtdWxhID0gWSB+IFgsIFxuICBkYXRhID0gc2ltZGF0YVxuKVxuXG4jIFp1c2FtbWVuZmFzc3VuZ1xubW9kX2xwICU+JSBcbiAgY29lZnRlc3QodmNvdiA9IHZjb3ZIQywgdHlwZSA9IFwiSEMxXCIpICU+JVxuICB0aWR5KCkiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWV9fQ==
</script>
</div>
</div>
<p>Beachte, dass lediglich die Vorzeichen der geschätzten Koeffizienten mit denen der wahren Werten übereinstimmmen. Da das lineare Modell fehlspezifiziert ist, sind die KQ-Schätzer der Koeffizienten hier inkonsistent.</p>
<p>Ein Probit-Modell kann mit <code><a href="https://rdrr.io/r/stats/glm.html">stats::glm()</a></code> geschätzt werden. Hierbei ist <code>formula</code> die Formel für den linearen Prädiktor <span class="math inline">\(z\)</span> und <code>family</code> eine Link-Funktion für den Zusammenhang von <span class="math inline">\(z\)</span> und <span class="math inline">\(P(Y\vert X)\)</span>. Mit <code>family = binomial(link = "probit")</code> wählen wir die Link-Funktion <code>probit</code>.</p>
<div class="cell">
<div>
<div id="webr-11">

</div>
<script type="webr-11-contents">
eyJjb2RlIjoiIyBQcm9iaXQtTW9kZWxsIHNjaMOkdHplblxubW9kX3Byb2JpdCA8LSBnbG0oXG4gIGZvcm11bGEgPSBZIH4gWCxcbiAgZGF0YSA9IHNpbWRhdGEsIFxuICBmYW1pbHkgPSBiaW5vbWlhbChsaW5rID0gXCJwcm9iaXRcIilcbilcblxuIyBadXNhbW1lbmZhc3N1bmdcbm1vZF9wcm9iaXQgJT4lXG4gIGNvZWZ0ZXN0KHZjb3YgPSB2Y292SEMsIHR5cGUgPSBcIkhDMVwiKSAlPiVcbiAgdGlkeSgpIiwiYXR0ciI6eyJldmFsIjp0cnVlLCJlZGl0Ijp0cnVlfX0=
</script>
</div>
</div>
<p>Die geschätzten Koeffizienten in der Probit-Regression liegen, wie erwartet, nahe bei Parametern des DGPs.</p>
<p>Um beide Schätzungen gemeinsam zu plotten, erzeugen wir mit <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> Vorhersagen für eine Menge von Werten <code>X</code> im Intervall <span class="math inline">\([0,11]\)</span>. Beachte, dass bei Vorhersagen für das Probit-Modell die gewünschte Transformation der vorherzusagenden Variable über <code>type</code> gewählt werden muss.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> Der Standardfall ist <code>type = "link"</code>, d.h. wir erhalten Vorhersagen für den linearen Prädiktor: <span class="math inline">\(\widehat{z} = \widehat\beta_0 + \widehat{\beta}_1X\)</span>. Mit <code>type = "response"</code> werden diese Werte mit der Link-Funktion, hier <span class="math inline">\(\Phi(\cdot)\)</span> zu vorhergesagten Wahrscheinlichkeiten <span class="math inline">\(\widehat{P}(Y=1\vert X = x)\)</span> transformiert.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;Dies gilt für jedes Modell mit einer anderen Link-Funktion als <span class="math inline">\(f(x) = x\)</span> ist (lineare Regression).</p></div></div><div class="cell">
<div>
<div id="webr-12">

</div>
<script type="webr-12-contents">
eyJjb2RlIjoiIyBnZXNjaMOkdHp0ZSBXYWhyc2NoZWlubGljaGtlaXRzZnVua3Rpb25cbiMgZsO8ciBsaW5lYXJlcyBNb2RlbGxcblggPC0gc2VxKDAsIDExLCAwLjAxKVxuXG5wcmVkIDwtIHRpYmJsZShcbiAgWCA9IFgsIFxuICBMUCA9IHByZWRpY3QoXG4gICAgb2JqZWN0ID0gbW9kX2xwLCBcbiAgICBuZXdkYXRhID0gdGliYmxlKFgpXG4gICksXG4gIHByb2JpdCA9IHByZWRpY3QoXG4gICAgb2JqZWN0ID0gbW9kX3Byb2JpdCxcbiAgICBuZXdkYXRhID0gdGliYmxlKFgpLFxuICAgIHR5cGUgPSBcInJlc3BvbnNlXCJcbiAgKVxuKVxuXG4jIMOcYmVyYmxpY2sgdmVyc2NoYWZmZW5cbnNsaWNlX2hlYWQocHJlZCwgbiA9IDEwKSIsImF0dHIiOnsiZXZhbCI6dHJ1ZSwiZWRpdCI6dHJ1ZX19
</script>
</div>
</div>
<p>Der nachfolgende Code-Chunk erstellt einen Punkte-Plot mit Jitter-Effekt (<code>position_jitter</code>), wobei die Beobachtungen zufällig leicht vertikal verschoben werden, um Überlappungen zu vermeiden. Zusätzlich zeichnen wir die geschätzten Regressionslinien für <code>mod_lp</code> (LPM) und <code>mod_probit</code> (Probit) sowie die tatsächliche Wahrscheinlichkeitsfunktion <span class="math inline">\(P(Y=1\vert X)\)</span> ein.</p>
<div class="cell">
<div>
<div id="webr-13">

</div>
<script type="webr-13-contents">
eyJjb2RlIjoiIyBEYXRlbiB1bmQgZ2VzY2jDpHR6dGUgTW9kZWxsZSBwbG90dGVuXG5wIDwtIHNpbWRhdGEgJT4lXG4gIGdncGxvdChtYXBwaW5nID0gYWVzKHggPSBYLCB5ID0gWSkpICtcbiAgZ2VvbV9wb2ludChcbiAgICBwb3NpdGlvbiA9IHBvc2l0aW9uX2ppdHRlcihcbiAgICAgIGhlaWdodCA9IC4wMjUsXG4gICAgICBzZWVkID0gMTIzNFxuICAgICksXG4gICAgYWxwaGEgPSAuMjUsXG4gICAgY29sb3IgPSBcImdyYXlcIlxuICApICtcbiAgZ2VvbV9saW5lKFxuICAgIGRhdGEgPSBwcmVkLCBcbiAgICBtYXBwaW5nID0gYWVzKHkgPSBMUCwgY29sb3IgPSBcIkxQTVwiKSxcbiAgICBsd2QgPSAuNzVcbiAgKSArXG4gIGdlb21fbGluZShcbiAgICBkYXRhID0gcHJlZCwgXG4gICAgbWFwcGluZyA9IGFlcyh5ID0gcHJvYml0LCBjb2xvciA9IFwiUHJvYml0XCIpLFxuICAgIGx3ZCA9IC43NVxuICApICtcbiAgZ2VvbV9mdW5jdGlvbihcbiAgICBmdW4gPSBcXCh4KSBwbm9ybSgtNCArIC43ICogeCksIFxuICAgIG1hcHBpbmcgPSBhZXMoY29sb3IgPSBcIldhaHJoZWl0XCIpXG4gICkgK1xuICBzY2FsZV9jb2xvcl9tYW51YWwoXG4gICAgbmFtZSA9IFwiXCIsXG4gICAgdmFsdWVzID0gYyhcbiAgICAgIFwiV2FocmhlaXRcIiA9IFwiYmxhY2tcIixcbiAgICAgIFwiTFBNXCIgPSBcInN0ZWVsYmx1ZVwiLCBcbiAgICAgIFwiUHJvYml0XCIgPSBcIm9yYW5nZVwiXG4gICAgKVxuICApICtcbiAgbGFicyh0aXRsZSA9IFwiR2VzY2guIE1vZGVsbGUgZsO8ciBiaW7DpHJlIGFiaMOkbmdpZ2UgVmFyaWFibGVcIikgK1xuICB0aGVtZV9jb3dwbG90KCkgK1xuICB0aGVtZShsZWdlbmQucG9zaXRpb24gPSBcInRvcFwiKVxuXG5wIiwiYXR0ciI6eyJldmFsIjp0cnVlLCJlZGl0Ijp0cnVlfX0=
</script>
</div>
</div>
<p>Die Grafik zeigt, dass beide Modelle den positiven Zusammenhang für <span class="math inline">\(X\)</span> und <span class="math inline">\(P(Y=1\vert X)\)</span> erfassen. Das lineare Wahrscheinlichkeitsmodell approximiert die tatsächliche nicht-lineare Wahrscheinlichkeitsfunktion nur schlecht und liefert insbesondere in den Rändern der Verteilung von <span class="math inline">\(X\)</span> (kleine und große Werte) unzulässige Vorhersagen außerhalb des Intervalls <span class="math inline">\([0,1]\)</span>. Die Probit-Spezifikation hingegen erfasst den nicht-linearen Verlauf der tatsächlichen Wahrscheinlichkeitsfunktion gut.</p>
</section></section><section id="sec-logreg" class="level3" data-number="4.2.3"><h3 data-number="4.2.3" class="anchored" data-anchor-id="sec-logreg">
<span class="header-section-number">4.2.3</span> Logistische Regression</h3>
<p>Bei logistischer Regression wird die logistische Funktion <span class="math inline">\(\Lambda(\cdot)\)</span> <span class="math display">\[\begin{align}
\Lambda(z) = \frac{1}{1 + \exp(-z)},
\end{align}\]</span> als Link-Funktion genutzt, um die Wahrscheinlichkeitsfunktion von <span class="math inline">\(Y\)</span> gegeben <span class="math inline">\(X\)</span> zu modellieren. Ähnlich wie im Probit-Modell nehmen wir hier an, dass <span class="math display">\[\begin{align}
E(Y\vert X) = P(Y=1\vert X) = \Lambda(\beta_0 + \beta_1 X). \label{eq:logitmodel}
\end{align}\]</span> In diesem Modell ist die Link-Funktion <span class="math inline">\(\Lambda^{-1}(\cdot)\)</span>. Für <span class="math inline">\(z=\beta_0 + \beta_1 X\)</span> ist <span class="math inline">\(\Lambda^{-1}(t)\)</span> der sogenannte <em>logit</em>: Dass logarithmierte Verhältnis von <span class="math inline">\(p := P(Y=1\vert X)\)</span> zu <span class="math inline">\(1 - p = P(Y=0\vert X)\)</span>, <span class="math display">\[\begin{align*}
  \textup{logit(p)} = \log\bigg(\frac{p}{1-p}\bigg) = \beta_0 + \beta_1 X.
\end{align*}\]</span> Der Koeffizient <span class="math inline">\(\beta_1\)</span> misst also die Veränderung des Logits pro Einheit Änderung im Regressor <span class="math inline">\(X\)</span>.</p>
<p>Ähnlich wie bei Probit-Regression ist der Einfluss von <span class="math inline">\(X\)</span> auf den Logit linear, jedoch besteht auch hier eine nicht-lineare Beziehung zwischen dem linearen Prädiktor und der Wahrscheinlichkeit <span class="math inline">\(P(Y=1\vert X)\)</span>, denn <span class="math inline">\(\Lambda(\cdot)\)</span> ist eine nicht-lineare Funktion mit dem Wertebereich <span class="math inline">\([0,1]\)</span>.</p>
<div class="cell">
<div>
<div id="webr-14">

</div>
<script type="webr-14-contents">
eyJjb2RlIjoiIyBQbG90OiBMb2dpc3Rpc2NoZSBGdW5rdGlvblxuZ2dwbG90KCkgK1xuICBzdGF0X2Z1bmN0aW9uKFxuICAgIGZ1biA9IFxcKHgpIDEgLyAoMSArIGV4cCgteCkpXG4gICAgKSArXG4gIHNjYWxlX3hfY29udGludW91cyhcbiAgICBuYW1lID0gXCJ6XCIsIFxuICAgIGxpbWl0cyA9IGMoLTQsIDQpXG4gICkgK1xuICBzY2FsZV95X2NvbnRpbnVvdXMobmFtZSA9IFwiTGFtYmRhKHopXCIpICtcbiAgbGFicyh0aXRsZSA9IFwiTG9naXN0aXNjaGUgRnVua3Rpb25cIikgK1xuICB0aGVtZV9jb3dwbG90KCkiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWV9fQ==
</script>
</div>
</div>
<div class="cell">
<div>
<div id="webr-15">

</div>
<script type="webr-15-contents">
eyJjb2RlIjoiIyBQbG90OiBMb2dpdFxuZ2dwbG90KCkgK1xuICBzdGF0X2Z1bmN0aW9uKFxuICAgIGZ1biA9IFxcKHgpIGxvZyh4IC8gKDEgLSB4KSlcbiAgICApICtcbiAgc2NhbGVfeF9jb250aW51b3VzKFxuICAgIG5hbWUgPSBcInBcIiwgXG4gICAgbGltaXRzID0gYygwLCAxKVxuICApICtcbiAgc2NhbGVfeV9jb250aW51b3VzKG5hbWUgPSBcIkxvZ2l0KHApXCIpICtcbiAgbGFicyh0aXRsZSA9IFwiTG9naXQtRnVua3Rpb25cIikgK1xuICB0aGVtZV9jb3dwbG90KCkiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWV9fQ==
</script>
</div>
</div>
<p>Die nachstehende interaktive Grafik illustriert, wie die Wahrscheinlichkeitsfunktion der latenten Variable <span class="math inline">\(z=\beta_0 + \beta_1 X\)</span> von den Parametern <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> jeweils für Logit- und Probit-Regression beeinflusst wird.</p>
<iframe class="obs-soft-box-shadow" width="100%" height="680" frameborder="0" src="https://observablehq.com/embed/@mca91/latent-variable-cdf?cells=plot%2Cviewof+beta0%2Cviewof+beta%2CMathJax">
</iframe>
<p>Aufgrund der Nicht-Linearität von <span class="math inline">\(\Lambda(z)\)</span> kann der Koeffizient <span class="math inline">\(\beta_1\)</span> wie im Probit-Modell nicht direkt als Effekt auf die Wahrscheinlichkeit <span class="math inline">\(P(Y=1\vert X)\)</span> interpretiert werden.</p>
<p>Um den partiellen Effekt einer Änderung in <span class="math inline">\(X\)</span> am Punkt <span class="math inline">\(X\)</span> auf <span class="math inline">\(P(Y=1\vert X)\)</span> zu ermitteln, berechnen wir die Ableitung des bedingten Erwartungswerts:</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial\textup{E}(Y\vert X)}{\partial X} = \frac{\partial\textup{P}(Y=1\vert X)}{\partial X} = \frac{\partial\Lambda(\beta_0 + \beta_1 X)}{\partial X} = \lambda(\beta_0 + \beta_1 X) \beta_1,
\end{align*}\]</span> wobei <span class="math inline">\(\lambda(\cdot)\)</span>, ähnlich wie die Dichtefunktion der Normalverteilung im Probit-Modell, die Dichtefunktion der logistischen Verteilung darstellt. Diese ist gegeben durch <span class="math display">\[\begin{align*}
\lambda(z) = \Lambda(z) \cdot (1 - \Lambda(z)).
\end{align*}\]</span></p>
<p>Die Interpretation des angepassten Modells ist aufgrund der Modellierung des Logits intuitiver als für Probit-Regression. Angenommen eine Bank möchte die Wahrscheinlichkeit modellieren, dass ein Kunde einen Kredit nicht zurückzahlt: <span class="math inline">\(P(Y=\textup{Zahlungsausfall}\vert X)\)</span>, wobei der Regressor <span class="math inline">\(X\)</span> das Verhältnis von aktuellem Schuldenstand und Monatseinkommen ist. Die Schätzung einer logistischen Regression ergibt, dass ein Anstieg von <span class="math inline">\(X =x\)</span> um 0.1 den Logit für die Wahrscheinlichkeit eines Kreditausfalls <span class="math inline">\(p(x)\)</span> um 0.4 erhöht: <span class="math display">\[\begin{align*}
  \textup{logit} \big[P(Y=\textup{Zahlungsausfall}\vert X = x + 0.1)\big] = \textup{logit}[p(x)] + 0.4.
\end{align*}\]</span></p>
<p>Das Modell besagt dann, dass die Wahrscheinlichkeit der Zahlungsunfähigkeit etwa um den <em>Faktor</em> 1.5 ansteigt, denn <span class="math display">\[\begin{align*}
  \exp\big(\textup{logit}[p(x)] + 0.4\big) = \frac{p(x)}{1-p(x)} \cdot \exp(0.4)
\end{align*}\]</span> mit <span class="math display">\[\begin{align*}
  \exp(0.4) \approx 1.50.
\end{align*}\]</span></p>
</section><section id="schätzung-1" class="level3" data-number="4.2.4"><h3 data-number="4.2.4" class="anchored" data-anchor-id="schätzung-1">
<span class="header-section-number">4.2.4</span> Schätzung</h3>
<p>Ähnlich wie bei Probit-Regressionen können Logit-Modelle mit Maximum-Likelihood geschätzt werden. Die Likelihood-Funktion für Logit-Regression lautet</p>
<p><span class="math display">\[\begin{align}
  L(\boldsymbol{\beta}) &amp;= \prod_{i=1}^n \left(\frac{1}{1 + \exp(-\mathbf{X}_i^\top \boldsymbol{\beta})}\right)^{y_i} \left(1 - \frac{1}{1 + \exp(-\mathbf{X}_i^\top \boldsymbol{\beta})}\right)^{1-y_i},
\end{align}\]</span></p>
<p>mit <span class="math display">\[\frac{1}{1 + \exp(-\mathbf{X}_i^\top \boldsymbol{\beta})}\]</span> der Wahrscheinlichkeit, dass <span class="math inline">\(Y_i = 1\)</span>. Für das Ereignis <span class="math inline">\(Y_i = 0\)</span> ist die Wahrscheinlichkeit entsprechend <span class="math display">\[1 - \frac{1}{1 + \exp(-\mathbf{X}_i^\top \boldsymbol{\beta})}.\]</span></p>
<p>Die Log-Likelihood-Funktion lautet</p>
<p><span class="math display">\[\begin{align*}
  \mathcal{L}(\boldsymbol{\beta}) &amp;= \sum_{i=1}^n \left[ y_i \log \left(\frac{1}{1 + \exp(-\mathbf{X}_i^\top \boldsymbol{\beta})}\right) + (1 - y_i) \log \left(1 - \frac{1}{1 + \exp(-\mathbf{X}_i^\top \boldsymbol{\beta})}\right) \right]
\end{align*}\]</span></p>
<p>und erlaubt die Schätzung von <span class="math inline">\(\boldsymbol{\beta}\)</span> durch Maximierung mit numerischen Methoden.</p>
<p>Für Anwendungen mit R nutzen wir <code><a href="https://rdrr.io/r/stats/glm.html">stats::glm()</a></code> und wählen die logistische Link-Funktion mit <code>family = binomial(link = "logit")</code>. Für die simulierten Daten <code>simdata</code> aus <a href="#sec-probitreg" class="quarto-xref"><span>Kapitel 4.2.2</span></a>:</p>
<div class="cell">
<div>
<div id="webr-16">

</div>
<script type="webr-16-contents">
eyJjb2RlIjoiIyBMb2dpdC1Nb2RlbGwgc2Now6R0emVuXG5tb2RfbG9naXQgPC0gZ2xtKFxuICBmb3JtdWxhID0gWSB+IFgsXG4gIGRhdGEgPSBzaW1kYXRhLCBcbiAgZmFtaWx5ID0gYmlub21pYWwobGluayA9IFwibG9naXRcIilcbilcblxuIyBSb2J1c3RlIFp1c2FtbWVuZmFzc3VuZ1xubW9kX2xvZ2l0ICU+JVxuICBjb2VmdGVzdCh2Y292ID0gdmNvdkhDLCB0eXBlID0gXCJIQzFcIilcbiAgdGlkeSgpIiwiYXR0ciI6eyJldmFsIjp0cnVlLCJlZGl0Ijp0cnVlfX0=
</script>
</div>
</div>
<p>Wir erweitern nun <code>pred</code> um die anhand von <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> für <code>mod_logit</code> geschätzten Wahrscheinlichkeiten von <span class="math inline">\(Y=1\vert X\)</span> für die Regressorwerte in <code>X</code>.</p>
<div class="cell">
<div>
<div id="webr-17">

</div>
<script type="webr-17-contents">
eyJjb2RlIjoiIyBnZXNjaC4gV1NLLUZ1bmt0aW9uIGdlbS4gTG9naXQtTW9kZWxsIGhpbnp1ZsO8Z2VuXG5wcmVkIDwtIHByZWQgJT4lXG4gIG11dGF0ZShcbiAgICBMb2dpdCA9IHByZWRpY3QobW9kX2xvZ2l0LCB0aWJibGUoWCksIHR5cGUgPSBcInJlc3BvbnNlXCIpXG4gICkiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWV9fQ==
</script>
</div>
</div>
<p>Anhand der Vorhersagen in <code>pred</code> können wir die im Objekt <code>p</code> gespeicherte Grafik um die geschätzte Regressionsfunktion für das Logit-Modell erweitern.</p>
<div class="cell">
<div>
<div id="webr-18">

</div>
<script type="webr-18-contents">
eyJjb2RlIjoiIyBHcmFmaWsgbWl0IExvZ2l0LWZpdCBlcndlaXRlcm5cbnAgKyBcbiAgZ2VvbV9saW5lKFxuICAgIGRhdGEgPSBwcmVkLCBcbiAgICBtYXBwaW5nID0gYWVzKHkgPSBMb2dpdCwgY29sb3IgPSBcIkxvZ2l0XCIpLFxuICAgIGx3ZCA9IC43NVxuICApICtcbiAgICBzY2FsZV9jb2xvcl9tYW51YWwoXG4gICAgbmFtZSA9IFwiXCIsXG4gICAgdmFsdWVzID0gYyhcbiAgICAgIFwiV2FocmhlaXRcIiA9IFwiYmxhY2tcIixcbiAgICAgIFwiTFBNXCIgPSBcInN0ZWVsYmx1ZVwiLCBcbiAgICAgIFwiUHJvYml0XCIgPSBcIm9yYW5nZVwiLFxuICAgICAgXCJMb2dpdFwiID0gXCJkYXJrcmVkXCJcbiAgICApXG4gICkiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWV9fQ==
</script>
</div>
</div>
<p>Die Logit-Regression kann den wahren Zusammenhang gut abbilden und ist praktisch nicht von der Probit-Schätzung unterscheidbar.</p>
</section><section id="modellgüte" class="level3 page-columns page-full" data-number="4.2.5"><h3 data-number="4.2.5" class="anchored" data-anchor-id="modellgüte">
<span class="header-section-number">4.2.5</span> Modellgüte</h3>
<p>Ähnlich wie bei linearer Regression kann die Anpassung von generalisierten linearen Modellen an die Daten mit Anpassungsmaßen verglichen werden. In generalisierten linearen Modellen für binäre Outcome-Variablen kann hierzu die <em>Deviance</em> verwendet werden. Für eine Schätzung anhand der Beobachtungen <span class="math inline">\(i=1,\dots,n\)</span> berechnet man die Deviance <span class="math inline">\(D\)</span> als <span class="math display">\[\begin{align*}
  D = -2 \sum_{i=1}^{n} \left[ y_i \cdot \log\left(\widehat{P}_i\right) + (1 - y_i) \cdot \log\left(1 - \widehat{P}_i\right) \right].
\end{align*}\]</span> <span class="math inline">\(D\)</span> quantifiziert die Abweichung eines geschätzten Modells von einem perfekt passenden Modell.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> Eine geringere Deviance deutet darauf hin, dass das Modell die Daten besser erklärt. Eine R-Funktion zur Anwendung für Objekte des Typs <code>glm</code> ist <code><a href="https://rdrr.io/r/stats/deviance.html">deviance()</a></code>.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;Im Allgemeinen vergleicht Deviance die Log-Likelihood des geschätzten Modells mit der Log-Likelihood des perfekten Modells.</p></div></div><div class="cell">
<div>
<div id="webr-19">

</div>
<script type="webr-19-contents">
eyJjb2RlIjoiIyBEZXZpYW5jZSBiZXJlY2huZW5cbmxpc3QoXG4gIFwiUHJvYml0XCIgPSBtb2RfcHJvYml0LCBcbiAgXCJMb2dpdFwiID0gbW9kX2xvZ2l0XG4pICU+JSBcbiAgbWFwX2RibCguZiA9IGRldmlhbmNlKSIsImF0dHIiOnsiZXZhbCI6dHJ1ZSwiZWRpdCI6dHJ1ZX19
</script>
</div>
</div>
<p>Die Deviance für das Probit-Modell ist tatsächlich etwas geringer als für das Logit-Modell.</p>
<p>Ähnlich wie <span class="math inline">\(R^2\)</span> für lineare Regression misst die Deviance <span class="math inline">\(D\)</span> lediglich die Anpassung des Modells an die beobachteten Daten. Daher eignet sich <span class="math inline">\(D\)</span> nur bedingt als Maß zur Einschätzung der Tauglichkeit eines Modells für Out-of-sample-Vorhersagen. Abhängig vom Ziel der Modellierung kann es hilfreich sein, eine robuste Einschätzung der Vorhersage-Güte unter Berücksichtigung der Modellkomplexität vorzunehmen. Hierfür werden oft Informationskriterien verwendet. Das Akaike-Informationskriterium (AIC) <span class="math display">\[\begin{align*}
  \text{AIC} = 2k - 2 \log(\widehat{\mathcal{L}})
\end{align*}\]</span> ist ein Maß zur Bewertung der Güte eines Modells unter Berücksichtigung der Modellkomplexität. Das AIC wägt die Anpassung des Modells an die Daten (gemessen durch die maximierte Likelihood-Funktion <span class="math inline">\(\widehat{\mathcal{L}}\)</span><a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>) und die Komplexität (gemessen als Funktion der Regressoranzahl <span class="math inline">\(k\)</span>) gegeneinander ab. Hierbei werden Modelle mit weniger Parametern bevorzugt, wenn sie die Daten ähnlich gut erklären, sodass eine Überanpassung und damit eine schlechte Vorhersagefähigkeit vermieden werden. In R können wir das AIC für Modell-Objekte mit <code><a href="https://rdrr.io/r/stats/AIC.html">AIC()</a></code> berechnen.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;<span class="math inline">\(\widehat{\mathcal{L}}\)</span> meint die Likelihood-Funktion für die geschätzten Koeffizienten.</p></div></div><div class="cell">
<div>
<div id="webr-20">

</div>
<script type="webr-20-contents">
eyJjb2RlIjoiIyBBSUMgYmVyZWNobmVuXG5saXN0KFxuICBQcm9iaXQgPSBtb2RfcHJvYml0LCBcbiAgTG9naXQgPSBtb2RfbG9naXRcbikgJT4lIFxuICBtYXBfZGJsKC5mID0gQUlDKSIsImF0dHIiOnsiZXZhbCI6dHJ1ZSwiZWRpdCI6dHJ1ZX19
</script>
</div>
</div>
<p>Auch das AIC zeigt an, dass die Schätzung des Probit-Modells in <code>mod_probit</code> besser geeignet für die Modiellierung von <code>simdata</code> ist als das Logit-Modell <code>mod_logit</code>.</p>
</section><section id="beispiel-klassifikation-von-palmer-piniguinen" class="level3" data-number="4.2.6"><h3 data-number="4.2.6" class="anchored" data-anchor-id="beispiel-klassifikation-von-palmer-piniguinen">
<span class="header-section-number">4.2.6</span> Beispiel: Klassifikation von Palmer-Piniguinen</h3>
<p>Mit den in diesem Kapitel betrachteten Methoden können wir Modelle zur Klassifikation von Pinguinen in <code><a href="https://allisonhorst.github.io/palmerpenguins/reference/penguins.html">palmerpenguins::penguins</a></code> hinsichtlich ihres Geschlechts konstruieren. Hierfür nutzen wir den bereinigten Datensatz <code>penguins_cleaned</code> und transformieren zunächst die abhängige Variable <code>sex</code> in ein numerisches Format.</p>
<div class="cell">
<div>
<div id="webr-21">

</div>
<script type="webr-21-contents">
eyJjb2RlIjoiIyAnc2V4JyB0cmFuc2Zvcm1pZXJlblxucGVuZ3VpbnNfY2xlYW5lZCA8LSBwZW5ndWluc19jbGVhbmVkICU+JSBcbiAgbXV0YXRlKFxuICAgICMgc2V4IGluIDAsMS1jb2RpZXJ0ZSBWYXJpYWJsZSB1bXdhbmRlbG5cbiAgICBzZXggPSBpZl9lbHNlKHNleCA9PSBcImZlbWFsZVwiLCAxLCAwKVxuICAgIClcblxuIyDDnGJlcnByw7xmZW5cbnBlbmd1aW5zX2NsZWFuZWQgJT4lXG4gIHNlbGVjdChzZXgpICU+JVxuICBzbGljZV9oZWFkKG4gPSAxMCkiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWV9fQ==
</script>
</div>
</div>
<p>Wir schätzen nachfolgend ein lineares Wahrscheinlichkeitsmodell <code>penguins_lp</code>, ein Probit-Modell <code>penguins_probit</code> sowie ein Logit-Modell <code>penguins_logit</code> die jeweils <code>sex</code> anhand der simplen Spezikation des linearen Prädiktors <span class="math display">\[z = \beta_0 + \beta_1 \textup{bill\_depth}\]</span> erklären.</p>
<div class="cell">
<div>
<div id="webr-22">

</div>
<script type="webr-22-contents">
eyJjb2RlIjoiIyBMaW5lYXJlcyBNb2RlbGxcbnBlbmd1aW5zX2xwIDwtIGxtKFxuICBmb3JtdWxhID0gc2V4IH4gYmlsbF9kZXB0aCwgXG4gIGRhdGEgPSBwZW5ndWluc19jbGVhbmVkXG4pIFxuXG4jIFJvYnVzdGUgWnVzYW1tZW5mYXNzdW5nXG5wZW5ndWluc19scCAlPiVcbiAgY29lZnRlc3QodmNvdiA9IHZjb3ZIQywgdHlwZSA9IFwiSEMxXCIpICU+JVxuICB0aWR5KCkiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWV9fQ==
</script>
</div>
</div>
<div class="cell">
<div>
<div id="webr-23">

</div>
<script type="webr-23-contents">
eyJjb2RlIjoiIyBQcm9iaXQtTW9kZWxsXG5wZW5ndWluc19wcm9iaXQgPC0gZ2xtKFxuICBmb3JtdWxhID0gc2V4IH4gYmlsbF9kZXB0aCwgXG4gIGRhdGEgPSBwZW5ndWluc19jbGVhbmVkLCBcbiAgZmFtaWx5ID0gYmlub21pYWwoXCJwcm9iaXRcIilcbilcblxuIyBSb2J1c3RlIFp1c2FtbWVuZmFzc3VuZ1xucGVuZ3VpbnNfcHJvYml0ICU+JSBcbiAgICBjb2VmdGVzdCh2Y292ID0gdmNvdkhDLCB0eXBlID0gXCJIQzFcIikgJT4lXG4gIHRpZHkoKSIsImF0dHIiOnsiZXZhbCI6dHJ1ZSwiZWRpdCI6dHJ1ZX19
</script>
</div>
</div>
<div class="cell">
<div>
<div id="webr-24">

</div>
<script type="webr-24-contents">
eyJjb2RlIjoiIyBMb2dpdC1Nb2RlbGxcbnBlbmd1aW5zX2xvZ2l0IDwtIGdsbShcbiAgZm9ybXVsYSA9IHNleCB+IGJpbGxfZGVwdGgsIFxuICBkYXRhID0gcGVuZ3VpbnNfY2xlYW5lZCwgXG4gIGZhbWlseSA9IGJpbm9taWFsKFwibG9naXRcIilcbilcblxuIyBSb2J1c3RlIFp1c2FtbWVuZmFzc3VuZ1xucGVuZ3VpbnNfbG9naXQgJT4lIFxuICBjb2VmdGVzdCh2Y292ID0gdmNvdkhDLCB0eXBlID0gXCJIQzFcIikgJT4lXG4gIHRpZHkoKSIsImF0dHIiOnsiZXZhbCI6dHJ1ZSwiZWRpdCI6dHJ1ZX19
</script>
</div>
</div>
<p>Mit <code><a href="https://modelsummary.com/man/modelsummary.html">modelsummary::modelsummary()</a></code> können wir die wichtigsten Ergebnisse der Regressionen in einer publikationsfähigen Tabelle darstellen. Hierzu übergeben wir dem Argument <code>models</code> eine (benannte) Liste der geschätzten Modelle. Bei Angabe von <code>vcov = "HC1"</code> werden robuste Standardfehler ausgegeben.</p>
<div class="cell">
<div>
<div id="webr-25">

</div>
<script type="webr-25-contents">
eyJjb2RlIjoibGlicmFyeShtb2RlbHN1bW1hcnkpXG5cbiMgR2VzY2jDpHR6dGUgTW9kZWxsZVxubW9kZWxzdW1tYXJ5KFxuICBtb2RlbHMgPSBcbiAgICBsaXN0KFxuICAgICAgXCJMUE1cIiA9IHBlbmd1aW5zX2xwLFxuICAgICAgXCJQcm9iaXRcIiA9IHBlbmd1aW5zX3Byb2JpdCxcbiAgICAgIFwiTG9naXRcIiA9IHBlbmd1aW5zX2xvZ2l0XG4gICAgKSwgXG4gIG91dHB1dCA9IFwiZ3RcIiwgXG4gIHZjb3YgPSBcIkhDMVwiLCBcbiAgc3RhcnMgPSBUUlVFLCBcbikgJT4lXG4gIHRhYl9oZWFkZXIoXG4gICAgdGl0bGUgPSBcIk1vZGVsbGUgZsO8ciBHZXNjaGxlY2h0IHYuIFBpbmd1aW5lblwiXG4gICkiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWV9fQ==
</script>
</div>
</div>
<p>Die geschätzten negativen und signifikanten Koeffizienten von <span class="math inline">\(\textup{bill\_depth}\)</span> erfassen den Zusammenhang, dass Pinguine mit größeren Schnäbeln tendenziell männlich sind: Je größer <span class="math inline">\(\textup{bill\_depth}\)</span>, desto geringer die geschätzte Wahrscheinlichkeit, dass ein Pinguin weiblich ist. Ein Vergleich anhand des AIC zeigt, dass das Probit-Modell <code>penguins_probit</code> am besten geeignet ist.</p>
<p>Analog zur Vorgehensweise in <a href="#sec-logreg" class="quarto-xref"><span>Kapitel 4.2.3</span></a> können wir die geschätzten Modelle vergleichen, in dem wir geschätzte Wahrscheinlichkeiten <span class="math inline">\(P(Y=\textup{weiblich}\vert\textup{bill\_depth})\)</span> für eine Menge repräsentativer Werte des Regressors <code>bill_depth</code> berechnen und gemeinsam mit den Beobachtungen plotten.</p>
<div class="cell">
<div>
<div id="webr-26">

</div>
<script type="webr-26-contents">
eyJjb2RlIjoiIyBTZXF1ZW56IGbDvHIgYmlsbF9kZXB0aCBlcnN0ZWxsZW5cbmJpbGxfZGVwdGhfbmV3IDwtIHNlcShcbiAgZnJvbSA9IG1pbihwZW5ndWluc19jbGVhbmVkJGJpbGxfZGVwdGgpLCBcbiAgdG8gPSBtYXgocGVuZ3VpbnNfY2xlYW5lZCRiaWxsX2RlcHRoKSwgXG4gIGJ5ID0gLjFcbilcblxuIyBWb3JoZXJzYWdlbiBXU0sgbWl0ICdiaWxsX2RlcHRoX25ldydcbnByZWRzIDwtIHRpYmJsZShcbiAgYmlsbF9kZXB0aCA9IGJpbGxfZGVwdGhfbmV3LFxuICBscCA9IHByZWRpY3QoXG4gICAgb2JqZWN0ID0gcGVuZ3VpbnNfbHAsIFxuICAgIG5ld2RhdGEgPSB0aWJibGUoYmlsbF9kZXB0aCA9IGJpbGxfZGVwdGhfbmV3KVxuICApLFxuICBwcm9iaXQgPSBwcmVkaWN0KFxuICAgIG9iamVjdCA9IHBlbmd1aW5zX3Byb2JpdCxcbiAgICBuZXdkYXRhID0gdGliYmxlKGJpbGxfZGVwdGggPSBiaWxsX2RlcHRoX25ldyksXG4gICAgdHlwZSA9IFwicmVzcG9uc2VcIlxuICApLFxuICBsb2dpdCA9IHByZWRpY3QoXG4gICAgb2JqZWN0ID0gcGVuZ3VpbnNfbG9naXQsXG4gICAgbmV3ZGF0YSA9IHRpYmJsZShiaWxsX2RlcHRoID0gYmlsbF9kZXB0aF9uZXcpLFxuICAgIHR5cGUgPSBcInJlc3BvbnNlXCJcbiAgKVxuKVxuXG4jIFByw7xmZW46XG5zbGljZV9oZWFkKHByZWRzLCBuID0gMTApIiwiYXR0ciI6eyJldmFsIjp0cnVlLCJlZGl0Ijp0cnVlfX0=
</script>
</div>
</div>
<div class="cell">
<div>
<div id="webr-27">

</div>
<script type="webr-27-contents">
eyJjb2RlIjoiIyBHZXNjaMOkdHp0ZSBiZWRpbmd0ZSBXU0sgcGxvdHRlblxucGVuZ3VpbnNfY2xlYW5lZCAlPiVcbiAgZ2dwbG90KFxuICAgIG1hcHBpbmcgPSBhZXMoeCA9IGJpbGxfZGVwdGgsIHkgPSBzZXgpXG4gICkgK1xuICBnZW9tX3BvaW50KFxuICAgIHBvc2l0aW9uID0gcG9zaXRpb25faml0dGVyKFxuICAgICAgaGVpZ2h0ID0gLjAyNSxcbiAgICAgIHNlZWQgPSAxMjM0XG4gICAgKSxcbiAgICBhbHBoYSA9IC4yNSxcbiAgICBjb2xvciA9IFwiYmx1ZVwiXG4gICkgK1xuICBnZW9tX2xpbmUoXG4gICAgZGF0YSA9IHByZWRzLCBcbiAgICBtYXBwaW5nID0gYWVzKHkgPSBscCwgY29sb3IgPSBcIkxQTVwiKVxuICApICtcbiAgZ2VvbV9saW5lKFxuICAgIGRhdGEgPSBwcmVkcywgXG4gICAgbWFwcGluZyA9IGFlcyh5ID0gcHJvYml0LCBjb2xvciA9IFwiUHJvYml0XCIpXG4gICkgK1xuICBnZW9tX2xpbmUoXG4gICAgZGF0YSA9IHByZWRzLCBcbiAgICBtYXBwaW5nID0gYWVzKHkgPSBsb2dpdCwgY29sb3IgPSBcIkxvZ2l0XCIpXG4gICkgK1xuICBzY2FsZV9jb2xvcl9tYW51YWwoXG4gICAgbmFtZSA9IFwiTW9kZWxsZVwiLFxuICAgIHZhbHVlcyA9IGMoXG4gICAgICBcIkxQTVwiID0gXCJzdGVlbGJsdWVcIiwgXG4gICAgICBcIlByb2JpdFwiID0gXCJvcmFuZ2VcIixcbiAgICAgIFwiTG9naXRcIiA9IFwiZGFya3JlZFwiXG4gICAgKVxuICApICtcbiAgbGFicyh0aXRsZSA9IFwiTW9kZWxsaWVydW5nIHYuIFBpbmd1aW4tR2VzY2hsZWNodCBtaXQgUmVncmVzc2lvblwiKSArXG4gIHRoZW1lX2Nvd3Bsb3QoKSArXG4gIHRoZW1lKGxlZ2VuZC5wb3NpdGlvbiA9IFwidG9wXCIpIiwiYXR0ciI6eyJldmFsIjp0cnVlLCJlZGl0Ijp0cnVlfX0=
</script>
</div>
</div>
<p>Die geschätzten Regressionsfunktionen unterscheiden sich für den Bereich beobachteter Werte von <span class="math inline">\(bill\_depth\)</span> nur wenig. Die Grafik zeigt, dass die Schätzungen mit Probit- und Logit-Ansatz nur wenig Nicht-Linearität aufweisen, sodass eine (leichter interpretierbare) Modellierung mit dem linearen Wahrscheinlichkeitsmodell <code>penguins_lp</code> hier zulässig scheint.</p>
<p>Die Klassifizierung der Pinguine im Datensatz hinsichtlich ihres Geschlechts anhand vorhergesagter Wahrscheinlichkeiten <span class="math inline">\(\widehat{P}_i\)</span> kann durch Abgleich mit einem Grenzwert erfolgen. Ein Beispiel ist <span class="math display">\[\begin{align}
  \widehat{Y}_i = \begin{cases}
    \textup{weiblich}, &amp; \widehat{P}_i \geq .5,\\
    \textup{männlich}, &amp; \textup{sonst.}
  \end{cases}\label{eq:pengclass}
\end{align}\]</span></p>
<p>Wir können diesen Ansatz in R implementieren, indem wir zunächst die für den Datensatz angepassten Wahrscheinlichkeiten <code>fitted</code> aus den Modell-Objekten auslesen.</p>
<div class="cell">
<div>
<div id="webr-28">

</div>
<script type="webr-28-contents">
eyJjb2RlIjoiKFxuICBXU0sgPC0gcGVuZ3VpbnNfY2xlYW5lZCAlPiVcbiAgc2VsZWN0KHNleCkgJT4lXG4gIG11dGF0ZShcbiAgICBsaXN0KFxuICAgICAgbGluZWFyID0gcGVuZ3VpbnNfbHAsIFxuICAgICAgcHJvYml0ID0gcGVuZ3VpbnNfcHJvYml0LFxuICAgICAgbG9naXQgPSBwZW5ndWluc19sb2dpdFxuICAgICkgJT4lIFxuICAgICAgbWFwX2RmYyguZiA9IH4gLiRmaXR0ZWQpICAgICBcbiAgKVxuKSIsImF0dHIiOnsiZXZhbCI6dHJ1ZSwiZWRpdCI6dHJ1ZX19
</script>
</div>
</div>
<p>Für die Klassifikation der Pinguine anhand der jeweiligen geschätzten Wahrscheinlichkeiten wenden wir die Regel <span class="math inline">\(\eqref{eq:pengclass}\)</span> mit <code><a href="https://dplyr.tidyverse.org/reference/across.html">across()</a></code> spaltenweise für die Modelle an und erzeugen neue Spalten mit vorhersagen des Geschlechts. Mit <code>.names = "{.col}_pred"</code> erhalten die neuen Spalten das Suffix <code>_pred</code>.</p>
<div class="cell">
<div>
<div id="webr-29">

</div>
<script type="webr-29-contents">
eyJjb2RlIjoiIyBLbGFzc2lmaWthdGlvbiBmLiBHZXNjaGxlY2h0IGR1cmNoZsO8aHJlblxudm9yaCA8LSBXU0sgJT4lXG4gIG11dGF0ZShcbiAgICBhY3Jvc3MoXG4gICAgICBjKGxpbmVhcjpsb2dpdCksIFxuICAgICAgLmZucyA9IH4gKC4gPiAwLjUpID09IHNleCxcbiAgICAgIC5uYW1lcyA9IFwiey5jb2x9X3ByZWRcIilcbiAgICApIiwiYXR0ciI6eyJldmFsIjp0cnVlLCJlZGl0Ijp0cnVlfX0=
</script>
</div>
</div>
<p>Mit <code><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarise()</a></code> berechnen wir nun den Anteil korrekter Vorhersagen.</p>
<div class="cell">
<div>
<div id="webr-30">

</div>
<script type="webr-30-contents">
eyJjb2RlIjoiIyBHZW5hdWlna2VpdCBkZXIgVm9yaGVyc2FnZSBiZXJlY2huZW5cbnZvcmggJT4lIFxuICBzdW1tYXJpc2UoXG4gICAgYWNyb3NzKGxpbmVhcl9wcmVkOmxvZ2l0X3ByZWQsIG1lYW4pXG4gICkiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWV9fQ==
</script>
</div>
</div>
<p>In diesem Beispiel unterscheiden sich die Vorhersagen der drei Modelle für den Grenzwert 0.5 nicht.</p>
</section></section><section id="sec-poissonreg" class="level2" data-number="4.3"><h2 data-number="4.3" class="anchored" data-anchor-id="sec-poissonreg">
<span class="header-section-number">4.3</span> Modellierung von Zählvariablen</h2>
<p>Eine weitere Klasse von <span class="math inline">\(Y\)</span> für die sich der Regressionsansatz von einfacher linearer Regression unterscheidet, sind <em>Zählvariablen</em>: Variablen, die diskrete, nicht-negative Werte annehmen. Wenn die abhängige Variable <span class="math inline">\(Y\)</span> Ereignisse in einem bestimmten Zeitraum misst (wie z.B. die Anzahl der Verkehrsunfälle in Essen innerhalb eines Monats) und weitere Bedingungen erfüllt sind, folgt <span class="math inline">\(Y\)</span> einer Poisson-Verteilung und kann mit Poisson-Regression modelliert werden. Wir erläutern nachfolgend die wesentlichen Komponenten von Poisson-Regression und diskutieren ein R-Beispiel mit fiktiven Daten.</p>
<section id="poisson-verteilung" class="level3" data-number="4.3.1"><h3 data-number="4.3.1" class="anchored" data-anchor-id="poisson-verteilung">
<span class="header-section-number">4.3.1</span> Poisson-Verteilung</h3>
<p>Die Zufallsvariable <span class="math inline">\(Y\)</span> folgt einer Poisson-Verteilung mit Parameter <span class="math inline">\(\lambda\)</span>, wenn</p>
<ol type="1">
<li><p><strong>die Ereignisse unabhängig voneinander auftreten:</strong> Das Auftreten eines Ereignisses beeinflusst nicht die Wahrscheinlichkeit, dass ein weiteres Ereignis auftritt.</p></li>
<li><p><strong>die Ereignisse einzeln auftreten:</strong> Die Wahrscheinlichkeit, dass in einem sehr kleinen Intervall (im Sinne von <span class="math inline">\([a,b]\)</span> für <span class="math inline">\(a \to b\)</span>) mehr als ein Ereignis auftritt, ist vernachlässigbar.</p></li>
<li><p><strong>die Rate der Ereignisse konstant ist:</strong> Die durchschnittliche Anzahl der Ereignisse pro Zeiteinheit oder pro Raumeinheit <span class="math inline">\(\lambda\)</span> ist konstant.</p></li>
</ol>
<p>Die Wahrscheinlichkeitsfunktion von <span class="math inline">\(Y\)</span> ist</p>
<p><span class="math display">\[\begin{align}
P(Y = y) = \frac{\lambda^y e^{-\lambda}}{y!} \quad \text{für} \quad y = 0, 1, 2, \ldots,\label{eq:poissonpmf}
\end{align}\]</span> wobei <span class="math inline">\(\lambda\)</span> sowohl der Erwartungswert als auch die Varianz der Verteilung ist, <span class="math display">\[\textup{E}(Y) = \textup{Var}(Y) = \lambda.\]</span></p>
<p>Die nächste Grafik zeigt die diskrete (Wahrscheinlichkeitsmasse-)Funktion <span class="math inline">\(\eqref{eq:poissonpmf}\)</span> für eine Poisson-verteilte Zufallsvariable <span class="math inline">\(Y\)</span> mit <span class="math inline">\(\lambda = 5\)</span> für den Wertebereich von 0 bis 15.</p>
<div class="cell">
<div>
<div id="webr-31">

</div>
<script type="webr-31-contents">
eyJjb2RlIjoidGliYmxlKFxuICAgIHggPSAwOjE1LFxuICAgIGRlbnMgPSBkcG9pcyh4LCBsYW1iZGEgPSA1KVxuKSAlPiVcbiAgICBcbiAgICBnZ3Bsb3QoIFxuICAgICAgICBtYXBwaW5nID0gYWVzKHggPSB4LCB5ID0gZGVucylcbiAgICApICtcbiAgICBnZW9tX2JhcihcbiAgICAgIHN0YXQgPSBcImlkZW50aXR5XCIsIFxuICAgICAgZmlsbCA9IFwic3RlZWxibHVlXCIsXG4gICAgICBjb2xvciA9IFwid2hpdGVcIlxuICAgICkgK1xuICAgIHNjYWxlX3hfY29udGludW91cyhicmVha3MgPSAwOjE1KSArIFxuICAgIGxhYnMoXG4gICAgICAgIHRpdGxlID0gXCJQb2lzc29uLURpY2h0ZWZ1bmt0aW9uIGbDvHIgbGFtYmRhID0gNVwiLCBcbiAgICAgICAgeSA9IFwiRGljaHRlXCJcbiAgICApICtcbiAgICB0aGVtZV9jb3dwbG90KCkiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWUsImxhYmVsIjoiZmlnLXBvaXNzb25kZW5zaXR5In19
</script>
</div>
</div>
</section><section id="poisson-regression" class="level3" data-number="4.3.2"><h3 data-number="4.3.2" class="anchored" data-anchor-id="poisson-regression">
<span class="header-section-number">4.3.2</span> Poisson-Regression</h3>
<p>Wie für die bisher betrachteten Regressionsansätzen modelliert Poisson-Regression den Erwartungswert (und damit gleichzeitig die Varianz) <span class="math inline">\(\lambda\)</span> der abhängigen Variable <span class="math inline">\(Y\)</span> als eine Funktion der Regressoren <span class="math inline">\(\mathbf{X} = (X_1, X_2, \ldots, X_k)\)</span>. Unter Annahme einer Poisson-Verteilung kann Poisson-Regression als generalisiertes lineares Modell verstanden werden, wobei eine logarithmische Verknüpfungsfunktion für den linearen Prädiktor <span class="math inline">\(\mathbf{X}_i^\top \boldsymbol{\beta}\)</span> verwendet wird:</p>
<p><span class="math display">\[\begin{align*}
\log(\lambda_i) &amp;= \mathbf{X}_i^\top \boldsymbol{\beta},
\end{align*}\]</span> sodass <span class="math display">\[\begin{align*}
\lambda_i &amp;= \exp(\mathbf{X}_i^\top \boldsymbol{\beta}),
\end{align*}\]</span> wobei</p>
<ul>
<li>
<span class="math inline">\(\lambda_i = \textup{E}(Y_i\vert \mathbf{X}_i) = \textup{Var}(Y_i\vert \mathbf{X}_i)\)</span> für Beobachtung <span class="math inline">\(i\)</span>,</li>
<li>
<span class="math inline">\(\mathbf{X}_i\)</span> der Vektor der unabhängigen Variablen für Beobachtung <span class="math inline">\(i\)</span> ist, und</li>
<li>
<span class="math inline">\(\boldsymbol{\beta}\)</span> der Vektor der Regressionskoeffizienten ist.</li>
</ul></section><section id="schätzung-2" class="level3" data-number="4.3.3"><h3 data-number="4.3.3" class="anchored" data-anchor-id="schätzung-2">
<span class="header-section-number">4.3.3</span> Schätzung</h3>
<p>Die Likelihood-Funktion für <span class="math inline">\(n\)</span> Beobachtungen ist</p>
<p><span class="math display">\[\begin{align}
L(\boldsymbol{\beta}) = \prod_{i=1}^n \frac{\lambda_i^{y_i} e^{-\lambda_i}}{y_i!}.
\end{align}\]</span></p>
<p>Die Log-Likelihood-Funktion ist daher</p>
<p><span class="math display">\[\begin{align}
\mathcal{L}(\boldsymbol{\beta}) = \sum_{i=1}^n \left( y_i \log(\lambda_i) - \lambda_i - \log(y_i!). \right)
\end{align}\]</span></p>
<p>Da <span class="math inline">\(\lambda_i = \exp(\mathbf{X}_i^\top \boldsymbol{\beta})\)</span>, wird die Log-Likelihood-Funktion zu</p>
<p><span class="math display">\[\begin{align}
\mathcal{L}(\boldsymbol{\beta}) = \sum_{i=1}^n \left( y_i (\mathbf{X}_i^\top \boldsymbol{\beta}) - \exp(\mathbf{X}_i^\top \boldsymbol{\beta}) - \log(y_i!) \right)
\end{align}\]</span></p>
<p>Den ML-Schätzer <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span> erhalten wir durch Maximierung der Log-Likelihoodfunktion <span class="math inline">\(\mathcal{L}(\boldsymbol{\beta})\)</span>. Die R-Implementierung von Poisson-Regression in <code><a href="https://rdrr.io/r/stats/glm.html">stats::glm()</a></code> wird mittels <code>family = poisson(link = "log")</code> aufgerufen.</p>
</section><section id="interpretation-der-koeffizienten" class="level3" data-number="4.3.4"><h3 data-number="4.3.4" class="anchored" data-anchor-id="interpretation-der-koeffizienten">
<span class="header-section-number">4.3.4</span> Interpretation der Koeffizienten</h3>
<p>Die Koeffizienten <span class="math inline">\(\boldsymbol{\beta}\)</span> in der Poisson-Regression haben eine logarithmisch-lineare Beziehung zur Zählvariable. Für einen bestimmten Koeffizienten <span class="math inline">\(\beta_j\)</span> ist die Interpretation wie folgt:</p>
<p>Eine Änderung der unabhängigen Variable <span class="math inline">\(X_j\)</span> um eine Einheit führt zu einer Änderung des <em>Logarithmus</em> des Erwartungswertes von <span class="math inline">\(Y\)</span> um <span class="math inline">\(\beta_j\)</span>. Der Erwartungswert <span class="math inline">\(\lambda\)</span> ändert sich also <em>multiplikativ</em> um den Faktor <span class="math inline">\(\exp(\beta_j)\)</span>.</p>
<p>Als Beispiel betrachten wir den linearen Prädiktor</p>
<p><span class="math display">\[\begin{align*}
  \log(\lambda) = \beta_0 + \beta_1 X.
\end{align*}\]</span></p>
<p>Für eine Änderung von <span class="math inline">\(X\)</span> um <span class="math inline">\(\Delta X\)</span> erhalten wir</p>
<p><span class="math display">\[\begin{align*}
   \lambda =&amp;\, \exp(\beta_0 + \beta_1 X) \\
    \lambda + \delta\lambda =&amp;\, \exp(\beta_0 + \beta_1 (X + \Delta X)) \\
    =&amp;\, \exp(\beta_0 + \beta_1 X) \cdot \exp(\beta\Delta X) \\
    =&amp;\, \lambda \cdot \exp(\beta\Delta X)
\end{align*}\]</span></p>
<p>Angenommen <span class="math inline">\(X\)</span> ist die Anzahl durchgeführter Werbekampagnen und die abhängige Zählvariable <span class="math inline">\(Y\)</span> misst die Anzahl der Verkäufe des beworbenen Produkts pro Monat.</p>
<p>Wenn <span class="math inline">\(\beta_1 = 0.5\)</span>, bedeutet dies, dass jede zusätzliche Werbekampagne (<span class="math inline">\(\Delta X = 1\)</span>) die erwartete Anzahl der Verkäufe pro Monat um einen Faktor von <span class="math inline">\(\exp(0.5) \approx 1.65\)</span> erhöht:</p>
<p>Das heißt, die <em>Rate</em> der Verkäufe steigt um 65% für jede zusätzliche Werbekampagne.</p>
<p>Zur Veranschaulichung der Schätzung einer Poisson-Regression für dieses Beispiel erzeugen wir Poisson-verteilte Daten für <span class="math display">\[\begin{align*}
  \log(\lambda) = 2 + 0.4 \cdot X
\end{align*}\]</span> und ziehen <span class="math inline">\(X\)</span> gleichverteilt aus <span class="math inline">\(\{1,2,\dots,8\}\)</span>.</p>
<div class="cell">
<div>
<div id="webr-32">

</div>
<script type="webr-32-contents">
eyJjb2RlIjoiIyBTZXR6ZSBkZW4gWnVmYWxsc3phaGxlbmdlbmVyYXRvciBmw7xyIFJlcHJvZHV6aWVyYmFya2VpdFxuc2V0LnNlZWQoMTIzNClcblxuIyBBbnphaGwgZGVyIEJlb2JhY2h0dW5nZW5cbm4gPC0gNTAwXG5cbiMgWsO8Z2UgZsO8ciB1bmFiaMOkbmdpZ2UgVmFyaWFibGUgWCAoQW56YWhsIGRlciBXZXJiZWthbXBhZ25lbilcblggPC0gc2FtcGxlKDE6OCwgcmVwbGFjZSA9IFQsIHNpemUgPSBuKVxuXG4jIEVyd2FydHVuZ3N3ZXJ0ZVxubGFtYmRhIDwtIGV4cCgyICsgMC40ICogWClcblxuIyBBYmjDpG5naWdlIFZhcmlhYmxlIFkgKEFuemFobCBkZXIgVmVya8OkdWZlKSBhbHMgUG9pc3Nvbi12ZXJ0ZWlsdGUgWnVmYWxsc3ZhcmlhYmxlLCBnZWdlYmVuIGxhbWJkYVxuWSA8LSBtYXBfZGJsKFxuICAueCA9IDE6biwgXG4gIC5mID0gfiBycG9pcyhcbiAgICBuID0gMSwgbGFtYmRhID0gbGFtYmRhWy54XVxuICApXG4pXG4gIFxuIyBEYXRlbiBpbiB0aWJibGUgc2FtbWVsblxuZGF0IDwtIHRpYmJsZShcbiAgS2FtcGFnbmVuID0gWCwgXG4gIFZlcmthZXVmZSA9IFlcbiAgKVxuXG4jIMOcYmVyYmxpY2tcbnNsaWNlX2hlYWQoZGF0LCBuID0gMTApIiwiYXR0ciI6eyJldmFsIjp0cnVlLCJlZGl0Ijp0cnVlfX0=
</script>
</div>
</div>
<p>Die Züge aus der abhängigen Variablen visualieren wir mit einem Häufigkeits-Histogramm.</p>
<div class="cell">
<div>
<div id="webr-33">

</div>
<script type="webr-33-contents">
eyJjb2RlIjoiIyBIaXN0b2dyYW1tIGRlciBBYmguIFZhcmlhYmxlXG5nZ3Bsb3QoXG4gIGRhdGEgPSBkYXQsIFxuICBtYXBwaW5nID0gYWVzKHggPSBWZXJrYWV1ZmUpXG4gICkgK1xuICBnZW9tX2hpc3RvZ3JhbShiaW53aWR0aCA9IDIpICtcbiAgbGFicyhcbiAgICB0aXRsZSA9IFwiUG9pc3Nvbi12ZXJ0ZWlsdGUgRGF0ZW5cIlxuICApICtcbiAgdGhlbWVfY293cGxvdCgpIiwiYXR0ciI6eyJldmFsIjp0cnVlLCJlZGl0Ijp0cnVlfX0=
</script>
</div>
</div>
<p>Wir schätzen das Modell und extrahieren die robuste Zusammenfassung mit <code><a href="https://generics.r-lib.org/reference/tidy.html">broom::tidy()</a></code>.</p>
<div class="cell">
<div>
<div id="webr-34">

</div>
<script type="webr-34-contents">
eyJjb2RlIjoiIyBQb2lzc29uLVJlZ3Jlc3Npb24gc2Now6R0emVuXG5tb2RfcG9pc3NvbiA8LSBnbG0oXG4gIGZvcm11bGEgPSBWZXJrYWV1ZmUgfiBLYW1wYWduZW4sIFxuICBmYW1pbHkgPSBwb2lzc29uKGxpbmsgPSBcImxvZ1wiKSwgXG4gIGRhdGEgPSBkYXRcbilcblxuIyBadXNhbW1lbmZhc3N1bmcgZGVzIGdlc2NoLiBNb2RlbGxzXG5tb2RfcG9pc3NvbiAlPiVcbiAgY29lZnRlc3QodmNvdiA9IHZjb3ZIQywgdHlwZSA9IFwiSEMxXCIpICU+JVxuICB0aWR5KCkiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWV9fQ==
</script>
</div>
</div>
<p>Die ML-Schätzung des Poisson-Modells liefert für die verwendete Stichprobe von 500 Beobachtungen Koeffizienten-Schätzungen nahe der wahren Parameter. Zur Veranschaulichung des geschätzten Modells überlagern wir die simulierten Datenpunkte aus <code>dat</code> mit der anhand von <code>mod_poisson</code> geschätzten Anzahl der Verkäufe je Anzahl an Werbekampagnen.</p>
<div class="cell">
<div>
<div id="webr-35">

</div>
<script type="webr-35-contents">
eyJjb2RlIjoiIyBWZWt0b3IgZsO8ciBLYW1wYWduZW5cbkthbXBhZ25lbl9uZXcgPC0gdGliYmxlKEthbXBhZ25lbiA9IDE6OClcblxuIyBWb3JoZXJzYWdlbiBtaXQgTW9kZWxsXG5wcmVkIDwtIHRpYmJsZShcbiAgS2FtcGFnbmVuID0gMTo4LFxuICBwcmVkaWN0ZWQgPSBwcmVkaWN0KFxuICAgIG1vZF9wb2lzc29uLCBcbiAgICBuZXdkYXRhID0gS2FtcGFnbmVuX25ldyxcbiAgICB0eXBlID0gXCJyZXNwb25zZVwiXG4gIClcbilcblxuIyBTaW11bGllcnRlIERhdGVuIHVuZCBTY2jDpHR6dW5nZW5cbmdncGxvdCgpICtcbiAgZ2VvbV9wb2ludChcbiAgICBkYXRhID0gZGF0LFxuICAgIG1hcHBpbmcgPSBhZXMoXG4gICAgICB4ID0gS2FtcGFnbmVuLCBcbiAgICAgIHkgPSBWZXJrYWV1ZmVcbiAgICApLCBcbiAgICBjb2xvciA9IFwiZ3JheVwiLFxuICAgIGFscGhhID0gMC4yNSwgXG4gICAgcG9zaXRpb24gPSBwb3NpdGlvbl9qaXR0ZXIod2lkdGggPSAuMSlcbiAgKSArXG4gICAgZ2VvbV9wb2ludChcbiAgICBkYXRhID0gcHJlZCxcbiAgICBtYXBwaW5nID0gYWVzKFxuICAgICAgeCA9IEthbXBhZ25lbixcbiAgICAgIHkgPSBwcmVkaWN0ZWRcbiAgICApLFxuICAgIGNvbG9yID0gXCJyZWRcIlxuICApICtcbiAgc2NhbGVfeF9jb250aW51b3VzKGJyZWFrcyA9IDE6OCkgK1xuICBsYWJzKFxuICAgIHRpdGxlID0gXCJEYXRlbnNhdHogdW5kIFBvaXNzb24tU2Now6R0enVuZ2VuIGRlciBWZXJrw6R1ZmVcIixcbiAgICB4ID0gXCJBbnphaGwgZGVyIFdlcmJla2FtcGFnbmVuXCIsXG4gICAgeSA9IFwiQW56YWhsIGRlciBWZXJrw6R1ZmVcIlxuICApICtcbiAgdGhlbWVfY293cGxvdCgpICtcbiAgdGhlbWUobGVnZW5kLnBvc2l0aW9uID0gXCJ0b3BcIikiLCJhdHRyIjp7ImV2YWwiOnRydWUsImVkaXQiOnRydWV9fQ==
</script>
</div>
</div>
</section></section><section id="zusammenfassung" class="level2" data-number="4.4"><h2 data-number="4.4" class="anchored" data-anchor-id="zusammenfassung">
<span class="header-section-number">4.4</span> Zusammenfassung</h2>
<p>In diesem Kapitel haben wir erweiterte Konzepte der Regressionsanalyse diskutiert. Anhand des Frisch-Waugh-Lovell-Theorems wurde die Wirkungsweise der Kontrolle von Kovariablen mit multipler Regression auf den interessierenden Koeffizienten (Effekt) einer Variable veranschaulicht. Weiterhin haben wir gängige Typen generalisierter linearer Modelle für binäre und Poisson-verteilte Outcome-Variablen eingeführt. Anhand relevanter Beispiele wurde gezeigt, wie diese generalisierten Regressionsmodelle in R spezifiziert, geschätzt und der resultierende Output mit Paketen wie <code>broom</code>, <code>ggplot2</code> und <code>modelsummary</code> interpretiert werden kann.</p>


<!-- -->

<script type="webr-data">
eyJwYWNrYWdlcyI6eyJwa2dzIjpbImV2YWx1YXRlIiwia25pdHIiLCJodG1sdG9vbHMiLCJicm9vbSIsImNvd3Bsb3QiLCJsbXRlc3QiLCJkcGx5ciIsImdncGxvdDIiLCJndCIsIm1vZGVsc3VtbWFyeSIsInBhbG1lcnBlbmd1aW5zIiwicHVycnIiLCJ0aWR5ciIsInJlYWRyIiwic2FuZHdpY2giXSwicmVwb3MiOltdfSwicmVuZGVyX2RmIjoiZGVmYXVsdCIsIm9wdGlvbnMiOnsiYmFzZVVybCI6Imh0dHBzOi8vd2Vici5yLXdhc20ub3JnL3YwLjQuMS8ifX0=
</script><script type="ojs-module-contents">
{"contents":[{"methodName":"interpretQuiet","cellName":"webr-widget-35","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_35;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-35","inline":false,"source":"viewof _webr_editor_35 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-35-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-35-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_35 = webROjs.process(_webr_editor_35, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-34","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_34;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-34","inline":false,"source":"viewof _webr_editor_34 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-34-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-34-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_34 = webROjs.process(_webr_editor_34, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-33","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_33;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-33","inline":false,"source":"viewof _webr_editor_33 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-33-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-33-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_33 = webROjs.process(_webr_editor_33, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-32","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_32;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-32","inline":false,"source":"viewof _webr_editor_32 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-32-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-32-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_32 = webROjs.process(_webr_editor_32, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-31","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_31;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-31","inline":false,"source":"viewof _webr_editor_31 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-31-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-31-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_31 = webROjs.process(_webr_editor_31, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-30","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_30;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-30","inline":false,"source":"viewof _webr_editor_30 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-30-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-30-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_30 = webROjs.process(_webr_editor_30, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-29","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_29;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-29","inline":false,"source":"viewof _webr_editor_29 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-29-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-29-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_29 = webROjs.process(_webr_editor_29, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-28","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_28;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-28","inline":false,"source":"viewof _webr_editor_28 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-28-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-28-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_28 = webROjs.process(_webr_editor_28, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-27","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_27;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-27","inline":false,"source":"viewof _webr_editor_27 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-27-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-27-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_27 = webROjs.process(_webr_editor_27, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-26","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_26;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-26","inline":false,"source":"viewof _webr_editor_26 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-26-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-26-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_26 = webROjs.process(_webr_editor_26, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-25","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_25;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-25","inline":false,"source":"viewof _webr_editor_25 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-25-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-25-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_25 = webROjs.process(_webr_editor_25, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-24","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_24;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-24","inline":false,"source":"viewof _webr_editor_24 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-24-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-24-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_24 = webROjs.process(_webr_editor_24, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-23","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_23;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-23","inline":false,"source":"viewof _webr_editor_23 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-23-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-23-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_23 = webROjs.process(_webr_editor_23, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-22","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_22;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-22","inline":false,"source":"viewof _webr_editor_22 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-22-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-22-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_22 = webROjs.process(_webr_editor_22, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-21","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_21;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-21","inline":false,"source":"viewof _webr_editor_21 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-21-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-21-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_21 = webROjs.process(_webr_editor_21, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-20","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_20;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-20","inline":false,"source":"viewof _webr_editor_20 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-20-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-20-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_20 = webROjs.process(_webr_editor_20, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-19","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_19;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-19","inline":false,"source":"viewof _webr_editor_19 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-19-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-19-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_19 = webROjs.process(_webr_editor_19, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-18","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_18;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-18","inline":false,"source":"viewof _webr_editor_18 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-18-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-18-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_18 = webROjs.process(_webr_editor_18, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-17","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_17;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-17","inline":false,"source":"viewof _webr_editor_17 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-17-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-17-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_17 = webROjs.process(_webr_editor_17, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-16","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_16;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-16","inline":false,"source":"viewof _webr_editor_16 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-16-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-16-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_16 = webROjs.process(_webr_editor_16, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-15","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_15;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-15","inline":false,"source":"viewof _webr_editor_15 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-15-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-15-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_15 = webROjs.process(_webr_editor_15, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-14","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_14;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-14","inline":false,"source":"viewof _webr_editor_14 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-14-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-14-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_14 = webROjs.process(_webr_editor_14, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-13","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_13;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-13","inline":false,"source":"viewof _webr_editor_13 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-13-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-13-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_13 = webROjs.process(_webr_editor_13, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-12","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_12;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-12","inline":false,"source":"viewof _webr_editor_12 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-12-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-12-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_12 = webROjs.process(_webr_editor_12, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-11","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_11;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-11","inline":false,"source":"viewof _webr_editor_11 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-11-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-11-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_11 = webROjs.process(_webr_editor_11, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-10","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_10;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-10","inline":false,"source":"viewof _webr_editor_10 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-10-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-10-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_10 = webROjs.process(_webr_editor_10, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-9","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_9;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-9","inline":false,"source":"viewof _webr_editor_9 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-9-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-9-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_9 = webROjs.process(_webr_editor_9, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-8","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_8;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-8","inline":false,"source":"viewof _webr_editor_8 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-8-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-8-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_8 = webROjs.process(_webr_editor_8, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-7","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_7;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-7","inline":false,"source":"viewof _webr_editor_7 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-7-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-7-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_7 = webROjs.process(_webr_editor_7, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-6","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_6;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-6","inline":false,"source":"viewof _webr_editor_6 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-6-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-6-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_6 = webROjs.process(_webr_editor_6, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-5","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_5;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-5","inline":false,"source":"viewof _webr_editor_5 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-5-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-5-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_5 = webROjs.process(_webr_editor_5, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-4","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_4;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-4","inline":false,"source":"viewof _webr_editor_4 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-4-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-4-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_4 = webROjs.process(_webr_editor_4, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-3","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_3;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-3","inline":false,"source":"viewof _webr_editor_3 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-3-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-3-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_3 = webROjs.process(_webr_editor_3, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-2","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_2;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-2","inline":false,"source":"viewof _webr_editor_2 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-2-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-2-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_2 = webROjs.process(_webr_editor_2, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-widget-1","inline":false,"source":"{\n  // Wait for output to be written to the DOM, then trigger widget rendering\n  await _webr_value_1;\n  if (window.HTMLWidgets) {\n    window.HTMLWidgets.staticRender();\n  }\n  if (window.PagedTableDoc) {\n    window.PagedTableDoc.initAll();\n  }\n}\n"},{"methodName":"interpret","cellName":"webr-1","inline":false,"source":"viewof _webr_editor_1 = {\n  const { WebRExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n  const scriptContent = document.querySelector(`script[type=\\\"webr-1-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `webr-1-contents` }, block.attr);\n  const editor = new WebRExerciseEditor(webROjs.webRPromise, block.code, options);\n\n  return editor.container;\n}\n_webr_value_1 = webROjs.process(_webr_editor_1, {});\n"},{"methodName":"interpretQuiet","cellName":"webr-prelude","inline":false,"source":"webROjs = {\n  const { WebR } = window._exercise_ojs_runtime.WebR;\n  const {\n    WebREvaluator,\n    WebREnvironmentManager,\n    setupR,\n    b64Decode,\n    collapsePath\n  } = window._exercise_ojs_runtime;\n\n  const statusContainer = document.getElementById(\"exercise-loading-status\");\n  const indicatorContainer = document.getElementById(\"exercise-loading-indicator\");\n  indicatorContainer.classList.remove(\"d-none\");\n\n  let statusText = document.createElement(\"div\")\n  statusText.classList = \"exercise-loading-details\";\n  statusText = statusContainer.appendChild(statusText);\n  statusText.textContent = `Initialise`;\n\n  // Hoist indicator out from final slide when running under reveal\n  const revealStatus = document.querySelector(\".reveal .exercise-loading-indicator\");\n  if (revealStatus) {\n    revealStatus.remove();\n    document.querySelector(\".reveal > .slides\").appendChild(revealStatus);\n  }\n\n  // webR supplemental data and options\n  const dataContent = document.querySelector(`script[type=\\\"webr-data\\\"]`).textContent;\n  const data = JSON.parse(b64Decode(dataContent));\n\n  // Grab list of resources to be downloaded\n  const filesContent = document.querySelector(`script[type=\\\"vfs-file\\\"]`).textContent;\n  const files = JSON.parse(b64Decode(filesContent));\n\n  // Initialise webR and setup for R code evaluation\n  let webRPromise = (async (webR) => {\n    statusText.textContent = `Downloading webR`;\n    await webR.init();\n\n    // Install provided list of packages\n    // Ensure webR default repo is included\n    data.packages.repos.push(\"https://repo.r-wasm.org\")\n    await data.packages.pkgs.map((pkg) => () => {\n      statusText.textContent = `Downloading package: ${pkg}`;\n      return webR.evalRVoid(`\n        webr::install(pkg, repos = repos)\n        library(pkg, character.only = TRUE)\n      `, { env: {\n        pkg: pkg,\n        repos: data.packages.repos,\n      }});\n    }).reduce((cur, next) => cur.then(next), Promise.resolve());\n\n    // Download and install resources\n    await files.map((file) => async () => {\n      const name = file.substring(file.lastIndexOf('/') + 1);\n      statusText.textContent = `Downloading resource: ${name}`;\n      const response = await fetch(file);\n      if (!response.ok) {\n        throw new Error(`Can't download \\`${file}\\`. Error ${response.status}: \"${response.statusText}\".`);\n      }\n      const data = await response.arrayBuffer();\n\n      // Store URLs in the cwd without any subdirectory structure\n      if (file.includes(\"://\")) {\n        file = name;\n      }\n\n      // Collapse higher directory structure\n      file = collapsePath(file);\n\n      // Create directory tree, ignoring \"directory exists\" VFS errors\n      const parts = file.split('/').slice(0, -1);\n      let path = '';\n      while (parts.length > 0) {\n        path += parts.shift() + '/';\n        try {\n          await webR.FS.mkdir(path);\n        } catch (e) {\n          if (!e.message.includes(\"FS error\")) {\n            throw e;\n          }\n        }\n      }\n\n      // Write this file to the VFS\n      return await webR.FS.writeFile(file, new Uint8Array(data));\n    }).reduce((cur, next) => cur.then(next), Promise.resolve());\n\n    statusText.textContent = `Installing webR shims`;\n    await webR.evalRVoid(`webr::shim_install()`);\n\n    statusText.textContent = `WebR environment setup`;\n    await setupR(webR, data);\n\n    statusText.remove();\n    if (statusContainer.children.length == 0) {\n      statusContainer.parentNode.remove();\n    }\n    return webR;\n  })(new WebR(data.options));\n\n  // Keep track of initial OJS block render\n  const renderedOjs = {};\n\n  const process = async (context, inputs) => {\n    const webR = await webRPromise;\n    const evaluator = new WebREvaluator(webR, context)\n    await evaluator.process(inputs);\n    return evaluator.container;\n  }\n\n  return {\n    process,\n    webRPromise,\n    renderedOjs,\n  };\n}\n"}]}
</script><div id="exercise-loading-indicator" class="exercise-loading-indicator d-none d-flex align-items-center gap-2">
<div id="exercise-loading-status" class="d-flex gap-2">

</div>
<div class="spinner-grow spinner-grow-sm">

</div>
</div>
<script type="vfs-file">
W10=
</script></section></main><!-- /main --><script type="ojs-module-contents">
eyJjb250ZW50cyI6W119
</script><script type="module">
if (window.location.protocol === "file:") { alert("The OJS runtime does not work with file:// URLs. Please use a web server to view this document."); }
window._ojs.paths.runtimeToDoc = "../..";
window._ojs.paths.runtimeToRoot = "../..";
window._ojs.paths.docToRoot = "";
window._ojs.selfContained = false;
window._ojs.runtime.interpretFromScriptTags();
</script><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Kopiert");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Kopiert");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./RR.html" class="pagination-link" aria-label="Reproduzierbarkeit">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Reproduzierbarkeit</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Simulation.html" class="pagination-link" aria-label="Simulation">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Simulation</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Quellcode</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb5" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> live-html</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="an">engine:</span><span class="co"> knitr</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="an">webr:</span><span class="co"> </span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">  packages: [</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">            'broom',</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">            'cowplot',</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">            'lmtest',</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co">            'dplyr',</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co">            'ggplot2',</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co">            'gt',</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co">            'modelsummary',</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">            'palmerpenguins',</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co">            'purrr',</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co">            'tidyr',</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co">            'readr',</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co">            'sandwich'</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co">            ]</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>{{&lt; include ./_extensions/r-wasm/live/_knitr.qmd &gt;}}</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="fu"># Regression {#sec-regression}</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>Viele der in diesem Companion behandelten Methoden basiert auf dem Konzept der Schätzung kausaler Effekte mit *Regression*. Als Regressionsansatz bezeichnet man eine Methode, welche die Beziehungen zwischen Variablen durch einen funktionalen Zusammenhang beschreibt und die Parameter der gewählten funktionalen Form anhand von beobachteten Daten schätzt. *Lineare Regression* nimmt eine lineare funktionale Form der Beziehung zwischen einer abhängigen Variable (Outcome-Variable) und erklärenden Variablen (Regressoren) an. *Nicht-lineare Regressionsmethoden* modellieren die Beziehung etwa durch Polynome höherer Ordnung, exponentielle Funktionen oder andere komplexere Formen. Die Wahl der funktionalen Form hängt von der Natur des datenerzeugenden Prozesses (DGP) und somit stets von der spezifischen Beziehung ab, die untersucht wird. </span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>Regressionsansätze gehören zu den am häufigsten verwendeten Methoden für Kausalanalysen, da mit Regression in vielen Forschungsdesigns kausale Effekte identifiziert werden können, indem Backdoors geschlossen werden: Regression kann die durch die Behandlungsvariable verursachte Variation in der Outcome-Variable isolieren, indem für gemeinsame Einflussfaktoren von Behandlungs- *und* Outcome-Variable kontrolliert wird. In diesem Kapitel erläutern wir Erweiterungen der Spezifikation und Schätzung von Regressionsansätzen, die für spätere Kapitel relevant sind. Neben einer Motivation der Schätzung kausaler Effekte mit multipler Regression betrachten wir Modelle für verschiedene Kategorien von Outcome-Variablen und diskutieren deren Implementierung mit R.</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cowplot)</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regression schließt Backdoors: Frisch-Waugh-Lovell-Theorem</span></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>Das Frisch-Waugh-Lovell-Theorem (FWL) besagt, dass die geschätzten Koeffizienten für eine interessierende Teilmenge der Regressoren in einer multiplen linearen Regression numerisch identisch mit den Koeffizientenschätzungen aus folgenden Schritten sind: </span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Rechne die Effekte der übrigen Regressoren auf (a) die Outcome-Variable und (b) die interessierende Teilmenge der Regressoren mit Regression heraus. </span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Regressiere anschließend die Residuen von Schritt (a) auf die Residuen aus Schritt (b). </span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>In einem multiplen Modell mit zwei Regressoren $X_1,\ X_2$,</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>  Y = \beta_0 + \beta_1 X + \beta_2 X_2 + \epsilon \label{eq:fwlfullreg}</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>kann der Effekt von $X_1$ auf $Y$ also mit der Regression</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>  \widehat{u}_{Y,X_2} = \beta_1 \widehat{u}_{X_1,X_2} + e \label{eq:fwl2reg}</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>geschätzt werden, wobei $\widehat{u}_{Y,X_2}$ und $\widehat{u}_{X_1,X_2}$ die Residuen der Regression von $Y$ auf $X_2$ und von $X_1$ auf $X_2$ sind.</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>FWL ermöglicht daher eine Vereinfachung der Schätzung komplexer Modelle durch die Zerlegung der Schätzung in Teilschritte. </span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>Für das Verständnis der Schätzung kausaler Effekte mit linearer Regression ist FWL hilfreich, denn es zeigt, wie sowohl die Variation in der Outcome-Variable ($\widehat{u}_{Y,X_2}$) als auch die Variation in der Behandlungsvariable ($\widehat{u}_{X_1,X_2}$), die jeweils *nicht* durch Kovariablen ($X_2$) verursacht wird, mit multipler Regression isoliert werden kann, sodass Backdoors geschlossen werden.</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>Wir illustrieren dieses Konzept anhand einer multiplen Regression für das Gewicht (<span class="in">`body_mass`</span>) von Pinguinen aus dem Datensatz <span class="in">`palmerpenguins::penguins`</span>,</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>  \textup{body<span class="sc">\_</span>mass} = \beta_0 + \beta_1\cdot\textup{bill<span class="sc">\_</span>length} + \beta_2\cdot \textup{flipper<span class="sc">\_</span>length} + \epsilon,\label{eq:billdepthmodel}</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>unter der Annahme, dass $\beta_1$ der interessierende Effekt ist: Die erwartete Änderung des Gewichts eines Pinguins (in Gramm) für eine Änderung der Schnabel-Länge um 1mm.</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>Vor der Schätzung von Modell \eqref{eq:billdepthmodel} lesen wir den Datensatz ein und erstellen eine bereinigte Variante <span class="in">`penguins_cleaned`</span>, analog zur Vorgehensweise in @sec-pp.</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a><span class="in">library(palmerpenguins)</span></span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a><span class="in">data(penguins)</span></span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a><span class="in"># Datensatz bereinigen</span></span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a><span class="in">penguins_cleaned &lt;- penguins %&gt;% </span></span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a><span class="in">  rename(</span></span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a><span class="in">    bill_depth = bill_depth_mm,</span></span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a><span class="in">    bill_length = bill_length_mm,</span></span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a><span class="in">    flipper_length = flipper_length_mm,</span></span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a><span class="in">    body_mass = body_mass_g</span></span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a><span class="in">  ) %&gt;% </span></span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a><span class="in">  drop_na() %&gt;% </span></span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a><span class="in">  filter(</span></span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a><span class="in">    body_mass &lt; quantile(body_mass, .95)</span></span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a><span class="in"># Überblick</span></span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a><span class="in">slice_head(penguins_cleaned, n = 10)</span></span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a>Wir schätzen nun Modell \eqref{eq:billdepthmodel} mit <span class="in">`lm()`</span> und erhalten eine Zusammenfassung der geschätzten Koeffizienten mit <span class="in">`broom::tidy()`</span>.</span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a><span class="in">library(broom)</span></span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a><span class="in"># "Großes" Modell schätzen</span></span>
<span id="cb5-98"><a href="#cb5-98" aria-hidden="true" tabindex="-1"></a><span class="in">lm(</span></span>
<span id="cb5-99"><a href="#cb5-99" aria-hidden="true" tabindex="-1"></a><span class="in">  formula = body_mass ~ bill_length + flipper_length, </span></span>
<span id="cb5-100"><a href="#cb5-100" aria-hidden="true" tabindex="-1"></a><span class="in">  data = penguins_cleaned</span></span>
<span id="cb5-101"><a href="#cb5-101" aria-hidden="true" tabindex="-1"></a><span class="in">) %&gt;%</span></span>
<span id="cb5-102"><a href="#cb5-102" aria-hidden="true" tabindex="-1"></a><span class="in">  tidy()</span></span>
<span id="cb5-103"><a href="#cb5-103" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-104"><a href="#cb5-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-105"><a href="#cb5-105" aria-hidden="true" tabindex="-1"></a>Das Ergebnis der Schätzung ist $\widehat{\beta}_1\approx3.80$. Der nächste Code-Block berechnet die Residuen aus den Regressionen</span>
<span id="cb5-106"><a href="#cb5-106" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-107"><a href="#cb5-107" aria-hidden="true" tabindex="-1"></a>  \textup{body<span class="sc">\_</span>mass} =&amp;\, \alpha_0 + \alpha_1 \textup{flipper<span class="sc">\_</span>length} + u_{\textup{body<span class="sc">\_</span>mass},\,\textup{flipper<span class="sc">\_</span>length}},<span class="sc">\\</span></span>
<span id="cb5-108"><a href="#cb5-108" aria-hidden="true" tabindex="-1"></a>  \textup{bill<span class="sc">\_</span>length} =&amp;\, \delta_0 + \delta_1 \textup{flipper<span class="sc">\_</span>length} + u_{\textup{bill<span class="sc">\_</span>length},\,\textup{flipper<span class="sc">\_</span>length}},</span>
<span id="cb5-109"><a href="#cb5-109" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-110"><a href="#cb5-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-111"><a href="#cb5-111" aria-hidden="true" tabindex="-1"></a>und speichert diese in <span class="in">`body_mass_res`</span> und <span class="in">`bill_length_res`</span>.</span>
<span id="cb5-112"><a href="#cb5-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-115"><a href="#cb5-115" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-116"><a href="#cb5-116" aria-hidden="true" tabindex="-1"></a><span class="in"># FWL-Schritt 1 (a)</span></span>
<span id="cb5-117"><a href="#cb5-117" aria-hidden="true" tabindex="-1"></a><span class="in">peng_mod_fwl1a &lt;- lm(</span></span>
<span id="cb5-118"><a href="#cb5-118" aria-hidden="true" tabindex="-1"></a><span class="in">  formula = body_mass ~ flipper_length, </span></span>
<span id="cb5-119"><a href="#cb5-119" aria-hidden="true" tabindex="-1"></a><span class="in">  data = penguins_cleaned</span></span>
<span id="cb5-120"><a href="#cb5-120" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb5-121"><a href="#cb5-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-122"><a href="#cb5-122" aria-hidden="true" tabindex="-1"></a><span class="in">body_mass_res &lt;- residuals(peng_mod_fwl1a)</span></span>
<span id="cb5-123"><a href="#cb5-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-124"><a href="#cb5-124" aria-hidden="true" tabindex="-1"></a><span class="in">head(body_mass_res, n = 10)</span></span>
<span id="cb5-125"><a href="#cb5-125" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-126"><a href="#cb5-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-129"><a href="#cb5-129" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-130"><a href="#cb5-130" aria-hidden="true" tabindex="-1"></a><span class="in"># FWL-Schritt 1 (b)</span></span>
<span id="cb5-131"><a href="#cb5-131" aria-hidden="true" tabindex="-1"></a><span class="in">peng_mod_fwl1b &lt;- lm(</span></span>
<span id="cb5-132"><a href="#cb5-132" aria-hidden="true" tabindex="-1"></a><span class="in">  formula = bill_length ~ flipper_length, </span></span>
<span id="cb5-133"><a href="#cb5-133" aria-hidden="true" tabindex="-1"></a><span class="in">  data = penguins_cleaned</span></span>
<span id="cb5-134"><a href="#cb5-134" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb5-135"><a href="#cb5-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-136"><a href="#cb5-136" aria-hidden="true" tabindex="-1"></a><span class="in">bill_length_res &lt;- residuals(peng_mod_fwl1b)</span></span>
<span id="cb5-137"><a href="#cb5-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-138"><a href="#cb5-138" aria-hidden="true" tabindex="-1"></a><span class="in">head(bill_length_res, n = 10)</span></span>
<span id="cb5-139"><a href="#cb5-139" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-140"><a href="#cb5-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-141"><a href="#cb5-141" aria-hidden="true" tabindex="-1"></a>Für den zweiten Schritt regressieren wir <span class="in">`body_mass_res`</span> auf <span class="in">`bill_length_res`</span>.</span>
<span id="cb5-142"><a href="#cb5-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-145"><a href="#cb5-145" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-146"><a href="#cb5-146" aria-hidden="true" tabindex="-1"></a><span class="in"># FWL-Schritt 2</span></span>
<span id="cb5-147"><a href="#cb5-147" aria-hidden="true" tabindex="-1"></a><span class="in">lm(formula = body_mass_res ~ bill_length_res - 1) %&gt;% </span></span>
<span id="cb5-148"><a href="#cb5-148" aria-hidden="true" tabindex="-1"></a><span class="in">  tidy()</span></span>
<span id="cb5-149"><a href="#cb5-149" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-150"><a href="#cb5-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-151"><a href="#cb5-151" aria-hidden="true" tabindex="-1"></a>Der geschätzte Koeffizient aus der Regression der Residuen stimmt mit dem geschätzten Koeffizienten von <span class="in">`bill_length`</span> aus der großen Regression \eqref{eq:billdepthmodel} überein.</span>
<span id="cb5-152"><a href="#cb5-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-153"><a href="#cb5-153" aria-hidden="true" tabindex="-1"></a>Wir können den Effekt der Kontrolle für <span class="in">`flipper_length`</span> visualisieren. Wir plotten hierzu:</span>
<span id="cb5-154"><a href="#cb5-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-155"><a href="#cb5-155" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Die originalen Datenpunkte für <span class="in">`bill_length`</span> und <span class="in">`body_mass`</span>^<span class="co">[</span><span class="ot">Für eine bessere Lesbarkeit der Grafik zentrieren wir beide Variablen um den jeweiligen Stichprobenmittelwert.</span><span class="co">]</span> gemeinsam mit der geschätzten Regressionslinie für das Modell $$ \textup{body<span class="sc">\_</span>mass} = \beta_0 + \beta_1\textup{bill<span class="sc">\_</span>length} + u $$ (keine Kontrolle für <span class="in">`flipper_length`</span>!)^<span class="co">[</span><span class="ot">Der R-Befehl für diese Regression ist `lm(I(body_mass - mean(body_mass)) ~ I(bill_length - mean(bill_length)) - 1, data = penguins_cleaned)`.</span><span class="co">]</span>.</span>
<span id="cb5-156"><a href="#cb5-156" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-157"><a href="#cb5-157" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Die um <span class="in">`flipper_length`</span> bereinigten Datenpunkte und die zugehörige geschätzte Regressionslinie.</span>
<span id="cb5-158"><a href="#cb5-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-161"><a href="#cb5-161" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-162"><a href="#cb5-162" aria-hidden="true" tabindex="-1"></a><span class="in"># Residuen in tibble sammeln</span></span>
<span id="cb5-163"><a href="#cb5-163" aria-hidden="true" tabindex="-1"></a><span class="in">p &lt;- tibble(</span></span>
<span id="cb5-164"><a href="#cb5-164" aria-hidden="true" tabindex="-1"></a><span class="in">  body_mass_res, </span></span>
<span id="cb5-165"><a href="#cb5-165" aria-hidden="true" tabindex="-1"></a><span class="in">  bill_length_res</span></span>
<span id="cb5-166"><a href="#cb5-166" aria-hidden="true" tabindex="-1"></a><span class="in">) %&gt;%</span></span>
<span id="cb5-167"><a href="#cb5-167" aria-hidden="true" tabindex="-1"></a><span class="in">  </span></span>
<span id="cb5-168"><a href="#cb5-168" aria-hidden="true" tabindex="-1"></a><span class="in">  ggplot() +</span></span>
<span id="cb5-169"><a href="#cb5-169" aria-hidden="true" tabindex="-1"></a><span class="in">  # Bereinigte Datenpunkte plotten</span></span>
<span id="cb5-170"><a href="#cb5-170" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_point(</span></span>
<span id="cb5-171"><a href="#cb5-171" aria-hidden="true" tabindex="-1"></a><span class="in">    mapping = aes(</span></span>
<span id="cb5-172"><a href="#cb5-172" aria-hidden="true" tabindex="-1"></a><span class="in">      x = bill_length_res, </span></span>
<span id="cb5-173"><a href="#cb5-173" aria-hidden="true" tabindex="-1"></a><span class="in">      y = body_mass_res,</span></span>
<span id="cb5-174"><a href="#cb5-174" aria-hidden="true" tabindex="-1"></a><span class="in">      color = "Um flipper_length bereinigte Daten"</span></span>
<span id="cb5-175"><a href="#cb5-175" aria-hidden="true" tabindex="-1"></a><span class="in">    )</span></span>
<span id="cb5-176"><a href="#cb5-176" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-177"><a href="#cb5-177" aria-hidden="true" tabindex="-1"></a><span class="in">  # Regressionslinie für bereinigte Datenpunkte</span></span>
<span id="cb5-178"><a href="#cb5-178" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_smooth(</span></span>
<span id="cb5-179"><a href="#cb5-179" aria-hidden="true" tabindex="-1"></a><span class="in">    mapping = aes(x = bill_length_res, y = body_mass_res),</span></span>
<span id="cb5-180"><a href="#cb5-180" aria-hidden="true" tabindex="-1"></a><span class="in">    method = "lm", </span></span>
<span id="cb5-181"><a href="#cb5-181" aria-hidden="true" tabindex="-1"></a><span class="in">    formula = "y ~ x - 1",</span></span>
<span id="cb5-182"><a href="#cb5-182" aria-hidden="true" tabindex="-1"></a><span class="in">    se = F,</span></span>
<span id="cb5-183"><a href="#cb5-183" aria-hidden="true" tabindex="-1"></a><span class="in">    col = "purple"</span></span>
<span id="cb5-184"><a href="#cb5-184" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-185"><a href="#cb5-185" aria-hidden="true" tabindex="-1"></a><span class="in">  scale_color_manual(</span></span>
<span id="cb5-186"><a href="#cb5-186" aria-hidden="true" tabindex="-1"></a><span class="in">    name = "",</span></span>
<span id="cb5-187"><a href="#cb5-187" aria-hidden="true" tabindex="-1"></a><span class="in">    values = c(</span></span>
<span id="cb5-188"><a href="#cb5-188" aria-hidden="true" tabindex="-1"></a><span class="in">      "Um flipper_length bereinigte Daten" = "purple",</span></span>
<span id="cb5-189"><a href="#cb5-189" aria-hidden="true" tabindex="-1"></a><span class="in">      "Ursprüngliche Datenpunkte" = "black"</span></span>
<span id="cb5-190"><a href="#cb5-190" aria-hidden="true" tabindex="-1"></a><span class="in">    )</span></span>
<span id="cb5-191"><a href="#cb5-191" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-192"><a href="#cb5-192" aria-hidden="true" tabindex="-1"></a><span class="in">  labs(</span></span>
<span id="cb5-193"><a href="#cb5-193" aria-hidden="true" tabindex="-1"></a><span class="in">    title = "Penguins: Anwendung von FWL",</span></span>
<span id="cb5-194"><a href="#cb5-194" aria-hidden="true" tabindex="-1"></a><span class="in">    x = "bill_length",</span></span>
<span id="cb5-195"><a href="#cb5-195" aria-hidden="true" tabindex="-1"></a><span class="in">    y = "body_mass"</span></span>
<span id="cb5-196"><a href="#cb5-196" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-197"><a href="#cb5-197" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_cowplot() +</span></span>
<span id="cb5-198"><a href="#cb5-198" aria-hidden="true" tabindex="-1"></a><span class="in">  theme(legend.position = "top")</span></span>
<span id="cb5-199"><a href="#cb5-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-200"><a href="#cb5-200" aria-hidden="true" tabindex="-1"></a><span class="in">p</span></span>
<span id="cb5-201"><a href="#cb5-201" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-202"><a href="#cb5-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-203"><a href="#cb5-203" aria-hidden="true" tabindex="-1"></a>Wir erweitern <span class="in">`p`</span> um die ursprünglichen Datenpunkte und die zugehörige Regressionslinie.</span>
<span id="cb5-204"><a href="#cb5-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-207"><a href="#cb5-207" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-208"><a href="#cb5-208" aria-hidden="true" tabindex="-1"></a><span class="in"># Ursprüngliche Datenpunkte hinzufügen</span></span>
<span id="cb5-209"><a href="#cb5-209" aria-hidden="true" tabindex="-1"></a><span class="in">p + geom_point(</span></span>
<span id="cb5-210"><a href="#cb5-210" aria-hidden="true" tabindex="-1"></a><span class="in">    data = penguins_cleaned, </span></span>
<span id="cb5-211"><a href="#cb5-211" aria-hidden="true" tabindex="-1"></a><span class="in">    mapping = aes(</span></span>
<span id="cb5-212"><a href="#cb5-212" aria-hidden="true" tabindex="-1"></a><span class="in">      x = bill_length - mean(bill_length), </span></span>
<span id="cb5-213"><a href="#cb5-213" aria-hidden="true" tabindex="-1"></a><span class="in">      y = body_mass - mean(body_mass),</span></span>
<span id="cb5-214"><a href="#cb5-214" aria-hidden="true" tabindex="-1"></a><span class="in">      color = "Ursprüngliche Datenpunkte"</span></span>
<span id="cb5-215"><a href="#cb5-215" aria-hidden="true" tabindex="-1"></a><span class="in">    ),</span></span>
<span id="cb5-216"><a href="#cb5-216" aria-hidden="true" tabindex="-1"></a><span class="in">    alpha = .5,</span></span>
<span id="cb5-217"><a href="#cb5-217" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-218"><a href="#cb5-218" aria-hidden="true" tabindex="-1"></a><span class="in">  # Regressionslinie für ursprüngliche Datenpunkte</span></span>
<span id="cb5-219"><a href="#cb5-219" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_smooth(</span></span>
<span id="cb5-220"><a href="#cb5-220" aria-hidden="true" tabindex="-1"></a><span class="in">    data = penguins_cleaned, </span></span>
<span id="cb5-221"><a href="#cb5-221" aria-hidden="true" tabindex="-1"></a><span class="in">    mapping = aes(</span></span>
<span id="cb5-222"><a href="#cb5-222" aria-hidden="true" tabindex="-1"></a><span class="in">      x = bill_length - mean(bill_length), </span></span>
<span id="cb5-223"><a href="#cb5-223" aria-hidden="true" tabindex="-1"></a><span class="in">      y = body_mass - mean(body_mass)</span></span>
<span id="cb5-224"><a href="#cb5-224" aria-hidden="true" tabindex="-1"></a><span class="in">    ),</span></span>
<span id="cb5-225"><a href="#cb5-225" aria-hidden="true" tabindex="-1"></a><span class="in">    method = "lm", </span></span>
<span id="cb5-226"><a href="#cb5-226" aria-hidden="true" tabindex="-1"></a><span class="in">    formula = "y ~ x - 1",</span></span>
<span id="cb5-227"><a href="#cb5-227" aria-hidden="true" tabindex="-1"></a><span class="in">    se = F,</span></span>
<span id="cb5-228"><a href="#cb5-228" aria-hidden="true" tabindex="-1"></a><span class="in">    col = alpha("black", .5)</span></span>
<span id="cb5-229"><a href="#cb5-229" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb5-230"><a href="#cb5-230" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-231"><a href="#cb5-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-232"><a href="#cb5-232" aria-hidden="true" tabindex="-1"></a>Der grafische Vergleich beider Vorgehensweisen zeigt den Effekt der Kontrolle für <span class="in">`flipper_length`</span>: Die geschätzte (schwarze) Regressionslinie für die bereinigten Daten hat eine deutlich geringere Steigung als die anhand der ursprünglichen Daten geschätzte (lilane) Linie. Der Effekt von <span class="in">`bill_length`</span> auf <span class="in">`body_mass`</span> wird mit der einfachen Regression <span class="in">`lm(body_mass ~ bill_length)`</span> vermutlich *überschätzt*, weil es andere Faktoren (wie <span class="in">`flipper_length`</span> gibt, die mit <span class="in">`bill_length`</span> und <span class="in">`body_mass`</span> korrelieren. Kontrollieren für <span class="in">`flipper_length`</span> in der multiplen Regression <span class="in">`lm(body_mass ~ bill_length + flipper_length)`</span> schließt die Backdoor durch <span class="in">`flipper_length`</span>. Die Konsequenz ist eine deutlich geringere Steigung der lilanen Regressionslinie.</span>
<span id="cb5-233"><a href="#cb5-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-234"><a href="#cb5-234" aria-hidden="true" tabindex="-1"></a><span class="fu">## Binäre Outcome-Variable {#sec-bov}</span></span>
<span id="cb5-235"><a href="#cb5-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-236"><a href="#cb5-236" aria-hidden="true" tabindex="-1"></a>Eine binäre Variable, auch als dichotome Variable oder Indikator-Variable bezeichnet, ist eine Variable, die nur zwei Ausprägungen annehmen kann. Diese beiden Ausprägungen werden typischerweise durch die Werte 0 und 1 repräsentiert und dienen dazu, zwei verschiedene Zustände oder Kategorien zu unterscheiden. Formal kann eine binäre Variable $B$ wie folgt definiert werden:</span>
<span id="cb5-237"><a href="#cb5-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-238"><a href="#cb5-238" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb5-239"><a href="#cb5-239" aria-hidden="true" tabindex="-1"></a>  B = \begin{cases} </span>
<span id="cb5-240"><a href="#cb5-240" aria-hidden="true" tabindex="-1"></a>  1, &amp; \text{Eigenschaft trifft zu,} <span class="sc">\\</span></span>
<span id="cb5-241"><a href="#cb5-241" aria-hidden="true" tabindex="-1"></a>  0, &amp; \text{Eigenschaft trifft nicht zu.}</span>
<span id="cb5-242"><a href="#cb5-242" aria-hidden="true" tabindex="-1"></a>  \end{cases}</span>
<span id="cb5-243"><a href="#cb5-243" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb5-244"><a href="#cb5-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-245"><a href="#cb5-245" aria-hidden="true" tabindex="-1"></a>Ein in späteren Kapiteln dieses Companions verwendeter *binärer Regressor* ist der Indikator für die Zuordnung von Beobachtungen zur Behandlungs- oder Kontrollgruppe (1 = Behandlungsgruppe, 0 = Kontrollgruppe). </span>
<span id="cb5-246"><a href="#cb5-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-247"><a href="#cb5-247" aria-hidden="true" tabindex="-1"></a>Für viele ökonomische Forschungsfragen ist es hilfreich, eine *binäre Outcome-Variable* mit Regression zu modellieren. Hierzu gibt es verschiedene Ansätze, die wir nachfolgend zusammenfassen und ihre Anwendung mit R zeigen.</span>
<span id="cb5-248"><a href="#cb5-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-249"><a href="#cb5-249" aria-hidden="true" tabindex="-1"></a><span class="fu">### Das lineare Wahrscheinlichkeitsmodell {#sec-lpm}</span></span>
<span id="cb5-250"><a href="#cb5-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-251"><a href="#cb5-251" aria-hidden="true" tabindex="-1"></a>Das lineare Regressionsmodell</span>
<span id="cb5-252"><a href="#cb5-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-253"><a href="#cb5-253" aria-hidden="true" tabindex="-1"></a>$$Y = \beta_0 + \beta_1 X_{1} + \beta_2 X_{2} + \dots + \beta_k X_{k} + u$$</span>
<span id="cb5-254"><a href="#cb5-254" aria-hidden="true" tabindex="-1"></a>mit einer binären abhängigen Variablen $Y_i\in<span class="sc">\{</span>0,1<span class="sc">\}</span>$ wird als *lineares Wahrscheinlichkeitsmodell* bezeichnet. Wie üblich modellieren wir den Erwartungswert der abhängigen Variable gegeben der Regressoren $X_1,\dots,X_k$ als lineare Funktion,</span>
<span id="cb5-255"><a href="#cb5-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-256"><a href="#cb5-256" aria-hidden="true" tabindex="-1"></a>$$E(Y\vert X_1,X_2,\dots,X_k) = P(Y=1\vert X_1, X_2,\dots, X_3).$$ Da $Y$ eine binäre Variable ist, gilt hier</span>
<span id="cb5-257"><a href="#cb5-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-258"><a href="#cb5-258" aria-hidden="true" tabindex="-1"></a>$$ P(Y = 1 \vert X_1, X_2, \dots, X_k) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_k X_k.$$</span>
<span id="cb5-259"><a href="#cb5-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-260"><a href="#cb5-260" aria-hidden="true" tabindex="-1"></a>Das lineare Wahrscheinlichkeitsmodell beschreibt also die *Wahrscheinlichkeit*, dass $Y=1$ als lineare Funktion der Regressoren: $\beta_j$ misst die Änderung in der Wahrscheinlichkeit für das Ereignis $Y_i=1$, unter der Bedingung, dass die anderen $k-1$ Regressoren konstant gehalten werden. Genau wie bei multipler Regression mit einer kontinuierlichen abhängigen Variablen können die $\beta_j$ mit der KQ-Methode geschätzt werden.</span>
<span id="cb5-261"><a href="#cb5-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-262"><a href="#cb5-262" aria-hidden="true" tabindex="-1"></a>Aufgrund der Beschränktheit der $Y_i$ auf $<span class="sc">\{</span>0,1<span class="sc">\}</span>$ ist $u_i$ heteroskedastisch. Folglich sollten Inferenzstatistiken mit robusten Standardfehlern berechnet werden. Weiterhin ist zu beachten, dass $R^2$ in den meisten Anwendungen von linearen Wahrscheinlichkeitsmodellen keine hilfreiche Interpretation hat, da das geschätzte Modell die Daten nicht perfekt erklären kann, wenn die abhängige Variable binär, aber die Regressoren kontinuierlich verteilt sind.</span>
<span id="cb5-263"><a href="#cb5-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-264"><a href="#cb5-264" aria-hidden="true" tabindex="-1"></a>Das lineare Wahrscheinlichkeitsmodell hat einen wesentlichen Nachteil: Das Modell nimmt an, dass die bedingte Wahrscheinlichkeitsfunktion linear ist und $P(Y=1\vert X_1,\dots,X_k)$ über das für Wahrscheinlichkeiten definierte Intervall $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$ hinausgehen kann. Ein angepasstes Modell hat dann für Regressorwerte, die zu Vorhersagen von $Y$ jenseits von $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$ führen keine sinnvolle Interpretation.</span>
<span id="cb5-265"><a href="#cb5-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-266"><a href="#cb5-266" aria-hidden="true" tabindex="-1"></a>Dieser Umstand verlangt nach Regressionsansätzen, die $P(Y=1)$ durch eine auf $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$ beschränkte (nicht-lineare) Funktion der Regressoren modellieren. Häufig verwendete Methoden sind Probit- und Logit-Regression.</span>
<span id="cb5-267"><a href="#cb5-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-268"><a href="#cb5-268" aria-hidden="true" tabindex="-1"></a>Ein lineares Wahrscheinlichkeitsmodell kann mit <span class="in">`lm()`</span> geschätzt werden, wobei die abhängige Variable den Typ <span class="in">`numeric`</span> oder <span class="in">`integer`</span> haben muss.</span>
<span id="cb5-269"><a href="#cb5-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-270"><a href="#cb5-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-271"><a href="#cb5-271" aria-hidden="true" tabindex="-1"></a><span class="fu">### Probit-Regression {#sec-probitreg}</span></span>
<span id="cb5-272"><a href="#cb5-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-273"><a href="#cb5-273" aria-hidden="true" tabindex="-1"></a>Bei der Probit-Regression wird die Standardnormalverteilungsfunktion $\Phi(\cdot)$ verwendet, um die Regressionsfunktion einer binären abhängigen Variable zu modellieren. Wir nehmen an, dass</span>
<span id="cb5-274"><a href="#cb5-274" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb5-275"><a href="#cb5-275" aria-hidden="true" tabindex="-1"></a>  E(Y\vert X) = P(Y=1\vert X) = \Phi(\beta_0 + \beta_1 X), \label{eq:probitmodel}</span>
<span id="cb5-276"><a href="#cb5-276" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb5-277"><a href="#cb5-277" aria-hidden="true" tabindex="-1"></a>sodass der mit der Verknüpfungsfunktion (Link-Funktion) $$\textup{probit}(\cdot) = \Phi^{-1}(\cdot)$$ transformierte Erwartungswert $P(Y=1\vert X)$ dem linearen Prädiktor $z=\beta_0 + \beta_1 X$ entspricht,</span>
<span id="cb5-278"><a href="#cb5-278" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-279"><a href="#cb5-279" aria-hidden="true" tabindex="-1"></a>  \Phi^{-1}\big<span class="co">[</span><span class="ot">P(Y=1\vert X)\big</span><span class="co">]</span> = \beta_0 + \beta_1 X.</span>
<span id="cb5-280"><a href="#cb5-280" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-281"><a href="#cb5-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-282"><a href="#cb5-282" aria-hidden="true" tabindex="-1"></a>$z=\beta_0 + \beta_1 X$ in \eqref{eq:probitmodel} modelliert hier also ein *Quantil* der Standardnormalverteilung,</span>
<span id="cb5-283"><a href="#cb5-283" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-284"><a href="#cb5-284" aria-hidden="true" tabindex="-1"></a>\Phi(z) = P(Z \leq z) \ , \ Z \sim \mathcal{N}(0,1).</span>
<span id="cb5-285"><a href="#cb5-285" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-286"><a href="#cb5-286" aria-hidden="true" tabindex="-1"></a>Der Koeffizient $\beta_1$ in \eqref{eq:probitmodel} misst die Änderung in $z$, die mit einer Änderung von $X$ um eine Einheit verbunden ist. Obwohl der Effekt einer Änderung in $X$ auf $z$ linear ist, ist der Zusammenhang zwischen $z$ und $\textup{E}(Y\vert X) = P(Y=1\vert X)$ *nicht linear*, denn $\Phi(\cdot)$ ist eine nicht-lineare Funktion von $X$.</span>
<span id="cb5-287"><a href="#cb5-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-290"><a href="#cb5-290" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-291"><a href="#cb5-291" aria-hidden="true" tabindex="-1"></a><span class="in"># N(0,1)-Quantilsfunktion / Probit-Link</span></span>
<span id="cb5-292"><a href="#cb5-292" aria-hidden="true" tabindex="-1"></a><span class="in">ggplot() +</span></span>
<span id="cb5-293"><a href="#cb5-293" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_function(fun = qnorm) +</span></span>
<span id="cb5-294"><a href="#cb5-294" aria-hidden="true" tabindex="-1"></a><span class="in">  scale_x_continuous(</span></span>
<span id="cb5-295"><a href="#cb5-295" aria-hidden="true" tabindex="-1"></a><span class="in">    name = "z", </span></span>
<span id="cb5-296"><a href="#cb5-296" aria-hidden="true" tabindex="-1"></a><span class="in">    limits = c(0, 1)</span></span>
<span id="cb5-297"><a href="#cb5-297" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-298"><a href="#cb5-298" aria-hidden="true" tabindex="-1"></a><span class="in">  scale_y_continuous(name = "Quantil") +</span></span>
<span id="cb5-299"><a href="#cb5-299" aria-hidden="true" tabindex="-1"></a><span class="in">  labs(title = "Probit-Funktion") +</span></span>
<span id="cb5-300"><a href="#cb5-300" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_cowplot()</span></span>
<span id="cb5-301"><a href="#cb5-301" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-302"><a href="#cb5-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-303"><a href="#cb5-303" aria-hidden="true" tabindex="-1"></a>Aufgrund der Nicht-Linearität der Link-Funktion hat der Koeffizient von $X$ keine einfache Interpretation hinsichtlich des Effekts auf $P(Y=1\vert X)$. Die Änderung in der Wahrscheinlichkeit, dass $Y=1$ ist, durch eine Änderung in $X$ (partieller Effekt von $X$) kann berechnet werden als:</span>
<span id="cb5-304"><a href="#cb5-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-305"><a href="#cb5-305" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-306"><a href="#cb5-306" aria-hidden="true" tabindex="-1"></a>  \frac{\partial\textup{E}(Y\vert X)}{\partial X} = \frac{\partial\textup{P}(Y=1\vert X)}{\partial X} = \frac{\partial\Phi(\beta_0 + \beta_1 X)}{\partial X} = \phi(\beta_0 + \beta_1 X) \beta_1,</span>
<span id="cb5-307"><a href="#cb5-307" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-308"><a href="#cb5-308" aria-hidden="true" tabindex="-1"></a>wobei $\phi(\cdot)$ die Dichtefunktion der Standardnormalverteilung ist. In empirischen Anwendungen wird der partielle Effekt häufig als Differenz in geschätzten Wahrscheinlichkeiten angegeben:</span>
<span id="cb5-309"><a href="#cb5-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-310"><a href="#cb5-310" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Berechne die geschätzte Wahrscheinlichkeit, dass $Y=1$ für einen Bezugswert $X$.</span>
<span id="cb5-311"><a href="#cb5-311" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Berechne die geschätzte Wahrscheinlichkeit, dass $Y=1$ für $X + \Delta X$.</span>
<span id="cb5-312"><a href="#cb5-312" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Berechne die Differenz zwischen der geschätzten Wahrscheinlichkeiten.</span>
<span id="cb5-313"><a href="#cb5-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-314"><a href="#cb5-314" aria-hidden="true" tabindex="-1"></a>Wie im linearen Wahrscheinlichkeitsmodell kann das Modell \eqref{eq:probitmodel} auf eine Probit-Regression mit $k+1$ Regressoren $\boldsymbol{X} := (1, X_1, \dots, X_k)$ verallgemeinert werden, um das Risiko einer Verzerrung durch ausgelassene Variablen zu mindern. Die Schritte 1 bis 3 für die Berechnung des partiellen Effekts einer Änderung in $X_j$ erfolgen dann unter der Annahme, dass die übrigen $k-1$ Regressoren konstant gehalten werden, wobei der partielle Effekt von den jeweiligen Regressorwerten abhängt. Im nächsten Abschnitt erläutern wir die Schätzung von Probit-Modellen mit $k+1$ Regressoren.</span>
<span id="cb5-315"><a href="#cb5-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-316"><a href="#cb5-316" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Schätzung</span></span>
<span id="cb5-317"><a href="#cb5-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-318"><a href="#cb5-318" aria-hidden="true" tabindex="-1"></a>Die Likelihood-Funktion für Probit-Regression ist</span>
<span id="cb5-319"><a href="#cb5-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-320"><a href="#cb5-320" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-321"><a href="#cb5-321" aria-hidden="true" tabindex="-1"></a>  L(\boldsymbol{\beta}) = \prod_{i=1}^n \Phi(\mathbf{X}_i^\top \boldsymbol{\beta})^{y_i} \left<span class="co">[</span><span class="ot">1 - \Phi(\mathbf{X}_i^\top \boldsymbol{\beta})\right</span><span class="co">]</span>^{1-y_i}</span>
<span id="cb5-322"><a href="#cb5-322" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-323"><a href="#cb5-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-324"><a href="#cb5-324" aria-hidden="true" tabindex="-1"></a>Hierbei ist $\Phi(\mathbf{X}_i^\top \boldsymbol{\beta})$ die Wahrscheinlichkeit, dass $Y_i = 1$ ist und $1 - \Phi(\mathbf{X}_i^\top \boldsymbol{\beta})$ ist die Wahrscheinlichkeit, dass $Y_i = 0$ ist.</span>
<span id="cb5-325"><a href="#cb5-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-326"><a href="#cb5-326" aria-hidden="true" tabindex="-1"></a>Die Log-Likelihood-Funktion ergibt sich als</span>
<span id="cb5-327"><a href="#cb5-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-328"><a href="#cb5-328" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-329"><a href="#cb5-329" aria-hidden="true" tabindex="-1"></a>  \mathcal{L}(\boldsymbol{\beta}) = \sum_{i=1}^n \left<span class="co">[</span><span class="ot"> y_i \log \Phi(\mathbf{X}_i^\top \boldsymbol{\beta}) + (1 - y_i) \log \left(1 - \Phi(\mathbf{X}_i^\top \boldsymbol{\beta})\right) \right</span><span class="co">]</span></span>
<span id="cb5-330"><a href="#cb5-330" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-331"><a href="#cb5-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-332"><a href="#cb5-332" aria-hidden="true" tabindex="-1"></a>Um den Maximum-Likelihood-Schätzer $\widehat{\boldsymbol{\beta}}$ zu finden, muss die Log-Likelihood-Funktion $\mathcal{L}(\boldsymbol{\beta})$ maximiert werden. In der Praxis erfolgt dies häufig durch numerische Optimierung, da die Log-Likelihood-Funktion der Probit-Regression im Allgemeinen keine geschlossene Form hat, sodass eine analytische Lösung nicht möglich ist.</span>
<span id="cb5-333"><a href="#cb5-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-334"><a href="#cb5-334" aria-hidden="true" tabindex="-1"></a>Für eine Anwendung in R und einen Vergleich mit dem linearen Wahrscheinlichkeitsmodell erzeugen wir einen Beispieldatensatz <span class="in">`simdata`</span> für einen datenerzeugenden Prozess (DGP)^<span class="co">[</span><span class="ot">Siehe @sec-sim für Erläuterungen von Simulationsmethoden in R.</span><span class="co">]</span> mit einem normalverteilten Regressor $X\sim N(5,2^2)$ und</span>
<span id="cb5-335"><a href="#cb5-335" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-336"><a href="#cb5-336" aria-hidden="true" tabindex="-1"></a>  P(Y=1\vert X) = \Phi(z), \quad z = -4 + 0.7 X.</span>
<span id="cb5-337"><a href="#cb5-337" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-338"><a href="#cb5-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-341"><a href="#cb5-341" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-342"><a href="#cb5-342" aria-hidden="true" tabindex="-1"></a><span class="in"># Daten simulieren</span></span>
<span id="cb5-343"><a href="#cb5-343" aria-hidden="true" tabindex="-1"></a><span class="in">set.seed(1234)</span></span>
<span id="cb5-344"><a href="#cb5-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-345"><a href="#cb5-345" aria-hidden="true" tabindex="-1"></a><span class="in"># Stichprobengröße</span></span>
<span id="cb5-346"><a href="#cb5-346" aria-hidden="true" tabindex="-1"></a><span class="in">n &lt;- 500 </span></span>
<span id="cb5-347"><a href="#cb5-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-348"><a href="#cb5-348" aria-hidden="true" tabindex="-1"></a><span class="in">simdata &lt;- tibble(</span></span>
<span id="cb5-349"><a href="#cb5-349" aria-hidden="true" tabindex="-1"></a><span class="in">  X = rnorm(n = n, mean = 5, sd = 2), # Regressor</span></span>
<span id="cb5-350"><a href="#cb5-350" aria-hidden="true" tabindex="-1"></a><span class="in">  P = pnorm(-4 + 0.7 * X),</span></span>
<span id="cb5-351"><a href="#cb5-351" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb5-352"><a href="#cb5-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-353"><a href="#cb5-353" aria-hidden="true" tabindex="-1"></a><span class="in"># Binäre Outcome-Variable hinzufügen</span></span>
<span id="cb5-354"><a href="#cb5-354" aria-hidden="true" tabindex="-1"></a><span class="in">simdata &lt;- simdata %&gt;%</span></span>
<span id="cb5-355"><a href="#cb5-355" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(</span></span>
<span id="cb5-356"><a href="#cb5-356" aria-hidden="true" tabindex="-1"></a><span class="in">    Y = as.integer(runif(n) &lt; P)</span></span>
<span id="cb5-357"><a href="#cb5-357" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb5-358"><a href="#cb5-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-359"><a href="#cb5-359" aria-hidden="true" tabindex="-1"></a><span class="in"># Überblick</span></span>
<span id="cb5-360"><a href="#cb5-360" aria-hidden="true" tabindex="-1"></a><span class="in">slice_head(simdata, n = 10)</span></span>
<span id="cb5-361"><a href="#cb5-361" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-362"><a href="#cb5-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-363"><a href="#cb5-363" aria-hidden="true" tabindex="-1"></a>Das lineare Wahrscheinlichkeitsmodell schätzen wir wie gewohnt mit <span class="in">`lm()`</span> und berechnen robuste Standardfehler mit <span class="in">`lmtest::coeftest()`</span>.</span>
<span id="cb5-364"><a href="#cb5-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-367"><a href="#cb5-367" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-368"><a href="#cb5-368" aria-hidden="true" tabindex="-1"></a><span class="in"># lineares Wahrscheinlichkeitsmodell schätzen</span></span>
<span id="cb5-369"><a href="#cb5-369" aria-hidden="true" tabindex="-1"></a><span class="in">mod_lp &lt;- lm(</span></span>
<span id="cb5-370"><a href="#cb5-370" aria-hidden="true" tabindex="-1"></a><span class="in">  formula = Y ~ X, </span></span>
<span id="cb5-371"><a href="#cb5-371" aria-hidden="true" tabindex="-1"></a><span class="in">  data = simdata</span></span>
<span id="cb5-372"><a href="#cb5-372" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb5-373"><a href="#cb5-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-374"><a href="#cb5-374" aria-hidden="true" tabindex="-1"></a><span class="in"># Zusammenfassung</span></span>
<span id="cb5-375"><a href="#cb5-375" aria-hidden="true" tabindex="-1"></a><span class="in">mod_lp %&gt;% </span></span>
<span id="cb5-376"><a href="#cb5-376" aria-hidden="true" tabindex="-1"></a><span class="in">  coeftest(vcov = vcovHC, type = "HC1") %&gt;%</span></span>
<span id="cb5-377"><a href="#cb5-377" aria-hidden="true" tabindex="-1"></a><span class="in">  tidy()</span></span>
<span id="cb5-378"><a href="#cb5-378" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-379"><a href="#cb5-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-380"><a href="#cb5-380" aria-hidden="true" tabindex="-1"></a>Beachte, dass lediglich die Vorzeichen der geschätzten Koeffizienten mit denen der wahren Werten übereinstimmmen. Da das lineare Modell fehlspezifiziert ist, sind die KQ-Schätzer der Koeffizienten hier inkonsistent.</span>
<span id="cb5-381"><a href="#cb5-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-382"><a href="#cb5-382" aria-hidden="true" tabindex="-1"></a>Ein Probit-Modell kann mit <span class="in">`stats::glm()`</span> geschätzt werden. Hierbei ist <span class="in">`formula`</span> die Formel für den linearen Prädiktor $z$ und <span class="in">`family`</span> eine Link-Funktion für den Zusammenhang von $z$ und $P(Y\vert X)$. Mit <span class="in">`family = binomial(link = "probit")`</span> wählen wir die Link-Funktion <span class="in">`probit`</span>.</span>
<span id="cb5-383"><a href="#cb5-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-386"><a href="#cb5-386" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-387"><a href="#cb5-387" aria-hidden="true" tabindex="-1"></a><span class="in"># Probit-Modell schätzen</span></span>
<span id="cb5-388"><a href="#cb5-388" aria-hidden="true" tabindex="-1"></a><span class="in">mod_probit &lt;- glm(</span></span>
<span id="cb5-389"><a href="#cb5-389" aria-hidden="true" tabindex="-1"></a><span class="in">  formula = Y ~ X,</span></span>
<span id="cb5-390"><a href="#cb5-390" aria-hidden="true" tabindex="-1"></a><span class="in">  data = simdata, </span></span>
<span id="cb5-391"><a href="#cb5-391" aria-hidden="true" tabindex="-1"></a><span class="in">  family = binomial(link = "probit")</span></span>
<span id="cb5-392"><a href="#cb5-392" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb5-393"><a href="#cb5-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-394"><a href="#cb5-394" aria-hidden="true" tabindex="-1"></a><span class="in"># Zusammenfassung</span></span>
<span id="cb5-395"><a href="#cb5-395" aria-hidden="true" tabindex="-1"></a><span class="in">mod_probit %&gt;%</span></span>
<span id="cb5-396"><a href="#cb5-396" aria-hidden="true" tabindex="-1"></a><span class="in">  coeftest(vcov = vcovHC, type = "HC1") %&gt;%</span></span>
<span id="cb5-397"><a href="#cb5-397" aria-hidden="true" tabindex="-1"></a><span class="in">  tidy()</span></span>
<span id="cb5-398"><a href="#cb5-398" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-399"><a href="#cb5-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-400"><a href="#cb5-400" aria-hidden="true" tabindex="-1"></a>Die geschätzten Koeffizienten in der Probit-Regression liegen, wie erwartet, nahe bei Parametern des DGPs.</span>
<span id="cb5-401"><a href="#cb5-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-402"><a href="#cb5-402" aria-hidden="true" tabindex="-1"></a>Um beide Schätzungen gemeinsam zu plotten, erzeugen wir mit <span class="in">`predict()`</span> Vorhersagen für eine Menge von Werten <span class="in">`X`</span> im Intervall $<span class="co">[</span><span class="ot">0,11</span><span class="co">]</span>$. Beachte, dass bei Vorhersagen für das Probit-Modell die gewünschte Transformation der vorherzusagenden Variable über <span class="in">`type`</span> gewählt werden muss.^<span class="co">[</span><span class="ot">Dies gilt für jedes Modell mit einer anderen Link-Funktion als $f(x) = x$ ist (lineare Regression).</span><span class="co">]</span> Der Standardfall ist <span class="in">`type = "link"`</span>, d.h. wir erhalten Vorhersagen für den linearen Prädiktor: $\widehat{z} = \widehat\beta_0 + \widehat{\beta}_1X$. Mit <span class="in">`type = "response"`</span> werden diese Werte mit der Link-Funktion, hier $\Phi(\cdot)$ zu vorhergesagten Wahrscheinlichkeiten $\widehat{P}(Y=1\vert X = x)$ transformiert.</span>
<span id="cb5-403"><a href="#cb5-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-406"><a href="#cb5-406" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-407"><a href="#cb5-407" aria-hidden="true" tabindex="-1"></a><span class="in"># geschätzte Wahrscheinlichkeitsfunktion</span></span>
<span id="cb5-408"><a href="#cb5-408" aria-hidden="true" tabindex="-1"></a><span class="in"># für lineares Modell</span></span>
<span id="cb5-409"><a href="#cb5-409" aria-hidden="true" tabindex="-1"></a><span class="in">X &lt;- seq(0, 11, 0.01)</span></span>
<span id="cb5-410"><a href="#cb5-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-411"><a href="#cb5-411" aria-hidden="true" tabindex="-1"></a><span class="in">pred &lt;- tibble(</span></span>
<span id="cb5-412"><a href="#cb5-412" aria-hidden="true" tabindex="-1"></a><span class="in">  X = X, </span></span>
<span id="cb5-413"><a href="#cb5-413" aria-hidden="true" tabindex="-1"></a><span class="in">  LP = predict(</span></span>
<span id="cb5-414"><a href="#cb5-414" aria-hidden="true" tabindex="-1"></a><span class="in">    object = mod_lp, </span></span>
<span id="cb5-415"><a href="#cb5-415" aria-hidden="true" tabindex="-1"></a><span class="in">    newdata = tibble(X)</span></span>
<span id="cb5-416"><a href="#cb5-416" aria-hidden="true" tabindex="-1"></a><span class="in">  ),</span></span>
<span id="cb5-417"><a href="#cb5-417" aria-hidden="true" tabindex="-1"></a><span class="in">  probit = predict(</span></span>
<span id="cb5-418"><a href="#cb5-418" aria-hidden="true" tabindex="-1"></a><span class="in">    object = mod_probit,</span></span>
<span id="cb5-419"><a href="#cb5-419" aria-hidden="true" tabindex="-1"></a><span class="in">    newdata = tibble(X),</span></span>
<span id="cb5-420"><a href="#cb5-420" aria-hidden="true" tabindex="-1"></a><span class="in">    type = "response"</span></span>
<span id="cb5-421"><a href="#cb5-421" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb5-422"><a href="#cb5-422" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb5-423"><a href="#cb5-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-424"><a href="#cb5-424" aria-hidden="true" tabindex="-1"></a><span class="in"># Überblick verschaffen</span></span>
<span id="cb5-425"><a href="#cb5-425" aria-hidden="true" tabindex="-1"></a><span class="in">slice_head(pred, n = 10)</span></span>
<span id="cb5-426"><a href="#cb5-426" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-427"><a href="#cb5-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-428"><a href="#cb5-428" aria-hidden="true" tabindex="-1"></a>Der nachfolgende Code-Chunk erstellt einen Punkte-Plot mit Jitter-Effekt (<span class="in">`position_jitter`</span>), wobei die Beobachtungen zufällig leicht vertikal verschoben werden, um Überlappungen zu vermeiden. Zusätzlich zeichnen wir die geschätzten Regressionslinien für <span class="in">`mod_lp`</span> (LPM) und <span class="in">`mod_probit`</span> (Probit) sowie die tatsächliche Wahrscheinlichkeitsfunktion $P(Y=1\vert X)$ ein.</span>
<span id="cb5-429"><a href="#cb5-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-432"><a href="#cb5-432" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-433"><a href="#cb5-433" aria-hidden="true" tabindex="-1"></a><span class="in"># Daten und geschätzte Modelle plotten</span></span>
<span id="cb5-434"><a href="#cb5-434" aria-hidden="true" tabindex="-1"></a><span class="in">p &lt;- simdata %&gt;%</span></span>
<span id="cb5-435"><a href="#cb5-435" aria-hidden="true" tabindex="-1"></a><span class="in">  ggplot(mapping = aes(x = X, y = Y)) +</span></span>
<span id="cb5-436"><a href="#cb5-436" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_point(</span></span>
<span id="cb5-437"><a href="#cb5-437" aria-hidden="true" tabindex="-1"></a><span class="in">    position = position_jitter(</span></span>
<span id="cb5-438"><a href="#cb5-438" aria-hidden="true" tabindex="-1"></a><span class="in">      height = .025,</span></span>
<span id="cb5-439"><a href="#cb5-439" aria-hidden="true" tabindex="-1"></a><span class="in">      seed = 1234</span></span>
<span id="cb5-440"><a href="#cb5-440" aria-hidden="true" tabindex="-1"></a><span class="in">    ),</span></span>
<span id="cb5-441"><a href="#cb5-441" aria-hidden="true" tabindex="-1"></a><span class="in">    alpha = .25,</span></span>
<span id="cb5-442"><a href="#cb5-442" aria-hidden="true" tabindex="-1"></a><span class="in">    color = "gray"</span></span>
<span id="cb5-443"><a href="#cb5-443" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-444"><a href="#cb5-444" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_line(</span></span>
<span id="cb5-445"><a href="#cb5-445" aria-hidden="true" tabindex="-1"></a><span class="in">    data = pred, </span></span>
<span id="cb5-446"><a href="#cb5-446" aria-hidden="true" tabindex="-1"></a><span class="in">    mapping = aes(y = LP, color = "LPM"),</span></span>
<span id="cb5-447"><a href="#cb5-447" aria-hidden="true" tabindex="-1"></a><span class="in">    lwd = .75</span></span>
<span id="cb5-448"><a href="#cb5-448" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-449"><a href="#cb5-449" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_line(</span></span>
<span id="cb5-450"><a href="#cb5-450" aria-hidden="true" tabindex="-1"></a><span class="in">    data = pred, </span></span>
<span id="cb5-451"><a href="#cb5-451" aria-hidden="true" tabindex="-1"></a><span class="in">    mapping = aes(y = probit, color = "Probit"),</span></span>
<span id="cb5-452"><a href="#cb5-452" aria-hidden="true" tabindex="-1"></a><span class="in">    lwd = .75</span></span>
<span id="cb5-453"><a href="#cb5-453" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-454"><a href="#cb5-454" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_function(</span></span>
<span id="cb5-455"><a href="#cb5-455" aria-hidden="true" tabindex="-1"></a><span class="in">    fun = \(x) pnorm(-4 + .7 * x), </span></span>
<span id="cb5-456"><a href="#cb5-456" aria-hidden="true" tabindex="-1"></a><span class="in">    mapping = aes(color = "Wahrheit")</span></span>
<span id="cb5-457"><a href="#cb5-457" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-458"><a href="#cb5-458" aria-hidden="true" tabindex="-1"></a><span class="in">  scale_color_manual(</span></span>
<span id="cb5-459"><a href="#cb5-459" aria-hidden="true" tabindex="-1"></a><span class="in">    name = "",</span></span>
<span id="cb5-460"><a href="#cb5-460" aria-hidden="true" tabindex="-1"></a><span class="in">    values = c(</span></span>
<span id="cb5-461"><a href="#cb5-461" aria-hidden="true" tabindex="-1"></a><span class="in">      "Wahrheit" = "black",</span></span>
<span id="cb5-462"><a href="#cb5-462" aria-hidden="true" tabindex="-1"></a><span class="in">      "LPM" = "steelblue", </span></span>
<span id="cb5-463"><a href="#cb5-463" aria-hidden="true" tabindex="-1"></a><span class="in">      "Probit" = "orange"</span></span>
<span id="cb5-464"><a href="#cb5-464" aria-hidden="true" tabindex="-1"></a><span class="in">    )</span></span>
<span id="cb5-465"><a href="#cb5-465" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-466"><a href="#cb5-466" aria-hidden="true" tabindex="-1"></a><span class="in">  labs(title = "Gesch. Modelle für binäre abhängige Variable") +</span></span>
<span id="cb5-467"><a href="#cb5-467" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_cowplot() +</span></span>
<span id="cb5-468"><a href="#cb5-468" aria-hidden="true" tabindex="-1"></a><span class="in">  theme(legend.position = "top")</span></span>
<span id="cb5-469"><a href="#cb5-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-470"><a href="#cb5-470" aria-hidden="true" tabindex="-1"></a><span class="in">p</span></span>
<span id="cb5-471"><a href="#cb5-471" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-472"><a href="#cb5-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-473"><a href="#cb5-473" aria-hidden="true" tabindex="-1"></a>Die Grafik zeigt, dass beide Modelle den positiven Zusammenhang für $X$ und $P(Y=1\vert X)$ erfassen. Das lineare Wahrscheinlichkeitsmodell approximiert die tatsächliche nicht-lineare Wahrscheinlichkeitsfunktion nur schlecht und liefert insbesondere in den Rändern der Verteilung von $X$ (kleine und große Werte) unzulässige Vorhersagen außerhalb des Intervalls $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$. Die Probit-Spezifikation hingegen erfasst den nicht-linearen Verlauf der tatsächlichen Wahrscheinlichkeitsfunktion gut.</span>
<span id="cb5-474"><a href="#cb5-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-475"><a href="#cb5-475" aria-hidden="true" tabindex="-1"></a><span class="fu">### Logistische Regression {#sec-logreg}</span></span>
<span id="cb5-476"><a href="#cb5-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-477"><a href="#cb5-477" aria-hidden="true" tabindex="-1"></a>Bei logistischer Regression wird die logistische Funktion $\Lambda(\cdot)$ </span>
<span id="cb5-478"><a href="#cb5-478" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb5-479"><a href="#cb5-479" aria-hidden="true" tabindex="-1"></a>\Lambda(z) = \frac{1}{1 + \exp(-z)},</span>
<span id="cb5-480"><a href="#cb5-480" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb5-481"><a href="#cb5-481" aria-hidden="true" tabindex="-1"></a>als Link-Funktion genutzt, um die Wahrscheinlichkeitsfunktion von $Y$ gegeben $X$ zu modellieren. Ähnlich wie im Probit-Modell nehmen wir hier an, dass</span>
<span id="cb5-482"><a href="#cb5-482" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb5-483"><a href="#cb5-483" aria-hidden="true" tabindex="-1"></a>E(Y\vert X) = P(Y=1\vert X) = \Lambda(\beta_0 + \beta_1 X). \label{eq:logitmodel}</span>
<span id="cb5-484"><a href="#cb5-484" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb5-485"><a href="#cb5-485" aria-hidden="true" tabindex="-1"></a>In diesem Modell ist die Link-Funktion $\Lambda^{-1}(\cdot)$. Für $z=\beta_0 + \beta_1 X$ ist $\Lambda^{-1}(t)$ der sogenannte *logit*: Dass logarithmierte Verhältnis von $p := P(Y=1\vert X)$ zu $1 - p = P(Y=0\vert X)$,</span>
<span id="cb5-486"><a href="#cb5-486" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-487"><a href="#cb5-487" aria-hidden="true" tabindex="-1"></a>  \textup{logit(p)} = \log\bigg(\frac{p}{1-p}\bigg) = \beta_0 + \beta_1 X.</span>
<span id="cb5-488"><a href="#cb5-488" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-489"><a href="#cb5-489" aria-hidden="true" tabindex="-1"></a>Der Koeffizient $\beta_1$ misst also die Veränderung des Logits pro Einheit Änderung im Regressor $X$. </span>
<span id="cb5-490"><a href="#cb5-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-491"><a href="#cb5-491" aria-hidden="true" tabindex="-1"></a>Ähnlich wie bei Probit-Regression ist der Einfluss von $X$ auf den Logit linear, jedoch besteht auch hier eine nicht-lineare Beziehung zwischen dem linearen Prädiktor und der Wahrscheinlichkeit $P(Y=1\vert X)$, denn $\Lambda(\cdot)$ ist eine nicht-lineare Funktion mit dem Wertebereich $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$.</span>
<span id="cb5-492"><a href="#cb5-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-495"><a href="#cb5-495" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-496"><a href="#cb5-496" aria-hidden="true" tabindex="-1"></a><span class="in"># Plot: Logistische Funktion</span></span>
<span id="cb5-497"><a href="#cb5-497" aria-hidden="true" tabindex="-1"></a><span class="in">ggplot() +</span></span>
<span id="cb5-498"><a href="#cb5-498" aria-hidden="true" tabindex="-1"></a><span class="in">  stat_function(</span></span>
<span id="cb5-499"><a href="#cb5-499" aria-hidden="true" tabindex="-1"></a><span class="in">    fun = \(x) 1 / (1 + exp(-x))</span></span>
<span id="cb5-500"><a href="#cb5-500" aria-hidden="true" tabindex="-1"></a><span class="in">    ) +</span></span>
<span id="cb5-501"><a href="#cb5-501" aria-hidden="true" tabindex="-1"></a><span class="in">  scale_x_continuous(</span></span>
<span id="cb5-502"><a href="#cb5-502" aria-hidden="true" tabindex="-1"></a><span class="in">    name = "z", </span></span>
<span id="cb5-503"><a href="#cb5-503" aria-hidden="true" tabindex="-1"></a><span class="in">    limits = c(-4, 4)</span></span>
<span id="cb5-504"><a href="#cb5-504" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-505"><a href="#cb5-505" aria-hidden="true" tabindex="-1"></a><span class="in">  scale_y_continuous(name = "Lambda(z)") +</span></span>
<span id="cb5-506"><a href="#cb5-506" aria-hidden="true" tabindex="-1"></a><span class="in">  labs(title = "Logistische Funktion") +</span></span>
<span id="cb5-507"><a href="#cb5-507" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_cowplot()</span></span>
<span id="cb5-508"><a href="#cb5-508" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-509"><a href="#cb5-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-512"><a href="#cb5-512" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-513"><a href="#cb5-513" aria-hidden="true" tabindex="-1"></a><span class="in"># Plot: Logit</span></span>
<span id="cb5-514"><a href="#cb5-514" aria-hidden="true" tabindex="-1"></a><span class="in">ggplot() +</span></span>
<span id="cb5-515"><a href="#cb5-515" aria-hidden="true" tabindex="-1"></a><span class="in">  stat_function(</span></span>
<span id="cb5-516"><a href="#cb5-516" aria-hidden="true" tabindex="-1"></a><span class="in">    fun = \(x) log(x / (1 - x))</span></span>
<span id="cb5-517"><a href="#cb5-517" aria-hidden="true" tabindex="-1"></a><span class="in">    ) +</span></span>
<span id="cb5-518"><a href="#cb5-518" aria-hidden="true" tabindex="-1"></a><span class="in">  scale_x_continuous(</span></span>
<span id="cb5-519"><a href="#cb5-519" aria-hidden="true" tabindex="-1"></a><span class="in">    name = "p", </span></span>
<span id="cb5-520"><a href="#cb5-520" aria-hidden="true" tabindex="-1"></a><span class="in">    limits = c(0, 1)</span></span>
<span id="cb5-521"><a href="#cb5-521" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-522"><a href="#cb5-522" aria-hidden="true" tabindex="-1"></a><span class="in">  scale_y_continuous(name = "Logit(p)") +</span></span>
<span id="cb5-523"><a href="#cb5-523" aria-hidden="true" tabindex="-1"></a><span class="in">  labs(title = "Logit-Funktion") +</span></span>
<span id="cb5-524"><a href="#cb5-524" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_cowplot()</span></span>
<span id="cb5-525"><a href="#cb5-525" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-526"><a href="#cb5-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-527"><a href="#cb5-527" aria-hidden="true" tabindex="-1"></a>Die nachstehende interaktive Grafik illustriert, wie die Wahrscheinlichkeitsfunktion der latenten Variable $z=\beta_0 + \beta_1 X$ von den Parametern $\beta_0$ und $\beta_1$ jeweils für Logit- und Probit-Regression beeinflusst wird.</span>
<span id="cb5-528"><a href="#cb5-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-529"><a href="#cb5-529" aria-hidden="true" tabindex="-1"></a>&lt;iframe class="obs-soft-box-shadow" width="100%" height="680" frameborder="0"</span>
<span id="cb5-530"><a href="#cb5-530" aria-hidden="true" tabindex="-1"></a>  src="https://observablehq.com/embed/@mca91/latent-variable-cdf?cells=plot%2Cviewof+beta0%2Cviewof+beta%2CMathJax"&gt;&lt;/iframe&gt;</span>
<span id="cb5-531"><a href="#cb5-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-532"><a href="#cb5-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-533"><a href="#cb5-533" aria-hidden="true" tabindex="-1"></a>Aufgrund der Nicht-Linearität von $\Lambda(z)$ kann der Koeffizient $\beta_1$ wie im Probit-Modell nicht direkt als Effekt auf die Wahrscheinlichkeit $P(Y=1\vert X)$ interpretiert werden.</span>
<span id="cb5-534"><a href="#cb5-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-535"><a href="#cb5-535" aria-hidden="true" tabindex="-1"></a>Um den partiellen Effekt einer Änderung in $X$ am Punkt $X$ auf $P(Y=1\vert X)$ zu ermitteln, berechnen wir die Ableitung des bedingten Erwartungswerts:</span>
<span id="cb5-536"><a href="#cb5-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-537"><a href="#cb5-537" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-538"><a href="#cb5-538" aria-hidden="true" tabindex="-1"></a>\frac{\partial\textup{E}(Y\vert X)}{\partial X} = \frac{\partial\textup{P}(Y=1\vert X)}{\partial X} = \frac{\partial\Lambda(\beta_0 + \beta_1 X)}{\partial X} = \lambda(\beta_0 + \beta_1 X) \beta_1,</span>
<span id="cb5-539"><a href="#cb5-539" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-540"><a href="#cb5-540" aria-hidden="true" tabindex="-1"></a>wobei $\lambda(\cdot)$, ähnlich wie die Dichtefunktion der Normalverteilung im Probit-Modell, die Dichtefunktion der logistischen Verteilung darstellt. Diese ist gegeben durch</span>
<span id="cb5-541"><a href="#cb5-541" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-542"><a href="#cb5-542" aria-hidden="true" tabindex="-1"></a>\lambda(z) = \Lambda(z) \cdot (1 - \Lambda(z)).</span>
<span id="cb5-543"><a href="#cb5-543" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-544"><a href="#cb5-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-545"><a href="#cb5-545" aria-hidden="true" tabindex="-1"></a>Die Interpretation des angepassten Modells ist aufgrund der Modellierung des Logits intuitiver als für Probit-Regression. Angenommen eine Bank möchte die Wahrscheinlichkeit modellieren, dass ein Kunde einen Kredit nicht zurückzahlt:  $P(Y=\textup{Zahlungsausfall}\vert X)$, wobei der Regressor $X$ das Verhältnis von aktuellem Schuldenstand und Monatseinkommen ist. Die Schätzung einer logistischen Regression ergibt, dass ein Anstieg von $X =x$ um 0.1 den Logit für die Wahrscheinlichkeit eines Kreditausfalls $p(x)$ um 0.4 erhöht:</span>
<span id="cb5-546"><a href="#cb5-546" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-547"><a href="#cb5-547" aria-hidden="true" tabindex="-1"></a>  \textup{logit} \big<span class="co">[</span><span class="ot">P(Y=\textup{Zahlungsausfall}\vert X = x + 0.1)\big</span><span class="co">]</span> = \textup{logit}<span class="co">[</span><span class="ot">p(x)</span><span class="co">]</span> + 0.4. </span>
<span id="cb5-548"><a href="#cb5-548" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-549"><a href="#cb5-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-550"><a href="#cb5-550" aria-hidden="true" tabindex="-1"></a>Das Modell besagt dann, dass die Wahrscheinlichkeit der Zahlungsunfähigkeit etwa um den *Faktor* 1.5 ansteigt, denn</span>
<span id="cb5-551"><a href="#cb5-551" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-552"><a href="#cb5-552" aria-hidden="true" tabindex="-1"></a>  \exp\big(\textup{logit}<span class="co">[</span><span class="ot">p(x)</span><span class="co">]</span> + 0.4\big) = \frac{p(x)}{1-p(x)} \cdot \exp(0.4)</span>
<span id="cb5-553"><a href="#cb5-553" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-554"><a href="#cb5-554" aria-hidden="true" tabindex="-1"></a>mit</span>
<span id="cb5-555"><a href="#cb5-555" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-556"><a href="#cb5-556" aria-hidden="true" tabindex="-1"></a>  \exp(0.4) \approx 1.50.</span>
<span id="cb5-557"><a href="#cb5-557" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-558"><a href="#cb5-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-559"><a href="#cb5-559" aria-hidden="true" tabindex="-1"></a><span class="fu">### Schätzung</span></span>
<span id="cb5-560"><a href="#cb5-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-561"><a href="#cb5-561" aria-hidden="true" tabindex="-1"></a>Ähnlich wie bei Probit-Regressionen können Logit-Modelle mit Maximum-Likelihood geschätzt werden. Die Likelihood-Funktion für Logit-Regression lautet</span>
<span id="cb5-562"><a href="#cb5-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-563"><a href="#cb5-563" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb5-564"><a href="#cb5-564" aria-hidden="true" tabindex="-1"></a>  L(\boldsymbol{\beta}) &amp;= \prod_{i=1}^n \left(\frac{1}{1 + \exp(-\mathbf{X}_i^\top \boldsymbol{\beta})}\right)^{y_i} \left(1 - \frac{1}{1 + \exp(-\mathbf{X}_i^\top \boldsymbol{\beta})}\right)^{1-y_i},</span>
<span id="cb5-565"><a href="#cb5-565" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb5-566"><a href="#cb5-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-567"><a href="#cb5-567" aria-hidden="true" tabindex="-1"></a>mit $$\frac{1}{1 + \exp(-\mathbf{X}_i^\top \boldsymbol{\beta})}$$ der Wahrscheinlichkeit, dass $Y_i = 1$. Für das Ereignis $Y_i = 0$ ist die  Wahrscheinlichkeit entsprechend $$1 - \frac{1}{1 + \exp(-\mathbf{X}_i^\top \boldsymbol{\beta})}.$$</span>
<span id="cb5-568"><a href="#cb5-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-569"><a href="#cb5-569" aria-hidden="true" tabindex="-1"></a>Die Log-Likelihood-Funktion lautet</span>
<span id="cb5-570"><a href="#cb5-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-571"><a href="#cb5-571" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-572"><a href="#cb5-572" aria-hidden="true" tabindex="-1"></a>  \mathcal{L}(\boldsymbol{\beta}) &amp;= \sum_{i=1}^n \left<span class="co">[</span><span class="ot"> y_i \log \left(\frac{1}{1 + \exp(-\mathbf{X}_i^\top \boldsymbol{\beta})}\right) + (1 - y_i) \log \left(1 - \frac{1}{1 + \exp(-\mathbf{X}_i^\top \boldsymbol{\beta})}\right) \right</span><span class="co">]</span></span>
<span id="cb5-573"><a href="#cb5-573" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-574"><a href="#cb5-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-575"><a href="#cb5-575" aria-hidden="true" tabindex="-1"></a>und erlaubt die Schätzung von $\boldsymbol{\beta}$ durch Maximierung mit numerischen Methoden.</span>
<span id="cb5-576"><a href="#cb5-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-577"><a href="#cb5-577" aria-hidden="true" tabindex="-1"></a>Für Anwendungen mit R nutzen wir <span class="in">`stats::glm()`</span> und wählen die logistische Link-Funktion mit <span class="in">`family = binomial(link = "logit")`</span>. Für die simulierten Daten <span class="in">`simdata`</span> aus @sec-probitreg:</span>
<span id="cb5-578"><a href="#cb5-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-581"><a href="#cb5-581" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-582"><a href="#cb5-582" aria-hidden="true" tabindex="-1"></a><span class="in"># Logit-Modell schätzen</span></span>
<span id="cb5-583"><a href="#cb5-583" aria-hidden="true" tabindex="-1"></a><span class="in">mod_logit &lt;- glm(</span></span>
<span id="cb5-584"><a href="#cb5-584" aria-hidden="true" tabindex="-1"></a><span class="in">  formula = Y ~ X,</span></span>
<span id="cb5-585"><a href="#cb5-585" aria-hidden="true" tabindex="-1"></a><span class="in">  data = simdata, </span></span>
<span id="cb5-586"><a href="#cb5-586" aria-hidden="true" tabindex="-1"></a><span class="in">  family = binomial(link = "logit")</span></span>
<span id="cb5-587"><a href="#cb5-587" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb5-588"><a href="#cb5-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-589"><a href="#cb5-589" aria-hidden="true" tabindex="-1"></a><span class="in"># Robuste Zusammenfassung</span></span>
<span id="cb5-590"><a href="#cb5-590" aria-hidden="true" tabindex="-1"></a><span class="in">mod_logit %&gt;%</span></span>
<span id="cb5-591"><a href="#cb5-591" aria-hidden="true" tabindex="-1"></a><span class="in">  coeftest(vcov = vcovHC, type = "HC1")</span></span>
<span id="cb5-592"><a href="#cb5-592" aria-hidden="true" tabindex="-1"></a><span class="in">  tidy()</span></span>
<span id="cb5-593"><a href="#cb5-593" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-594"><a href="#cb5-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-595"><a href="#cb5-595" aria-hidden="true" tabindex="-1"></a>Wir erweitern nun <span class="in">`pred`</span> um die anhand von <span class="in">`predict()`</span> für <span class="in">`mod_logit`</span> geschätzten Wahrscheinlichkeiten von $Y=1\vert X$ für die Regressorwerte in <span class="in">`X`</span>.</span>
<span id="cb5-596"><a href="#cb5-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-599"><a href="#cb5-599" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-600"><a href="#cb5-600" aria-hidden="true" tabindex="-1"></a><span class="in"># gesch. WSK-Funktion gem. Logit-Modell hinzufügen</span></span>
<span id="cb5-601"><a href="#cb5-601" aria-hidden="true" tabindex="-1"></a><span class="in">pred &lt;- pred %&gt;%</span></span>
<span id="cb5-602"><a href="#cb5-602" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(</span></span>
<span id="cb5-603"><a href="#cb5-603" aria-hidden="true" tabindex="-1"></a><span class="in">    Logit = predict(mod_logit, tibble(X), type = "response")</span></span>
<span id="cb5-604"><a href="#cb5-604" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb5-605"><a href="#cb5-605" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-606"><a href="#cb5-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-607"><a href="#cb5-607" aria-hidden="true" tabindex="-1"></a>Anhand der Vorhersagen in <span class="in">`pred`</span> können wir die im Objekt <span class="in">`p`</span> gespeicherte Grafik um die geschätzte Regressionsfunktion für das Logit-Modell erweitern.</span>
<span id="cb5-608"><a href="#cb5-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-611"><a href="#cb5-611" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-612"><a href="#cb5-612" aria-hidden="true" tabindex="-1"></a><span class="in"># Grafik mit Logit-fit erweitern</span></span>
<span id="cb5-613"><a href="#cb5-613" aria-hidden="true" tabindex="-1"></a><span class="in">p + </span></span>
<span id="cb5-614"><a href="#cb5-614" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_line(</span></span>
<span id="cb5-615"><a href="#cb5-615" aria-hidden="true" tabindex="-1"></a><span class="in">    data = pred, </span></span>
<span id="cb5-616"><a href="#cb5-616" aria-hidden="true" tabindex="-1"></a><span class="in">    mapping = aes(y = Logit, color = "Logit"),</span></span>
<span id="cb5-617"><a href="#cb5-617" aria-hidden="true" tabindex="-1"></a><span class="in">    lwd = .75</span></span>
<span id="cb5-618"><a href="#cb5-618" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-619"><a href="#cb5-619" aria-hidden="true" tabindex="-1"></a><span class="in">    scale_color_manual(</span></span>
<span id="cb5-620"><a href="#cb5-620" aria-hidden="true" tabindex="-1"></a><span class="in">    name = "",</span></span>
<span id="cb5-621"><a href="#cb5-621" aria-hidden="true" tabindex="-1"></a><span class="in">    values = c(</span></span>
<span id="cb5-622"><a href="#cb5-622" aria-hidden="true" tabindex="-1"></a><span class="in">      "Wahrheit" = "black",</span></span>
<span id="cb5-623"><a href="#cb5-623" aria-hidden="true" tabindex="-1"></a><span class="in">      "LPM" = "steelblue", </span></span>
<span id="cb5-624"><a href="#cb5-624" aria-hidden="true" tabindex="-1"></a><span class="in">      "Probit" = "orange",</span></span>
<span id="cb5-625"><a href="#cb5-625" aria-hidden="true" tabindex="-1"></a><span class="in">      "Logit" = "darkred"</span></span>
<span id="cb5-626"><a href="#cb5-626" aria-hidden="true" tabindex="-1"></a><span class="in">    )</span></span>
<span id="cb5-627"><a href="#cb5-627" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb5-628"><a href="#cb5-628" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-629"><a href="#cb5-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-630"><a href="#cb5-630" aria-hidden="true" tabindex="-1"></a>Die Logit-Regression kann den wahren Zusammenhang gut abbilden und ist praktisch nicht von der Probit-Schätzung unterscheidbar. </span>
<span id="cb5-631"><a href="#cb5-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-632"><a href="#cb5-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-633"><a href="#cb5-633" aria-hidden="true" tabindex="-1"></a><span class="fu">### Modellgüte</span></span>
<span id="cb5-634"><a href="#cb5-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-635"><a href="#cb5-635" aria-hidden="true" tabindex="-1"></a>Ähnlich wie bei linearer Regression kann die Anpassung von generalisierten linearen Modellen an die Daten mit Anpassungsmaßen verglichen werden. In generalisierten linearen Modellen für binäre Outcome-Variablen kann hierzu die *Deviance* verwendet werden. Für eine Schätzung anhand der Beobachtungen $i=1,\dots,n$ berechnet man die Deviance $D$ als</span>
<span id="cb5-636"><a href="#cb5-636" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-637"><a href="#cb5-637" aria-hidden="true" tabindex="-1"></a>  D = -2 \sum_{i=1}^{n} \left<span class="co">[</span><span class="ot"> y_i \cdot \log\left(\widehat{P}_i\right) + (1 - y_i) \cdot \log\left(1 - \widehat{P}_i\right) \right</span><span class="co">]</span>.</span>
<span id="cb5-638"><a href="#cb5-638" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-639"><a href="#cb5-639" aria-hidden="true" tabindex="-1"></a>$D$ quantifiziert die Abweichung eines geschätzten Modells von einem perfekt passenden Modell.^<span class="co">[</span><span class="ot">Im Allgemeinen vergleicht Deviance die Log-Likelihood des geschätzten Modells mit der Log-Likelihood des perfekten Modells.</span><span class="co">]</span> Eine geringere Deviance deutet darauf hin, dass das Modell die Daten besser erklärt. Eine R-Funktion zur Anwendung für Objekte des Typs <span class="in">`glm`</span> ist <span class="in">`deviance()`</span>.</span>
<span id="cb5-640"><a href="#cb5-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-643"><a href="#cb5-643" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-644"><a href="#cb5-644" aria-hidden="true" tabindex="-1"></a><span class="in"># Deviance berechnen</span></span>
<span id="cb5-645"><a href="#cb5-645" aria-hidden="true" tabindex="-1"></a><span class="in">list(</span></span>
<span id="cb5-646"><a href="#cb5-646" aria-hidden="true" tabindex="-1"></a><span class="in">  "Probit" = mod_probit, </span></span>
<span id="cb5-647"><a href="#cb5-647" aria-hidden="true" tabindex="-1"></a><span class="in">  "Logit" = mod_logit</span></span>
<span id="cb5-648"><a href="#cb5-648" aria-hidden="true" tabindex="-1"></a><span class="in">) %&gt;% </span></span>
<span id="cb5-649"><a href="#cb5-649" aria-hidden="true" tabindex="-1"></a><span class="in">  map_dbl(.f = deviance)</span></span>
<span id="cb5-650"><a href="#cb5-650" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-651"><a href="#cb5-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-652"><a href="#cb5-652" aria-hidden="true" tabindex="-1"></a>Die Deviance für das Probit-Modell ist tatsächlich etwas geringer als für das Logit-Modell. </span>
<span id="cb5-653"><a href="#cb5-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-654"><a href="#cb5-654" aria-hidden="true" tabindex="-1"></a>Ähnlich wie $R^2$ für lineare Regression misst die Deviance $D$ lediglich die Anpassung des Modells an die beobachteten Daten. Daher eignet sich $D$ nur bedingt als Maß zur Einschätzung der Tauglichkeit eines Modells für Out-of-sample-Vorhersagen. Abhängig vom Ziel der Modellierung kann es hilfreich sein, eine robuste Einschätzung der Vorhersage-Güte unter Berücksichtigung der Modellkomplexität vorzunehmen. Hierfür werden oft Informationskriterien verwendet. Das Akaike-Informationskriterium (AIC) </span>
<span id="cb5-655"><a href="#cb5-655" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-656"><a href="#cb5-656" aria-hidden="true" tabindex="-1"></a>  \text{AIC} = 2k - 2 \log(\widehat{\mathcal{L}})</span>
<span id="cb5-657"><a href="#cb5-657" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-658"><a href="#cb5-658" aria-hidden="true" tabindex="-1"></a>ist ein Maß zur Bewertung der Güte eines Modells unter Berücksichtigung der Modellkomplexität. Das AIC wägt die Anpassung des Modells an die Daten (gemessen durch die maximierte Likelihood-Funktion $\widehat{\mathcal{L}}$^<span class="co">[</span><span class="ot">$\widehat{\mathcal{L}}$ meint die Likelihood-Funktion für die geschätzten Koeffizienten.</span><span class="co">]</span>) und die Komplexität (gemessen als Funktion der Regressoranzahl $k$) gegeneinander ab. Hierbei werden Modelle mit weniger Parametern bevorzugt, wenn sie die Daten ähnlich gut erklären, sodass eine Überanpassung und damit eine schlechte Vorhersagefähigkeit vermieden werden. In R können wir das AIC für Modell-Objekte mit <span class="in">`AIC()`</span> berechnen. </span>
<span id="cb5-659"><a href="#cb5-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-662"><a href="#cb5-662" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-663"><a href="#cb5-663" aria-hidden="true" tabindex="-1"></a><span class="in"># AIC berechnen</span></span>
<span id="cb5-664"><a href="#cb5-664" aria-hidden="true" tabindex="-1"></a><span class="in">list(</span></span>
<span id="cb5-665"><a href="#cb5-665" aria-hidden="true" tabindex="-1"></a><span class="in">  Probit = mod_probit, </span></span>
<span id="cb5-666"><a href="#cb5-666" aria-hidden="true" tabindex="-1"></a><span class="in">  Logit = mod_logit</span></span>
<span id="cb5-667"><a href="#cb5-667" aria-hidden="true" tabindex="-1"></a><span class="in">) %&gt;% </span></span>
<span id="cb5-668"><a href="#cb5-668" aria-hidden="true" tabindex="-1"></a><span class="in">  map_dbl(.f = AIC)</span></span>
<span id="cb5-669"><a href="#cb5-669" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-670"><a href="#cb5-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-671"><a href="#cb5-671" aria-hidden="true" tabindex="-1"></a>Auch das AIC zeigt an, dass die Schätzung des Probit-Modells in <span class="in">`mod_probit`</span> besser geeignet für die Modiellierung von <span class="in">`simdata`</span> ist als das Logit-Modell <span class="in">`mod_logit`</span>.</span>
<span id="cb5-672"><a href="#cb5-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-673"><a href="#cb5-673" aria-hidden="true" tabindex="-1"></a><span class="fu">### Beispiel: Klassifikation von Palmer-Piniguinen</span></span>
<span id="cb5-674"><a href="#cb5-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-675"><a href="#cb5-675" aria-hidden="true" tabindex="-1"></a>Mit den in diesem Kapitel betrachteten Methoden können wir Modelle zur Klassifikation von Pinguinen in <span class="in">`palmerpenguins::penguins`</span> hinsichtlich ihres Geschlechts konstruieren. Hierfür nutzen wir den bereinigten Datensatz <span class="in">`penguins_cleaned`</span> und transformieren zunächst die abhängige Variable <span class="in">`sex`</span> in ein numerisches Format.</span>
<span id="cb5-676"><a href="#cb5-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-679"><a href="#cb5-679" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-680"><a href="#cb5-680" aria-hidden="true" tabindex="-1"></a><span class="in"># 'sex' transformieren</span></span>
<span id="cb5-681"><a href="#cb5-681" aria-hidden="true" tabindex="-1"></a><span class="in">penguins_cleaned &lt;- penguins_cleaned %&gt;% </span></span>
<span id="cb5-682"><a href="#cb5-682" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(</span></span>
<span id="cb5-683"><a href="#cb5-683" aria-hidden="true" tabindex="-1"></a><span class="in">    # sex in 0,1-codierte Variable umwandeln</span></span>
<span id="cb5-684"><a href="#cb5-684" aria-hidden="true" tabindex="-1"></a><span class="in">    sex = if_else(sex == "female", 1, 0)</span></span>
<span id="cb5-685"><a href="#cb5-685" aria-hidden="true" tabindex="-1"></a><span class="in">    )</span></span>
<span id="cb5-686"><a href="#cb5-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-687"><a href="#cb5-687" aria-hidden="true" tabindex="-1"></a><span class="in"># Überprüfen</span></span>
<span id="cb5-688"><a href="#cb5-688" aria-hidden="true" tabindex="-1"></a><span class="in">penguins_cleaned %&gt;%</span></span>
<span id="cb5-689"><a href="#cb5-689" aria-hidden="true" tabindex="-1"></a><span class="in">  select(sex) %&gt;%</span></span>
<span id="cb5-690"><a href="#cb5-690" aria-hidden="true" tabindex="-1"></a><span class="in">  slice_head(n = 10)</span></span>
<span id="cb5-691"><a href="#cb5-691" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-692"><a href="#cb5-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-693"><a href="#cb5-693" aria-hidden="true" tabindex="-1"></a>Wir schätzen nachfolgend ein lineares Wahrscheinlichkeitsmodell <span class="in">`penguins_lp`</span>, ein Probit-Modell <span class="in">`penguins_probit`</span> sowie ein Logit-Modell <span class="in">`penguins_logit`</span> die jeweils <span class="in">`sex`</span> anhand der simplen Spezikation des linearen Prädiktors $$z = \beta_0 + \beta_1 \textup{bill<span class="sc">\_</span>depth}$$ erklären.</span>
<span id="cb5-694"><a href="#cb5-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-697"><a href="#cb5-697" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-698"><a href="#cb5-698" aria-hidden="true" tabindex="-1"></a><span class="in"># Lineares Modell</span></span>
<span id="cb5-699"><a href="#cb5-699" aria-hidden="true" tabindex="-1"></a><span class="in">penguins_lp &lt;- lm(</span></span>
<span id="cb5-700"><a href="#cb5-700" aria-hidden="true" tabindex="-1"></a><span class="in">  formula = sex ~ bill_depth, </span></span>
<span id="cb5-701"><a href="#cb5-701" aria-hidden="true" tabindex="-1"></a><span class="in">  data = penguins_cleaned</span></span>
<span id="cb5-702"><a href="#cb5-702" aria-hidden="true" tabindex="-1"></a><span class="in">) </span></span>
<span id="cb5-703"><a href="#cb5-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-704"><a href="#cb5-704" aria-hidden="true" tabindex="-1"></a><span class="in"># Robuste Zusammenfassung</span></span>
<span id="cb5-705"><a href="#cb5-705" aria-hidden="true" tabindex="-1"></a><span class="in">penguins_lp %&gt;%</span></span>
<span id="cb5-706"><a href="#cb5-706" aria-hidden="true" tabindex="-1"></a><span class="in">  coeftest(vcov = vcovHC, type = "HC1") %&gt;%</span></span>
<span id="cb5-707"><a href="#cb5-707" aria-hidden="true" tabindex="-1"></a><span class="in">  tidy()</span></span>
<span id="cb5-708"><a href="#cb5-708" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-709"><a href="#cb5-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-712"><a href="#cb5-712" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-713"><a href="#cb5-713" aria-hidden="true" tabindex="-1"></a><span class="in"># Probit-Modell</span></span>
<span id="cb5-714"><a href="#cb5-714" aria-hidden="true" tabindex="-1"></a><span class="in">penguins_probit &lt;- glm(</span></span>
<span id="cb5-715"><a href="#cb5-715" aria-hidden="true" tabindex="-1"></a><span class="in">  formula = sex ~ bill_depth, </span></span>
<span id="cb5-716"><a href="#cb5-716" aria-hidden="true" tabindex="-1"></a><span class="in">  data = penguins_cleaned, </span></span>
<span id="cb5-717"><a href="#cb5-717" aria-hidden="true" tabindex="-1"></a><span class="in">  family = binomial("probit")</span></span>
<span id="cb5-718"><a href="#cb5-718" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb5-719"><a href="#cb5-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-720"><a href="#cb5-720" aria-hidden="true" tabindex="-1"></a><span class="in"># Robuste Zusammenfassung</span></span>
<span id="cb5-721"><a href="#cb5-721" aria-hidden="true" tabindex="-1"></a><span class="in">penguins_probit %&gt;% </span></span>
<span id="cb5-722"><a href="#cb5-722" aria-hidden="true" tabindex="-1"></a><span class="in">    coeftest(vcov = vcovHC, type = "HC1") %&gt;%</span></span>
<span id="cb5-723"><a href="#cb5-723" aria-hidden="true" tabindex="-1"></a><span class="in">  tidy()</span></span>
<span id="cb5-724"><a href="#cb5-724" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-725"><a href="#cb5-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-728"><a href="#cb5-728" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-729"><a href="#cb5-729" aria-hidden="true" tabindex="-1"></a><span class="in"># Logit-Modell</span></span>
<span id="cb5-730"><a href="#cb5-730" aria-hidden="true" tabindex="-1"></a><span class="in">penguins_logit &lt;- glm(</span></span>
<span id="cb5-731"><a href="#cb5-731" aria-hidden="true" tabindex="-1"></a><span class="in">  formula = sex ~ bill_depth, </span></span>
<span id="cb5-732"><a href="#cb5-732" aria-hidden="true" tabindex="-1"></a><span class="in">  data = penguins_cleaned, </span></span>
<span id="cb5-733"><a href="#cb5-733" aria-hidden="true" tabindex="-1"></a><span class="in">  family = binomial("logit")</span></span>
<span id="cb5-734"><a href="#cb5-734" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb5-735"><a href="#cb5-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-736"><a href="#cb5-736" aria-hidden="true" tabindex="-1"></a><span class="in"># Robuste Zusammenfassung</span></span>
<span id="cb5-737"><a href="#cb5-737" aria-hidden="true" tabindex="-1"></a><span class="in">penguins_logit %&gt;% </span></span>
<span id="cb5-738"><a href="#cb5-738" aria-hidden="true" tabindex="-1"></a><span class="in">  coeftest(vcov = vcovHC, type = "HC1") %&gt;%</span></span>
<span id="cb5-739"><a href="#cb5-739" aria-hidden="true" tabindex="-1"></a><span class="in">  tidy()</span></span>
<span id="cb5-740"><a href="#cb5-740" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-741"><a href="#cb5-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-742"><a href="#cb5-742" aria-hidden="true" tabindex="-1"></a>Mit <span class="in">`modelsummary::modelsummary()`</span> können wir die wichtigsten Ergebnisse der Regressionen in einer publikationsfähigen Tabelle darstellen. Hierzu übergeben wir dem Argument <span class="in">`models`</span> eine (benannte) Liste der geschätzten Modelle. Bei Angabe von <span class="in">`vcov = "HC1"`</span> werden robuste Standardfehler ausgegeben.</span>
<span id="cb5-743"><a href="#cb5-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-746"><a href="#cb5-746" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-747"><a href="#cb5-747" aria-hidden="true" tabindex="-1"></a><span class="in">library(modelsummary)</span></span>
<span id="cb5-748"><a href="#cb5-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-749"><a href="#cb5-749" aria-hidden="true" tabindex="-1"></a><span class="in"># Geschätzte Modelle</span></span>
<span id="cb5-750"><a href="#cb5-750" aria-hidden="true" tabindex="-1"></a><span class="in">modelsummary(</span></span>
<span id="cb5-751"><a href="#cb5-751" aria-hidden="true" tabindex="-1"></a><span class="in">  models = </span></span>
<span id="cb5-752"><a href="#cb5-752" aria-hidden="true" tabindex="-1"></a><span class="in">    list(</span></span>
<span id="cb5-753"><a href="#cb5-753" aria-hidden="true" tabindex="-1"></a><span class="in">      "LPM" = penguins_lp,</span></span>
<span id="cb5-754"><a href="#cb5-754" aria-hidden="true" tabindex="-1"></a><span class="in">      "Probit" = penguins_probit,</span></span>
<span id="cb5-755"><a href="#cb5-755" aria-hidden="true" tabindex="-1"></a><span class="in">      "Logit" = penguins_logit</span></span>
<span id="cb5-756"><a href="#cb5-756" aria-hidden="true" tabindex="-1"></a><span class="in">    ), </span></span>
<span id="cb5-757"><a href="#cb5-757" aria-hidden="true" tabindex="-1"></a><span class="in">  output = "gt", </span></span>
<span id="cb5-758"><a href="#cb5-758" aria-hidden="true" tabindex="-1"></a><span class="in">  vcov = "HC1", </span></span>
<span id="cb5-759"><a href="#cb5-759" aria-hidden="true" tabindex="-1"></a><span class="in">  stars = TRUE, </span></span>
<span id="cb5-760"><a href="#cb5-760" aria-hidden="true" tabindex="-1"></a><span class="in">) %&gt;%</span></span>
<span id="cb5-761"><a href="#cb5-761" aria-hidden="true" tabindex="-1"></a><span class="in">  tab_header(</span></span>
<span id="cb5-762"><a href="#cb5-762" aria-hidden="true" tabindex="-1"></a><span class="in">    title = "Modelle für Geschlecht v. Pinguinen"</span></span>
<span id="cb5-763"><a href="#cb5-763" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb5-764"><a href="#cb5-764" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-765"><a href="#cb5-765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-766"><a href="#cb5-766" aria-hidden="true" tabindex="-1"></a>Die geschätzten negativen und signifikanten Koeffizienten von $\textup{bill<span class="sc">\_</span>depth}$ erfassen den Zusammenhang, dass Pinguine mit größeren Schnäbeln tendenziell männlich sind: Je größer $\textup{bill<span class="sc">\_</span>depth}$, desto geringer die geschätzte Wahrscheinlichkeit, dass ein Pinguin weiblich ist. Ein Vergleich anhand des AIC zeigt, dass das Probit-Modell <span class="in">`penguins_probit`</span> am besten geeignet ist.</span>
<span id="cb5-767"><a href="#cb5-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-768"><a href="#cb5-768" aria-hidden="true" tabindex="-1"></a>Analog zur Vorgehensweise in @sec-logreg können wir die geschätzten Modelle vergleichen, in dem wir geschätzte Wahrscheinlichkeiten $P(Y=\textup{weiblich}\vert\textup{bill<span class="sc">\_</span>depth})$ für eine Menge repräsentativer Werte des Regressors <span class="in">`bill_depth`</span> berechnen und gemeinsam mit den Beobachtungen plotten.</span>
<span id="cb5-769"><a href="#cb5-769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-772"><a href="#cb5-772" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-773"><a href="#cb5-773" aria-hidden="true" tabindex="-1"></a><span class="in"># Sequenz für bill_depth erstellen</span></span>
<span id="cb5-774"><a href="#cb5-774" aria-hidden="true" tabindex="-1"></a><span class="in">bill_depth_new &lt;- seq(</span></span>
<span id="cb5-775"><a href="#cb5-775" aria-hidden="true" tabindex="-1"></a><span class="in">  from = min(penguins_cleaned$bill_depth), </span></span>
<span id="cb5-776"><a href="#cb5-776" aria-hidden="true" tabindex="-1"></a><span class="in">  to = max(penguins_cleaned$bill_depth), </span></span>
<span id="cb5-777"><a href="#cb5-777" aria-hidden="true" tabindex="-1"></a><span class="in">  by = .1</span></span>
<span id="cb5-778"><a href="#cb5-778" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb5-779"><a href="#cb5-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-780"><a href="#cb5-780" aria-hidden="true" tabindex="-1"></a><span class="in"># Vorhersagen WSK mit 'bill_depth_new'</span></span>
<span id="cb5-781"><a href="#cb5-781" aria-hidden="true" tabindex="-1"></a><span class="in">preds &lt;- tibble(</span></span>
<span id="cb5-782"><a href="#cb5-782" aria-hidden="true" tabindex="-1"></a><span class="in">  bill_depth = bill_depth_new,</span></span>
<span id="cb5-783"><a href="#cb5-783" aria-hidden="true" tabindex="-1"></a><span class="in">  lp = predict(</span></span>
<span id="cb5-784"><a href="#cb5-784" aria-hidden="true" tabindex="-1"></a><span class="in">    object = penguins_lp, </span></span>
<span id="cb5-785"><a href="#cb5-785" aria-hidden="true" tabindex="-1"></a><span class="in">    newdata = tibble(bill_depth = bill_depth_new)</span></span>
<span id="cb5-786"><a href="#cb5-786" aria-hidden="true" tabindex="-1"></a><span class="in">  ),</span></span>
<span id="cb5-787"><a href="#cb5-787" aria-hidden="true" tabindex="-1"></a><span class="in">  probit = predict(</span></span>
<span id="cb5-788"><a href="#cb5-788" aria-hidden="true" tabindex="-1"></a><span class="in">    object = penguins_probit,</span></span>
<span id="cb5-789"><a href="#cb5-789" aria-hidden="true" tabindex="-1"></a><span class="in">    newdata = tibble(bill_depth = bill_depth_new),</span></span>
<span id="cb5-790"><a href="#cb5-790" aria-hidden="true" tabindex="-1"></a><span class="in">    type = "response"</span></span>
<span id="cb5-791"><a href="#cb5-791" aria-hidden="true" tabindex="-1"></a><span class="in">  ),</span></span>
<span id="cb5-792"><a href="#cb5-792" aria-hidden="true" tabindex="-1"></a><span class="in">  logit = predict(</span></span>
<span id="cb5-793"><a href="#cb5-793" aria-hidden="true" tabindex="-1"></a><span class="in">    object = penguins_logit,</span></span>
<span id="cb5-794"><a href="#cb5-794" aria-hidden="true" tabindex="-1"></a><span class="in">    newdata = tibble(bill_depth = bill_depth_new),</span></span>
<span id="cb5-795"><a href="#cb5-795" aria-hidden="true" tabindex="-1"></a><span class="in">    type = "response"</span></span>
<span id="cb5-796"><a href="#cb5-796" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb5-797"><a href="#cb5-797" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb5-798"><a href="#cb5-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-799"><a href="#cb5-799" aria-hidden="true" tabindex="-1"></a><span class="in"># Prüfen:</span></span>
<span id="cb5-800"><a href="#cb5-800" aria-hidden="true" tabindex="-1"></a><span class="in">slice_head(preds, n = 10)</span></span>
<span id="cb5-801"><a href="#cb5-801" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-802"><a href="#cb5-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-805"><a href="#cb5-805" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-806"><a href="#cb5-806" aria-hidden="true" tabindex="-1"></a><span class="in"># Geschätzte bedingte WSK plotten</span></span>
<span id="cb5-807"><a href="#cb5-807" aria-hidden="true" tabindex="-1"></a><span class="in">penguins_cleaned %&gt;%</span></span>
<span id="cb5-808"><a href="#cb5-808" aria-hidden="true" tabindex="-1"></a><span class="in">  ggplot(</span></span>
<span id="cb5-809"><a href="#cb5-809" aria-hidden="true" tabindex="-1"></a><span class="in">    mapping = aes(x = bill_depth, y = sex)</span></span>
<span id="cb5-810"><a href="#cb5-810" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-811"><a href="#cb5-811" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_point(</span></span>
<span id="cb5-812"><a href="#cb5-812" aria-hidden="true" tabindex="-1"></a><span class="in">    position = position_jitter(</span></span>
<span id="cb5-813"><a href="#cb5-813" aria-hidden="true" tabindex="-1"></a><span class="in">      height = .025,</span></span>
<span id="cb5-814"><a href="#cb5-814" aria-hidden="true" tabindex="-1"></a><span class="in">      seed = 1234</span></span>
<span id="cb5-815"><a href="#cb5-815" aria-hidden="true" tabindex="-1"></a><span class="in">    ),</span></span>
<span id="cb5-816"><a href="#cb5-816" aria-hidden="true" tabindex="-1"></a><span class="in">    alpha = .25,</span></span>
<span id="cb5-817"><a href="#cb5-817" aria-hidden="true" tabindex="-1"></a><span class="in">    color = "blue"</span></span>
<span id="cb5-818"><a href="#cb5-818" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-819"><a href="#cb5-819" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_line(</span></span>
<span id="cb5-820"><a href="#cb5-820" aria-hidden="true" tabindex="-1"></a><span class="in">    data = preds, </span></span>
<span id="cb5-821"><a href="#cb5-821" aria-hidden="true" tabindex="-1"></a><span class="in">    mapping = aes(y = lp, color = "LPM")</span></span>
<span id="cb5-822"><a href="#cb5-822" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-823"><a href="#cb5-823" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_line(</span></span>
<span id="cb5-824"><a href="#cb5-824" aria-hidden="true" tabindex="-1"></a><span class="in">    data = preds, </span></span>
<span id="cb5-825"><a href="#cb5-825" aria-hidden="true" tabindex="-1"></a><span class="in">    mapping = aes(y = probit, color = "Probit")</span></span>
<span id="cb5-826"><a href="#cb5-826" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-827"><a href="#cb5-827" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_line(</span></span>
<span id="cb5-828"><a href="#cb5-828" aria-hidden="true" tabindex="-1"></a><span class="in">    data = preds, </span></span>
<span id="cb5-829"><a href="#cb5-829" aria-hidden="true" tabindex="-1"></a><span class="in">    mapping = aes(y = logit, color = "Logit")</span></span>
<span id="cb5-830"><a href="#cb5-830" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-831"><a href="#cb5-831" aria-hidden="true" tabindex="-1"></a><span class="in">  scale_color_manual(</span></span>
<span id="cb5-832"><a href="#cb5-832" aria-hidden="true" tabindex="-1"></a><span class="in">    name = "Modelle",</span></span>
<span id="cb5-833"><a href="#cb5-833" aria-hidden="true" tabindex="-1"></a><span class="in">    values = c(</span></span>
<span id="cb5-834"><a href="#cb5-834" aria-hidden="true" tabindex="-1"></a><span class="in">      "LPM" = "steelblue", </span></span>
<span id="cb5-835"><a href="#cb5-835" aria-hidden="true" tabindex="-1"></a><span class="in">      "Probit" = "orange",</span></span>
<span id="cb5-836"><a href="#cb5-836" aria-hidden="true" tabindex="-1"></a><span class="in">      "Logit" = "darkred"</span></span>
<span id="cb5-837"><a href="#cb5-837" aria-hidden="true" tabindex="-1"></a><span class="in">    )</span></span>
<span id="cb5-838"><a href="#cb5-838" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-839"><a href="#cb5-839" aria-hidden="true" tabindex="-1"></a><span class="in">  labs(title = "Modellierung v. Pinguin-Geschlecht mit Regression") +</span></span>
<span id="cb5-840"><a href="#cb5-840" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_cowplot() +</span></span>
<span id="cb5-841"><a href="#cb5-841" aria-hidden="true" tabindex="-1"></a><span class="in">  theme(legend.position = "top")</span></span>
<span id="cb5-842"><a href="#cb5-842" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-843"><a href="#cb5-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-844"><a href="#cb5-844" aria-hidden="true" tabindex="-1"></a>Die geschätzten Regressionsfunktionen unterscheiden sich für den Bereich beobachteter Werte von $bill<span class="sc">\_</span>depth$ nur wenig. Die Grafik zeigt, dass die Schätzungen mit Probit- und Logit-Ansatz nur wenig Nicht-Linearität aufweisen, sodass eine (leichter interpretierbare) Modellierung mit dem linearen Wahrscheinlichkeitsmodell <span class="in">`penguins_lp`</span> hier zulässig scheint.</span>
<span id="cb5-845"><a href="#cb5-845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-846"><a href="#cb5-846" aria-hidden="true" tabindex="-1"></a>Die Klassifizierung der Pinguine im Datensatz hinsichtlich ihres Geschlechts anhand vorhergesagter Wahrscheinlichkeiten $\widehat{P}_i$ kann durch Abgleich mit einem Grenzwert erfolgen. Ein Beispiel ist</span>
<span id="cb5-847"><a href="#cb5-847" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb5-848"><a href="#cb5-848" aria-hidden="true" tabindex="-1"></a>  \widehat{Y}_i = \begin{cases}</span>
<span id="cb5-849"><a href="#cb5-849" aria-hidden="true" tabindex="-1"></a>    \textup{weiblich}, &amp; \widehat{P}_i \geq .5,<span class="sc">\\</span></span>
<span id="cb5-850"><a href="#cb5-850" aria-hidden="true" tabindex="-1"></a>    \textup{männlich}, &amp; \textup{sonst.}</span>
<span id="cb5-851"><a href="#cb5-851" aria-hidden="true" tabindex="-1"></a>  \end{cases}\label{eq:pengclass}</span>
<span id="cb5-852"><a href="#cb5-852" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb5-853"><a href="#cb5-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-854"><a href="#cb5-854" aria-hidden="true" tabindex="-1"></a>Wir können diesen Ansatz in R implementieren, indem wir zunächst die für den Datensatz angepassten Wahrscheinlichkeiten <span class="in">`fitted`</span> aus den Modell-Objekten auslesen.</span>
<span id="cb5-855"><a href="#cb5-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-858"><a href="#cb5-858" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-859"><a href="#cb5-859" aria-hidden="true" tabindex="-1"></a><span class="in">(</span></span>
<span id="cb5-860"><a href="#cb5-860" aria-hidden="true" tabindex="-1"></a><span class="in">  WSK &lt;- penguins_cleaned %&gt;%</span></span>
<span id="cb5-861"><a href="#cb5-861" aria-hidden="true" tabindex="-1"></a><span class="in">  select(sex) %&gt;%</span></span>
<span id="cb5-862"><a href="#cb5-862" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(</span></span>
<span id="cb5-863"><a href="#cb5-863" aria-hidden="true" tabindex="-1"></a><span class="in">    list(</span></span>
<span id="cb5-864"><a href="#cb5-864" aria-hidden="true" tabindex="-1"></a><span class="in">      linear = penguins_lp, </span></span>
<span id="cb5-865"><a href="#cb5-865" aria-hidden="true" tabindex="-1"></a><span class="in">      probit = penguins_probit,</span></span>
<span id="cb5-866"><a href="#cb5-866" aria-hidden="true" tabindex="-1"></a><span class="in">      logit = penguins_logit</span></span>
<span id="cb5-867"><a href="#cb5-867" aria-hidden="true" tabindex="-1"></a><span class="in">    ) %&gt;% </span></span>
<span id="cb5-868"><a href="#cb5-868" aria-hidden="true" tabindex="-1"></a><span class="in">      map_dfc(.f = ~ .$fitted)     </span></span>
<span id="cb5-869"><a href="#cb5-869" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb5-870"><a href="#cb5-870" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb5-871"><a href="#cb5-871" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-872"><a href="#cb5-872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-873"><a href="#cb5-873" aria-hidden="true" tabindex="-1"></a>Für die Klassifikation der Pinguine anhand der jeweiligen geschätzten Wahrscheinlichkeiten wenden wir die Regel \eqref{eq:pengclass} mit <span class="in">`across()`</span> spaltenweise für die Modelle an und erzeugen neue Spalten mit vorhersagen des Geschlechts. Mit <span class="in">`.names = "{.col}_pred"`</span> erhalten die neuen Spalten das Suffix <span class="in">`_pred`</span>.</span>
<span id="cb5-874"><a href="#cb5-874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-877"><a href="#cb5-877" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-878"><a href="#cb5-878" aria-hidden="true" tabindex="-1"></a><span class="in"># Klassifikation f. Geschlecht durchführen</span></span>
<span id="cb5-879"><a href="#cb5-879" aria-hidden="true" tabindex="-1"></a><span class="in">vorh &lt;- WSK %&gt;%</span></span>
<span id="cb5-880"><a href="#cb5-880" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(</span></span>
<span id="cb5-881"><a href="#cb5-881" aria-hidden="true" tabindex="-1"></a><span class="in">    across(</span></span>
<span id="cb5-882"><a href="#cb5-882" aria-hidden="true" tabindex="-1"></a><span class="in">      c(linear:logit), </span></span>
<span id="cb5-883"><a href="#cb5-883" aria-hidden="true" tabindex="-1"></a><span class="in">      .fns = ~ (. &gt; 0.5) == sex,</span></span>
<span id="cb5-884"><a href="#cb5-884" aria-hidden="true" tabindex="-1"></a><span class="in">      .names = "{.col}_pred")</span></span>
<span id="cb5-885"><a href="#cb5-885" aria-hidden="true" tabindex="-1"></a><span class="in">    )</span></span>
<span id="cb5-886"><a href="#cb5-886" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-887"><a href="#cb5-887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-888"><a href="#cb5-888" aria-hidden="true" tabindex="-1"></a>Mit <span class="in">`summarise()`</span> berechnen wir nun den Anteil korrekter Vorhersagen.</span>
<span id="cb5-889"><a href="#cb5-889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-892"><a href="#cb5-892" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-893"><a href="#cb5-893" aria-hidden="true" tabindex="-1"></a><span class="in"># Genauigkeit der Vorhersage berechnen</span></span>
<span id="cb5-894"><a href="#cb5-894" aria-hidden="true" tabindex="-1"></a><span class="in">vorh %&gt;% </span></span>
<span id="cb5-895"><a href="#cb5-895" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(</span></span>
<span id="cb5-896"><a href="#cb5-896" aria-hidden="true" tabindex="-1"></a><span class="in">    across(linear_pred:logit_pred, mean)</span></span>
<span id="cb5-897"><a href="#cb5-897" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb5-898"><a href="#cb5-898" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-899"><a href="#cb5-899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-900"><a href="#cb5-900" aria-hidden="true" tabindex="-1"></a>In diesem Beispiel unterscheiden sich die Vorhersagen der drei Modelle für den Grenzwert 0.5 nicht.</span>
<span id="cb5-901"><a href="#cb5-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-902"><a href="#cb5-902" aria-hidden="true" tabindex="-1"></a><span class="fu">## Modellierung von Zählvariablen {#sec-poissonreg}</span></span>
<span id="cb5-903"><a href="#cb5-903" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-904"><a href="#cb5-904" aria-hidden="true" tabindex="-1"></a>Eine weitere Klasse von $Y$ für die sich der Regressionsansatz von einfacher linearer Regression unterscheidet, sind *Zählvariablen*: Variablen, die diskrete, nicht-negative Werte annehmen. Wenn die abhängige Variable $Y$ Ereignisse in einem bestimmten Zeitraum misst (wie z.B. die Anzahl der Verkehrsunfälle in Essen innerhalb eines Monats) und weitere Bedingungen erfüllt sind, folgt $Y$ einer Poisson-Verteilung und kann mit Poisson-Regression modelliert werden. Wir erläutern nachfolgend die wesentlichen Komponenten von Poisson-Regression und diskutieren ein R-Beispiel mit fiktiven Daten.</span>
<span id="cb5-905"><a href="#cb5-905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-906"><a href="#cb5-906" aria-hidden="true" tabindex="-1"></a><span class="fu">### Poisson-Verteilung</span></span>
<span id="cb5-907"><a href="#cb5-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-908"><a href="#cb5-908" aria-hidden="true" tabindex="-1"></a>Die Zufallsvariable $Y$ folgt einer Poisson-Verteilung mit Parameter $\lambda$, wenn</span>
<span id="cb5-909"><a href="#cb5-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-910"><a href="#cb5-910" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**die Ereignisse unabhängig voneinander auftreten:** Das Auftreten eines Ereignisses beeinflusst nicht die Wahrscheinlichkeit, dass ein weiteres Ereignis auftritt.</span>
<span id="cb5-911"><a href="#cb5-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-912"><a href="#cb5-912" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**die Ereignisse einzeln auftreten:** Die Wahrscheinlichkeit, dass in einem sehr kleinen Intervall (im Sinne von $<span class="co">[</span><span class="ot">a,b</span><span class="co">]</span>$ für $a \to b$) mehr als ein Ereignis auftritt, ist vernachlässigbar.</span>
<span id="cb5-913"><a href="#cb5-913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-914"><a href="#cb5-914" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**die Rate der Ereignisse konstant ist:** Die durchschnittliche Anzahl der Ereignisse pro Zeiteinheit oder pro Raumeinheit $\lambda$ ist konstant.</span>
<span id="cb5-915"><a href="#cb5-915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-916"><a href="#cb5-916" aria-hidden="true" tabindex="-1"></a>Die Wahrscheinlichkeitsfunktion von $Y$ ist</span>
<span id="cb5-917"><a href="#cb5-917" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-918"><a href="#cb5-918" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb5-919"><a href="#cb5-919" aria-hidden="true" tabindex="-1"></a>P(Y = y) = \frac{\lambda^y e^{-\lambda}}{y!} \quad \text{für} \quad y = 0, 1, 2, \ldots,\label{eq:poissonpmf}</span>
<span id="cb5-920"><a href="#cb5-920" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb5-921"><a href="#cb5-921" aria-hidden="true" tabindex="-1"></a>wobei $\lambda$ sowohl der Erwartungswert als auch die Varianz der Verteilung ist, $$\textup{E}(Y) = \textup{Var}(Y) = \lambda.$$</span>
<span id="cb5-922"><a href="#cb5-922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-923"><a href="#cb5-923" aria-hidden="true" tabindex="-1"></a>Die nächste Grafik zeigt die diskrete (Wahrscheinlichkeitsmasse-)Funktion \eqref{eq:poissonpmf} für eine Poisson-verteilte Zufallsvariable $Y$ mit $\lambda = 5$ für den Wertebereich von 0 bis 15.</span>
<span id="cb5-924"><a href="#cb5-924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-927"><a href="#cb5-927" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-928"><a href="#cb5-928" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-poissondensity</span></span>
<span id="cb5-929"><a href="#cb5-929" aria-hidden="true" tabindex="-1"></a><span class="in">tibble(</span></span>
<span id="cb5-930"><a href="#cb5-930" aria-hidden="true" tabindex="-1"></a><span class="in">    x = 0:15,</span></span>
<span id="cb5-931"><a href="#cb5-931" aria-hidden="true" tabindex="-1"></a><span class="in">    dens = dpois(x, lambda = 5)</span></span>
<span id="cb5-932"><a href="#cb5-932" aria-hidden="true" tabindex="-1"></a><span class="in">) %&gt;%</span></span>
<span id="cb5-933"><a href="#cb5-933" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb5-934"><a href="#cb5-934" aria-hidden="true" tabindex="-1"></a><span class="in">    ggplot( </span></span>
<span id="cb5-935"><a href="#cb5-935" aria-hidden="true" tabindex="-1"></a><span class="in">        mapping = aes(x = x, y = dens)</span></span>
<span id="cb5-936"><a href="#cb5-936" aria-hidden="true" tabindex="-1"></a><span class="in">    ) +</span></span>
<span id="cb5-937"><a href="#cb5-937" aria-hidden="true" tabindex="-1"></a><span class="in">    geom_bar(</span></span>
<span id="cb5-938"><a href="#cb5-938" aria-hidden="true" tabindex="-1"></a><span class="in">      stat = "identity", </span></span>
<span id="cb5-939"><a href="#cb5-939" aria-hidden="true" tabindex="-1"></a><span class="in">      fill = "steelblue",</span></span>
<span id="cb5-940"><a href="#cb5-940" aria-hidden="true" tabindex="-1"></a><span class="in">      color = "white"</span></span>
<span id="cb5-941"><a href="#cb5-941" aria-hidden="true" tabindex="-1"></a><span class="in">    ) +</span></span>
<span id="cb5-942"><a href="#cb5-942" aria-hidden="true" tabindex="-1"></a><span class="in">    scale_x_continuous(breaks = 0:15) + </span></span>
<span id="cb5-943"><a href="#cb5-943" aria-hidden="true" tabindex="-1"></a><span class="in">    labs(</span></span>
<span id="cb5-944"><a href="#cb5-944" aria-hidden="true" tabindex="-1"></a><span class="in">        title = "Poisson-Dichtefunktion für lambda = 5", </span></span>
<span id="cb5-945"><a href="#cb5-945" aria-hidden="true" tabindex="-1"></a><span class="in">        y = "Dichte"</span></span>
<span id="cb5-946"><a href="#cb5-946" aria-hidden="true" tabindex="-1"></a><span class="in">    ) +</span></span>
<span id="cb5-947"><a href="#cb5-947" aria-hidden="true" tabindex="-1"></a><span class="in">    theme_cowplot()</span></span>
<span id="cb5-948"><a href="#cb5-948" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-949"><a href="#cb5-949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-950"><a href="#cb5-950" aria-hidden="true" tabindex="-1"></a><span class="fu">### Poisson-Regression</span></span>
<span id="cb5-951"><a href="#cb5-951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-952"><a href="#cb5-952" aria-hidden="true" tabindex="-1"></a>Wie für die bisher betrachteten Regressionsansätzen modelliert Poisson-Regression den Erwartungswert (und damit gleichzeitig die Varianz) $\lambda$ der abhängigen Variable $Y$ als eine Funktion der Regressoren $\mathbf{X} = (X_1, X_2, \ldots, X_k)$. Unter Annahme einer Poisson-Verteilung kann Poisson-Regression als generalisiertes lineares Modell verstanden werden, wobei eine logarithmische Verknüpfungsfunktion für den linearen Prädiktor $\mathbf{X}_i^\top \boldsymbol{\beta}$ verwendet wird:</span>
<span id="cb5-953"><a href="#cb5-953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-954"><a href="#cb5-954" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-955"><a href="#cb5-955" aria-hidden="true" tabindex="-1"></a>\log(\lambda_i) &amp;= \mathbf{X}_i^\top \boldsymbol{\beta},</span>
<span id="cb5-956"><a href="#cb5-956" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-957"><a href="#cb5-957" aria-hidden="true" tabindex="-1"></a>sodass</span>
<span id="cb5-958"><a href="#cb5-958" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-959"><a href="#cb5-959" aria-hidden="true" tabindex="-1"></a>\lambda_i &amp;= \exp(\mathbf{X}_i^\top \boldsymbol{\beta}),</span>
<span id="cb5-960"><a href="#cb5-960" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-961"><a href="#cb5-961" aria-hidden="true" tabindex="-1"></a>wobei</span>
<span id="cb5-962"><a href="#cb5-962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-963"><a href="#cb5-963" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\lambda_i = \textup{E}(Y_i\vert \mathbf{X}_i) = \textup{Var}(Y_i\vert \mathbf{X}_i)$ für Beobachtung $i$,</span>
<span id="cb5-964"><a href="#cb5-964" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\mathbf{X}_i$ der Vektor der unabhängigen Variablen für Beobachtung $i$ ist, und</span>
<span id="cb5-965"><a href="#cb5-965" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\boldsymbol{\beta}$ der Vektor der Regressionskoeffizienten ist.</span>
<span id="cb5-966"><a href="#cb5-966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-967"><a href="#cb5-967" aria-hidden="true" tabindex="-1"></a><span class="fu">### Schätzung</span></span>
<span id="cb5-968"><a href="#cb5-968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-969"><a href="#cb5-969" aria-hidden="true" tabindex="-1"></a>Die Likelihood-Funktion für $n$ Beobachtungen ist </span>
<span id="cb5-970"><a href="#cb5-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-971"><a href="#cb5-971" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb5-972"><a href="#cb5-972" aria-hidden="true" tabindex="-1"></a>L(\boldsymbol{\beta}) = \prod_{i=1}^n \frac{\lambda_i^{y_i} e^{-\lambda_i}}{y_i!}.</span>
<span id="cb5-973"><a href="#cb5-973" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb5-974"><a href="#cb5-974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-975"><a href="#cb5-975" aria-hidden="true" tabindex="-1"></a>Die Log-Likelihood-Funktion ist daher</span>
<span id="cb5-976"><a href="#cb5-976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-977"><a href="#cb5-977" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb5-978"><a href="#cb5-978" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(\boldsymbol{\beta}) = \sum_{i=1}^n \left( y_i \log(\lambda_i) - \lambda_i - \log(y_i!). \right)</span>
<span id="cb5-979"><a href="#cb5-979" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb5-980"><a href="#cb5-980" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-981"><a href="#cb5-981" aria-hidden="true" tabindex="-1"></a>Da $\lambda_i = \exp(\mathbf{X}_i^\top \boldsymbol{\beta})$, wird die Log-Likelihood-Funktion zu</span>
<span id="cb5-982"><a href="#cb5-982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-983"><a href="#cb5-983" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb5-984"><a href="#cb5-984" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(\boldsymbol{\beta}) = \sum_{i=1}^n \left( y_i (\mathbf{X}_i^\top \boldsymbol{\beta}) - \exp(\mathbf{X}_i^\top \boldsymbol{\beta}) - \log(y_i!) \right)</span>
<span id="cb5-985"><a href="#cb5-985" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb5-986"><a href="#cb5-986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-987"><a href="#cb5-987" aria-hidden="true" tabindex="-1"></a>Den ML-Schätzer $\widehat{\boldsymbol{\beta}}$ erhalten wir durch Maximierung der Log-Likelihoodfunktion $\mathcal{L}(\boldsymbol{\beta})$. Die R-Implementierung von Poisson-Regression in <span class="in">`stats::glm()`</span> wird mittels <span class="in">`family = poisson(link = "log")`</span></span>
<span id="cb5-988"><a href="#cb5-988" aria-hidden="true" tabindex="-1"></a>aufgerufen.</span>
<span id="cb5-989"><a href="#cb5-989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-990"><a href="#cb5-990" aria-hidden="true" tabindex="-1"></a><span class="fu">### Interpretation der Koeffizienten</span></span>
<span id="cb5-991"><a href="#cb5-991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-992"><a href="#cb5-992" aria-hidden="true" tabindex="-1"></a>Die Koeffizienten $\boldsymbol{\beta}$ in der Poisson-Regression haben eine logarithmisch-lineare Beziehung zur Zählvariable. Für einen bestimmten Koeffizienten $\beta_j$ ist die Interpretation wie folgt:</span>
<span id="cb5-993"><a href="#cb5-993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-994"><a href="#cb5-994" aria-hidden="true" tabindex="-1"></a>Eine Änderung der unabhängigen Variable $X_j$ um eine Einheit führt zu einer Änderung des *Logarithmus* des Erwartungswertes von $Y$ um $\beta_j$. Der Erwartungswert $\lambda$ ändert sich also *multiplikativ* um den Faktor $\exp(\beta_j)$.</span>
<span id="cb5-995"><a href="#cb5-995" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-996"><a href="#cb5-996" aria-hidden="true" tabindex="-1"></a>Als Beispiel betrachten wir den linearen Prädiktor</span>
<span id="cb5-997"><a href="#cb5-997" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-998"><a href="#cb5-998" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-999"><a href="#cb5-999" aria-hidden="true" tabindex="-1"></a>  \log(\lambda) = \beta_0 + \beta_1 X.</span>
<span id="cb5-1000"><a href="#cb5-1000" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-1001"><a href="#cb5-1001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1002"><a href="#cb5-1002" aria-hidden="true" tabindex="-1"></a>Für eine Änderung von $X$ um $\Delta X$ erhalten wir</span>
<span id="cb5-1003"><a href="#cb5-1003" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1004"><a href="#cb5-1004" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-1005"><a href="#cb5-1005" aria-hidden="true" tabindex="-1"></a>   \lambda =&amp;\, \exp(\beta_0 + \beta_1 X) <span class="sc">\\</span></span>
<span id="cb5-1006"><a href="#cb5-1006" aria-hidden="true" tabindex="-1"></a>    \lambda + \delta\lambda =&amp;\, \exp(\beta_0 + \beta_1 (X + \Delta X)) <span class="sc">\\</span></span>
<span id="cb5-1007"><a href="#cb5-1007" aria-hidden="true" tabindex="-1"></a>    =&amp;\, \exp(\beta_0 + \beta_1 X) \cdot \exp(\beta\Delta X) <span class="sc">\\</span></span>
<span id="cb5-1008"><a href="#cb5-1008" aria-hidden="true" tabindex="-1"></a>    =&amp;\, \lambda \cdot \exp(\beta\Delta X)</span>
<span id="cb5-1009"><a href="#cb5-1009" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-1010"><a href="#cb5-1010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1011"><a href="#cb5-1011" aria-hidden="true" tabindex="-1"></a>Angenommen $X$ ist die Anzahl durchgeführter Werbekampagnen und die abhängige Zählvariable $Y$ misst die Anzahl der Verkäufe des beworbenen Produkts pro Monat.</span>
<span id="cb5-1012"><a href="#cb5-1012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1013"><a href="#cb5-1013" aria-hidden="true" tabindex="-1"></a>Wenn $\beta_1 = 0.5$, bedeutet dies, dass jede zusätzliche Werbekampagne ($\Delta X = 1$) die erwartete Anzahl der Verkäufe pro Monat um einen Faktor von $\exp(0.5) \approx 1.65$ erhöht:</span>
<span id="cb5-1014"><a href="#cb5-1014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1015"><a href="#cb5-1015" aria-hidden="true" tabindex="-1"></a>Das heißt, die *Rate* der Verkäufe steigt um 65\% für jede zusätzliche Werbekampagne.</span>
<span id="cb5-1016"><a href="#cb5-1016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1017"><a href="#cb5-1017" aria-hidden="true" tabindex="-1"></a>Zur Veranschaulichung der Schätzung einer Poisson-Regression für dieses Beispiel erzeugen wir Poisson-verteilte Daten für</span>
<span id="cb5-1018"><a href="#cb5-1018" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb5-1019"><a href="#cb5-1019" aria-hidden="true" tabindex="-1"></a>  \log(\lambda) = 2 + 0.4 \cdot X</span>
<span id="cb5-1020"><a href="#cb5-1020" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb5-1021"><a href="#cb5-1021" aria-hidden="true" tabindex="-1"></a>und ziehen $X$ gleichverteilt aus $<span class="sc">\{</span>1,2,\dots,8<span class="sc">\}</span>$.</span>
<span id="cb5-1022"><a href="#cb5-1022" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1025"><a href="#cb5-1025" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-1026"><a href="#cb5-1026" aria-hidden="true" tabindex="-1"></a><span class="in"># Setze den Zufallszahlengenerator für Reproduzierbarkeit</span></span>
<span id="cb5-1027"><a href="#cb5-1027" aria-hidden="true" tabindex="-1"></a><span class="in">set.seed(1234)</span></span>
<span id="cb5-1028"><a href="#cb5-1028" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1029"><a href="#cb5-1029" aria-hidden="true" tabindex="-1"></a><span class="in"># Anzahl der Beobachtungen</span></span>
<span id="cb5-1030"><a href="#cb5-1030" aria-hidden="true" tabindex="-1"></a><span class="in">n &lt;- 500</span></span>
<span id="cb5-1031"><a href="#cb5-1031" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1032"><a href="#cb5-1032" aria-hidden="true" tabindex="-1"></a><span class="in"># Züge für unabhängige Variable X (Anzahl der Werbekampagnen)</span></span>
<span id="cb5-1033"><a href="#cb5-1033" aria-hidden="true" tabindex="-1"></a><span class="in">X &lt;- sample(1:8, replace = T, size = n)</span></span>
<span id="cb5-1034"><a href="#cb5-1034" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1035"><a href="#cb5-1035" aria-hidden="true" tabindex="-1"></a><span class="in"># Erwartungswerte</span></span>
<span id="cb5-1036"><a href="#cb5-1036" aria-hidden="true" tabindex="-1"></a><span class="in">lambda &lt;- exp(2 + 0.4 * X)</span></span>
<span id="cb5-1037"><a href="#cb5-1037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1038"><a href="#cb5-1038" aria-hidden="true" tabindex="-1"></a><span class="in"># Abhängige Variable Y (Anzahl der Verkäufe) als Poisson-verteilte Zufallsvariable, gegeben lambda</span></span>
<span id="cb5-1039"><a href="#cb5-1039" aria-hidden="true" tabindex="-1"></a><span class="in">Y &lt;- map_dbl(</span></span>
<span id="cb5-1040"><a href="#cb5-1040" aria-hidden="true" tabindex="-1"></a><span class="in">  .x = 1:n, </span></span>
<span id="cb5-1041"><a href="#cb5-1041" aria-hidden="true" tabindex="-1"></a><span class="in">  .f = ~ rpois(</span></span>
<span id="cb5-1042"><a href="#cb5-1042" aria-hidden="true" tabindex="-1"></a><span class="in">    n = 1, lambda = lambda[.x]</span></span>
<span id="cb5-1043"><a href="#cb5-1043" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb5-1044"><a href="#cb5-1044" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb5-1045"><a href="#cb5-1045" aria-hidden="true" tabindex="-1"></a><span class="in">  </span></span>
<span id="cb5-1046"><a href="#cb5-1046" aria-hidden="true" tabindex="-1"></a><span class="in"># Daten in tibble sammeln</span></span>
<span id="cb5-1047"><a href="#cb5-1047" aria-hidden="true" tabindex="-1"></a><span class="in">dat &lt;- tibble(</span></span>
<span id="cb5-1048"><a href="#cb5-1048" aria-hidden="true" tabindex="-1"></a><span class="in">  Kampagnen = X, </span></span>
<span id="cb5-1049"><a href="#cb5-1049" aria-hidden="true" tabindex="-1"></a><span class="in">  Verkaeufe = Y</span></span>
<span id="cb5-1050"><a href="#cb5-1050" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb5-1051"><a href="#cb5-1051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1052"><a href="#cb5-1052" aria-hidden="true" tabindex="-1"></a><span class="in"># Überblick</span></span>
<span id="cb5-1053"><a href="#cb5-1053" aria-hidden="true" tabindex="-1"></a><span class="in">slice_head(dat, n = 10)</span></span>
<span id="cb5-1054"><a href="#cb5-1054" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-1055"><a href="#cb5-1055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1056"><a href="#cb5-1056" aria-hidden="true" tabindex="-1"></a>Die Züge aus der abhängigen Variablen visualieren wir mit einem Häufigkeits-Histogramm.</span>
<span id="cb5-1057"><a href="#cb5-1057" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1060"><a href="#cb5-1060" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-1061"><a href="#cb5-1061" aria-hidden="true" tabindex="-1"></a><span class="in"># Histogramm der Abh. Variable</span></span>
<span id="cb5-1062"><a href="#cb5-1062" aria-hidden="true" tabindex="-1"></a><span class="in">ggplot(</span></span>
<span id="cb5-1063"><a href="#cb5-1063" aria-hidden="true" tabindex="-1"></a><span class="in">  data = dat, </span></span>
<span id="cb5-1064"><a href="#cb5-1064" aria-hidden="true" tabindex="-1"></a><span class="in">  mapping = aes(x = Verkaeufe)</span></span>
<span id="cb5-1065"><a href="#cb5-1065" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-1066"><a href="#cb5-1066" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_histogram(binwidth = 2) +</span></span>
<span id="cb5-1067"><a href="#cb5-1067" aria-hidden="true" tabindex="-1"></a><span class="in">  labs(</span></span>
<span id="cb5-1068"><a href="#cb5-1068" aria-hidden="true" tabindex="-1"></a><span class="in">    title = "Poisson-verteilte Daten"</span></span>
<span id="cb5-1069"><a href="#cb5-1069" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-1070"><a href="#cb5-1070" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_cowplot()</span></span>
<span id="cb5-1071"><a href="#cb5-1071" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-1072"><a href="#cb5-1072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1073"><a href="#cb5-1073" aria-hidden="true" tabindex="-1"></a>Wir schätzen das Modell und extrahieren die robuste Zusammenfassung mit <span class="in">`broom::tidy()`</span>.</span>
<span id="cb5-1074"><a href="#cb5-1074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1077"><a href="#cb5-1077" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-1078"><a href="#cb5-1078" aria-hidden="true" tabindex="-1"></a><span class="in"># Poisson-Regression schätzen</span></span>
<span id="cb5-1079"><a href="#cb5-1079" aria-hidden="true" tabindex="-1"></a><span class="in">mod_poisson &lt;- glm(</span></span>
<span id="cb5-1080"><a href="#cb5-1080" aria-hidden="true" tabindex="-1"></a><span class="in">  formula = Verkaeufe ~ Kampagnen, </span></span>
<span id="cb5-1081"><a href="#cb5-1081" aria-hidden="true" tabindex="-1"></a><span class="in">  family = poisson(link = "log"), </span></span>
<span id="cb5-1082"><a href="#cb5-1082" aria-hidden="true" tabindex="-1"></a><span class="in">  data = dat</span></span>
<span id="cb5-1083"><a href="#cb5-1083" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb5-1084"><a href="#cb5-1084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1085"><a href="#cb5-1085" aria-hidden="true" tabindex="-1"></a><span class="in"># Zusammenfassung des gesch. Modells</span></span>
<span id="cb5-1086"><a href="#cb5-1086" aria-hidden="true" tabindex="-1"></a><span class="in">mod_poisson %&gt;%</span></span>
<span id="cb5-1087"><a href="#cb5-1087" aria-hidden="true" tabindex="-1"></a><span class="in">  coeftest(vcov = vcovHC, type = "HC1") %&gt;%</span></span>
<span id="cb5-1088"><a href="#cb5-1088" aria-hidden="true" tabindex="-1"></a><span class="in">  tidy()</span></span>
<span id="cb5-1089"><a href="#cb5-1089" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-1090"><a href="#cb5-1090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1091"><a href="#cb5-1091" aria-hidden="true" tabindex="-1"></a>Die ML-Schätzung des Poisson-Modells liefert für die verwendete Stichprobe von 500 Beobachtungen Koeffizienten-Schätzungen nahe der wahren Parameter. Zur Veranschaulichung des geschätzten Modells überlagern wir die simulierten Datenpunkte aus <span class="in">`dat`</span> mit der anhand von <span class="in">`mod_poisson`</span> geschätzten Anzahl der Verkäufe je Anzahl an Werbekampagnen. </span>
<span id="cb5-1092"><a href="#cb5-1092" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1095"><a href="#cb5-1095" aria-hidden="true" tabindex="-1"></a><span class="in">```{webr}</span></span>
<span id="cb5-1096"><a href="#cb5-1096" aria-hidden="true" tabindex="-1"></a><span class="in"># Vektor für Kampagnen</span></span>
<span id="cb5-1097"><a href="#cb5-1097" aria-hidden="true" tabindex="-1"></a><span class="in">Kampagnen_new &lt;- tibble(Kampagnen = 1:8)</span></span>
<span id="cb5-1098"><a href="#cb5-1098" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1099"><a href="#cb5-1099" aria-hidden="true" tabindex="-1"></a><span class="in"># Vorhersagen mit Modell</span></span>
<span id="cb5-1100"><a href="#cb5-1100" aria-hidden="true" tabindex="-1"></a><span class="in">pred &lt;- tibble(</span></span>
<span id="cb5-1101"><a href="#cb5-1101" aria-hidden="true" tabindex="-1"></a><span class="in">  Kampagnen = 1:8,</span></span>
<span id="cb5-1102"><a href="#cb5-1102" aria-hidden="true" tabindex="-1"></a><span class="in">  predicted = predict(</span></span>
<span id="cb5-1103"><a href="#cb5-1103" aria-hidden="true" tabindex="-1"></a><span class="in">    mod_poisson, </span></span>
<span id="cb5-1104"><a href="#cb5-1104" aria-hidden="true" tabindex="-1"></a><span class="in">    newdata = Kampagnen_new,</span></span>
<span id="cb5-1105"><a href="#cb5-1105" aria-hidden="true" tabindex="-1"></a><span class="in">    type = "response"</span></span>
<span id="cb5-1106"><a href="#cb5-1106" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb5-1107"><a href="#cb5-1107" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb5-1108"><a href="#cb5-1108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1109"><a href="#cb5-1109" aria-hidden="true" tabindex="-1"></a><span class="in"># Simulierte Daten und Schätzungen</span></span>
<span id="cb5-1110"><a href="#cb5-1110" aria-hidden="true" tabindex="-1"></a><span class="in">ggplot() +</span></span>
<span id="cb5-1111"><a href="#cb5-1111" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_point(</span></span>
<span id="cb5-1112"><a href="#cb5-1112" aria-hidden="true" tabindex="-1"></a><span class="in">    data = dat,</span></span>
<span id="cb5-1113"><a href="#cb5-1113" aria-hidden="true" tabindex="-1"></a><span class="in">    mapping = aes(</span></span>
<span id="cb5-1114"><a href="#cb5-1114" aria-hidden="true" tabindex="-1"></a><span class="in">      x = Kampagnen, </span></span>
<span id="cb5-1115"><a href="#cb5-1115" aria-hidden="true" tabindex="-1"></a><span class="in">      y = Verkaeufe</span></span>
<span id="cb5-1116"><a href="#cb5-1116" aria-hidden="true" tabindex="-1"></a><span class="in">    ), </span></span>
<span id="cb5-1117"><a href="#cb5-1117" aria-hidden="true" tabindex="-1"></a><span class="in">    color = "gray",</span></span>
<span id="cb5-1118"><a href="#cb5-1118" aria-hidden="true" tabindex="-1"></a><span class="in">    alpha = 0.25, </span></span>
<span id="cb5-1119"><a href="#cb5-1119" aria-hidden="true" tabindex="-1"></a><span class="in">    position = position_jitter(width = .1)</span></span>
<span id="cb5-1120"><a href="#cb5-1120" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-1121"><a href="#cb5-1121" aria-hidden="true" tabindex="-1"></a><span class="in">    geom_point(</span></span>
<span id="cb5-1122"><a href="#cb5-1122" aria-hidden="true" tabindex="-1"></a><span class="in">    data = pred,</span></span>
<span id="cb5-1123"><a href="#cb5-1123" aria-hidden="true" tabindex="-1"></a><span class="in">    mapping = aes(</span></span>
<span id="cb5-1124"><a href="#cb5-1124" aria-hidden="true" tabindex="-1"></a><span class="in">      x = Kampagnen,</span></span>
<span id="cb5-1125"><a href="#cb5-1125" aria-hidden="true" tabindex="-1"></a><span class="in">      y = predicted</span></span>
<span id="cb5-1126"><a href="#cb5-1126" aria-hidden="true" tabindex="-1"></a><span class="in">    ),</span></span>
<span id="cb5-1127"><a href="#cb5-1127" aria-hidden="true" tabindex="-1"></a><span class="in">    color = "red"</span></span>
<span id="cb5-1128"><a href="#cb5-1128" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-1129"><a href="#cb5-1129" aria-hidden="true" tabindex="-1"></a><span class="in">  scale_x_continuous(breaks = 1:8) +</span></span>
<span id="cb5-1130"><a href="#cb5-1130" aria-hidden="true" tabindex="-1"></a><span class="in">  labs(</span></span>
<span id="cb5-1131"><a href="#cb5-1131" aria-hidden="true" tabindex="-1"></a><span class="in">    title = "Datensatz und Poisson-Schätzungen der Verkäufe",</span></span>
<span id="cb5-1132"><a href="#cb5-1132" aria-hidden="true" tabindex="-1"></a><span class="in">    x = "Anzahl der Werbekampagnen",</span></span>
<span id="cb5-1133"><a href="#cb5-1133" aria-hidden="true" tabindex="-1"></a><span class="in">    y = "Anzahl der Verkäufe"</span></span>
<span id="cb5-1134"><a href="#cb5-1134" aria-hidden="true" tabindex="-1"></a><span class="in">  ) +</span></span>
<span id="cb5-1135"><a href="#cb5-1135" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_cowplot() +</span></span>
<span id="cb5-1136"><a href="#cb5-1136" aria-hidden="true" tabindex="-1"></a><span class="in">  theme(legend.position = "top")</span></span>
<span id="cb5-1137"><a href="#cb5-1137" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-1138"><a href="#cb5-1138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1139"><a href="#cb5-1139" aria-hidden="true" tabindex="-1"></a><span class="fu">## Zusammenfassung</span></span>
<span id="cb5-1140"><a href="#cb5-1140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-1141"><a href="#cb5-1141" aria-hidden="true" tabindex="-1"></a>In diesem Kapitel haben wir erweiterte Konzepte der Regressionsanalyse diskutiert. Anhand des Frisch-Waugh-Lovell-Theorems wurde die Wirkungsweise der Kontrolle von Kovariablen mit multipler Regression auf den interessierenden Koeffizienten (Effekt) einer Variable veranschaulicht. Weiterhin haben wir gängige Typen generalisierter linearer Modelle für binäre und Poisson-verteilte Outcome-Variablen eingeführt. Anhand relevanter Beispiele wurde gezeigt, wie diese generalisierten Regressionsmodelle in R spezifiziert, geschätzt und der resultierende Output mit Paketen wie <span class="in">`broom`</span>, <span class="in">`ggplot2`</span> und <span class="in">`modelsummary`</span> interpretiert werden kann.</span>
</code><button title="In die Zwischenablage kopieren" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/mca91/kasa_book/edit/main/Reg.qmd" class="toc-action"><i class="bi bi-github"></i>Seite editieren</a></li><li><a href="https://github.com/mca91/kasa_book/issues/new" class="toc-action"><i class="bi empty"></i>Problem melden</a></li><li><a href="https://github.com/mca91/kasa_book/blob/main/Reg.qmd" class="toc-action"><i class="bi empty"></i>Quellcode anzeigen</a></li></ul></div></div></div></footer></body></html>