[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kausalanalyse und Machine Learning in R",
    "section": "",
    "text": "Einleitung\n\n\n\nIn den letzten Jahren hat sich die datengetriebene Forschung in vielen Fachgebieten, insbesondere in der Ökonometrie und den empirischen Wirtschaftswissenschaften, grundlegend verändert. Haupttreiber dieses Wandels ist die zunehmende Verfügbarkeit von big data – hochdimensionale Datenmengen die regelmäßig in Unternehmen und öffentlichen Institutionen anfallen und die Entwicklung sowie den Einsatz neuer statistischer Verfahren im Gebiet machine learning prominent gemacht haben. Mit diesen Verfahren können große Datenmengen schnell und effizient verarbeitet und analysiert werden, was ihre zunehmende Relevanz für die evidenzbasierte Entscheidungsfindung in Politik und Wirtschaft begründet.\nEin weiterer Treiber der empirischen wirtschaftswissenschaftlichen Forschung ist die11 Bekannst als the credibility revolution in empirical economics (Angrist und Pischke 2010).\n\nData Science / Varian zitieren: der hat recht behalten\nReproducibility\nProgrammierung / Relevanz von Coding\nkanonischer Unterrichtskatalog in Ökonometrie aufbrechen\nAlles zusammenlegen als ein wichtiger Block für Wirtschaftswissenschaftler und solche die es werden wollen. Und es wird noch wichtiger werden.\n\n(Angrist und Pischke 2010)\n\n\n\n\nAngrist, Joshua D, und Jörn-Steffen Pischke. 2010. „The credibility revolution in empirical economics: How better research design is taking the con out of econometrics“. Journal of economic perspectives 24 (2): 3–30."
  },
  {
    "objectID": "R_Einfuehrung.html",
    "href": "R_Einfuehrung.html",
    "title": "\n1  Statistische Programmierung mit R\n",
    "section": "",
    "text": "Dieses Kapitel ist nicht als umfassende Einführung in R gedacht, sondern behandelt Kernkonzepte und soll der Selbsteinschätzung dienen. Wenngleich die Inhalte deutlich über ein Hallo-Welt-Beispiel1 hinausgehen, betrachten wir hier absolutes Basiswissen. Dieses ist Vorraussetzung für das Verständnis fortgeschrittener Konzepte in späteren Kapitel. Falls Sie bereits über solide Grundkenntnisse im Umgang mit R verfügen, können Sie problemlos zu Kapitel XYZ springen. Sollten Sie nicht oder nur teilweise mit den hier gezeigten Befehlen vertraut sein, empfiehlt sich eine Erarbeitung bzw. Wiederholung der Grundlagen. Nachstehede Ressourcen finden wir hilfreich:1 https://de.wikipedia.org/wiki/Hallo-Welt-Programm\n\nFeedbackgestütze interaktive Übungsaufgaben bei DataCamp, bspw. Einführung in R2\nOpen-source-Literatur wie der Umfangreiche Leitfaden von Ellis und Mayer (2023).\n\n2 Ein Teil des hier angebotenen Katalogs (exlusive Einführung in R) ist kostenpflichtig.\nR lädt, etwas Geduld bitte...\n\n\n\n\n\n\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. \n\nLade Pakete, etwas Geduld bitte...  \n\n\n\n\n\nR Basics\n\n1.0.0.1 Pinguine und Pipes"
  },
  {
    "objectID": "RDD.html#sharp-regression-discontinuity-design",
    "href": "RDD.html#sharp-regression-discontinuity-design",
    "title": "\n2  Regression Discontiniuty Designs\n",
    "section": "\n2.1 Sharp Regression Discontinuity Design",
    "text": "2.1 Sharp Regression Discontinuity Design\nModelle und funktionale Form\nDie korrekte Spezifikation der funktionalen Form für RDD ist wichtig, um eine unverzerrte Schätzung des Effekts zu vermeiden. Die einfachste Form eines SRDD kann anhand der linearen Regression \\[\\begin{align}\nY_i = \\beta_0 + \\beta_1 D_i + \\beta_2 (X_i - C) + u_i\\label{eq-simpleSRDD}\n\\end{align}\\] geschätzt werden, wobei \\(D_i\\) Behandlung anzeigt: \\(D_i\\) ist eine Dummy-Variable für das Überschreiten des Schwellenwertes C, d.h. \\[\\begin{align*}\n  D_i=\\begin{cases}\n    0 & X_i &lt; C\\\\\n    1 & X_i \\geq C.\n  \\end{cases}\n\\end{align*}\\] Hierbei ist zu beachten, dass \\((X_i - C)\\) die um den Schwellenwert zentrierte Laufvariable ist, sodass \\(\\beta_1\\) der Effekt der Behandlung bei \\((X_i - C)\\geq 0\\) ist.\nModell \\(\\eqref{eq-simpleSRDD}\\) unterstellt, dass \\(X\\) links- und rechtsseitig von \\(C\\) denselben Effekt \\(\\beta_2\\) auf \\(Y\\) hat. Eine Alternative ist ein lineares Interaktionsmodell \\[\\begin{align}\nY_i = \\beta_0 + \\beta_1 D_i + \\beta_2 (X_i - C) + \\beta_3(X_i-C)\\times D_i + u_i.\\label{eq:linearSRDD}\n\\end{align}\\] In Modell \\(\\eqref{eq:linearSRDD}\\) erfasst \\(\\beta_3\\) den Unterschied des Effekts von \\(X\\) auf \\(Y\\) für Beoabachtungen oberhalb von \\(C\\) gegenüber Beobachtungen unterhalb von \\(C\\), sodass unterschiedliche lineare Effekte von \\(X\\) auf \\(Y\\) link- und rechtsseitig von \\(C\\) modelliert werden können.\nBandweite\nNeben der funktionalen Form muss spezifiziert werden, welche Beobachtungen hinreichend nahe am Schwellenwert C liegen. Hierfür verwenden wir eine sogenannte Bandweite \\(h\\), wobei \\[\\begin{align}\n  \\lvert(X_i-C)\\rvert\\leq h \\label{eq:bwc}\n\\end{align}\\] das Kriterium für eine Berücksichtigung von Beobachtung \\(i\\) bei der Schätzung ist. Unter Berücksichtigung einer Bandweite \\(h\\) wird der Regressionsansatz \\(\\eqref{eq:linearSRDD}\\) als local linear regression mit Uniform-Kernelfunktion bezeichnet.2 Der Uniform-Kernel ist neben dem Triangular-Kernel eine häufig in der Praxis genutzte lineare Kernelfunktion.3 Der nachstehende Code plottet die Uniform- (grün) sowie die Triangular-Kernelfunktion (blau) wie in Abbildung 2.2 dargestellt.2 Local regression ist ein nicht-parametrisches Verfahren. Hierbei kann die Beziehung zwischen Variablen flexibel modelliert werden.3 In der Praxis wird oftmals local linear regression mit linearen Kernelfunktionen zurückgegriffen und die Robustheit der Ergebnisse anhand flexiblerer Spezifikationen geprüft.\n\nCodelibrary(ggplot2)\nlibrary(cowplot)\nggplot() + \n    geom_function(\n      fun = ~ ifelse(abs(.) &lt;= 1, 1, 0), col = \"green\"\n      ) + \n    geom_function(\n      fun = ~ ifelse(abs(.) &lt;= 1, 1-abs(.), 0), col = \"blue\"\n      ) + \n    scale_x_continuous(\"x\", limits = c(-1.5, 1.5), \n                       labels = c(\"-h\", 0, \"h\"), \n                       breaks = c(-1, 0, 1)) +\n    scale_y_continuous(\"K(x)\", \n                       breaks = c(0, 1), \n                       limits = c(0, 1.5)) +\n    theme_cowplot()\n\n\n\n\nAbbildung 2.2: Uniform-Kernel auf [-h, h]\n\n\n\nDie Wahl der Bandweite ist eine wichtige Komponente der RDD-Schätzung. Falls der wahre Zusammenhang nicht-linear ist, erlauben kleine Bandweiten eine Schätzung der Regressionsfunktion nahe des Schwellenwertes mit wenig Verzerrung. Allerdings kann diese Schätzung unpräzise sein, wenn nur wenige Beobachtungen \\(\\eqref{eq:bwc}\\) erfüllen. In der Praxis wird \\(h\\) daher anhand einer Schätzfunktion (G. Imbens und Kalyanaraman 2012) oder anhand von Cross Validation (bspw. G. W. Imbens und Lemieux 2008) bestimmt. Die später in diesem Kapitel betrachteten R-Pakete halten diese Methoden bereit.\n\n2.1.1 Beispiel: Amtsinhaber-Vorteil (Lee 2008)\n\nLee (2008) untersucht den Einfluss des Amtsinhaber-Vorteils auf die Wahl von Mitgliedern des US-Repräsentantenhauses. Entfällt ein Stimmenanteil von mehr als 50% auf eine Partei, hat diese Partei den Vorsitz des Repräsentantenhauses gewonnen. Durch die Analyse der 6558 Wahlen im Zeitraum 1946-1998 mit RDD kommt die Studie zu dem Ergebnis, dass die amtsinhabende im Durchschnitt einen Vorteil von etwa 8%-10% bei der Wahl hat. Dieses Ergebnis kann als Vorteil kann durch verschiedene Faktoren erklärt werden, bspw. dass die amtierende Partei höhere finanzielle Ressourcen und von einer besseren Organisation als die Opposition profitiert. Anhand der Datensätze house und house_binned illustrieren wir nachfolgend die Schätzung von SRDD-Modellen für den Wahlerfolg der demokratischen Partei, wenn diese Amtsinhaber ist.\nWir verschaffen uns zunächst einen Überblick über den Datensatz house.\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\nDer Datensatz house enthält Stimmenanteile der Demokraten bei der Wahl zum Zeitpunkt \\(T\\) (StimmenT) sowie um den Schwellenwert von 50% zentrierte Stimmenanteile bei der vorherigen Wahl zum Zeitpunkt \\(T-1\\) (StimmenTm1).\nhouse_binned ist eine aggregierte Version von house mit Mittelwerten von jeweils 50 gleichgroßen Intervallen oberhalb und unterhalb der Schwelle von 0. Dieser Datensatz eignet sich, um einen ersten Eindruck des funktionalen Zusammenhangs auf beiden Seiten zu gewinnen. Wir stellen die klassierten Daten mit ggplot2 graphisch dar.\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\nDie Grafik zeigt eindeutig einen Sprung an der Stelle \\(StimmenTm1 = 0\\). Weiterhin erkennen wir, dass der Zusammenhang nahe 0 jeweils gut durch eine lineare Funktion approximiert werden kann. Eine Modell-Spezifikation mit gleicher Steigung auf beiden Seiten des Schwellenwertes scheint hingegen ungeeignet.\nAls nächstes fügen wir dem Datensatz eine Dummyvariable D hinzu. Diese dient als Indikator für den Wahlgewinn in der letzten Wahl.\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\nAls nächstes schätzen wir das Modell \\[\\begin{align}\n  \\text{StimmenT}_i = \\beta_0 + \\beta_1 D_i + \\beta_2 (\\text{StimmenTm1}_i - 50) + \\beta_3(\\text{StimmenTm1}_i - 50)\\times D_i + u_i\n\\end{align}\\] bei einer Bandweite von \\(h = 1\\). Aufgrund der Skalierung der Daten bedeutet dies die Verwendung des gesamten Datensatzes für die Schätzung.\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\nDer geschätzte Koeffizient von \\(D\\) (DTRUE) beträgt etwa 0.12 und ist hochsignifikant. Übereinstimmend mit der (oben erstellten) Grafik erhalten wir also eine positive Schätzung des Treatment-Effekts. Diese Schätzung könnte jedoch invalide sein:\n\nDie (implizite) Wahl von \\(h=1\\) macht die Isolation des relevanten Frontdoor-Paths (\\(C=0\\) → Treatment → StimmenT) wenig plausibel.\nWeiterhin könnte die lineare funktionale Form unser Regression für den gesamten Datensatz inadäquat sein: Die lineare Approximation könnte nur “lokal” zu 0 gut sein und anderweitig in einer verzerrten Schätzung des Effekts resultieren.\n\n\n\n\n\nhtml`\n&lt;style&gt;\ncircle {\n  fill-opacity: .8;\n  stroke: #000;\n  stroke-opacity: 1;\n}\n.regression {\n  fill: none;\n  stroke: #000;\n  stroke-width: 1.5px;\n}\n.axis line {\n  stroke: #ddd;\n}\n.axis .baseline line {\n  stroke: #555;\n}\n.axis .domain {\n  display: none;\n} \n&lt;/style&gt;\n`\n\n\n\n\n\n\n\nd3 = require(\"d3-array@3\", \"d3-axis@3\", \"d3-regression@1\", \"d3-scale@4\", \"d3-shape@3\", \"d3-selection@3\")\n\nmargin = ({left: 33, right: 8, top: 13, bottom: 24});\nbase = Math.min(width, 500);\ninnerWidth = base - margin.left - margin.right;\ninnerHeight = base-100 - margin.top - margin.bottom;\n\nviewof bandwidth = Inputs.range([.01, .5], {\n  label: \"Bandweite LOESS\",\n  step: .01,\n  value: .25\n});\n\nxScaleLoess = d3.scaleLinear()\n   .domain([-.55, .55])\n   .range([0, innerWidth]);\n   \nyScaleLoess = d3.scaleLinear()\n  .domain([.2, .8])\n  .range([innerHeight, 0]);\n\nlineLoess = d3.line()\n  .x(d =&gt; xScaleLoess(d[0]))\n  .y(d =&gt; yScaleLoess(d[1]));\n  \nxAxisLoess = d3.axisBottom(xScaleLoess)\n  .tickSize(innerHeight + 10)\n  .tickValues([-.5, -.25, 0, .25, .5])\n  .tickFormat(d =&gt; d);\n\nyAxisLoess = d3.axisLeft(yScaleLoess)\n  .tickSize(innerWidth + 10)\n  .tickValues([.2, .35, .5, .65, .8])\n  .tickFormat(d =&gt; d);\n\nloessRegression = d3.regressionLoess()\n  .x(d =&gt; d.StimmenTm1)\n  .y(d =&gt; d.StimmenT)\n  .bandwidth(bandwidth);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  const svg = d3.select(DOM.svg(innerWidth + margin.left + margin.right, innerHeight + margin.top + margin.bottom))\n  \n  const g = svg.append(\"g\")\n      .attr(\"transform\", `translate(${margin.left}, ${margin.top})`);\n\n  g.append(\"g\")\n      .attr(\"class\", \"axis\")\n      .call(xAxisLoess);\n\n  g.append(\"g\")\n    .attr(\"class\", \"axis\")\n    .attr(\"transform\", `translate(${innerWidth})`)\n    .call(yAxisLoess);\n\n  g.selectAll(\"circle\")\n    .data(transpose(house_binned))\n    .enter().append(\"circle\")\n    .attr(\"r\", 2)\n    .attr(\"cx\", d =&gt; xScaleLoess(d.StimmenTm1))\n    .attr(\"cy\", d =&gt; yScaleLoess(d.StimmenT));\n\n  g.append(\"path\")\n      .attr(\"class\", \"regression\")\n      .datum(loessRegression(\n        transpose(house)\n          .filter(function(d){ return d.StimmenTm1 &lt; 0 & d.StimmenTm1 &gt;= -.5 })\n          )\n        )\n      .attr(\"d\", lineLoess);\n  \n  g.append(\"path\")\n      .attr(\"class\", \"regression\")\n      .datum(loessRegression(\n        transpose(house)\n          .filter(function(d){ return d.StimmenTm1 &gt;= 0 & d.StimmenTm1 &lt;= .5 })\n          )\n        )\n      .attr(\"d\", lineLoess);\n  \n  g.append(\"line\")\n  .attr(\"x1\", xScaleLoess(0))\n  .attr(\"y1\", 0)\n  .attr(\"x2\", xScaleLoess(0))\n  .attr(\"y2\", innerHeight)\n  .style(\"stroke\", \"black\")\n  .style(\"stroke-dasharray\", \"4\")\n  .style(\"stroke-width\", \"1\");\n\n  return svg.node();\n}\n\n\n\n\nAbbildung 2.3: Nicht-parametrische Regression auf beiden Seiten des Cut-offs.\n\n\n\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\nCarpenter und Dobkin (2009) untersuchen den Zusammenhang zwischen Alkoholkonsum und Sterblichkeit mit einem RDD.4 Die Autoren nutzen Variation im gesetzliche Mindestalter für Alkoholkonsum zwischen US-Bundesstaaten: Hierbei ist Alter die Laufvariable und des Mindestalter der Schwellenwert. Personen, die knapp über dem Mindestalter liegen und daher legal Alkohol konsumieren dürfen, weisen ähnliche Merkmale auf wie Personen knapp unter dem Mindestalter, so dass Backdoors vermieden werden.4 Die Studie sowie die Daten sind hier abrufbar.\nDie Ergebnisse der Studie zeigen, dass der Übergang zum legalen Alkoholkonsum im erlaubten Alter zu einem signifikanten Anstieg der Sterblichkeit führt. Insbesondere stellen die Autoren fest, dass junge Menschen, die legal Alkohol trinken dürfen, ein höheres Risiko haben, an alkoholbedingten Todesfällen zu sterben, im Vergleich zu Personen knapp unter dem Mindestalter."
  },
  {
    "objectID": "RDD.html#case-study-protestantische-arbeitsethik",
    "href": "RDD.html#case-study-protestantische-arbeitsethik",
    "title": "\n2  Regression Discontiniuty Designs\n",
    "section": "\n2.2 Case Study: Protestantische Arbeitsethik",
    "text": "2.2 Case Study: Protestantische Arbeitsethik\n\n\n\nDie Studie Beyond Work Ethic: Religion, Individual, and Political Preferences von Christoph Basten und Frank Betz aus dem Jahr 2013 untersucht den Zusammenhang zwischen Religion, individuellen Merkmalen und politischen Präferenzen. Das Hauptaugenmerk liegt dabei auf der Rolle der Religiosität als Einflussfaktor auf politische Einstellungen.\nDie Autoren argumentieren, dass die Religiosität eines Individuums über den traditionellen Rahmen von Moralvorstellungen und sozialen Normen hinausgeht und auch politische Präferenzen beeinflussen kann. Sie behaupten, dass die Religion eine eigenständige Dimension darstellt, die das politische Verhalten und die Einstellungen einer Person mitgestaltet.\nUm ihre Hypothesen zu testen, nutzen Basten und Betz Daten aus dem World Values Survey, einer internationalen Umfrage, die verschiedene Aspekte von Werten und Einstellungen untersucht. Sie analysieren insbesondere die Zusammenhänge zwischen Religiosität, individuellen Merkmalen wie Geschlecht, Bildung und Einkommen sowie politischen Präferenzen wie links-rechts-Ausrichtung, Einstellungen zur Umverteilung und zur Einwanderung.\nDie Ergebnisse der Studie zeigen, dass Religiosität tatsächlich einen signifikanten Einfluss auf politische Präferenzen hat. Insbesondere stellen die Autoren fest, dass religiöse Menschen tendenziell konservativere Einstellungen haben und eher rechten politischen Parteien zuneigen. Dieser Effekt bleibt auch nach Kontrolle anderer Faktoren wie Bildung und Einkommen bestehen.\nDarüber hinaus betonen die Autoren, dass der Zusammenhang zwischen Religion und politischen Präferenzen nicht allein durch moralische Werte erklärt werden kann. Sie argumentieren, dass religiöse Institutionen auch eine soziale und politische Agenda verfolgen, die von den Gläubigen internalisiert wird. Diese Agenda kann beispielsweise Positionen zu Themen wie Abtreibung, gleichgeschlechtlicher Ehe, Einwanderung oder Umweltschutz umfassen.\nZusammenfassend zeigt das Paper “Beyond Work Ethic: Religion, Individual, and Political Preferences” von Christoph Basten und Frank Betz, dass Religiosität einen Einfluss auf politische Präferenzen hat, der über traditionelle Moralvorstellungen hinausgeht. Es deutet darauf hin, dass religiöse Menschen eher konservative politische Ansichten haben und dass religiöse Institutionen eine Rolle bei der Formulierung dieser Ansichten spielen können.\n\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(vtable)\nlibrary(rdrobust)\n\n\nBastenBetz &lt;- read_dta('BastenBetz.dta')\n\n\n# Table 1\nT1 &lt;- BastenBetz %&gt;%\n    filter(abs(borderdis) &lt; 5.0283684) %&gt;%\n    transmute(\n        group = ifelse(vaud == 1, \"T\", \"C\"),\n        prot1980s = prot1980s * 100,\n        reineink = reineink_pc_mean * 1000,\n        noreligion1980s,\n        altitude, \n        pfl, \n        pfr, \n        pfi,\n        gini = Ecoplan_gini\n    ) %&gt;%\n    group_by(group) %&gt;%\n    summarise(\n      across(everything(), list(Mean = mean, SD = sd, N = length))\n      ) %&gt;%\n    pivot_longer(\n      -group, \n      names_to = c(\"variable\", \"statistic\"), \n      names_sep = \"_\"\n    )\n\n\nT1_wider &lt;- T1 %&gt;% \n    pivot_wider(\n        names_from = c(\"group\", \"statistic\")\n    )\n\n\nT1_wider %&gt;%\n  gt(rowname_col = \"Variable\") %&gt;% \n  tab_spanner_delim(\n    delim = \"_\",\n  ) %&gt;%\n tabopts\n\n\n\n\n\n\n\n  \n\nvariable\n      \n        C\n      \n      \n        T\n      \n    \n\nMean\n      SD\n      N\n      Mean\n      SD\n      N\n    \n\n\n\nprot1980s\n9.428\n5.695\n49\n83.245\n11.411\n84\n\n\nreineink\n43,692.71\n3,369.175\n49\n47,253.272\n5,342.36\n84\n\n\nnoreligion1980s\n1.729\n1.499\n49\n2.95\n2.726\n84\n\n\naltitude\n642.592\n120.23\n49\n639.607\n113.564\n84\n\n\npfl\n48.239\n4.774\n49\n39.508\n5.723\n84\n\n\npfr\n43.049\n2.634\n49\n39.19\n5.025\n84\n\n\npfi\n52.642\n2.94\n49\n47.086\n3.368\n84\n\n\ngini\n0.302\n0.029\n49\n0.367\n0.052\n84\n\n\n\nTabelle 2.1:  Datensatz BastenBetz – Zusammenfassende Statistiken \n\n\n\nImbens und Kalyanaraman (2012) zeigen\n\nbw_selection &lt;- rdbwselect(\n  y = BastenBetz$pfl,\n  x = BastenBetz$borderdis,\n  fuzzy = BastenBetz$prot1980s, \n  bwselect = \"mserd\", \n  kernel = \"uniform\") \n\nsummary(bw_selection)\n\nCall: rdbwselect\n\nNumber of Obs.                  509\nBW type                       mserd\nKernel                      Uniform\nVCE method                       NN\n\nNumber of Obs.                  127          382\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nUnique Obs.                      97          261\n\n=======================================================\n                  BW est. (h)    BW bias (b)\n            Left of c Right of c  Left of c Right of c\n=======================================================\n     mserd     5.078      5.078     10.905     10.905\n=======================================================\n\nOB &lt;- bw_selection$bws[1]\n\n\n# Table 2: First stage results \n# (1) (close to the) Imbens and Kalyanaraman (2012) optimal BW of 5.01 reported in\n# the paper\nFS1 &lt;- lm(\n  formula = prot1980s ~ vaud + borderdis + vaud * borderdis, \n  data = BastenBetz %&gt;% filter(abs(borderdis) &lt; OB)\n  )\n\n# (2) Constant BW: 10\nFS2 &lt;- lm(\n  formula = prot1980s ~ vaud + borderdis + vaud * borderdis, \n  data = BastenBetz %&gt;% filter(abs(borderdis) &lt; 10)\n  )\n\n# (3)  Constant BW: 20\nFS3 &lt;- lm(\n  formula = prot1980s ~ vaud + borderdis + vaud * borderdis, \n  data = BastenBetz %&gt;% filter(abs(borderdis) &lt; 20)\n  )\n\n\nmodelsummary::modelsummary(\n  list(FS1, FS2, FS3), \n  vcov = \"HC1\", stars = T, gof_map = \"nobs\", output = \"gt\"\n) %&gt;%\n  tabopts()\n\n\n\n\n\n\n \n      (1)\n      (2)\n      (3)\n    \n\n\n(Intercept)\n0.134***\n0.100***\n0.103***\n\n\n\n(0.017)\n(0.013)\n(0.010)\n\n\nvaud\n0.671***\n0.726***\n0.756***\n\n\n\n(0.034)\n(0.022)\n(0.018)\n\n\nborderdis\n0.017**\n0.001\n0.001\n\n\n\n(0.006)\n(0.003)\n(0.001)\n\n\nvaud × borderdis\n-0.006\n-0.001\n-0.009***\n\n\n\n(0.012)\n(0.005)\n(0.003)\n\n\nNum.Obs.\n133\n207\n312\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n    \n\n\n\n\n\n# Figure 3\nrdrobust::rdplot(y = BastenBetz$prot1980s, \n                 x = BastenBetz$borderdis, \n                 h = c(OB, OB), \n                 p = 1, \n                 nbins = c(6, 14), \n                 masspoints = \"off\")\nrdrobust::rdplot(y = BastenBetz$prot1980s, \n                 x = BastenBetz$borderdis, \n                 h = c(10, 10), \n                 p = 1, \n                 nbins = c(6, 14),\n                  masspoints = \"off\")\nrdrobust::rdplot(y = BastenBetz$prot1980s, \n                 x = BastenBetz$borderdis, \n                 h = c(20, 20), \n                 p = 1, \n                 nbins = c(6, 14),\n                  masspoints = \"off\")\nrdrobust::rdplot(y = BastenBetz$prot1980s, \n                 x = BastenBetz$borderdis, \n                 p = 1, \n                 nbins = c(6, 14),\n                 masspoints = \"off\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCarpenter, Christopher, und Carlos Dobkin. 2009. „The effect of alcohol consumption on mortality: regression discontinuity evidence from the minimum drinking age“. American Economic Journal: Applied Economics 1 (1): 164–82.\n\n\nImbens, G. W., und Thomas Lemieux. 2008. „Regression discontinuity designs: A guide to practice“. Journal of econometrics 142 (2): 615–35.\n\n\nImbens, Guido, und Karthik Kalyanaraman. 2012. „Optimal bandwidth choice for the regression discontinuity estimator“. The Review of economic studies 79 (3): 933–59.\n\n\nLee, David S. 2008. „Randomized experiments from non-random selection in US House elections“. Journal of Econometrics 142 (2): 675–97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "\n3  Summary\n",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2\n\n\n \n            # What is the capital of Berlin? (**SC**)\n            \n            In this question you are asked a **very** difficult question. \n            \n            &gt; Do some research! \n            \n            - [x] Berlin\n                &gt; This is the correct answer. \n            - [ ] Stuttgart \n            - [ ] Cologne \n                &gt; Cologne is the fourth largest city. \n            - [ ] Düsseldorf \n            \n            # Please bring the following into order! \n            \n            Below you find the steps of the machine learning workflow. \n            Do you find the **correct order**? \n            \n            &gt; The model selection happens before the `final model evaluation`!\n            \n            1. Get the data \n            2. Explore the data \n            3. Train test split with `train_test_split()` \n            4. Feature engineering \n            5. Model selection \n            6. Model evaluation \n            7. Deployment \n            \n            # Welchen Wert hat `y`? \n            \n            ```r\n            y \n\n\n\n \n\n      \n         2  Regression Discontiniuty Designs\n                \n  \n  \n      \n        References"
  },
  {
    "objectID": "Literatur.html",
    "href": "Literatur.html",
    "title": "References",
    "section": "",
    "text": "Angrist, Joshua D, and Jörn-Steffen Pischke. 2010. “The\nCredibility Revolution in Empirical Economics: How Better Research\nDesign Is Taking the Con Out of Econometrics.” Journal of\nEconomic Perspectives 24 (2): 3–30.\n\n\nCarpenter, Christopher, and Carlos Dobkin. 2009. “The Effect of\nAlcohol Consumption on Mortality: Regression Discontinuity Evidence from\nthe Minimum Drinking Age.” American Economic Journal: Applied\nEconomics 1 (1): 164–82.\n\n\nImbens, G. W., and Thomas Lemieux. 2008. “Regression Discontinuity\nDesigns: A Guide to Practice.” Journal of Econometrics\n142 (2): 615–35.\n\n\nImbens, Guido, and Karthik Kalyanaraman. 2012. “Optimal Bandwidth\nChoice for the Regression Discontinuity Estimator.” The\nReview of Economic Studies 79 (3): 933–59.\n\n\nLee, David S. 2008. “Randomized Experiments from Non-Random\nSelection in US House Elections.” Journal of\nEconometrics 142 (2): 675–97."
  }
]