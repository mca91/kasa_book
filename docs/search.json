[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kausalanalyse mit R",
    "section": "",
    "text": "1 Einführung\n\n\n\n\n\n\n\n\n\n\n\n\njust some test.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "R_Einfuehrung.html",
    "href": "R_Einfuehrung.html",
    "title": "\n2  Statistische Programmierung mit R\n",
    "section": "",
    "text": "2.1 Lange, weite und “tidy” Datenformate\nWir betrachten den in Tabelle 2.1 dargestellten Datensatz Klausurergebnisse.\nName\nMikro\nMakro\nMathe\n\n\n\nTim\nNA\n1.3\n3\n\n\nLena\n1\n3\nNA\n\n\nRicarda\n2\n1.7\n1.3\n\n\nSimon\n2.3\n3.3\nNA\n\n\n\n\n\n\n\nTabelle 2.1: Datensatz Klausurergebnisse\nDer Datensatz ist noch nicht in der R-Arbeitsumgebung verfügbar. Mit der Funktion tribble() können wir Tabelle 2.1 händisch als R-Objekt der Klasse tibble definieren\nklausurergebnisse enhält die Klausurnoten der vier Studierenden (Boebachtungen) spaltenweise pro Modul, d.h. die Spaltennamen Mikro, Makro und Mathe sind Ausprägungen der Variable Modul. Der Datensatz liegt also nicht im s.g. Tidy-Format vor.\nDas Tidy-Format ist hilfreich für statistische Analysen mit tidyverse-Funktionen wie bspw. ggplot(). Wir nutzen die Funktion tidyr::pivot_longer(), um klausurergebnisse ein (langes) Tidy-Format zu transformieren.\nBeachte, dass die Spalte Name die Zugehörigkeit der Ausprägungen (Note) jeder Variable (Modul) zu einer Beobachtung identifiziert. Mit dieser Information können wir den langen Datensatz wieder in das ursprüngliche (weite) Format zurückführen. Wir nutzen hierzu tidyr::pivot_wider().\nWenn die Zuweisung von Zwischenergebnissen in Variablen nicht benötigt wird, kann eine Verkettung von Funktionsaufrufen die Verständlichkeit des Codes verbessern. Hierzu wird der Pipe-Operator %&gt;% genutzt. Wir wiederholen die Transformationen mit den tidyr::pivot_*-Funktion bei Verwendung von %&gt;%.\nEin Beispiel für den Nachteil des weiten Formats im Umgang mit tidyverse-Paketen ist die Funktion tidyr::drop_na(). Diese entfernt sämtliche Zeilen eines Datensatzes, die NA-Einträge (d.h. fehlende Werte) aufweisen. Beachte, dass diese Operation im ursprünglichen weiten Format zum Entfernen ganzer Beobachtungen aus wide führt.\nIm Tidy-Format long hingegen bleiben die übrigen Informationen betroffener Beobachtungen erhalten.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Statistische Programmierung mit R</span>"
    ]
  },
  {
    "objectID": "R_Einfuehrung.html#lange-weite-und-tidy-datenformate",
    "href": "R_Einfuehrung.html#lange-weite-und-tidy-datenformate",
    "title": "\n2  Statistische Programmierung mit R\n",
    "section": "",
    "text": "Tidy-Format\n\n\n\nTidy-Format: Jede Spalte ist eine Variable, jede Reihe ist eine Beobachtung und jede Zelle enthält einen einen Wert. Datensätze im Tidy-Format sind häufig lang: Die Zeilendimension ist größer als die Spaltendimension.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Statistische Programmierung mit R</span>"
    ]
  },
  {
    "objectID": "R_Einfuehrung.html#sec-pp",
    "href": "R_Einfuehrung.html#sec-pp",
    "title": "\n2  Statistische Programmierung mit R\n",
    "section": "\n2.2 Pinguine und Pipes",
    "text": "2.2 Pinguine und Pipes\nIn diesem Abschnitt zeigen wir die Verwendung häufig verwendeter dplyr-Funktionen (s.g. Verben) für die Transformation von Datensätzen: mutate(), select(), filter(),summarise() und arrange().\nFür die Illustration verwenden wir den Datensatz penguins aus dem R-Paket palmerpenguins. Dieser Datensatz wurde im Zeitraum 2007 bis 2009 von Dr. Kristen Gorman im Rahmen des Palmer Station Long Term Ecological Research Program zusammengetragen und enthält Größenmessungen für drei Pinguinarten, die auf den Inseln des Palmer-Archipels in der Antarktis beobachtet wurden.\n\n# Paket 'palmerpenguins' installieren\n# install.packages(\"palmerpenguins\")\n\n# Paket 'palmerpenguins' laden\nlibrary(palmerpenguins)\n\nMit data() wird der Datensatz in der Arbeitsumgebung verfügbar gemacht. Wir nutzen glimpse(), um einen Überblick zu erhalten.\n\n\n\n\n\n\n\n2.2.1 dplyr::mutate()\n\nMit mutate() können bestehende Variablen überschrieben oder neue Variablen als Funktion bestehender Variablen definiert werden. mutate() operiert in der Spaltendimension des Datensatz.\nWir definieren eine neue Variable body_mass_kg als Transformation body_mass_g/1000.\n\n\n\n\n\n\nMit across() kann die dieselbe Operation auf mehrere Variablen angewendet werden.\nIm nachstehenden Beispiel ändern wir den typ (type) der Variablen species, island, sex und year zu character.\n\n\n\n\n\n\ntransmute() ist eine Variante von mutate(), die lediglich die transformierten Variablen beibehält.\n\n\n\n\n\n\n\n2.2.2 dplyr::select()\n\nMit select() werden Variablen aus dem Datensatz ausgewählt. Dies geschieht entweder über den Variablennamen…\n\n\n\n\n\n\n… oder über eine Indexmenge.3\n3 Hilfreich: dplyr::pull() selektiert eine Variable und wandelt diese in einen Vektor um.\n\n\n\n\n\nVariablen können anhand eines Muster im Namen selektiert werden. Die Selektion von ends_with(\"mm\") bezieht nur Variablen mit Endung mm im Namen ein:\n\n\n\n\n\n\nMit where() können wir Variablen aufgrund bestimmter Eigenschaften ihrer Ausprägungen selektieren.\n\n\n\n\n\n\n\n2.2.3 dplyr::filter()\n\nDas Verb filter() filtert den Datensatz in der Zeilendimension. So können Beobachtungen ausgewält werden, deren Merkmalsausprägungen bestimmte Kriterien erfüllen. Hierzu muss filter() ein logischer (logical) Ausdruck übergeben werden. Häufig erfolgt dies über Vergleichsoperatoren.\n\n\n\n\n\n\n\n\n\n\n\n\nOft ist es praktisch, mehrere Kriterien zu kombinieren.\n\n\n\n\n\n\nAnalog: komma-getrennte Kriterien werden intern über den Und-Operator (&) verknüpft.\n\n\n\n\n\n\nÄhnlich wie bei select() verwenden wir häufig nützliche Funktionen, welche die Interpretation des Codes erleichtern. dplyr::between() erlaubt filtern innerhalb eines Intervals.\n\n\n\n\n\n\nMit diesen Verben sind wir bereits in der Lage, den Datensatz gemäß folgender Vorschrift zu bereinigen:\n\nEntfernen der Maßeinheiten aus den Variablennamen\nEntfernen von Pinguinen mit fehlenden Werten (NA)\nEntfernen von Pinguinen mit einem Gewicht oberhalb des 95%-Stichprobenquantils\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDurch die Verkettung mit %&gt;% können wir sämtliche Schritte für die Bereinigung ohne das Abspeichern von Zwischenergebnissen durchführen.\n\n\n\n\n\n\n\n2.2.4 dplyr::summarise()\n\nDas Verb summarise() fasst Variablen über Beobachtungen hinweg zusammen. Der nachstehende Code-Chunk erzeugt eine Tabelle mit Stichprobenmittelwert und -standardabweichung von flipper_length_mm.4 Um zu vermeiden, dass die Auswertung aufgrund fehlender Werte (NA) in flipper_length_mm scheitert, lassen wir NAs mit na.rm = TRUE bei der Berechnung unberücksichtigt (wir verwenden weiterhin den unbereinigten Datensatz penguins).\n4 dplyr::summarise() darf nicht mit base::summary() verwechselt werden!\n\n\n\n\n\nVarianten von summarise() können über mehrere Variablen angewendet werden. Wir verwenden across() und where(), um lediglich numerische Variablen mit den in der liste definierten Funktionen zusammenzufassen. Beachte, dass \\(x) mean(x) eine anonyme Funktion definiert.\n\n\n\n\n\n\n\n2.2.5 dplyr::arrange()\n\nMit arrange() können Datensätze in Abhängigkeit der beobachteten Ausprägungen von Variablen sortiert werden.\n\n\n\n\n\n\nDie Funktion dplyr::desc() kehrt die Reihenfolge zu einer absteigenden Sortierung um.\n\n\n\n\n\n\nKomplexe Sortier-Muster werden durch Übergabe von Variablennamen in der gewünschten Reihenfolge erreicht.\n\n\n\n\n\n\n\n2.2.6 Operationen mit gruppierten Datensätzen\nFür manche Transformationen ist eine Gruppierung der Daten hilfreich. Wir illustrieren nachfolgend die unterschiedlichen Verhaltensweisen ausgewählter Verben durch Vergleiche von gruppierten und nicht-gruppierten Anwendungen.\n\n\n\n\n\n\nspecies hat drei Ausprägungen. Entsprechend ist penguins_grouped nun in drei Gruppen eingeteilt.\nBei gruppierten Datensätzen fasst summarise() die Variablen pro Guppe zusammen.\n\n\n\n\n\n\n\n\n\n\n\n\nmutate() definiert bzw. transformiert für jede Gruppe separat. Im dies zu veranschaulichen, ziehen wir eine Zufallsstichprobe von 10 Pinguinen aus der Datensatz.\n\n\n\n\n\n\n\n\n\n\n\n\nFür den ungruppierten Datensatz berechnet mutate() das Stichprobenmittel von bill_length_mm über alle zehn Datenpunkte und weißt diesen Wert jeweils in der Variable mean zu.\n\n\n\n\n\n\nBei gruppierten Daten berechnet mutate() das Stichprobenmittel pro Gruppe und weist die Mittelwerte entsprechend zu.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Statistische Programmierung mit R</span>"
    ]
  },
  {
    "objectID": "R_Einfuehrung.html#eine-explorative-analyse-mit-ggplot2",
    "href": "R_Einfuehrung.html#eine-explorative-analyse-mit-ggplot2",
    "title": "\n2  Statistische Programmierung mit R\n",
    "section": "\n2.3 Eine explorative Analyse mit ggplot2",
    "text": "2.3 Eine explorative Analyse mit ggplot2\nDer bereinigte Datensatz penguins_cleaned eignet sich gut für eine graphische Auswertung mit dem R-Paket ggplot2, welches Bestandteil des tidyverse ist. Nachfolgend untersuchen wir Zusammenhänge zwischen den Körpermaßen der Pinguine.\nWir erstellen zunächst einen einfachen Punkteplot des Gewichts (body_mass) und der Schnabeltiefe (bill_depth).\n\n\n\n\n\n\nDie Grafik zeigt einen positiven Zusammenhang zwischen dem Gewicht und der Schnabeltiefe. Als nächstes passen wir den Code so an, dass die Datenpunkte entsprechend der Art (species) eingefärbt sind.\n\n\n\n\n\n\nOffenbar gibt es deutliche Unterschiede in der (gemeinsamen) Verteilung von Gewicht und Schnabeltiefe zwischen den verschiedenen Arten.\nUm den Zusammenhang zwischen Gewicht und Schnabeltiefe zu untersuchen, schätzen wir lineare Regressionen \\[body\\_mass = \\beta_0 + \\beta_1 bill\\_depth + u\\] separat für jede der drei Pinguinarten mit der KQ-Methode. Anschließend zeichnen wir die geschätzten Regressionsgeraden ein.\n\n\n\n\n\n\nDie Schätzungen bekräftigen die Vermutung, dass der lineare Zusammenhang zwischen Gewicht und Schnabeltiefe sich nicht zwischen den verschiedenen Pinguinarten unterscheidet: Pinguine der Art Gentoo sind im Mittel schwerer als Pinguine der übrigen Arten, haben jedoch eine geringere Schnabeltiefe.\nDer nachfolgende Code fügt der Grafik eine Regressionsline über alle Arten hinzu. Wir setzen hierbei das Argment inherit_aes = FALSE und legen damit fest, dass die Regression für body_mass und bill_depth ohne Differenzierung per species durchgeführt wird.\n\n\n\n\n\n\nOffenbar ist die vorherige Analyse per Spezies sinnvoller: Die Regression über alle Arten suggeriert einen negativen Zusammenhang zwischen Gewicht und Schnabeltiefe.\nFacetting mit facet_wrap() erlaubt eine Untersuchung des Zusammenhangs je Insel (island), auf der die Messung erfolgt ist.\n\n\n\n\n\n\nWir sehen, dass es hinsichtlich des Zusammenhangs von Gewicht und Schnabeltiefe keine wesentlichen Diskrepanzen zwischen den drei Inseln gibt. Darüber hinaus lässt sich anhand der Facetten leicht erkennen, wie die drei Arten über die Inseln verteilt sind.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Statistische Programmierung mit R</span>"
    ]
  },
  {
    "objectID": "R_Einfuehrung.html#footnotes",
    "href": "R_Einfuehrung.html#footnotes",
    "title": "2  Statistische Programmierung mit R",
    "section": "",
    "text": "https://de.wikipedia.org/wiki/Hallo-Welt-Programm↩︎\nEin Teil des hier angebotenen Katalogs (exlusive Einführung in R) ist kostenpflichtig.↩︎\nHilfreich: dplyr::pull() selektiert eine Variable und wandelt diese in einen Vektor um.↩︎\ndplyr::summarise() darf nicht mit base::summary() verwechselt werden!↩︎",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Statistische Programmierung mit R</span>"
    ]
  },
  {
    "objectID": "ex.html",
    "href": "ex.html",
    "title": "3  Übungsaufgaben",
    "section": "",
    "text": "Calculate the average of all of the integers from 1 to 10.\n#| exercise: ex_1_r\n#| check: true\nif (identical(.result, mean(1:10))) {\n  list(correct = TRUE, message = \"Nice work!\")\n} else {\n  list(correct = FALSE, message = \"That's incorrect, sorry.\")\n}\n#| exercise: ex_1_r\n______(1:10)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Übungsaufgaben</span>"
    ]
  },
  {
    "objectID": "Reg.html",
    "href": "Reg.html",
    "title": "4  Regression",
    "section": "",
    "text": "4.1 Regression schließt Backdoors: Frish-Waugh-Lovell-Theorem\nDas Frisch-Waugh-Lovell-Theorem (FWL) besagt, dass in einer multiplen linearen Regression die geschätzten Koeffizienten für eine Teilmenge der Regressoren numerisch identisch zu Koeffizientenschätzungen aus folgenden Schritten sind\nIn einem multiplen Modell mit zwei Regressoren \\(X_1,\\ X_2\\), \\[\\begin{align}\n  Y = \\beta_0 + \\beta_1 X + \\beta_2 X_2 + \\epsilon \\label{eq:fwlfullreg}\n\\end{align}\\] kann der Effekt von \\(X_1\\) auf \\(Y\\) also mit der Regression \\[\\begin{align*}\n  \\widehat{u}_{Y,X_2} = \\beta_1 \\widehat{u}_{X_1,X_2} + e \\label{eq:fwl2reg}\n\\end{align*}\\] geschätzt werden, wobei \\(\\widehat{u}_{Y,X_2}\\) und \\(\\widehat{u}_{X_1,X_2}\\) die Residuen der Regression von \\(Y\\) auf \\(X_2\\) und von \\(X_1\\) auf \\(X_2\\) sind.\nFWL ermöglicht daher eine Vereinfachung der Schätzung komplexer Modelle durch die Zerlegung der Schätzung in Teilschritte.\nFür das Verständnis der Schätzung kausaler Effekte mit linearer Regression ist FWL hilfreich, denn es zeigt, wie sowohl die Variation in der Outcome-Variable (\\(\\widehat{u}_{Y,X_2}\\)) als auch die Variation in der Behandlungsvariable (\\(\\widehat{u}_{X_1,X_2}\\)), die jeweils nicht durch Kovariablen (\\(X_2\\)) verursacht wird, mit multipler Regression isoliert werden kann, sodass Backdoors geschlossen werden.\nWir illustrieren dieses Konzept anhand einer multiplen Regression für die Schnabeltiefe (body_mass) von Pinguinen aus dem Datensatz palmerpenguins::penguins,\n\\[\\begin{align}\n  \\textup{body\\_mass} = \\beta_0 + \\beta_1\\cdot\\textup{bill\\_length} + \\beta_2\\cdot \\textup{flipper\\_length} + \\epsilon,\\label{eq:billdepthmodel}\n\\end{align}\\] unter der Annahme, dass \\(\\beta_1\\) der interessierende Effekt ist: Die erwartete Änderung des Gewichts eines Pinguins (in Gramm) für eine Änderung der Schnabel-Länge um 1mm.\nVor der Schätzung von Modell \\(\\eqref{eq:billdepthmodel}\\) lesen wir den Datensatz ein und erstellen eine bereinigte Variante penguins_cleaned, analog zur Vorgehensweise in Kapitel 2.2.\nWir schätzen nun Modell \\(\\eqref{eq:billdepthmodel}\\) mit lm() und erhalten eine Zusammenfassung der geschätzen Koeffizienten mit broom::tidy().\nDas Ergebnis der Schätzung ist \\(\\widehat{\\beta}_1\\approx3.80\\). Der nächste Code-Block berechnet die Residuen aus den Regressionen \\[\\begin{align*}\n  \\textup{body\\_mass} =&\\, \\alpha_0 + \\alpha_1 \\textup{flipper\\_length} + u_{\\textup{body\\_mass},\\,\\textup{flipper\\_length}},\\\\\n  \\textup{bill\\_length} =&\\, \\delta_0 + \\delta_1 \\textup{flipper\\_length} + u_{\\textup{bill\\_length},\\,\\textup{flipper\\_length}},\n\\end{align*}\\]\nund speichert diese in body_mass_res und bill_length_res.\nDer geschätzte Koeffizient aus der Regression der Residuen stimmt mit dem geschätzten Koeffizienten von bill_length aus der großen Regression \\(\\eqref{eq:billdepthmodel}\\) überein.\nWir können den Effekt der Kontrolle für flipper_length visualisieren. Wir plotten hierzu:\nDer grafische Vergleich beider Vorgehensweisen zeigt den Effekt der Kontrolle für flipper_length: Die geschätzte (schwarze) Regressionslinie für die bereinigten Daten hat eine deutlich geringere Steigung als die anhand der ursprünglichen Daten geschätzte (lilane) Linie. Der Effekt von bill_length auf body_mass wird mit der einfachen Regression lm(body_mass ~ bill_length) vermutlich überschätzt, weil es andere Faktoren (wie flipper_length gibt, die mit bill_length und body_mass korrelieren. Kontrollieren für flipper_length in der multiplen Regression lm(body_mass ~ bill_length + flipper_length) schließt die Backdoor durch flipper_length. Die Konsequenz ist eine deutlich geringere Steigung der lilanen Regressionslinie.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "Reg.html#regression-schließt-backdoors-frish-waugh-lovell-theorem",
    "href": "Reg.html#regression-schließt-backdoors-frish-waugh-lovell-theorem",
    "title": "4  Regression",
    "section": "",
    "text": "Rechne die Effekte der übrigen Variablen auf (a) die Outcome-Variable und (b) die Teilmenge der erklärenden Variablen mit Regression heraus und\nregressiere anschließend die Residuen von Schritt (a) auf die Residuen aus Schritt (b).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie originalen Datenpunkte für bill_length und body_mass1 gemeinsam mit der geschätzten Regressionslinie für das Modell \\[ \\textup{body\\_mass} = \\beta_0 + \\beta_1\\textup{bill\\_length} + u \\] (keine Kontrolle für flipper_length!)2.\nDie um flipper_length bereinigten Datenpunkte und die zugehörige geschätzte Regressionslinie.\n\n1 Für eine bessere Lesbarkeit der Grafik zentrieren wir beide Variablen um den jeweiligen Stichprobenmittelwert.2 Der R-Befehl für diese Regression ist lm(I(body_mass - mean(body_mass)) ~ I(bill_length - mean(bill_length)) - 1, data = penguins_cleaned).",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "Reg.html#binäre-outcome-variable",
    "href": "Reg.html#binäre-outcome-variable",
    "title": "4  Regression",
    "section": "\n4.2 Binäre Outcome-Variable",
    "text": "4.2 Binäre Outcome-Variable\nEine binäre Variable, auch als dichotome Variable oder Indikator-Variable bezeichnet, ist eine Variable, die nur zwei Ausprägungen annehmen kann. Diese beiden Ausprägungen werden typischerweise durch die Werte 0 und 1 repräsentiert und dienen dazu, zwei verschiedene Zustände oder Kategorien zu unterscheiden. Formal kann eine binäre Variable \\(B\\) wie folgt definiert werden:\n\\[\\begin{align}\n  B = \\begin{cases}\n  1, & \\text{Eigenschaft trifft zu,} \\\\\n  0, & \\text{Eigenschaft trifft nicht zu.}\n  \\end{cases}\n\\end{align}\\]\nEine in späteren Kapiteln dieses Companions als verwendeter binärer Regressor ist der Indikator für die Zuordnung von Beobachtungen in Behandlungs- oder Kontrollgruppe (1 = Behandlungsgruppe, 0 = Kontrollgruppe).\nFür viele ökonomische Forschungsfragen ist es hilfreich, eine binäre Outcome-Variable mit Regression zu modellieren. Hierzu gibt es verschiedene Ansätze, die wir nachfolgend zusammenfassen und ihre Anwendung mit R zeigen.\n\n4.2.1 Das lineare Wahrscheinlichkeitsmodell\nDas lineare Regressionsmodell\n\\[Y = \\beta_0 + \\beta_1 X_{1} + \\beta_2 X_{2} + \\dots + \\beta_k X_{k} + u\\] mit einer binären abhängigen Variablen \\(Y_i\\in\\{0,1\\}\\) wird als lineares Wahrscheinlichkeitsmodell bezeichnet. Wie üblich modellieren wir den Erwartungswert der abhängigen Variable gegeben der Regressoren \\(X_1,\\dots,X_k\\) als lineare Funktion,\n\\[E(Y\\vert X_1,X_2,\\dots,X_k) = P(Y=1\\vert X_1, X_2,\\dots, X_3).\\] Da \\(Y\\) eine binäre Variable ist, gilt hier\n\\[ P(Y = 1 \\vert X_1, X_2, \\dots, X_k) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_k X_k.\\]\nDas lineare Wahrscheinlichkeitsmodell beschreibt also die Wahrscheinlichkeit, dass \\(Y=1\\) als lineare Funktion der Regressoren: \\(\\beta_j\\) misst die Änderung in der Wahrscheinlichkeit für das Ereignis \\(Y_i=1\\), unter der Bedingung, dass die anderen \\(k-1\\) Regressoren konstant gehalten werden. Genau wie bei multipler Regression mit einer kontinuierlichen abhängigen Variablen können die \\(\\beta_j\\) mit der KQ-Methode geschätzt werden.\nAufgrund der Beschränktheit der \\(Y_i\\) auf \\(\\{0,1\\}\\) sind die \\(u_i\\) heteroskedastisch. Folglich sollten Inferenzstatistiken mit robusten Standardfehlern berechnet werden. Weiterhin ist zu beachten, dass \\(R^2\\) in den meisten Anwendungen von linearen Wahrscheinlichkeitsmodellen keine hilfreiche Interpretation hat, da das geschätzte Modell die Daten nicht perfekt erklären kann, wenn die abhängige Variable binär, aber die Regressoren kontinuierlich verteilt sind.\nDas lineare Wahrscheinlichkeitsmodell hat einen wesentlichen Nachteil: Das Modell nimmt an, dass die bedingte Wahrscheinlichkeitsfunktion linear ist und \\(P(Y=1\\vert X_1,\\dots,X_k)\\) nicht auf das für Wahrscheinlichkeiten definierte Intervall \\([0,1]\\) beschränkt ist. Ein angepasstes Modell hat dann für Regressorwerte, die zu Vorhersagen von \\(Y\\) jenseits von \\([0,1]\\) führen keine sinnvolle Interpretation.\nDieser Umstand verlangt nach Regressionsansätzen, die \\(P(Y=1)\\) durch eine auf \\([0,1]\\) beschränkte (nicht-lineare) Funktion der Regressoren modellieren. Häufig verwendete Methoden sind Probit- und Logit-Regression.\n\n4.2.2 Probit-Regression\nBei der Probit-Regression wird die Standardnormalverteilungsfunktion \\(\\Phi(\\cdot)\\) verwendet, um die Regressionsfunktion bei einer binären abhängigen Variable zu modellieren. Wir nehmen an, dass \\[\\begin{align}\n  E(Y\\vert X) = P(Y=1\\vert X) = \\Phi(\\beta_0 + \\beta_1 X). \\label{eq:probitmodel}\n\\end{align}\\]\n\\(\\beta_0 + \\beta_1 X\\) in \\(\\eqref{eq:probitmodel}\\) ist hier ein Quantil \\(z\\) der Standardnormalverteilung, \\[\\begin{align}\n\\Phi(z) = P(Z \\leq z) \\ , \\ Z \\sim \\mathcal{N}(0,1),\n\\end{align}\\] sodass der Koeffizient \\(\\beta_1\\) in \\(\\eqref{eq:probitmodel}\\) die Änderung in \\(z\\) misst, die mit einer Änderung von einer Einheit in \\(X\\) verbunden ist. Obwohl der Effekt einer Änderung in \\(X\\) auf \\(z\\) linear ist, ist der Zusammenhang zwischen \\(z\\) und der abhängigen Variable \\(Y\\) nicht linear, denn \\(\\Phi(\\cdot)\\) ist eine nicht-lineare Funktion von \\(X\\) (vgl. ?fig-snvf)!\n\n\n\n\n\n\nAufgrund der Nicht-Linearität hat der Koeffizient von \\(X\\) keine einfache Interpretation hinsichtlich des Effekts auf \\(Y\\). Die Änderung in der Wahrscheinlichkeit, dass \\(Y=1\\) ist, durch eine Änderung in \\(X\\) (partieller Effekt) kann berechnet werden als:\n\\[\\begin{align}\n  \\frac{\\partial\\textup{E}(Y\\vert X)}{\\partial X} = \\frac{\\partial\\textup{P}(Y=1\\vert X)}{\\partial X} = \\frac{\\partial\\Phi(\\beta_0 + \\beta_1 X)}{\\partial X} = \\phi(\\beta_0 + \\beta_1 X) \\beta_1,\n\\end{align}\\] wobei \\(\\phi(\\cdot)\\) die Dichtefunktion der Standardnormalverteilung ist. In empirischen Anwendungen wird der partielle Effekt häufig als Differenz in geschätzten Wahrscheinlichkeiten angegeben:\n\nBerechne die geschätzte Wahrscheinlichkeit, dass \\(Y=1\\) für einen Bezugswert \\(X\\).\nBerechne die geschätzte Wahrscheinlichkeit, dass \\(Y=1\\) für \\(X + \\Delta X\\).\nBerechne die Differenz zwischen der geschätzten Wahrscheinlichkeiten.\n\nWie im linearen Wahrscheinlichkeitsmodell kann das Modell \\(\\eqref{eq:probitmodel}\\) auf eine Probit-Regression mit mehreren Regressoren \\(X_j\\), \\(j=1,\\dots,k\\) verallgemeinert werden, um das Risiko einer Verzerrung durch ausgelassene Variablen zu mindern. Die Schritte 1 bis 3 für die Berechnung des partiellen Effekts einer Änderung in \\(X_j\\) erfolgen dann unter der Annahme, dass die übrigen \\(k-1\\) Regressoren konstant gehalten werden, wobei der partielle Effekt von den jeweiligen Regressorwerten abhängt.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.2.3 Logistische Regression\nBei der logistischen Regression wird die logistische Funktion \\(\\Lambda(\\cdot)\\) \\[\\begin{align}\n\\Lambda(z) = \\frac{1}{1 + \\exp(-z)},\n\\end{align}\\] genutzt, um die Wahrscheinlichkeitsfunktion von \\(Y\\) zu modellieren. Ähnlich wie im Probit-Modell nehmen wir hier an, dass \\[\\begin{align}\nE(Y\\vert X) = P(Y=1\\vert X) = \\Lambda(\\beta_0 + \\beta_1 X). \\label{eq:logitmodel}\n\\end{align}\\] In diesem Modell entspricht \\(\\beta_0 + \\beta_1 X\\) dem sogenannten Logit, dem logarithmierten Verhältnis von \\(p = P(Y=1\\vert X)\\) und \\(1-p = P(Y=0\\vert X)\\), \\[\\begin{align*}\n  \\textup{Logit(p)} = \\log\\bigg(\\frac{p}{1-p}\\bigg) = \\beta_0 + \\beta_1 X.\n\\end{align*}\\] wobei \\(\\beta_1\\) die Veränderung des Logits pro Einheit Änderung im Regressor \\(X\\) angibt. Wie bereits im Probit-Fall ist der Einfluss von \\(X\\) auf den Logit linear, jedoch besteht auch hier eine nicht-lineare Beziehung zwischen dem Logit und der Wahrscheinlichkeit \\(P(Y=1)\\), da \\(\\Lambda(\\cdot)\\), ähnlich wie die Normalverteilungsfunktion im Probit-Modell, eine nicht-lineare Funktion mit dem Wertebereich \\([0,1]\\) ist.\n\n\n\n\n\n\nAufgrund dieser Nicht-Linearität lässt sich der Koeffizient \\(\\beta_1\\) ebenso wie im Probit-Modell nicht direkt als einfacher Effekt auf die Wahrscheinlichkeit \\(P(Y=1)\\) interpretieren. Um den partiellen Effekt einer Änderung in \\(X\\) auf \\(P(Y=1)\\) zu ermitteln, berechnet man die Ableitung:\n\\[\\begin{align}\n\\frac{\\partial\\textup{E}(Y\\vert X)}{\\partial X} = \\frac{\\partial\\textup{P}(Y=1\\vert X)}{\\partial X} = \\frac{\\partial\\Lambda(\\beta_0 + \\beta_1 X)}{\\partial X} = \\lambda(\\beta_0 + \\beta_1 X) \\beta_1,\n\\end{align}\\] wobei \\(\\lambda(\\cdot)\\), ähnlich wie die Dichtefunktion der Normalverteilung im Probit-Modell, die Dichtefunktion der logistischen Verteilung darstellt. Diese ist gegeben durch \\[\\begin{align}\n\\lambda(z) = \\Lambda(z) \\cdot (1 - \\Lambda(z)).\n\\end{align}\\]\n\n4.2.4 Schätzung mit R",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "Reg.html#sec-poissonreg",
    "href": "Reg.html#sec-poissonreg",
    "title": "4  Regression",
    "section": "\n4.3 Modellierung von Zählvariablen mit Poisson-Regression",
    "text": "4.3 Modellierung von Zählvariablen mit Poisson-Regression\nDie Poisson-Regression ist ein statistisches Modell, das verwendet wird, um Zählvariablen (d.h. Variablen, die diskrete, nicht-negative Werte annehmen) zu modellieren, insbesondere wenn die Zählwerte eine Poisson-Verteilung aufweisen. Dieses Modell wird häufig in Fällen verwendet, in denen die abhängige Variable die Anzahl der Ereignisse in einem bestimmten Zeitraum oder Raum beschreibt, wie z.B. die Anzahl der Verkehrsunfälle in einer Stadt innerhalb eines Monats.\n\n4.3.1 Poisson-Verteilung\nEine Zufallsvariable \\(Y\\) folgt einer Poisson-Verteilung mit Parameter \\(\\lambda\\), wenn ihre Wahrscheinlichkeitsverteilung gegeben ist durch:\n\\[\\begin{align}\nP(Y = y) = \\frac{\\lambda^y e^{-\\lambda}}{y!} \\quad \\text{für} \\quad y = 0, 1, 2, \\ldots\n\\end{align}\\]\nHierbei ist \\(\\lambda\\) sowohl der Mittelwert als auch die Varianz der Verteilung (\\(\\mathbb{E}[Y] = \\text{Var}(Y) = \\lambda\\)).\n\nn &lt;- 500\ndat &lt;- tibble(\n  Y = rpois(n = n, lambda = 5)\n)\n\n\nggplot(\n    data = dat, \n    mapping = aes(x = Y)\n) +\n    geom_histogram(\n        mapping = aes(y = after_stat(density)), \n        binwidth = 1, \n        color = \"white\"\n    ) +\n    geom_line(\n        data = tibble(\n            X = 0:13,\n            Y = dpois(x = X, lambda = 5)\n        ),\n        mapping = aes(x = X, y = Y),\n        color = \"red\"\n    ) +\n    theme_cowplot()\n\n\n\n\n\n\nAbbildung 4.1: Stichprobenverteilung und Poisson-Dichtefunktion\n\n\n\n\n\n4.3.2 Beispiel: Klassifikation für Palmer-Piniguinen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.3.3 Der Regressionsansatz\nIn der Poisson-Regression modellieren wir den Erwartungswert der abhängigen Variable \\(Y\\) als eine Funktion der unabhängigen Variablen \\(\\mathbf{X} = (X_1, X_2, \\ldots, X_k)\\). Der Erwartungswert von \\(Y\\) wird durch den Parameter \\(\\lambda\\) repräsentiert, der wiederum eine Funktion der unabhängigen Variablen ist. Die Beziehung wird typischerweise durch eine logarithmische Verknüpfungsfunktion beschrieben:\n\\[\\begin{align}\n\\log(\\lambda_i) = \\mathbf{X}_i^\\top \\boldsymbol{\\beta}\n\\end{align}\\]\nDies kann auch als\n\\[\\begin{align}\n\\lambda_i = \\exp(\\mathbf{X}_i^\\top \\boldsymbol{\\beta})\n\\end{align}\\]\ngeschrieben werden, wobei:\n\n\\(\\lambda_i\\) der Erwartungswert von \\(Y\\) für Beobachtung \\(i\\),\n\\(\\mathbf{X}_i\\) der Vektor der unabhängigen Variablen für Beobachtung \\(i\\) und\n\\(\\boldsymbol{\\beta}\\) der Vektor der Regressionskoeffizienten ist.\n\n4.3.4 Modellanpassung\nDie Parameter \\(\\boldsymbol{\\beta}\\) werden durch Maximum-Likelihood-Schätzung (MLE) geschätzt. Die Likelihood-Funktion für \\(n\\) Beobachtungen ist gegeben durch\n\\[\\begin{align}\nL(\\boldsymbol{\\beta}) = \\prod_{i=1}^n \\frac{\\lambda_i^{y_i} e^{-\\lambda_i}}{y_i!}.\n\\end{align}\\]\nDie Log-Likelihood-Funktion ist daher\n\\[\\begin{align}\n\\mathcal{L}(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left( y_i \\log(\\lambda_i) - \\lambda_i - \\log(y_i!). \\right)\n\\end{align}\\]\nDa \\(\\lambda_i = \\exp(\\mathbf{X}_i^\\top \\boldsymbol{\\beta})\\), wird die Log-Likelihood-Funktion zu\n\\[\\begin{align}\n\\mathcal{L}(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left( y_i (\\mathbf{X}_i^\\top \\boldsymbol{\\beta}) - \\exp(\\mathbf{X}_i^\\top \\boldsymbol{\\beta}) - \\log(y_i!) \\right)\n\\end{align}\\]\nDen Maximum-Likelihood-Schätzer \\(\\widehat{\\boldsymbol{\\beta}}\\) erhalten wir durch Maximierung der Log-Likelihoodfunktion \\(\\mathcal{L}(\\boldsymbol{\\beta})\\). Eine R-Implementierung finden wir in stats::glm().\n\n4.3.5 Interpretation der Koeffizienten\nDie Koeffizienten \\(\\boldsymbol{\\beta}\\) in der Poisson-Regression haben eine log-lineare Beziehung zur Zählvariable. Für einen bestimmten Koeffizienten \\(\\beta_j\\) ist die Interpretation wiefolgt:\n\nEin Anstieg der unabhängigen Variable \\(X_j\\) um eine Einheit führt zu einer Änderung des Logarithmus des Erwartungswertes von \\(Y\\) um \\(\\beta_j\\).\nDer Erwartungswert \\(\\lambda\\) ändert sich multiplikativ um \\(\\exp(\\beta_j)\\).\n\nAngenommen, wir haben eine unabhängige Variable \\(X\\) (z.B. die Anzahl der durchgeführten Werbekampagnen) und eine Zählvariable \\(Y\\) (z.B. die Anzahl der Verkäufe). Das Modell könnte wie folgt aussehen:\n\\[\\begin{align}\n\\log(\\lambda) = \\beta_0 + \\beta_1 X\n\\end{align}\\]\nWenn \\(\\beta_1 = 0.5\\), bedeutet dies, dass jede zusätzliche Werbekampagne die erwartete Anzahl der Verkäufe um einen Faktor von \\(\\exp(0.5) \\approx 1.65\\) erhöht. Das heißt, die Rate der Verkäufe steigt um 65% für jede zusätzliche Werbekampagne.\n\n# Setze den Zufallszahlengenerator für Reproduzierbarkeit\n#set.seed(1234)\n\n# Anzahl der Beobachtungen\nn &lt;- 500\n\n# Simuliere die unabhängige Variable X (Anzahl der Werbekampagnen)\nX &lt;- sample(1:8, replace = T, size = n)\n\n# Setze die wahren Parameter für das Modell\nbeta_1 &lt;- 0.4  # Koeffizient für X\n\n# Berechne den Erwartungswert lambda basierend auf dem Modell\nlambda &lt;- exp(2 + beta_1 * X)\n\n# Simuliere die abhängige Variable Y (Anzahl der Verkäufe) als Poisson-verteilte Zufallsvariable\nY &lt;- rpois(n, lambda = lambda)\n\ndat &lt;- tibble(X = X, Y = Y)\n\n\nggplot(\n  data = dat, \n  mapping = aes(x = Y)\n  ) +\n  geom_histogram(binwidth = 2) +\n  theme_cowplot()\n\n\n\n\n\n\n\n\n# Poisson-Regression schätzen\nmodel &lt;- glm(\n  formula = Y ~ X, \n  family = poisson(link = \"log\"), \n  data = dat\n)\n\n# Zusammenfassung des gesch. Modells\nsummary(model)\n\n\nCall:\nglm(formula = Y ~ X, family = poisson(link = \"log\"), data = dat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) 1.979339   0.019488   101.6   &lt;2e-16 ***\nX           0.403034   0.002954   136.4   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 23821.79  on 499  degrees of freedom\nResidual deviance:   513.36  on 498  degrees of freedom\nAIC: 3306.1\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n# Vorhersagen\ndat$predicted &lt;- predict(model, type = \"response\")\n\n# Simulierte Daten und Schätzungen\nggplot(\n  data = dat, \n  mapping = aes(x = X, y = Y)\n) +\n  geom_point(\n    mapping = aes(color = \"Simulierte Daten\"), \n    alpha = 0.5, \n    position = position_jitter(width = .1)\n  ) +\n  geom_line(\n    aes(y = predicted, color = \"Geschätztes Modell\")\n    ) +\n  labs(\n    x = \"Anzahl der Werbekampagnen\",\n    y = \"Anzahl der Eisverkäufe\"\n  ) +\n  scale_color_manual(\n    \"\",\n    values = c(\n      \"Simulierte Daten\" = \"blue\", \n      \"Geschätztes Modell\" = \"red\"\n    )\n  ) +\n  theme_cowplot() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\nAbbildung 4.2: Simulierte Daten und angepasstes Poisson-Modell",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "Reg.html#footnotes",
    "href": "Reg.html#footnotes",
    "title": "4  Regression",
    "section": "",
    "text": "Für eine bessere Lesbarkeit der Grafik zentrieren wir beide Variablen um den jeweiligen Stichprobenmittelwert.↩︎\nDer R-Befehl für diese Regression ist lm(I(body_mass - mean(body_mass)) ~ I(bill_length - mean(bill_length)) - 1, data = penguins_cleaned).↩︎",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "Simulation.html",
    "href": "Simulation.html",
    "title": "5  Simulation",
    "section": "",
    "text": "5.1 Simulation der Stichprobenverteilung eines Schätzers\nZur Illustration der Simulation von Stichprobenverteilungen eines Schätzers betrachten wir zunächst das kanonische Beispiel der Schätzung des Erwartungswerts \\(\\mu_X\\) einer normalverteilen Zufallsvariable \\(X\\) anhand einer \\(n\\)-elementigen Stichprobe, \\[\\begin{align}\n  X_i \\sim\\,u.i.v. N(\\mu_X,\\ \\sigma_X^2), \\quad i=1,\\dots,n.\\label{eq:distx}\n\\end{align}\\] Die Vorschrift \\(\\eqref{eq:distx}\\) ist der datenerzeugende Prozess (DGP)1. Das arithmetische Mittel der \\(X_i\\), \\[\\begin{align*}\n  \\overline{X} := \\sum_{i=1}^n X_i,\n\\end{align*}\\] ist ein konsistenter Schätzer für \\(\\mu_X\\) und hat (aufgrund der Normalverteilung der \\(X_i\\)) die formal herleitbare Eigenschaft, dass die Stichprobenverteilung normal ist2, \\[\\begin{align*}\n  \\overline{X} \\sim N(\\mu_X, \\sigma_X^2 / n), \\qquad \\overline{X}\\xrightarrow{p}\\mu_X.\n\\end{align*}\\]\nWir können die Eigenschaften von \\(\\overline{X}\\) mit wenig Aufwand in R prüfen indem wir die Stichprobenentnahme durch wiederholtes Ziehen einer (großen) Anzahl von \\(N\\) Stichproben aus der Populationsverteilung von \\(X\\) gemäß der Vorschrift \\(\\eqref{eq:distx}\\) simulieren und jeweils \\(\\overline{X}\\) für diese simulierten Stichproben berechnen. Wir simulieren so Züge aus der Stichprobenverteilung von \\(\\overline{X}\\), deren Eigenschaften – in Abhängigkeit von \\(\\mu_X\\), \\(\\sigma_X^2\\) und \\(n\\) – wir anhand der Realisierungen von \\(\\overline{X}\\) ableiten können. In den nachfolgenden Code-Beispielen wählen wir \\[\\begin{align*}\n  \\mu_X = 50,\\quad \\sigma_X^2=12^2,\\quad n = 50.\n\\end{align*}\\]\nEine einfache Zufallsstichprobe von \\(X\\) erzeugen wir mit rnorm() und berechnen das arithmetische Mittel mit mean().\nDieses einfache Simulationsexperiment mit \\(N=1\\) ergibt zwar eine Schätzung des Erwartungswerts von \\(X\\) nahe des wahren Werts \\(\\mu_X = 50\\), ist jedoch wenig informativ über die Qualität des Schätzers, d.h. die Eigenschaften der Stichprobenverteilung von \\(\\overline{X}\\). Diese Realisation könnte zufällig nahe bei \\(\\mu_X = 50\\) liegen, obwohl die Stichprobenverteilung \\(\\overline{X}\\) einen von \\(50\\) verschiedenen Erwartungswert hat und/oder eine große Varianz aufweist.\nUm die Stichprobenverteilung zu simulieren, wiederholen wir das Simulationsexperiment \\(N=1000\\) mal: Wir erzeugen \\(N=1000\\) Realisierungen aus der Stichprobenverteilung von \\(\\overline{X}\\) für die gewählten Parameter. Hierfür verwenden wir Iteration in R: Eine for()-Schleife wiederholt das Simulationsexperiment über 1:N Iterationen und speichert das Ergebnis des j-ten Experiments in einem zuvor definierten numerischen Vektor sim_est.3\nDie zusammenfassenden Statistiken sind Schätzungen der Verteilungseigenschaften von \\(\\overline{X}\\). Da wir die Anzahl der Replikation \\(N\\) selber wählen, können wir die wahren Parameter theoretisch “beliebig” genau approximieren: Lediglich die Rechenleistung des Computers limitiert die Güte dieser Approximation. In vielen Anwendungen liefert eine vierstellige Zahl an Simulationsdurchläufen gute Approximationen. Tatsächlich liegen die simulierten Parameter der Stichprobenverteilung von \\(\\overline{X}\\) nahe bei den wahren Werten.\nFür einen grafischen Vergleich der simulierten Stichprobenverteilung mit der theoretischen \\(N(50, 12^2/50)\\)-Verteilung plotten wir die theoretische Dichte sowie ein Dichte-Histogramm der simulierten Züge von \\(\\overline{X}\\) in sim_est.\nDie Abbildung zeigt, dass die simulierte Stichprobenverteilung (graues Dichte-Histogramm) die Dichte der theoretischen Verteilung (gestrichelte Linie) gut approximiert.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "Simulation.html#sec-simspv",
    "href": "Simulation.html#sec-simspv",
    "title": "5  Simulation",
    "section": "",
    "text": "1 Englische Abkürzung für data generating process.2 D.h. hier ist \\(\\overline{X}\\sim N(50, 2.88)\\).\n\n\n\n\n\n\n\n\n\n3 Iteration mit Funktionen aus dem Paket purrr (siehe tab) ist eine Alternative zum “klassischen” Ansatz mit einer for()-Schleife.\nIteration mit for()-SchleifeIteration mit purrr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.1.1 Simulation mit nicht-normalen Daten\nSimulationen sind insbesondere dann hilfreich, wenn die Stichproben-Eigenschaften eines Schätzers unbekannt sind. Im nachfolgenden Beispiel wiederholen wir die Simulation für eine Log-normal-verteilte Zufallsvariable4 \\(X\\) mit Erwartungswert \\(\\mu_X = 50\\) und plotten die geschätzten Dichtefunktionen der Stichprobenverteilungen von \\(\\overline{X}\\) für einen Vergleich.\n4 Ist \\(X\\) log-normal-verteilt mit Erwartungswert \\(\\mu_X\\) und Varianz \\(\\sigma_X^2\\), dann ist \\(\\log X\\) normal-verteilt mit \\(\\mu_{\\log X} = \\log \\mu_X - \\sigma_X^2/2\\) und \\(\\sigma^2_{\\log X} = \\mu_X^2 [\\exp(\\sigma_X^2)-1]\\).\n\n\n\n\n\nDie funktionale Form der Stichprobenverteilung von \\(\\overline{X}\\) für eine log-normalverteilte Population ist unbekannt. Unsere Simulation erlaubt jedoch Rückschlüsse auf Eigenschaften dieser Verteilung: Die Verteilung ist rechtsschief und weißt eine höhere Varianz auf als die Stichprobenverteilung von \\(\\overline{X}\\) für die normal-verteilte Population.\n\n\n5.1.2 Regression: Verzerrung durch Confounder\nDer DGP in Abbildung 5.1 zeigt eine typische Situation, in der wir den kausalen Effekt von \\(X\\) auf \\(Y\\) nicht ohne Weiteres mit Regression identifizieren können: Die Variablen \\(U\\) und \\(e\\) sind unbeobachtbar. \\(e\\) ist ein unsystematischer Fehler, der lediglich \\(Y\\) beeinflusst. Die Variable \\(U\\) hingegen beeinflusst sowohl \\(X\\) als auch \\(Y\\) und ist damit eine Backdoor-Variable: \\(U\\) ist ein Counfounder, sodass der kausale Effekt von \\(X\\) auf \\(Y\\) in einer Regression, die nicht für den Effekt von \\(U\\) kontrolliert, verzerrt geschätzt wird. Wie stark die Verzerrung ist, hängt von den Eigenschaften des DGP ab. Simulation kann hilfreich sein, um die Verzerrung eines Schätzers in Abhängigkeit der Parameter des DGP zu untersuchen.\n\n\n\n\n\n\n\n\nCONFSIM\n\n\n\nX\n\nX\n\n\n\nY\n\nY\n\n\n\nX-&gt;Y\n\n\nbeta = 2\n\n\n\nU\n\nU\n\n\n\nU-&gt;X\n\n\nbeta = 1\n\n\n\nU-&gt;Y\n\n\nbeta = -1\n\n\n\ne\n\ne\n\n\n\ne-&gt;Y\n\n\n\n\n\n\n\n\nAbbildung 5.1: DGP mit unbeobachtbarem Confounder U\n\n\n\n\n\nFür die Simulation von Stichproben gemäß Abbildung 5.1 nutzen wir den linearen Prozess\n\\[\\begin{align*}\n  X =& \\, a + \\alpha_1 U,\\\\\n  Y =& \\, \\beta_1 X + \\beta_2 U + e,\n\\end{align*}\\]\nmit \\(a \\sim \\mathcal{U}[0,1]\\), \\(U\\sim N(0, 2^2)\\) und \\(e\\sim N(0, 10)\\) und wählen die Parameter \\(\\alpha_1 = 1\\), \\(\\beta_1 = 2\\) und \\(\\beta_2 = -1\\).5 Der nächste Code-Block implementiert den DGP und zeigt die KQ-Schätzung des fehlspezifizierten Modells\n5 \\(\\mathcal{U}[a,b]\\) meint die stetige Gleichverteilung auf dem Intervall \\([a,b]\\)\\[\\begin{align*}\n  Y = \\beta_1 X + \\epsilon\n\\end{align*}\\]\nanhand einer simulierten Stichprobe mit einem Umfang von 100 Beobachtungen.\n\n\n\n\n\n\nAnalog zu Kapitel 5.1 ist diese Simulation mit nur einer Iteration wenig aussagekräftig für die Verzerrung der KQ-Schätzers. Für eine ausführlichere Analyse implementieren wir zunächst beide Schritte der Simulation (Stichprobe generieren, Modell schätzen) in einer Funktion sim_function_conf(), der wir sämtliche Parameter sowie das zu schätzende Regressionsmodell als Fomel übergeben können. Diese Funktion gibt die aus dem lm-Objekt ausgelesene KQ-Schätzung von \\(\\beta_1\\) zurück. Wir testen die Funktion sim_function_conf() durch Verwendung des selben Seeds.\n\n\n\n\n\n\nDer mit sim_function_conf() simulierte Zug aus der Stichprobenverteilung stimmt mit dem Ergebnis des vorherigen Zufallsexperiments überein. Wir können nun die Simulation durch iterative Berechnung von sim_function_conf() über die Indexmenge 1:N durchführen. Wie zuvor visualisieren wir die Simulationsergebnisse mit einem Plot der geschätzten Dichtefunktion von \\(\\widehat{\\beta}_1\\).\n\n\n\n\n\n\nDer grafische Vergleich der simulierten Stichprobenverteilung von \\(\\widehat{\\beta}_1\\) mit dem wahren Koeffizienten \\(\\beta_1 = 2\\) (gestrichelte rote Linie) zeigt, dass \\(\\widehat{\\beta}_1\\) aufgrund des ausgelassenen Confounders \\(U\\) für die hier gewählte Spezifikation des DGP tatsächlich ein verzerrter Schätzer für den kausalen Effekt \\(\\beta_1\\) ist: Die geschätzte Dichtefunktion ist ein Indikator dafür, dass die Verteilungsfunktion von \\(\\widehat{\\beta}_1\\) einen Großteil der Wahrscheinlichkeitsmasse im Wertebereich oberhalb von \\(\\beta_1 = 2\\) hat, sodass wir den kausalen Effekt im Mittel überschätzen.\nWir können die Simulationsergebnisse in sim_est nutzen, um die Verzerrung6 von \\(\\widehat\\beta_1\\) zu schätzen.\n6 Die Verzerrung (engl. bias) eines Schätzers \\(\\widehat{\\beta}_1\\) für \\(\\beta_1\\) ist \\(\\textup{bias}(\\widehat{\\beta}_1) = \\textup{E}(\\widehat{\\beta}_1 - \\beta_1)\\).\n\n\n\n\n\nDiese Berechnung anhand von Zügen aus der Stichprobenverteilung von \\(\\widehat{\\beta}_1\\) zeigt eine deutliche positive Verzerrung des KQ-Schätzers von \\(\\beta_1\\) aufgrund des Confounders \\(U\\) von etwa 0.94.\nAnhand von sim_function_conf() können wir die Identifizierbarkeit des kausalen Effekts \\(\\beta_1\\) bei Kontrolle für \\(U\\) im Modell\n\\[\\begin{align*}\n  Y = \\beta_0 + \\beta_1 X + \\beta_2 U + \\varepsilon\n\\end{align*}\\]\nüberprüfen, in dem wir die Simulation unter Angabe dieses Modells über das Argument formula durchführen.\n\n\n\n\n\n\nDie geschätzte Stichprobenverteilung von \\(\\widehat{\\beta}_1\\) bei Kontrolle für den Confounder \\(U\\) zeigt keine Anzeichen für eine Verzerrung des Schätzers für den kausalen Effekt von \\(X\\) auf \\(Y\\). Die Monte-Carlo-Schätzung der Verzerrung von \\(\\widehat{\\beta}_1\\) unterstützt das Ergebnis der grafischen Analyse.\n\n\n\n\n\n\n\n\n5.1.3 Regression: Verzerrung durch Collider\nDer Graph in Abbildung 5.2 zeigt einen DGP, bei dem die Variable \\(C\\) ein Collider auf dem Pfad \\(X\\rightarrow C \\leftarrow Y\\) ist. Für die Identifikation des Effekts von \\(X\\) auf \\(Y\\) ist \\(C\\) damit eine irrelavante Variable, für die nicht kontrolliert werden darf: Statistische Verfahren, die den Effekt von \\(X\\) auf \\(Y\\) unter Kontrolle des Effekts von \\(C\\) auf \\(Y\\) schätzen sind verzerrt, weil ein Backdoor-Pfad durch \\(C\\) besteht.\n\n\n\n\n\n\n\n\nCOLSIM\n\n\n\nX\n\nX\n\n\n\nY\n\nY\n\n\n\nX-&gt;Y\n\n\nbeta_1 = 2\n\n\n\nC\n\nC\n\n\n\nX-&gt;C\n\n\nbeta = .25\n\n\n\nY-&gt;C\n\n\nbeta = .25\n\n\n\ne\n\ne\n\n\n\ne-&gt;Y\n\n\n\n\n\n\n\n\nAbbildung 5.2: DGP mit Collider-Variable C\n\n\n\n\n\nÄhnlich wie in Kapitel 5.1.2 können wir die Konsequezen der Kontrolle für eine Collider-Variable in einem linearen Regressionsmodell anhand einer Simulationsstudie untersuchen. Wir implementieren hierzu den DGP\n\\[\\begin{align*}\n  X \\sim& \\, N(0,1),\\\\\n  Y =& \\, \\beta_1 X + e,\\\\\n  C =& \\, N(0,1) + .25X + .25Y,\n\\end{align*}\\] wobei \\(e \\sim N(0,3^2)\\) erneut ein unsystematischer Fehlterterm für \\(Y\\) ist. Wie im DGP aus Kapitel 5.1.2 wählen wir \\(\\beta_1 = 2\\) für den wahren kausalen Effekt von \\(X\\) auf \\(Y\\).\n\n\n\n\n\n\nIn der nachfolgenden Simulation iterieren wir sim_function_col() für zwei verschiedene Modelle und speichern Ergebnisse in einer tibble: Die erste Spalte von sim_est_col enthält simulierte KQ-Schätzungen von \\(\\widehat{\\beta}_1\\) in einem einfachen Regressionsmodell, dass nicht für den Collider \\(C\\) kontrolliert (formula = \"Y ~ X\"). Die zweite Spalte hingegen sammelt Schätzungen für ein multiples Modell mit Kontrolle für \\(C\\) (formula = \"Y ~ X + C\").\n\n\n\n\n\n\nFür die Auswertung der Simulationsergebnisse hinsichtlich der Konsequenzen der Kontrolle für den Collider \\(C\\) plotten wir die geschätzen Dichtefunktionen für die Stichprobenverteilung von \\(\\widehat{\\beta}_1\\) aus beiden Monte-Carlo-Experimenten gemeinsam und vergleich mit dem wahren Wert \\(\\beta_1 = 2\\).\n\n\n\n\n\n\nDie Abbildung zeigt deutlich die (negative) Verzerrung des KQ-Schätzers für den interessierenden kausalen Effekt im Modell mit Kontrolle für den Collider \\(C\\). Die Simulationsergebnisse für eine einfache Regression von \\(Y\\) auf \\(X\\) hingegen stimmen mit dem theretischen Resultat überein, dass der KQ-Schätzer für \\(\\beta_1\\) in diesem Modell erwartungstreu ist.\nDurch Zusammenfassung der Simulationsergebnisse mit dplyr::summarize() können wir den Collider-Bias im Modell mit Kontrolle für \\(C\\) schätzen und die Unverzerrtheit von \\(\\widehat{\\beta}_1\\) in der einfachen Regression von \\(Y\\) auf \\(X\\) prüfen.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "Simulation.html#regression-durchschnittlicher-behandlungseffekt",
    "href": "Simulation.html#regression-durchschnittlicher-behandlungseffekt",
    "title": "5  Simulation",
    "section": "5.2 Regression: Durchschnittlicher Behandlungseffekt",
    "text": "5.2 Regression: Durchschnittlicher Behandlungseffekt\nWir können Simulation einsetzen, um die Güte der Schätzung von Behandlungseffekten in linearen Regressionsmodellen zu untersuchen. Hierzu implementieren wir einen DGP gemäß Abbildung 5.3.\n\n\n\n\n\n\n\n\nHETEFFSIM\n\n\n\nB\n\nB\n\n\n\nY\n\nY\n\n\n\nB-&gt;Y\n\n\nβ_1 heterogen\n\n\n\nX\n\nX\n\n\n\nX-&gt;Y\n\n\nβ_2 = 2\n\n\n\ne\n\ne\n\n\n\ne-&gt;Y\n\n\n\n\n\n\n\n\nAbbildung 5.3: DGP mit heterogenen Behandlungseffekten\n\n\n\n\n\nFür die Komponenten wählen wir: \\[\\begin{align}\n  \\begin{split}\n    \\text{B} &\\sim \\text{Bernoulli}(0.5) \\\\\n    X &\\sim N(0, 2) \\\\\n    \\beta_1 &\\sim \\mathcal{U}(0, 3) \\\\\n    e &\\sim N(0, 2) \\\\\n    \\\\\n    Y &= 1 + \\beta_1 \\cdot \\text{B} + 2 \\cdot X + e\n  \\end{split}\\label{eq:dgpatesim}\n\\end{align}\\]\nIn diesem linearen DGP bestimmt \\(B\\) über die Zuteilung der Behandlung. \\(X\\) ist eine Determinante der Outcome-Variable \\(Y\\) ohne Backdoor-Pfad. Der Behandlungseffekt \\(\\beta_1\\) ist heterogen, da \\(\\beta_1\\) aus einer kontinuierlichen Gleichverteilung auf dem Intervall \\([0, 3]\\) gezogen wird. Der durchschnittliche Behandlungseffekt (ATE) entspricht hier dem Erwartungswert von \\(\\beta_1\\), was zu einem ATE von 1.5 führt, da\n\\[\\begin{align*}\n  \\textup{ATE} =&\\, \\textup{E}(\\beta_1)\\\\\n  =&\\, \\frac{1}{2}(a + b)\\\\\n  =&\\, \\frac{1}{2}(0 + 3) = 1.5.\n\\end{align*}\\]\nWir verfizieren nachfolgend mit Monte-Carlo-Simulation für Stichproben von DGP \\(\\eqref{eq:dgpatesim}\\) mit \\(n=150\\), dass\n\nder KQ-Schätzer für \\(\\beta_1\\) im Modell \\(Y=\\beta_0 + \\beta_1 B + \\epsilon\\) ein erwartungstreuer Schätzer für den ATE ist und\nkontrollieren für \\(X\\) hier die Präzision der Schätzung des ATE verbessert.\n\nIm nachfolgenden Code-Block erzeugen wir die Simulationsergebnisse in jeder Iteration durch Berechnung der interessierenen Schätzer auf derselben simulierten Stichprobe und geben die Ergebnisse als tibble() mit einer Reihe und zwei benannten Einträgen zurück. Die Funktion map_dfr() fasst die Ergebnisse nach der Iteration über 1:N als tibble() zusammen. Wir nutzen hier einen Ansatz, bei dem die Schritte für die Simulation dem Argument .f über den Syntax ~ { ... } innerhalb einer anonymen Funktion ohne Argumente.7\n7 Anonyme Funktionen in R (auch Lambda-Funktionen genannt) sind Funktionen, die ohne Namen definiert werden und in der Regel sofort angwendet werden. ~ ist eine Kurznotation für anonyme Funktionen innerhalb von purrr-Funktionen.\n\n\n\n\n\nFür die grafische Auswertung transformieren wir die Simulationsergebnisse in sim_res_ATE mit pivot_longer() in ein langes Format.\n\n\n\n\n\n\nDie grafische Analyse der Stichprobenverteilungen bestätigt, dass der KQ-Schätzer für \\(\\beta_1\\) sowohl im Modell mit Kontrolle für \\(X\\) als auch im Modell ohne \\(X\\) erwartungstreu für den ATE von 1.5 ist. Da \\(X\\) gemäß DGP \\(\\eqref{eq:dgpatesim}\\) einen größeren Teil der Variation in \\(Y\\) verursacht, verbesserte Kontrolle für \\(X\\) hier die Präzision der Schätzung des ATE mit KQ.\nDie Variabilität der Ansätze können wir durch Zusammenfassung der Spalten in sim_res_ATE mit summarize() und across() quantifizieren, wobei wir sd als zusammenfassende Statistik nutzen und .names = \"sd_{.col}\" ein entsprechendes Präfix für die Variablennamen einführt.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "Simulation.html#verletzung-von-modellannahmen-heteroskedastizität",
    "href": "Simulation.html#verletzung-von-modellannahmen-heteroskedastizität",
    "title": "5  Simulation",
    "section": "5.3 Verletzung von Modellannahmen: Heteroskedastizität",
    "text": "5.3 Verletzung von Modellannahmen: Heteroskedastizität\nUnter der Annahme von Homoskedastizität (konstante Varianz) der Fehlerterme des Modells ist die KQ-Schätzung von Behandlungseffekten anhand linearer Regression effizient, d.h. der KQ-Schätzer hat die geringste Varianz unter allen unverzerrten Schätzern des interessierenden Koeffizienten.8 Hängt die Varianz der Fehlerterme von den Regressoren ab, liegt Heteroskedastizität vor: Die Fehlerterm-Varianz unterscheided sich zwischen den Beobachtungen, in Abhängigkeit der Ausprägungen der Regressoren. Unter Heteroskedastie ist der KQ-Schätzer nicht länger der effizienteste Schätzer: In Verfahren wie der gewichteten KQ-Methode (WKQ)9 haben Beobachtungen mit geringer Fehlerterm-Varianz einen größeren Einfluss als Beobachtungen mit großer Varianz, sodass der WKQ-Schätzer präziser als der KQ-Schätzer sein kann.\n8 Die ist die Kern-Aussage des Gauss-Markov-Theorems.9 Engl. weighted least squares.Weiterhin sind bei heteroskedastischen Fehlertermen die (aus historischen Gründen) standardmäßig von summary() berechneten Standardfehler ungültig, und können die Unsicherheit von KQ unterschätzen. Dies ist problematisch, da unter Verwendung von ungültigen Standardfehlern berechnete Inferenzsstatistiken ebenfalls ungültig sind. Als Konsequenz erhöht sich die Gefahr falscher Schlussfolgerungen hinsichtlich des zu schätzenden Behandlungseffekts anhand von Test-Statistiken und Konfidenzintervallen.\nWir zeigen nachfolgend, wie die Konsequenzen von Heteroskedastizität für den KQ-Schätzer mit Simulation untersucht werden können. Hierfür betrachten wir den DGP\n\\[\\begin{align}\n  \\begin{split}\n    X \\sim&\\, \\chi^2_{50}\\\\\n    e \\sim&\\, N(0, \\sigma_e^2(X))\\\\\n    Y =&\\, \\beta_1 X + e,\n  \\end{split}\\label{eq:simhetdgp}\n\\end{align}\\]\nwobei die Fehlerterm-Varianz \\(\\sigma_e^2(X)\\) eine Funktion von \\(X\\) ist, \\[\\begin{align*}\n  \\sigma_e^2(X) = \\textup{Var}(e\\vert X) = \\lvert X-50 \\rvert^{p}.\n\\end{align*}\\] Der Parameter \\(p\\) bestimmt die funktionale Form dieser bedingten Varianz.\nDer nächste Code-Chunk plottet die Funktion \\(f(x) = \\lvert X-50 \\rvert^{p}\\) für verschiedene \\(p\\) über den Wertebereich von \\(X\\). Hierfür berechnen wir \\(f(x)\\) für ein mit expand_grid() erstelltes Raster von Werten für \\(X\\) und \\(p\\).\n\n\n\n\n\n\nFür die Simulation heteroskedastischer Daten mit \\(\\eqref{eq:simhetdgp}\\) verwenden wir \\(p = 1.5\\) und \\(\\beta_1 = 0\\) (kein Effekt). Die nachfolgende Grafik zeigt eine simulierte Stichprobe mit 150 Beobachtungen.\n\n\n\n\n\n\nIn den Simulationsdurchläufen schätzen wir jeweils \\(\\beta_1\\) im Modell \\(Y=\\beta_1X+\\epsilon\\) mit KQ, berechnen den nur bei Homoskedastie gültigen Standardfehler und eine bei Heteroskedastie robuste Schätzung. Für lezteres verwenden wir sandwich::vcovHC() und mit type = \"HC1\".10 Wir fassen diese Schritte in der Funktion sim_function_het() zusammen.\n10 Der Typ HC1, auch bekannt als Huber-White-Schätzer, ist ein häufig genutzter Standardfehler und wird in späteren Kapiteln dieses Companions häufig angewendet.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie quantitative Auswertung der Ergebnisse deuten darauf hin, dass der nur bei Homoskedastie gültige Standardfehler die Standardabweichung von \\(\\widehat{\\beta}_1\\) deutlich unterschätzt. Der anhand der Simulationsergebnisse geschätzte Erwartungswert des robusten Standardfehlers hingegen liegt nahe bei der Standardabweichung der simulierten Stichprobenverteilung von \\(\\widehat{\\beta}_1\\). Die Tendenz des nur bei Homoskedastie gültigen Standardfehlers, kleinere Schätzungen der Unsicherheit von \\(\\widehat{\\beta}_1\\) zu liefern, können wir anhand der geschätzten Dichtefunktionen für se und se_rob grafisch zeigen.\n\n\n\n\n\n\nAls Konsequenz falscher Standardfehler kann die nominale \\(\\alpha\\)-Fehlerrate von Signifikanztests verletzt sein: Der Hypothesentest lehnt dann eine korrekte Nullhypothese mit einer geringeren oder höheren Fehlerwahrscheinlichkeit (das nominale Signifikanzniveau \\(\\alpha\\)) als gewünscht ab.\nInwiefern die in der Simulation gewählte Form von Heteroskedastizität die \\(\\alpha\\)-Fehlerrate eines t-Tests beeinflusst, können wir anhand der Simulationsergebnisse schätzen: Wir berechnen die Ablehnrate für t-Tests der (wahren) Null-Hypothese \\(H_0:\\beta_1=0\\) zum 5%-Niveau jeweils für robuste und nicht-robuste Standardfehler und vergleichen. Wir vergleichen die so berechneten Test-Statistiken mit dem entsprechenden kritischen Wert der t-Verteilung mit \\(n-1\\) Freiheitsgraden.\n\n\n\n\n\n\nDie Simulationsergebnisse deuten darauf hin, dass ein Fehler erster Art für den Signifikanztest ohne korrigierte Standardfehler oberhalb des 5%-Niveaus liegt. Für die robuste Teststatistik hingegen liegt die Schätzung des \\(\\alpha\\)-Fehlers nahe 5%.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "Simulation.html#der-bootstrap",
    "href": "Simulation.html#der-bootstrap",
    "title": "5  Simulation",
    "section": "5.4 Der Bootstrap",
    "text": "5.4 Der Bootstrap\nIn den zuvor diskutierten Simulationsstudien haben wir iterativ Stichproben basierend auf einem bekannten DGP generiert, um die Eigenschaften der Stichprobenverteilung eines Schätzers (für bestimmte Parameterwerte) zu untersuchen. Der Bootstrap (Efron 1979) ist eine Methode zur Approximation der unbekannten Stichprobenverteilung eines Schätzers, bei der zufällige Stichproben mit Zurücklegen aus einer beobachteten Stichprobe gezogen werden.11 Bootstrapping approximiert die Verteilung eines Schätzers aus beobachteten Datenpunkten und ohne Kenntnis des wahren DGP. Der Bootstrap ist daher eine Simulationsmethode, die in empirischen Anwendungen für die Bestimmung der Unsicherheit (Standardfehler) eines Schätzers genutzt werden kann. Bootstrapping ist hilfreich für Hypothesentests, wenn die beobachtete Stichprobe klein oder untypisch ist, was dazu führen kann, dass Standard-Inferenz für Behandlungseffekte nicht zuverlässig anwendbar oder ungültig ist. Insbesondere wenn Modellannahmen verletzt sind wird bootstrapping häufig in empirischen Studien eingesetzt, um Konfidenzintervalle, Standardfehler oder p-Werte zu berechnen.\n11 Diese Vorgehensweise wird auch als resampling bezeichnet.Die nachfolgenden Key Facts fassen die wesentlichen Eigenschaften des Bootstraps und die grundsätzliche Vorgehensweise zusammen.\n\n\n\n\n\n\nKey Facts zum Bootstrap\n\n\n\nDer Bootstrap ist eine statistische Methode, die durch wiederholtes Ziehen von Stichproben mit Zurücklegen aus einer beobachteten Stichprobe die Stichprobenverteilung eines Schätzers approximieren kann. Bootstrapping ermöglicht die Berechnung gültiger Inferenzstatistiken, ohne starke Annahmen über den zugrundeliegenden unbekannten DGP zu treffen.\nVorgehensweise\n\nStichproben mit Zurücklegen ziehen: Ziehe wiederholt (\\(B\\) mal) Stichproben der Größe \\(N\\) (Größe der ursprünglichen Stichprobe) mit Zurücklegen aus der originalen Stichprobe.\nParameterschätzung für jede Bootstrap-Stichprobe: Wende die Schätzfunktion \\(\\widehat{\\beta}\\) auf jede der \\(B\\) Bootstrap-Stichproben an und erhalte \\(B\\) Bootstrap-Schätzwerte \\(\\widehat{\\beta}^1,\\dots,\\widehat{\\beta}^B\\) des interessierenden Koeffizienten \\(\\beta\\).12\nVerteilungsparameter Schätzen: Anhand der \\(B\\) Bootstrap-Schätzungen aus Schritt 2 können die Eigenschaften der Verteilung des Schätzers \\(\\widehat{\\beta}\\) (oder für Funktionen von \\(\\widehat{\\beta}\\)) geschätzt werden:\n\nDas arithmetische Mittel der \\(B\\) Bootstrap-Schätzungen ist ein konsistenter Schätzer des Erwartungswerts von \\(\\widehat{\\beta}\\)\nDer Standardfehler des Schätzers \\(\\widehat{\\beta}\\) kann durch die Standardabweichung der \\(B\\) Bootstrap-Schätzungen approximiert werden\nEin \\(1-\\alpha\\%\\)-Bootstrap-Konfidenzintervall für \\(\\beta_1\\) kann anhand des \\(\\alpha/2\\%\\)- und des \\(1-\\alpha/2\\%\\)-Perzentils der Bootstrap-Verteilung approximiert werden\n\n\n\nBootstrapping wird häufig genutzt, um die Unsicherheit eines Schätzers zu ermitteln. Dies ist insbesondere dann hilfreich, wenn keine analytische Darstellung für die Verteilung eines Schätzers existiert oder “starke” Verteilungsannahmen (z.B. Normalverteilung) unplausibel sind.\nEin Bootstrap-Schätzer für einen unbekannten Parameter13 ist im Allgemeinen nicht erwartungstreu für den interessierenden Effekt, selbst wenn ein erwartungstreuer Schätzer verwendet wird. Bootstrap-Schätzer sind jedoch in vielen Fällen unter schwachen Annahmen konsistent für den wahren Parameter.\n\n\n\n13 Das arithmetische Mittel von \\(B\\) Bootstrap-Schätzwerten ist ein einfacher Bootstrap-Schätzer.12 Häufig wird für \\(B\\) eine ungerade Anzahl (z.B. 199) gewählt. Dies ermöglicht ein genaue Bestimmung des Medians der Bootstrap-Verteilung, was die Berechnung von Konfidenzintervallen erleichtert.Der nächste Abschnitt diskutiert Bootstrapping der Stichprobenverteilung von \\(\\overline{X}\\) anhand des Beispiels aus Kapitel 5.1.\n\n5.4.1 Interaktive Visualisierung des Bootstraps\nDie nachfolgende interaktive Visualisierung illustriert die Vorgehensweise des oben beschriebenen Bootstrap-Algorithmus für die Schätzung eines \\(95\\%\\)-Konfidenzintervalls für den Erwartungswert einer normalen Verteilung basierend auf einer Stichprobe, wenn das arithmetische Mittel als Schätzer verwendet wird. Diese Pupulationsverteilung ist \\(N(\\mu = 50, \\sigma^2 = 12^2)\\). In jeder Iteration des Bootstraps wird eine Bootstrap-Stichprobe mit Zurücklegen aus der originalen Stichprobe gezogen. Für jede Bootstrap-Stichprobe berechnen wir das Arithmetische Mittel (grüne Punkte). Für hinreichend viele Bootstrap-Schätzungen erhalten wir eine repräsentative Bootstrap-Verteilung unseres Schätzers.14 Basierend auf dieser Verteilung berechnen wir eine Bootstrap-Schätzung des Erwartungswerts \\(\\mu\\) (schwarzer Punkt) und ein \\(95\\%\\)-Konfidenzintervall (schwarze Linie).\n14 Die Grüne Linie zeigt eine Kerndichte-Schätzung der Bootstrap-Verteilung. Die Bandweite dieser Schätzung kann in der Applikation variiert werden.In der interaktiven Grafik können wir insbesondere folgende Eigenschaften des Bootstrap-Verfahrens überprüfen:\n\nDie Populationsverteilung ist normal. Daher ist auch die Stichproben-Verteilung des arithmetischen Mittels \\(\\overline{X}\\) für jede Stichprobengröße normal. Die Illustration zeigt, dass die Bootstrap-Verteilung diese Normalverteilung des Schätzers (die typische Glockenform) tatsächlich gut approximieren kann, wenn \\(B\\) hinreichend groß gewählt wird.\nDer Bootstrap-Schätzer von \\(\\mu\\) ist nicht erwartungstreu für \\(\\mu\\), da wir mit Zurückziehen aus einer Stichprobe ziehen und so die zentrale Tendenz in den beobachteten Daten reproduzieren. Diese Verzerrung verringert sich mit der Größe der originalen Stichprobe.\nGrößere Stichproben verringern die Unsicherheit des interessierenden Schätzers \\(\\overline{X}\\): Die Varianz der Stichprobenverteilung von \\(\\overline{X}\\) nimmt mit der Stichprobengröße ab. Da der Bootstrap die Verteilung von \\(\\overline{X}\\) approximiert, spiegelt sich diese Eigenschaft auch in der Bootstrap-Verteilung.\n\n\n\n\n\n5.4.2 Bootstrap mit R durchführen\nMit dem R-Paket boot kann Bootstrapping komfortabel für eine selbst definierte Schätzfunktion durchgeführt werden. Diese Funktion (boot_fun im nachfolgenden Code-Beispiel) muss den Schätzer unter Angabe einer Indexmenge für die beobachteten Daten berechnen und zurückgeben.15\n15 boot::boot() zieht in jeder Bootstrap-Iteration mit Zurücklegen aus der Indexmenge der originalen Stichprobe, um die Bootstrap-Stichprobe festzulegen.Der nächste Code-Chunk zeigt, wie boot::boot() angewendet werden kann, um den Bootstrap von Efron (1979) für \\(\\overline{X}\\) anhand einer Stichprobe mit \\(n=250\\) aus der in Kapitel 5.1 betrachteten \\(N(\\mu = 50, \\sigma^2 = 12^2)\\)-Populationsverteilung für \\(B=999\\) Iterationen zu berechnen.\n\n\n\n\n\n\nDer Output in boot_est beinhaltet die Schätzung von \\(\\mu\\) mit \\(\\overline{X}\\) anhand der originalen Stichprobe (original), eine Schätzung der Verzerrung von \\(\\overline{X}\\) (bias) sowie den Bootstrap-Standardfehler (std. error). Wir können die Berechnung dieser Maße mit der originalen Stichprobe sowie den Bootstrap-Berechnungen von \\(\\overline{X}\\) (boot_est$t) nachvollziehen.\n\n\n\n\n\n\nDie Bootstrap-Verteilung von \\(\\overline{X}\\) ist recht gut mit der tatsächlichen \\(N(\\mu=50,\\sigma^2 = 12^2/250)\\)-Stichprobenverteilung vergleichbar.\n\n\n\n\n\n\nMit boot::boot.ci() erhalten wir ein symmetrisches 95%-Bootstrap-Konfidenzintervall für \\(\\mu\\), \\[\\begin{align}\n  95\\%\\textup{-KI}_\\textup{boot} = \\big[2\\cdot \\overline{X}_o - q_{.975,\\,\\textup{boot}}, \\ 2\\cdot \\overline{X}_o - q_{.025,\\,\\textup{boot}}\\big].\\label{eq:95bootci}\n\\end{align}\\]\n\n\n\n\n\n\nFür die Berechnung per Hand mit der Formel \\(\\eqref{eq:95bootci}\\) bestimmen wir die Quantile der Bootstrap-Verteilung mit der Funktion quantile().\n\n\n\n\n\n\nAnhand dieses Konfidenzintervalls können wir Hypothesen zum 5%-Niveau testen.\n\n\n\n\n\n\nWir können die (wahre) Nullhypothese \\(H_0: \\mu = 50\\) also zum 5%-Niveau nicht ablehnen.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "Simulation.html#footnotes",
    "href": "Simulation.html#footnotes",
    "title": "5  Simulation",
    "section": "",
    "text": "Englische Abkürzung für data generating process.↩︎\nD.h. hier ist \\(\\overline{X}\\sim N(50, 2.88)\\).↩︎\nIteration mit Funktionen aus dem Paket purrr (siehe tab) ist eine Alternative zum “klassischen” Ansatz mit einer for()-Schleife.↩︎\nIst \\(X\\) log-normal-verteilt mit Erwartungswert \\(\\mu_X\\) und Varianz \\(\\sigma_X^2\\), dann ist \\(\\log X\\) normal-verteilt mit \\(\\mu_{\\log X} = \\log \\mu_X - \\sigma_X^2/2\\) und \\(\\sigma^2_{\\log X} = \\mu_X^2 [\\exp(\\sigma_X^2)-1]\\).↩︎\n\\(\\mathcal{U}[a,b]\\) meint die stetige Gleichverteilung auf dem Intervall \\([a,b]\\)↩︎\nDie Verzerrung (engl. bias) eines Schätzers \\(\\widehat{\\beta}_1\\) für \\(\\beta_1\\) ist \\(\\textup{bias}(\\widehat{\\beta}_1) = \\textup{E}(\\widehat{\\beta}_1 - \\beta_1)\\).↩︎\nAnonyme Funktionen in R (auch Lambda-Funktionen genannt) sind Funktionen, die ohne Namen definiert werden und in der Regel sofort angwendet werden. ~ ist eine Kurznotation für anonyme Funktionen innerhalb von purrr-Funktionen.↩︎\nDie ist die Kern-Aussage des Gauss-Markov-Theorems.↩︎\nEngl. weighted least squares.↩︎\nDer Typ HC1, auch bekannt als Huber-White-Schätzer, ist ein häufig genutzter Standardfehler und wird in späteren Kapiteln dieses Companions häufig angewendet.↩︎\nDiese Vorgehensweise wird auch als resampling bezeichnet.↩︎\nHäufig wird für \\(B\\) eine ungerade Anzahl (z.B. 199) gewählt. Dies ermöglicht ein genaue Bestimmung des Medians der Bootstrap-Verteilung, was die Berechnung von Konfidenzintervallen erleichtert.↩︎\nDas arithmetische Mittel von \\(B\\) Bootstrap-Schätzwerten ist ein einfacher Bootstrap-Schätzer.↩︎\nDie Grüne Linie zeigt eine Kerndichte-Schätzung der Bootstrap-Verteilung. Die Bandweite dieser Schätzung kann in der Applikation variiert werden.↩︎\nboot::boot() zieht in jeder Bootstrap-Iteration mit Zurücklegen aus der Indexmenge der originalen Stichprobe, um die Bootstrap-Stichprobe festzulegen.↩︎",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "Matching.html",
    "href": "Matching.html",
    "title": "\n6  Matching\n",
    "section": "",
    "text": "6.1 Balance: Vergleichbarkeit von Behandlungs- und Kontrollgruppe\nDer Lehrstuhl für Ökonometrie an der Universität Duisburg-Essen betreibt einen Ökonometrie-Blog und interessiert sich für den kausalen Effekt der Einführung eines darkmode auf die Verweildauer der User auf der Webseite. Die Webseite ist zwar nicht-kommerziell, hat sich allerdings insb. für die Aquise internationaler Studierender für den Studiengang MSc. Econometrics als wichtiges Marketing-Instrument erwiesen. Ein anprechendes Design wird daher als hoch-relevant erachtet.\nIdealerweise sollte der Effekt des Design-Relaunches auf die Nutzungsintensität in einem kontrollierten randomisierten Experiment untersucht werden. Hierbei würden wir Nutzern zufällig das neue oder das alte Design zuweisen und den Effekt als Differnz des durchschnittlichen Verweildauer für die Gruppen bestimmen. Eine solche Studie ist jedoch aus technischen und finanziellen Gründen nicht realisierbar, sodass die Auswirkungen des darkmode mit vorliegenden nicht-experimenellen Nutzungsstatistiken für die Webseite geschätzt werden sollen.\nDie Nutzungsstatistiken sind im Datensatz darkmode.csv enthalten und sollen der Analyse des Effekts des darkmode (dark_mode) auf die Verweildauer der Leser auf der Webseite (read_time) dienen.\nTabelle 6.1 zeigt die Definitionen der Variablen in darkmode.csv.\nVariable\nBeschreibung\n\n\n\nread_time\nLesezeit (Minuten/Woche)\n\n\ndark_mode\nIndikator: Beobachtung nach Einführung darkmode\n\n\nmale\nIndikator: Individuum männlich\n\n\nage\nAlter (in Jahren)\n\n\nhours\nBisherige Verweildauer auf der Seite\n\n\n\n\n\n\n\nTabelle 6.1: Variablen im Datensatz darkmode\nFür die Analyse lesen wir zunächst den Datensatz darkmode.csv mit readr::read_csv() ein und verschaffen uns einen Überblick über die verfügbaren Variablen.\n# Paket `tidyverse` laden\nlibrary(tidyverse)\n\n# Datensatz 'darkmode' einlesen\ndarkmode &lt;- read_csv(\n  file = \"datasets/darkmode.csv\"\n)\ndark_mode hat den Typ logical. Mit dplyr::mutate_all() können wir komfortabel alle Spalten in den Typ numeric transformieren.\n# Alle Variablen zu typ 'numeric' formatieren...\ndarkmode &lt;- darkmode %&gt;% \n  mutate_all(.funs = as.numeric)\n\n# ... und überprüfen\nglimpse(darkmode)\n\nRows: 300\nColumns: 5\n$ read_time &lt;dbl&gt; 14.4, 15.4, 20.9, 20.0, 21.5, 19.5, 22.0, 17.4, 23.6, 15.7, …\n$ dark_mode &lt;dbl&gt; 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, …\n$ male      &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, …\n$ age       &lt;dbl&gt; 43, 55, 23, 41, 29, 64, 18, 53, 59, 53, 43, 38, 42, 23, 39, …\n$ hours     &lt;dbl&gt; 65.6, 125.4, 642.6, 129.1, 190.2, 185.3, 333.5, 279.3, 1302.…\nEine naive Schätzung des durchschnittlichen Behandlungseffekts (ATE) \\(\\widehat{\\tau}^{\\text{naiv}}\\) erhalten wir als Mittelwertdifferenz von read_time für die Behandlungsgruppe (dark_mode == 1) und die Kontrollgruppe (dark_mode == 0) \\[\\begin{align}\n  \\widehat{\\tau}^{\\text{naiv}} = \\overline{\\text{read\\_time}}_{\\text{Behandlung}} - \\overline{\\text{read\\_time}}_{\\text{Kontrolle}}.\\label{eq:naivATEdarkmode}\n\\end{align}\\]\nDiese Berechnung ist schnell mit R durchgeführt.\n# Naiver Schätzer für ATE: \n# Differenz der Gruppen-Durchschnitte\n\n# Outcome in Behandlungsgruppe\nread_time_mTG &lt;- darkmode %&gt;% \n  filter(dark_mode == 1) %&gt;% \n  pull(\"read_time\")\n\n# Outcome in Kontrollgruppe\nread_time_mKG &lt;- darkmode %&gt;% \n  filter(dark_mode == 0) %&gt;% \n  pull(\"read_time\")\n\n# Mittelwert-Differenz\nmean(read_time_mTG) - mean(read_time_mKG)\n\n[1] -0.4446331\nDie Schätzung ergibt einen negativen Behandlungseffekt, mit der Interpreation, dass das neue Design zu einer Reduktion der Lesezeit um etwa 0.44 Minuten pro Woche führt. Dieses Ergebnis ist allerdings zweifelhaft, weil eine Isolierung des Behandlungseffekts aufgrund von Backdoor-Pfaden im DGP vermutlich nicht gewähleistet ist. Ein Indikator hierfür sind systematische Unterschiede hinsichtlich von (möglicherweise unbeobachtbaren) Charakteristika von Kontrollgruppe und Behandlungsgruppe.\nDa die User sich beim Aufrufen der Seite aktiv für oder gegen den das neue Design entscheiden müssen (und somit selektieren, ob Sie in der Behandlungs- oder Kontrollgruppe landen), liegt wahrscheinlich Confounding vor: Unsere Hypothese ist zunächst, dass männliche User eine durchschnittlich längere Lesezeit aufweisen und mit größerer Wahrscheinlichkeit auf das neue Design wechseln als nicht-männliche Leser. Dann ist male eine Backdoor-Variable. Diese Situation ist unter der Annahme, dass nur diese Faktoren den DGP bestimmen, in Abbildung 6.1 dargestellt.\nread_time\nread_timedark_mode\ndark_modedark_mode-&gt;read_time\nmale\nmalemale-&gt;read_time\nmale-&gt;dark_mode\n\n\n\n\nAbbildung 6.1: Backdoor durch ‘male’ im Website-Design-Bespiel\nDer DGP in Abbildung 6.1 führt zu einer verzerrten Schätzung des kausalen Effekts von dark_mode auf read_time mit \\(\\eqref{eq:naivATEdarkmode}\\), wenn das Verhältnis von männlichen und nicht-männlichen Usern in Bahandlungs- und Kontrollgruppe nicht ausgeglichen ist. Wir überprüfen dies mit R.\n# Anteile männlicher und nicht-männlicher User\n(\n  anteile &lt;- darkmode %&gt;% \n  group_by(dark_mode) %&gt;% \n  summarise(\n    gesamt = n(),\n    ant_m = mean(male),\n    ant_nm = 1 - ant_m,\n    anz_m = sum(male),\n    anz_nm = gesamt - anz_m\n    )\n)\n\n# A tibble: 2 × 6\n  dark_mode gesamt ant_m ant_nm anz_m anz_nm\n      &lt;dbl&gt;  &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1         0    151 0.338  0.662    51    100\n2         1    149 0.658  0.342    98     51\nDie Zusammenfassung anteile_m zeigt, dass der Anteil männlicher User in der Behandlungsgruppe deutlich höher ist als in der Kontrollgruppe.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Matching</span>"
    ]
  },
  {
    "objectID": "Matching.html#sec-balance",
    "href": "Matching.html#sec-balance",
    "title": "\n6  Matching\n",
    "section": "",
    "text": "6.1.1 Matching durch Gewichtung\nMatching eliminiert die Variation von male zwischen den Gruppen. Eine Möglichkeit hierfür ist die Gewichtung der Beobachtungen in der Kontrollgruppe entsprechend der Anteile von Männern und Nicht-Männern in der Behandlungsgruppe, sodass die Vergleichbarkeit mit der Behandlungsgruppe hinsichtlich des Geschlechts gewährleistet ist. Dies wird in der Literatur als Balance bezeichnet. Der Behandlungseffekt wird dann analog zu \\(\\eqref{eq:naivATEdarkmode}\\) geschätzt.\nDie Gewichte für Beobachtungen in der Kontrollgruppe \\(w_i\\) werden berechnet als \\[\\begin{align}\n  w_i =\n  \\begin{cases}\n    \\text{ant\\_m}_B/\\text{anz\\_m}_{K}, & \\text{falls } \\text{male}_i = 1\\\\\n        \\text{ant\\_nm}_B/\\text{anz\\_nm}_{K}, & \\text{sonst.}\\\\\n  \\end{cases}\\label{eq:darkmodeweights}\n\\end{align}\\] Anhand der Formel für einen gewichteten Durchschnitt, \\[\\begin{align}\n  \\overline{X}_w = \\frac{\\sum_i w_i \\cdot X_i}{\\sum_i w_i},\n\\end{align}\\] berechnen wir die gewichteten Mittelwerte für male und read_time in der Kontrollgruppe.\n\n# Anteile und Anzahlen aus `anteile` auslesen\nanz_m_K &lt;- anteile %&gt;% \n  filter(dark_mode == 0) %&gt;% pull(anz_m)\n\nanz_nm_K &lt;- anteile %&gt;% \n  filter(dark_mode == 0) %&gt;% pull(anz_nm)\n\nant_m_B &lt;- anteile %&gt;% \n  filter(dark_mode == 1) %&gt;% pull(ant_m)\n\nant_nm_B &lt;- anteile %&gt;% \n  filter(dark_mode == 1) %&gt;% pull(ant_nm)\n\n\n# Gewichtete Mittel für Kontrollgruppe berechnen\n(\ngew_K &lt;- darkmode %&gt;% \n  filter(dark_mode == 0) %&gt;% \n  select(read_time, male) %&gt;%\n  mutate(w = ifelse(\n    male == 1, \n    ant_m_B/anz_m_K, \n    ant_nm_B/anz_nm_K)\n    ) %&gt;%\n  summarise(\n    male_k = sum(male * w) / sum(w),\n    mean_read_time_wK = sum(read_time * w) / sum(w)\n  )\n)\n\n# A tibble: 1 × 2\n  male_k mean_read_time_wK\n   &lt;dbl&gt;             &lt;dbl&gt;\n1  0.658              18.1\n\n\nEin Vergleich des gewichteten Mittelwertes von male in der Kontrollgruppe mit dem Mittelwert in der Behandlungsgruppe (male_k) zeigt, dass die Gewichte die Variation in male zwischen beiden Gruppen eliminieren, sodass die Backdoor durch male geschlossen ist. Mit wmean_read_time_K haben wir einen entsprechend gewichteten Mittelwert der Verweildauer für die Kontrollgruppe berechnet. Wir schätzen den Behandlungseffekt nun als \\[\\begin{align}\n  \\widehat{\\tau}^{\\text{w}} = \\overline{\\text{read\\_time}}_{B} - \\overline{\\text{read\\_time}}_{w,K}.\\label{eq:weightedATEdarkmode}\n\\end{align}\\]\n\nmean(read_time_mTG)  - gew_K$mean_read_time_wK\n\n[1] 0.6383579\n\n\nEntgegen der naiven Schätzung andhand von \\(\\eqref{eq:naivATEdarkmode}\\) erhalten wir nach Matching für male eine positive Schätzung des Behandlungseffekts von etwa \\(0.64\\).\nDie Schätzung des Behandlungseffekts anhand von \\(\\eqref{eq:weightedATEdarkmode}\\) entspricht dem geschätzten Koeffizienten \\(\\widehat{\\beta}_1\\) aus einer gewichteten KQ-Regression im Modell \\[\\begin{align*}\n  \\text{read\\_time} = \\beta_0 + \\beta_1 \\text{dark\\_mode} + u,\n\\end{align*}\\] wobei die Beobachtungen der Kontrollgruppe wie in \\(\\eqref{eq:darkmodeweights}\\) gewichtet werden und \\(w_i=1\\) für Beobachtungen der Behandlungsgruppe ist. Wir überprüfen dies mit R.\n\ndarkmode_w &lt;- darkmode %&gt;% \n  mutate(\n    w = case_when(\n      male == 1 & dark_mode == 0 ~ ant_m_B/anz_m_K,\n      male == 0 & dark_mode == 0 ~ ant_nm_B/anz_nm_K,\n      T ~ 1\n    )\n  ) \n\nlm(read_time ~ dark_mode, weights = w, data = darkmode_w) %&gt;%\n  summary()\n\n\nCall:\nlm(formula = read_time ~ dark_mode, data = darkmode_w, weights = w)\n\nWeighted Residuals:\n     Min       1Q   Median       3Q      Max \n-11.4302  -0.6929   0.0814   0.7230  12.8698 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  18.0918     3.4796   5.199 3.72e-07 ***\ndark_mode     0.6384     3.4912   0.183    0.855    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.48 on 298 degrees of freedom\nMultiple R-squared:  0.0001122, Adjusted R-squared:  -0.003243 \nF-statistic: 0.03343 on 1 and 298 DF,  p-value: 0.855\n\n\nDer geschätzte Koeffizient von dark_mode entspricht \\(\\widehat{\\tau}^w\\).\nDa male eine binäre Variable ist, reduziert sich eine Beurteilung der Vergleichbarkeit der Verteilungen von male in Behandlungs- und Kontrollgruppe auf einen simplen Vergleich des Männeranteils beider Gruppen. In der Praxis gibt es meist eine Vielzahl potentieller Backdoor-Variablen, die zudem kontinuierlich verteilt sind. Es scheint plausibel, dass das Alter der Nutzer sowohl die Akzeptanz des Design-Updates als auch die Lesezeit beeinflusst. Die bisherige Verweildauer ist mindestens eine plausible Determinante der Lesezeit.\nDer erweiterte DGP ist in Abbildung Abbildung 6.2 dargestellt, wobei der zusätzliche Backdoor-Pfad durch age ebenfalls mit roten Pfeilen gekennzeichnet sind.\n\n\n\n\n\nread_time\nread_timedark_mode\ndark_modedark_mode-&gt;read_time\nmale\nmalemale-&gt;read_time\nmale-&gt;dark_mode\nage\nageage-&gt;read_time\nage-&gt;dark_mode\nhours\nhourshours-&gt;read_time\n\n\n\n\nAbbildung 6.2: Erweiterter DGP im Website-Design-Beispiel\n\n\n\n\nDie Beurteilung der Balance von Kontrollgruppe und Behandlungsgruppe kann durch eine grafische Gegenüberstellung der empirischen Verteilungen der Kovariablen beider Gruppen erfolgen. Wir visualisieren die empirischen Verteilungen mit ggplot2. Hierzu standardisieren wir age und hours zunächst mit scale().\n\n# Datensatz für graphische Darstellung formatieren\ndarkmode_p &lt;- darkmode %&gt;% \n  # Standardisierung mit 'scale()'\n  mutate(\n    dark_mode = as_factor(dark_mode),\n    age = scale(age), \n    hours = scale(hours)\n  )\n\nhead(darkmode_p)\n\n# A tibble: 6 × 5\n  read_time dark_mode  male age[,1] hours[,1]\n      &lt;dbl&gt; &lt;fct&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n1      14.4 0             0  0.0377    -0.591\n2      15.4 0             1  1.11      -0.459\n3      20.9 1             0 -1.74       0.684\n4      20   0             0 -0.141     -0.451\n5      21.5 1             0 -1.21      -0.316\n6      19.5 0             0  1.91      -0.327\n\n\nFür age und hours eignen sich die geschätzten Dichtefunktionen für einen Vergleich der Verteilungen in Behandlungs- und Kontrollgruppe.\n\n# Vergleich mit Dichteschätzungen\ndarkmode_p %&gt;%\n  select(dark_mode, hours, age) %&gt;%\n  # in langes Format überführen\n  pivot_longer(cols = c(-dark_mode)) %&gt;%\n  \n  ggplot(\n    aes(x = value, fill = dark_mode)\n    ) +\n  geom_density(alpha = .5) + \n  facet_wrap(\n    facets = ~ name, \n    scales = \"free\", \n    nrow = 2\n    )\n\n\n\n\n\n\n\nDie graphische Analyse zeigt deutliche Unterschiede in den Verteilungen von age zwischen Kontroll- und Behandlungsgruppe. Für einen Beurteilung mit deskriptiven Statistiken wird häufig eine sogenannte Balance Table herangezogen. Wir berechnen diese für age, hours und male mit cobalt::bal.tab()\n\nlibrary(cobalt)\n\n# Balance table mit 'cobalt::bal.tab()'\nbal.tab(\n  x = darkmode %&gt;% \n    select(age, hours, male), \n  treat = darkmode$dark_mode, \n   # berechne SMD für KG und TG:\n  disp = \"m\", \n  s.d.denom = \"pooled\"\n)\n\nBalance Measures\n         Type   M.0.Un   M.1.Un Diff.Un\nage   Contin.  46.0132  39.0940 -0.6469\nhours Contin. 337.7775 328.5738 -0.0203\nmale   Binary   0.3377   0.6577  0.3200\n\nSample sizes\n    Control Treated\nAll     151     149\n\n\nDie Einträge M.0.Un und M.1.Un zeigen die jeweiligen Stichprobenmittelwerte der Variablen für Kontroll- und Behandlungsgruppe. Diff.Un gibt eine standardisierte Mittelwertdifferenz \\(SMD\\) an, wobei \\[\\begin{align*}\n  SMD_j := \\left(\\overline{X}_{j,B} - \\overline{X}_{j,K}\\right) \\bigg/ \\sqrt{\\frac{1}{2}\\left(\\widehat{\\text{Var}}(X_{j,B}) + \\widehat{\\text{Var}}(X_{j,K})\\right)},\n\\end{align*}\\] mit Stichprobenmitteln \\(\\overline{X}_{j,B}\\) und \\(\\overline{X}_{j,K}\\) und Stichprobenvarianzen \\(\\widehat{\\text{Var}}(X_{j,B})\\) und \\(\\widehat{\\text{Var}}(X_{j,K})\\) für eine kontinuierliche Kovariable \\(j\\).1 Obwohl es keinen einheitlichen Schwellenwert für die standardisierte Differenz gibt, der ein erhebliches Ungleichgewicht anzeigt, gilt für kontinuierliche Variablen eine standardisierte (absolute) Differenz von weniger als \\(0.1\\) als Hinweis auf einen vernachlässigbaren Unterschied zwischen den Gruppen.\n1 Siehe P. Austin (2011) für einen Überblick zu Balance-Statistiken.Die Balance Table weist also auf einen vernachlässigbaren Unterschied für hours hin und bestätigt den aus den Grafiken abgeleiteten Eindruck einer relevanten Differenzen für age.\n\n6.1.2 Entropy Balancing\nEntropy Balancing (Hainmueller 2012) ist eine weitere Methode zur Gewährleistung der Vergleichbarkeit von Behandlungs- und Kontrollgruppe anhand von Gewichten. Das Verfahren nutzt Konzepte aus der Informationstheorie um die Gewichte für Subjekte in der Kontrollgruppe so anzupassen, dass die Verteilung der Matchingvariablen in der Kontrollgruppe die Verteilung in der Behandlungsgruppe möglichst gut approximiert. Dies geschieht unter der Restriktion, dass bestimmte empirische Momente (meist Mittelwerte und Varianzen) der Matchingvariablen exakt übereinstimmen. Mathematisch werden die Gewichte für Kontrollgruppenbeobachtungen durch Minimierung der Kullback-Leibler-Divergenz zwischen den Verteilungen gefunden, wobei die Divergenz ein Maß für den Unterschied von Wahrscheinlichkeitsverteilungen ist.\nEntropy Balancing ist im R-Paket WeightIt implementiert. Wir zeigen, wie die benötigten Gewichte für eine Schätzungen des ATT im Website-Beispiel mit WeightIt::wightit() bestimmt werden können. Über das Argument moments legen wir fest, dass die Gewichte unter der Restriktion übereinstimmender Mittelwerte aller Matching-Variablen zwischen Behandlungs- und Kontrollgruppe erfolgen soll.\n\nlibrary(WeightIt)\n\n# Gewichte für Entropy Balancing\n(\n  W1 &lt;- weightit(\n  dark_mode ~ age + male + hours,\n  data = darkmode,\n  method = \"ebal\", \n  estimand = \"ATT\",\n  moments = 1\n  )\n )\n\nA weightit object\n - method: \"ebal\" (entropy balancing)\n - number of obs.: 300\n - sampling weights: none\n - treatment: 2-category\n - estimand: ATT (focal: 1)\n - covariates: age, male, hours\n\n\nWir schätzen den Behandlungseffekt nach Entropy Balancing mit gewichteter Regression.\n\n# Mittelwert-Vergleich mit lm()\nfit &lt;- lm(\n  formula = read_time ~ dark_mode, \n  data = darkmode, \n  weights = W1$weights\n)\nsummary(fit)\n\n\nCall:\nlm(formula = read_time ~ dark_mode, data = darkmode, weights = W1$weights)\n\nWeighted Residuals:\n     Min       1Q   Median       3Q      Max \n-16.6652  -2.3552   0.8786   2.9585  27.1808 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  17.7601     0.4093  43.395   &lt;2e-16 ***\ndark_mode     0.9701     0.5807   1.671   0.0959 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.029 on 298 degrees of freedom\nMultiple R-squared:  0.009278,  Adjusted R-squared:  0.005953 \nF-statistic: 2.791 on 1 and 298 DF,  p-value: 0.09586\n\n\nBeachte, dass die von summary() berechneten Standardfehler bei Entropy Balancing ungültig sind. In Abschnitt Kapitel 6.4 erläutern wir die Berechnung von Standardfehlern für Matching-Schätzer mit dem Bootstrap.\n\n6.1.3 Mehrere Matching-Variablen und der Propensity Score\nBei mehreren Backdoor-Variablen kann eine Gewichtung anhand der Behandlungswahrscheinlichkeit (Treatment Propensity) erfolgen. Die Idee hierbei ist, dass der DGP wie in Abbildung 6.3 dargestellt werden kann.\n\n\n\n\n\nread_time\nread_timedark_mode\ndark_modedark_mode-&gt;read_time\nTreatmentPropensity\nTreatmentPropensityTreatmentPropensity-&gt;dark_mode\nmale\nmalemale-&gt;read_time\nmale-&gt;TreatmentPropensity\nage\nageage-&gt;read_time\nage-&gt;TreatmentPropensity\nhours\nhourshours-&gt;read_time\n\n\n\n\nAbbildung 6.3: Propensity im Website-Design-Beispiel\n\n\n\n\nHierbei beeinflussen die Backdoor-Variablen age und male die Behandlungsvariable dark_mode lediglich durch die Behandlungswahrscheinlichkeit Treatment Propensity. Diese Darstellung zeigt, das die mehrdimensionale Information bzgl. der Ähnlichkeit von Subjekten hinsichtlich der beobachteten Kovariablen in einer einzigen Variable zusammengefasst werden kann. Die Backdoor-Pfade können daher geschlossen werden, indem wir Subjekte anhand von Treatment Propensity derart gewichten, dass beide Gruppen hinsichtlich der Verteilung der Behandlungswahrscheinlichkeit vergleichbar sind. Betrachte erneut \\(\\eqref{eq:cia}\\) und beachte, dass \\[\\begin{align}\n  Y_i = Y_i^{(1)} D_i + Y_i^{(0)} (1-D_i).\n\\end{align}\\] Rosenbaum und Rubin (1983) zeigen, dass es hinsichtlich \\(\\eqref{eq:cia}\\) äquivalent ist für die Treatment Propensity \\(P_i(X_i):=P(B_i=1\\vert X_i = x)\\) zu kontrollieren, d.h. \\[\\begin{align}\n  \\left\\{Y_i^{(1)},Y_i^{(0)}\\right\\} \\perp B_i\\vert X_i \\quad\\Leftrightarrow\\quad \\left\\{Y_i^{(1)},Y_i^{(0)}\\right\\} \\perp B_i\\vert P_i(X_i).\n\\end{align}\\]\nDer Behandlungseffekt kann so als Differenz von gewichteten Gruppenmittelwerten berechnet werden, mit inversem Wahrscheinlichkeitsgewicht (IPW) \\(w_{i,B} = 1/P_i(X_i)\\) für Beobachtungen in der Behandlungsgruppe und \\(w_{i,K} = 1/(1-P_i(X_i))\\) für Beobachtungen in der Kontrollgruppe, \\[\\begin{align}\n  \\tau^{\\text{IPW}} = \\frac{1}{n}\\sum_{i=1}^n \\left[\\frac{B_i Y_i}{P_i(X_i)} - \\frac{(1-B_i)Y_i}{1-P_i(X_i)} \\right].\\label{eq:tauipw}\n\\end{align}\\]\nGrundsätzlich ist TreatmentPropensity eine nicht beobachtbare Variable und muss daher aus den Daten geschätzt werden. Eine geschätzte Behandlungswahrscheinlichkeiten \\(\\widehat{P}_i(X_i)\\) wird als Propensity Score bezeichnet. In der Praxis erfolgt die Schätzung von Propensity Scores meist mit logistischer Regression. Ein erwartungstreuer Schätzer des ATE ist \\[\\begin{align}\n  \\widehat{\\tau}^{\\text{IPW}} = \\frac{1}{n}\\sum_{i=1}^n \\left[\\frac{B_i Y_i}{\\widehat{P}_i(X_i)} - \\frac{(1-B_i)Y_i}{1-\\widehat{P}_i(X_i)} \\right].\\label{eq:hattauipw}\n\\end{align}\\] Hirano, Imbens, und Ridder (2003) diskutieren Alternativen zu \\(\\eqref{eq:hattauipw}\\) für die Schätzung anderer Typen von Behandlungseffekten.\nWir schätzen nachfolgend die Propensity Scores für unser Anwendungsbeispiel, erläutern die Berechnung der Gewichte sowie die Schätzung von Behandlungseffekten mit gewichteter Regression. Hierbei betrachten wir eine Variante von \\(\\eqref{eq:hattauipw}\\) mit normalisierten Gewichten \\(\\tilde{w}_{i,B} = w_{i,B}/\\sum_i w_{i,B}\\) und \\(\\tilde{w}_{i,K} = w_{i,K}/\\sum_i w_{i,K}\\) die sich jeweils zu 1 summieren.2 Dies ergibt den Hájek-Schätzer3 \\[\\begin{align}\n    \\widehat{\\tau}_N^{\\text{IPW}} = \\frac{\\sum_i\\tilde{w}_{i,B}Y_i}{\\sum_i\\tilde{w}_{i,B}} -  \\frac{\\sum_i\\tilde{w}_{i,K}Y_i}{\\sum_i\\tilde{w}_{i,K}}.\\label{eq:hattauhajek}\n\\end{align}\\]\n2 Eine Normalisierung der Gewichte reduziert die Varianz des Schätzers, vgl. Hirano, Imbens, und Ridder (2003)3 Siehe Hájek (1971).Zunächst Schätzen wir ein logistisches Regressionsmodell mit age, male und hours als erklärende Variablen für dark_mode.\n\n# Logit-Modell mit 'glm()' schätzen\n(\n  darkmode_ps_logit &lt;- glm(\n    formula = dark_mode ~ age + male + hours,\n    data = darkmode,\n    family = binomial\n  )\n)\n\n\nCall:  glm(formula = dark_mode ~ age + male + hours, family = binomial, \n    data = darkmode)\n\nCoefficients:\n(Intercept)          age         male        hours  \n  2.330e+00   -7.330e-02    1.623e+00   -9.293e-05  \n\nDegrees of Freedom: 299 Total (i.e. Null);  296 Residual\nNull Deviance:      415.9 \nResidual Deviance: 346.4    AIC: 354.4\n\n\nDie Propensity Scores erhalten wir als angepasste Werte aus der Regression darkmode_ps_logit mit fitted(). Wir erweitern den Datensatz mit den Ergebnissen.\n\n# Datensatz um Propensity Scores erweitern\n(\n  darkmode_probs &lt;- \n    darkmode %&gt;%\n    mutate(\n      PS = fitted(darkmode_ps_logit)\n    )\n)\n\n# A tibble: 300 × 6\n   read_time dark_mode  male   age  hours     PS\n       &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1      14.4         0     0    43   65.6 0.304 \n 2      15.4         0     1    55  125.  0.478 \n 3      20.9         1     0    23  643.  0.642 \n 4      20           0     0    41  129.  0.335 \n 5      21.5         1     0    29  190.  0.547 \n 6      19.5         0     0    64  185.  0.0849\n 7      22           1     0    18  334.  0.727 \n 8      17.4         0     0    53  279.  0.171 \n 9      23.6         0     0    59 1303.  0.108 \n10      15.7         0     0    53   16.1 0.174 \n# ℹ 290 more rows\n\n\nZur Beurteilung der Überlappung (vgl. Annahme \\(\\eqref{eq:overlap}\\) können wir die Verteilung der Propensity Scores nach Behandlungs-Indikator mit Histogrammen visualisieren.\n\n# Überlappung prüfen:\n# Histogramme der PS nach Treatment-Indikator\ndarkmode_probs %&gt;%\n  ggplot(\n    mapping = aes(\n      x = PS, \n      fill = factor(dark_mode)\n    )\n  ) + \n  geom_histogram(\n    alpha = .5, \n    bins = 25, \n    position = \"identity\"\n  )\n\n\n\n\n\n\n\nEin Vergleich der Histogramme zeigt, dass die Überlappung der Propensity Scores in der linken Flanken der Verteilungen der Kontrollgruppe und in der rechten Flanke der Behandlungsgruppe schlechter wird. Wir entfernen zunächst Beobachtungen aus der Stichprobe deren Propensity Scores wenig bzw. keine Überlappung aufweisen.\n\n# Datensatz nach PS trimmen\ndarkmode_probs &lt;- darkmode_probs %&gt;% \n  filter(\n    between(\n      x = PS,\n      left = .25,\n      right = .75\n    )\n  )\n\n\n# Überlappung nach trimming prüfen:\n# Dichteschätzung der PS nach Treatment-Indikator\ndarkmode_probs %&gt;%\nggplot(\n  mapping = aes(\n    x = PS, \n    fill = factor(dark_mode))\n  ) + \n  geom_histogram(\n    alpha = .5, \n    bins = 25, \n    position = \"identity\"\n  )\n\n\n\n\n\n\n\nIPWs anhand der Propensity Scores können schnell mit der Vorschrift \\[\\begin{align}\n  \\text{IPW} = \\frac{\\text{dark\\_mode}}{\\text{PS}} + \\frac{1 - \\text{dark\\_mode}}{1 - \\text{PS}},\n\\end{align}\\] berechnet werden.\n\n# Datensatz um IPWs erweitern\ndarkmode_IPW &lt;- darkmode_probs %&gt;%\n  mutate(\n    IPW = dark_mode / PS + (1 - dark_mode) / (1 - PS)\n  )\n\ndarkmode_IPW %&gt;% \n  select(IPW)\n\n# A tibble: 194 × 1\n     IPW\n   &lt;dbl&gt;\n 1  1.44\n 2  1.91\n 3  1.56\n 4  1.50\n 5  1.83\n 6  1.38\n 7  1.43\n 8  1.47\n 9  2.71\n10  1.42\n# ℹ 184 more rows\n\n\nEine Schätzung des durchschnittlichen Behandlungseffekts gemäß \\(\\eqref{eq:hattauhajek}\\) implementieren wir mit dplyr.\n\ndarkmode_IPW %&gt;%\n  group_by(dark_mode) %&gt;%\n  mutate(w = IPW / sum(IPW)) %&gt;%\n  summarise(weighted_mean = sum(read_time * w)) %&gt;%\n  summarise(diff = diff(weighted_mean))\n\n# A tibble: 1 × 1\n   diff\n  &lt;dbl&gt;\n1  1.90\n\n\nDiese Schätzung des Behandlungseffekts ist äquivalent zur gewichteten KQ-Schätzung anhand eines einfachen linearen Regressionsmodells.\n\n# Mit IPWs gewichteter KQ-Schaetzer berechnet den ATE\nmodel_ipw &lt;- lm(\n  formula = read_time ~ dark_mode, \n  data = darkmode_IPW,\n  weights = IPW\n)\n\nsummary(model_ipw)\n\n\nCall:\nlm(formula = read_time ~ dark_mode, data = darkmode_IPW, weights = IPW)\n\nWeighted Residuals:\n     Min       1Q   Median       3Q      Max \n-18.5086  -4.4579   0.6096   4.1345  20.4566 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  17.9709     0.4942  36.362  &lt; 2e-16 ***\ndark_mode     1.9011     0.6952   2.735  0.00683 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.913 on 192 degrees of freedom\nMultiple R-squared:  0.03749,   Adjusted R-squared:  0.03248 \nF-statistic: 7.478 on 1 and 192 DF,  p-value: 0.006829\n\n\nUnsere Schätzung des ATE ist der geschätzte Koeffizient von dark_mode. Die ausgegebenen Standardfehler und Inferenzstatistiken sind jedoch ungültig aufgrund der Gewichtung mit IPWs, den inversen geschätzten Wahrscheinlichkeiten für eine Behandlung. Der Grund hierfür ist, dass die Berechnung der Standardfehler in summary() die zusätzliche Unsicherheit durch die geschätzen Propensity Scores nicht berücksichtigt! Später im Kapitel erläutern wir die Berechnung gültiger Standardfehler für IPW-Schätzer basierend auf Propensity Scores mit dem Bootstrap.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Matching</span>"
    ]
  },
  {
    "objectID": "Matching.html#selektierende-matching-verfahren",
    "href": "Matching.html#selektierende-matching-verfahren",
    "title": "\n6  Matching\n",
    "section": "\n6.2 Selektierende Matching-Verfahren",
    "text": "6.2 Selektierende Matching-Verfahren\nDas grundsätzliche Konzept von selektierendem Matching wird in der nachstehenden interaktiven Grafik veranschaulicht. Hier betrachten wir beobachtete Ausprägungen von zwei (unabhängig und identisch verteilten) Matching-Variablen für Subjekte in der Behandlungsgruppe (blau) sowie Kontrollgruppe (rot). Als Matches qualifizieren sich sämtliche Beobachtungen der anderen Gruppe, deren Euklidische Distanz zu dem ausgewählten Punkt das über den Slider eingestellte Maximum Caliper nicht überschreitet.4 Diese Region wird durch den gestrichelten Kreis gekennzeichnet und kann über den zugehörigen Slider angepasst werden. Per Klick auf eine Beobachtung werden Matches aus der anderen Gruppe durch eine verbindende Linie und farbliches Hervorheben kenntlich gemacht. Mit dem Slider für k wird festgelegt, dass nur die nahesten k qualifizierten Beobachtungen als Matches behandelt werden. Die Grafik illustriert inbesondere, dass Beobachtungen in Abhängigkeit von k und Caliper falls gewünscht mehrfach (s.g. Matching mit Zurücklegen) oder gar nicht gematcht werden können.\n4 Es handelt sich hierbei um einen Spezialfall von Matching anhand der Mahalanobis-Distanz.\n\nFür die nachfolgenden Code-Beispiele verwenden wir das R-Paket MatchIt. MatchIt::matchit() nutzt standardmäßig Eins-zu-Eins-Matching (ohne Zurücklegen) von Beobachtungen der Treatment-Gruppe mit Beobachtungen der Kontrollgruppe.5 Die für das Matching zu verwendenden Variablen werden über das Argument formula als Funktion des Behandlungsindikators definiert. matchit() bereitet das Objekt für eine Schätzung des ATT mit einer geeigneten Funktionen, s. ?matchit und hier insb. die Erläuterungen der Argumente replace = F, ratio = 1 und estimand = \"ATT\" für Details. Mit cobalt::balt.tab() erhalten wir eine balance table für den gematchten Datensatz.\n5 Dieses Schema zielt auf eine Schätzung des ATT ab.Wir zeigen als nächstes, wie MatchIt::matchit() für Matching anhand der Regressoren age, hours, und male in unserem Website-Beispiel für unterschiedliche Varianten durchgeführt werden kann.\n\n6.2.1 Exaktes Matching\nExaktes Matching ordnet einem Subjekt aus der Behandlungsgruppe ein oder mehrere Subjekte aus der Kontrollgruppe zu, wenn die boebachteten Ausprägung der Matching-Variablen exakt übereinstimmen. Hierbei muss die ‘Distanz’ zwischen den Ausprägung der Matching-Variablen folglich \\(0\\) sein. Dieses Verfahren findet meist bei ausschließlich diskret verteilten Merkmalen Anwendung. Bei kontinuierlich verteilten Merkmalen (vgl. die obige interaktive Grafik) sind exakte Matches zwar theoretisch unmöglich, ergeben sich jedoch in der Praxis aus der Datenerfassung, bspw. durch Rundungsfehler. In matchit() erhalten wir exaktes Ein-zu-eins-Matching mit method = \"exact\".\n\nlibrary(MatchIt)\n\n# Exaktes Eins-zu-Eins-Matching durchführen\nres_em &lt;- matchit(\n  formula = dark_mode ~ age + male + hours, \n  data = darkmode,\n  estimand = \"ATT\",\n  method = \"exact\"\n)\n\nError in `matchit()`:\n! No exact matches were found.\n\nres_em\n\nError in eval(expr, envir, enclos): object 'res_em' not found\n\n\nAufgrund der kontinulierliche Verteilten Variable hours gibt es in unserem Website-Beispiel keine exakten Matches. Dieses Verfahren ist hier folglich ungeeignet.\n\n6.2.2 Coarsened Exact Matching\nBei dieser Methode werden kontinuierliche Matching-Variablen grob (Engl. coarse) klassiert, ähnlich wie bei einem Histogram. Diese Diskretisierung ermöglicht es exakte Übereinstimmungen zwischen Behandlungs- und Kontrollgruppenbeobachtungen hinsichtlich ihrer klassierten Ausprägungen zu finden. Sowohl Behandlungs- als auch Kontrollbeobachtungen die mindestents einen exakten Match haben, werden Teil des gematchten Datensatzes. In matchit() wird Coarsened Exact Matching mit method = \"cem\" durchgeführt. Über das Argument cutpoints geben wir an, dass hours in 6 Klassen und age in 4 Klassen eingeteilt werden soll.6 Mit k1k = TRUE erfolgt Eins-zu-eins-Matching: Bei mehreren exakten Matches wird die Beobachtung mit der geringsten Mahalanobis-Distanz (für die unklassierten Matching-Variablen) gewählt.\n6 Diese Werte wurden ad-hoc gewählt da sie zu einem guten Ergebnis führen.\n# Coarsened Exact Matching\nres_CEM &lt;- matchit(\n  formula = dark_mode ~ age + male + hours, \n  data = darkmode, \n  estimand = \"ATT\",\n  method = \"cem\", \n  k2k = TRUE,\n  cutpoints = list(\n    \"hours\" = 6, \n    \"age\" = 4\n  ) \n)\nres_CEM\n\nA matchit object\n - method: Coarsened exact matching\n - number of obs.: 300 (original), 164 (matched)\n - target estimand: ATT\n - covariates: age, male, hours\n\n\n\n# Balance-Table Coarsened Exact Matching\nbal.tab(res_CEM)\n\nBalance Measures\n         Type Diff.Adj\nage   Contin.   0.0106\nmale   Binary   0.0000\nhours Contin.  -0.0135\n\nSample sizes\n          Control Treated\nAll           151     149\nMatched        82      82\nUnmatched      69      67\n\n\nMit Coarsened Exact Matching erhalten wir einen Datensatz mit 82 Beobachtungen und guter Balance.\n\n6.2.3 Matching mit der Mahalanobis-Distanz\nDie Euklidische Distanz misst den direkten Abstand zwischen zwei Punkten und ist nicht invariant gegenüber Transformationen, insbesondere bei unterschiedlichen Skalierungen und bei Korrelation der Matching-Variablen. Die Mahalanobis-Distanz hingegen ist ein standardisiertes Distanzmaß, das unter Berücksichtigung der Varianz-Kovarianz-Struktur der Daten angibt, wie viele Standardabweichungen zwei Datenpunkte voneinander entfernt sind. Die Mahalanobis-Distanz ist invariant gegenüber linearen Transformationen (Skalierung, Translation und Rotation) der Daten und bietet ein genaueres Maß für die Unähnlichkeit zweier Beobachtungen hinsichtlich ihrer Ausprägungen der Matching-Variablen.\nBetrachte die Datenpunkte \\(P_1=(X_1,Y_1)'\\) und \\(P_2=(X_2,Y_2)'\\) für die Matching-Variablen \\(X\\) und \\(Y\\). Die Mahalanobis-Distanz zwischen \\(P_1\\) und \\(P_2\\) ist definiert als \\[\\begin{align*}\n  d_M(P_1,\\,P_2) = \\sqrt{(P_1 - P_2)'\\boldsymbol{S}^{-1} (P_1 - P_2)},\n\\end{align*}\\] wobei \\(\\boldsymbol{S}\\) die Varianz-Kovarianz-Matrix von \\(X\\) und \\(Y\\) ist. Die Mahalanobis-Distanz \\(d_M(P_1,\\,P_2)\\) ist also die Euklidische Distanz zwischen den standardisierten Datenpunkten.\nIn empirischen Anwendungen ersetzen wir die (unbekannten) Komponenten der Varianz-Kovarianz-Matrix durch Stichprobenvarianten. Dies ergibt die Formel\n\\[\\begin{align*}\n  \\widehat{d}_M(P_1,\\,P_2) = \\sqrt{\n  \\begin{pmatrix}\n    X_1 - X_2\\\\\n    Y_1 - Y_2\n  \\end{pmatrix}'\n  \\begin{pmatrix}\n    \\widehat{\\text{Var}}(X^2) & \\widehat{\\text{Cov}}(X, Y) \\\\\n     \\widehat{\\text{Cov}}(X, Y) & \\widehat{\\text{Var}}(Y^2)\n  \\end{pmatrix}^{-1}\n    \\begin{pmatrix}\n    X_1 - X_2\\\\\n    Y_1 - Y_2\n  \\end{pmatrix}\n}.\n\\end{align*}\\]\nDie nachstehende interaktive Grafik zeigt Beobachtungen zweier Matching-Variablen, die aus einer bivariaten Normalverteilung mit positiver Korrelation generiert wurden. Diese bivariate Verteilung ist identisch für Beobachtungen aus der Kontrollgruppe (rot) und Beobachtungen aus der Behandlungsgruppe (blau). Für die ausgewählte Beobachtung aus der Behandlungsgruppe (schwarzer Rand) werden potentielle Matches in der Kontrollgruppe innerhalb der vorgegebenen Mahalanobis-Distanz in Cyan kenntlich gemacht. Beachte, dass die Mahalanobis-Distanz Varianzen und Kovarianzen der Daten berücksichtigt, sodass die gematchten Beobachtungen in einem elliptischen Bereich um die betrachtete behandelte Beobachtung liegen. Eine Euklidische Distanz hingegen (gestrichelte Linie) ignoriert die Skalierung der Daten.\n\n\n\n\n\n\n\n\n\n\nFür Eins-zu-Eins-Matching im Website-Beispiel anhand der Mahalanobis-Distanz mit matchit() setzen wir distance = \"mahalanobis\" und wählen method = \"nearest\". Mit diesen Parametern wird jeder Behandlung aus der Behandlungsgruppe die gemäß \\(d_M\\) am ehesten vergleichbarste Beobachtung aus der Kontrollgruppe zugewiesen, wobei keine mehrfachen Matches zulässig sind.\n\n# 1:1 Mahalanobis-Distanz-Matching\nres_maha &lt;- matchit(\n  formula = dark_mode ~ age + male + hours, \n  data = darkmode, \n  estimand = \"ATT\",\n  distance = \"mahalanobis\", \n  method = \"nearest\"\n)\nres_maha\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Mahalanobis\n - number of obs.: 300 (original), 298 (matched)\n - target estimand: ATT\n - covariates: age, male, hours\n\n\n\n# Balance-Table für 1:1 Mahalanobis-Matching\nbal.tab(res_maha)\n\nBalance Measures\n         Type Diff.Adj\nage   Contin.  -0.5826\nmale   Binary   0.3154\nhours Contin.   0.0106\n\nSample sizes\n          Control Treated\nAll           151     149\nMatched       149     149\nUnmatched       2       0\n\n\nDie Ergebnisse zeigen, dass für sämtliche \\(149\\) Beobachtungen aus der Behandlungsgruppe ein individueller Match in der Kontrollgruppe gefunden werden konnte. Es werden lediglich \\(2\\) Beobachtungen der \\(151\\) Beobachtungen in der Kontrollgruppe nicht gematcht.\nEntsprechend zeigt die Balance-Table eine ähnliche Diskrepanz beider Gruppen hinsichtlich der Matching-Variablen an.\nMahalanobis-Distanz mit Caliper .25 für Propensity Scores basierend auf logistischer Regression\nFür eine strengeres Matching-Kriterium kann ein Caliper, d.h. eine maximal zulässige Distanz, herangezogen werden. Die Mahalanobis-Distanz hat jedoch keine einheitliche Skala: Ob eine Distanz als groß oder klein betrachten werden kann, hängt von der Anzahl der Matching-Variablen und dem Überlappungsgrad zwischen den Gruppen ab. Daher wird die Beschränkung durch einen Caliper nicht auf \\(\\widehat{d}_M\\) sondern auf Propensity Scores angewendet.\nIm nächsten Code-Beispiel spezifizieren wir mit distance = \"glm\", dass Propensity Scores gemäß der Vorschrift in formula geschätzt werden. Mit mahvars = ~ age + male + hours legen wir die Matching-Variablen für die Berechnung von \\(\\widehat{d}_M\\) fest. caliper = .25 legt fest, dass lediglich Beobachtungen der Kontrollgruppe bei einer absoluten Differenz der Propensity Scores von höchstens \\(0.25\\) Standardabweichungen als Match für eine Beobachtung in der Behandlungsgruppe qualifiziert sind.\n\n\n\n\n\n\n\n# Mahalanobis-Matchig mit PS-Caliper\nres_mahaC &lt;- matchit(\n  formula = dark_mode ~ age + male + hours, \n  data = darkmode, \n  distance = \"glm\",\n  estimand = \"ATT\",\n  method = \"nearest\",\n  mahvars = ~ age + male + hours,\n  caliper = .25\n)\nres_mahaC\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Mahalanobis [matching]\n             Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.058)\n - number of obs.: 300 (original), 208 (matched)\n - target estimand: ATT\n - covariates: age, male, hours\n\n\n\n# Balance Table\nbal.tab(res_mahaC)\n\nBalance Measures\n             Type Diff.Adj\ndistance Distance   0.1812\nage       Contin.  -0.1176\nmale       Binary   0.0481\nhours     Contin.  -0.0001\n\nSample sizes\n          Control Treated\nAll           151     149\nMatched       104     104\nUnmatched      47      45\n\n\nDie Balance-Table zeigt einen deutlichen Effekt der Beschränkung qualifizierter Beobachtungen durch caliper = .25: Aufgrund der oberen Grenze für die Propensity-Score-Differenz von \\(0.058\\) wird für lediglich \\(104\\) Beobachtungen aus der Behandlungsgruppe ein individueller Match in der Kontrollgruppe gefunden.7 Weiterhin finden wir eine verbesserte Balance für den gematchten Datensatz.\n7 Die durch caliper implizierte Obergrenze ergibt sich als .25 * sd(fitted(darkmode_ps_logit))).\n\n\n\n\n\n\n6.2.4 Propensity Score Matching\nEine gängige Variante ist Matching ausschließlich anhand von Propensity Scores innerhalb eines Calipers.\n\n# 1:1 Matching mit PS und Caliper\nres_PSC &lt;- matchit(\n  formula = dark_mode ~ age + male + hours, \n  data = darkmode, \n  estimand = \"ATT\",\n  distance = \"glm\", \n  method = \"nearest\", \n  caliper = .25\n)\nres_PSC\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.058)\n - number of obs.: 300 (original), 208 (matched)\n - target estimand: ATT\n - covariates: age, male, hours\n\n\n\n# Balance Table\nbal.tab(res_PSC)\n\nBalance Measures\n             Type Diff.Adj\ndistance Distance   0.1640\nage       Contin.  -0.0976\nmale       Binary   0.0481\nhours     Contin.   0.0134\n\nSample sizes\n          Control Treated\nAll           151     149\nMatched       104     104\nUnmatched      47      45\n\n\nLaut Balance-Table führt Eins-zu-Eins-Matching basierend auf Propensity Scores zu einem Datensatz mit \\(104\\) gematchten Beobachtungen in der Behandlungsgruppe. Hinsichtlich der standardisierten Mittelwertdifferenz (Diff.Adj) erzielt diese Methode die beste Balance unter den betrachteten Ansätzen.\nVergleich der Balance verschiedener Verfahren mit Love-Plot\nStandardisierte Mittelwertdifferenzen für verschiedene Matching-Verfahren können grafisch mit einem Love-Plot (Love 2004) veranschaulicht werden. Hierzu nutzen wir cobalt::love.plot() und übergeben die mit matchit() generierten Objekte im Argument weights.\n\n# Love-Plot für\nlove.plot(\n  x = dark_mode ~ age + male + hours, \n  weights = list(\n    CEM = res_CEM,\n    Mahalanobis = res_maha,\n    Mahalanobis_Cal = res_mahaC,\n    PSC = res_PSC\n  ),\n  data = darkmode, \n  line = T,\n  # absolute Mittelwertdifferenz plotten\n  abs = T\n)\n\n\n\n\n\n\n\nDie Grafik zeigt, dass Coarsened Exact Matching (CEM) unter allen betrachteten Verfahren die Stichprobe mit der besten Balance ergibt. Diesen gematchten Datensatz erhalten wir mit MatchIt::match.data().\n\n# gematchten Datensatz zuweisen\ndarkmode_matched_CEM &lt;- match.data(res_CEM)\nhead(darkmode_matched_CEM)\n\n# A tibble: 6 × 7\n  read_time dark_mode  male   age hours weights subclass\n      &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;   \n1      15.4         0     1    55  125.       1 26      \n2      20.9         1     0    23  643.       1 70      \n3      21.5         1     0    29  190.       1 79      \n4      22           1     0    18  334.       1 80      \n5      17.4         0     0    53  279.       1 11      \n6      20.4         0     0    43  138.       1 9       \n\n\ndarkmode_matched enthält Gewichte (weights) für die jeweilige Gruppe zu denen gemachte Beobachtungen gehören (subclass). Dies ist relevant, falls Beobachtungen mehrfach gematcht werden. Wegen Eins-zu-eins-Matching ohne Zurücklegen gibt es in unserem Beispiel 82 Beobachtungspaare und sämtliche Gewichte sind 1. Die Berücksichtigung der Gewicht in den nachfolgenden Aufrufen von Schätzfunktionen (bspw.lm()) ist daher nicht nötig und erfolgt lediglich zur Illustration der grundsätzlichen Vorgehensweise.\nEine Wiederholung der grafischen Analyse in Kapitel 6.1 zeigt eine deutlich verbesserte Vergleichbarkeit hinsichtlich der Verteilung der Matching-Variablen in darkmode_matched.\n\ndarkmode_matched_CEM %&gt;%\n  group_by(dark_mode) %&gt;%\n  select(age, hours) %&gt;%\n  mutate_all(scale) %&gt;%\n  pivot_longer(cols = c(-dark_mode)) %&gt;%\n  \n  ggplot(\n    aes(x = value, fill = as.factor(dark_mode))\n  ) +\n  geom_density( alpha = .5) + \n  facet_wrap(\n    facets = ~ name, \n    scales = \"free\", \n    nrow = 3\n  )\n\n\n\n\n\n\ndarkmode_matched_CEM %&gt;% \n  group_by(dark_mode) %&gt;%\n  mutate(\n    male = as.factor(male), \n    dark_mode = as.factor(dark_mode)\n  ) %&gt;%\n  \n  ggplot(\n    aes(x = dark_mode, fill = male)\n  ) +\n  geom_bar(position = \"fill\") +\n  ylab(\"Anteil\")\n\n\n\n\n\n\n\nWir beobachten eine bessere Balance bei age und hours. Inbesondere ist male für Kontroll- und Behandlungsgruppe ausgeglichen.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Matching</span>"
    ]
  },
  {
    "objectID": "Matching.html#sec-regadj",
    "href": "Matching.html#sec-regadj",
    "title": "\n6  Matching\n",
    "section": "\n6.3 Schätzung und Inferenz für den Behandlungseffekt nach Matching",
    "text": "6.3 Schätzung und Inferenz für den Behandlungseffekt nach Matching\nWir schätzen nun den Behandlungseffekt von dark_mode auf read_time für die mit CEM und Propensity Score Matching ermittelten Datensätzen und vergleichen die Ergebniss anschließend mit einer Regressionsschätzung ohne Matching.\nWir kombinieren die Matching-Verfahren mit linearer Regression, d.h. wir Schätzen den Behandlungseffekt anhand es gematchten Datensatzes als Mittelwertdifferenz nach zusätzlicher Kontrolle für die Matching-Variablen. Diese Kombination von Matching mit Regression wird in der Literatur als Regression Adjustment bezeichnet und ist insbesondere hilfreich, wenn Backdoors mit Matching geschlossen werden sollen, der kausale Effekt jedoch nur unter Verwendung einer nicht-trivialen Regressionsfunktion ermittelt werden kann. Zum Beispiel kann bei einer kontinuierlichen Behandlungsvariable und einem nicht-linearen Zusammenhang mit \\(Y\\) der kausale Effekt nicht durch einen bloßen Mittelwertvergleich erfasst werden, sondern erfordert eine adäquate Modellierung dieses Zusammenhangs in der Regressionsfunktion. Die zusätzliche Kontrolle für Matching-Variablen kann die Varianz der Schätzung verringern und das Risiko einer verzerrten Schätzung abmildern, falls nach Matching noch Unterschiede in der Balance von Behandlungs- und Kontrollgruppe vorliegen.\n\n# ATT mit linearem Modell schätzen: CEM Datensatz\nATT_mod_CEM &lt;- lm(\n  formula = read_time ~ age + male + hours + dark_mode,\n  data = darkmode_matched_CEM, \n  weights = weights \n)\n\nsummary(ATT_mod_CEM)\n\n\nCall:\nlm(formula = read_time ~ age + male + hours + dark_mode, data = darkmode_matched_CEM, \n    weights = weights)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.9310 -2.3856 -0.0194  2.5407 14.0020 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 16.6088953  1.5255529  10.887  &lt; 2e-16 ***\nage          0.0380982  0.0344699   1.105  0.27072    \nmale        -4.0915725  0.6858131  -5.966 1.53e-08 ***\nhours        0.0050129  0.0006977   7.185 2.45e-11 ***\ndark_mode    1.6532234  0.6149439   2.688  0.00794 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.937 on 159 degrees of freedom\nMultiple R-squared:  0.414, Adjusted R-squared:  0.3992 \nF-statistic: 28.08 on 4 and 159 DF,  p-value: &lt; 2.2e-16\n\n\n\n# Datensatz für Propensity Score Matching zuweisen\ndarkmode_matched_PSC &lt;- match.data(res_PSC)\n\n# ATT mit linearem Modell schätzen: PSM Datensatz\nATT_mod_PSC &lt;- lm(\n  formula = read_time ~ age + male + hours + dark_mode,\n  data = darkmode_matched_PSC, \n  weights = weights \n)\n\nsummary(ATT_mod_PSC)\n\n\nCall:\nlm(formula = read_time ~ age + male + hours + dark_mode, data = darkmode_matched_PSC, \n    weights = weights)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.972 -2.605 -0.044  2.587 14.951 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 17.3654519  1.2762648  13.606  &lt; 2e-16 ***\nage          0.0283941  0.0301484   0.942  0.34741    \nmale        -3.9858702  0.6480072  -6.151 4.03e-09 ***\nhours        0.0046119  0.0006685   6.899 6.53e-11 ***\ndark_mode    1.6346636  0.5769812   2.833  0.00507 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.141 on 203 degrees of freedom\nMultiple R-squared:  0.3171,    Adjusted R-squared:  0.3037 \nF-statistic: 23.57 on 4 and 203 DF,  p-value: 5.098e-16\n\n\n\n# ATT mit linearem Modell ohne Matching\nATT_mod_org &lt;- lm(\n  formula = read_time ~ age + male + hours + dark_mode,\n  data = darkmode\n)\n\nsummary(ATT_mod_org)\n\n\nCall:\nlm(formula = read_time ~ age + male + hours + dark_mode, data = darkmode)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.2697  -2.6710   0.0164   2.5909  14.5739 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 16.859075   1.082303  15.577  &lt; 2e-16 ***\nage          0.051332   0.022215   2.311  0.02154 *  \nmale        -4.485545   0.498957  -8.990  &lt; 2e-16 ***\nhours        0.004348   0.000516   8.427 1.58e-15 ***\ndark_mode    1.385810   0.523793   2.646  0.00859 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.03 on 295 degrees of freedom\nMultiple R-squared:  0.3434,    Adjusted R-squared:  0.3345 \nF-statistic: 38.57 on 4 and 295 DF,  p-value: &lt; 2.2e-16\n\n\nBeachte, dass für die gematchten Datensätze jeweils ein durchschnittlicher Behandlungseffekt für die Beobachtungen mit erfolgter Behandlung ermittelt wird: In sämtlichen oben gezeigten Matchibg-Verfahren werden mit estimand = \"ATT\" vergleichbarere Kontrollbeobachtungen für die behandelten Beobachtungen ermittelt. Wir schätzen den Effekt der Behandlung, indem wir die Ergebnisse von behandelten Personen mit denen von gematchten Personen vergleichen, die keine Behandlung erhalten haben. Diese Vergleichsgruppe dient als Ersatz für den hypothetischen Zustand der Behandlungsgruppe, wenn keine Behandlung erfolgt wäre. Dies entspricht der Definition eines ATT — ein average treatment effect on the treated.\n\n6.3.1 Cluster-robuste Standardfehler\nFür Matching-Verfahren sind die mit summary() berechneten Standardfehler (und damit auch Konfidenzintervalle, t-Statistiken und p-Werte) für den Behandlungseffekt grundsätzlich ungültig. Je nach Matching-Verfahren liegen unterschiedliche Quellen von Schätzunsicherheit vor, die bei der Berechnung von Standardfehlern zusätzlich zu der “üblichen” Stichproben-Variabilität berücksichtig werden müssen. Gründe hierfür sind der Matching-Prozess ansich oder weitere Unsicherheit durch die Schätzung zusätzlicher Parameter, etwa bei der Berechnung von Propensity Scores mit logistischer Regression. Eine weiterere Ursache zusätzlicher Variation durch den Matching-Prozess, die wir bisher nicht näher betrachtet haben ensteht durch Zurücklegen, d.h. wenn Beobachtungen mehrfach gematcht werden können. Auch dieser Faktor wird in der von summary() verwendeten Formel für den Standardfehler des Effekt-Schätzers nicht berücksichtigt.\nDie Standardfehlerberechnung für Matching-Schätzer von Behandlungseffekten ist ein Gegenstand aktueller methodischer Forschung. P. C. Austin und Small (2014) und Abadie und Spiess (2022) belegen die Gültigkeit von cluster-robusten Standardfehlern mit Clustering auf Ebene der Beobachtungsgruppen (subclass im output von match.data()) bei Matching ohne Zurücklegen. Für Matching anhand von Propensity Scores (auch mit Zurücklegen) zeigt Imbens (2016), dass ignorieren der zusätzlichen Unsicherheit durch die Schätzung der Propensity Scores zu konservativer Inferenz für den ATE anhand eines cluster-robusten Standardfehlerschätzers führt, jedoch ungültige Inferenz für die Schätzung des ATT bedeuten kann. Ähnlich zu P. C. Austin und Small (2014) deuten die Ergebnisse der Simulationsstudie von Bodory u. a. (2020) jedoch auf grundsätzlich bessere Eigenschaften der Schätzung hin, wenn die Standardfehler nicht für die Schätzung der Propensity Scores adjustiert werden.\nWeiterhin ist die Kontrolle für Kovariablen mit Erklärungskraft für die Outcome-Variable und für die Matching-Variablen mit Regression Adjustment (vgl. Kapitel 6.3) für die Schätzung des Behandlungseffekts nach Matching eine etablierte Strategie, vgl. Hill und Reiter (2006) und Abadie und Spiess (2022). So können die Varianz der Schätzung und das Risiko einer Verzerrung der Standardfehler aufgrund verbleibender Imbalance von Behandlungs- und Kontrollgruppe nach Matching verringert werden.\nZur Demonstration von (cluster)-robuster Inferenz und für eine tabellarische Zusammenfassung der Ergebnisse nutzen wir die Pakete marginaleffects und modelsummary. Mit marginaleffects::avg_comparisons() können p-Werte und Kofindenzintervalle unter Berücksichtigung von robuster Standardfehlern und der Gewichte aus dem Matching-Verfahren berechnet werden.\n\nlibrary(marginaleffects)\n\n# Inferenz: Multiple Regression, ungematchter Datensatz\n(\n  sum_orig &lt;- avg_comparisons(\n    model = ATT_mod_org,\n    variables = \"dark_mode\",\n    # Heteroskedastie-robuste SE:\n    vcov = \"HC3\", \n    # Identifizierung der Kontrollgruppe:\n    newdata = subset(darkmode, dark_mode == 1) \n  )\n) \n\n\n      Term          Contrast Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n dark_mode mean(1) - mean(0)     1.39      0.537 2.58  0.00988 6.7 0.333   2.44\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\n# Inferenz: Multiple Regression bei CEM\n(\n  sum_CEM &lt;- avg_comparisons(\n  model = ATT_mod_CEM ,\n  variables = \"dark_mode\",\n  # Cluster-robuste SE\n  vcov = ~ subclass, \n  newdata = subset(darkmode_matched_CEM, dark_mode == 1),\n  wts = \"weights\"\n  )\n)\n\n\n      Term          Contrast Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n dark_mode mean(1) - mean(0)     1.65      0.549 3.01  0.00262 8.6 0.576   2.73\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\n# Inferenz: Multiple Regression bei PSM\n(\n  sum_PSC &lt;- avg_comparisons(\n    model = ATT_mod_PSC ,\n    variables = \"dark_mode\",\n    vcov = ~ subclass, \n    newdata = subset(darkmode_matched_PSC, dark_mode == 1),\n    wts = \"weights\"\n  )\n)\n\n\n      Term          Contrast Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n dark_mode mean(1) - mean(0)     1.63      0.565 2.89  0.00381 8.0 0.527   2.74\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\nWir fassen die Ergebnisse mit modelsummary::modelsummary() tabellarisch zusammen.\n\nlibrary(modelsummary)\n\n# Tabellarische Zusammenfassung erzeugen\nmodelsummary(\n  models = list(\n   \"Kein Matching\" = sum_orig, \n   \"Coarsened Exact\" = sum_CEM, \n   \"Propensity Scores\" = sum_PSC\n  ),\n  stars = T, \n  gof_map = \"nobs\", \n  output = \"gt\"\n) %&gt;%\n  tabopts()\n\n\n\n\n\n\nKein Matching\nCoarsened Exact\nPropensity Scores\n\n\n\ndark_mode\n1.386**\n1.653**\n1.635**\n\n\n\n(0.537)\n(0.549)\n(0.565)\n\n\nNum.Obs.\n300\n164\n208\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Matching</span>"
    ]
  },
  {
    "objectID": "Matching.html#sec-bootmatching",
    "href": "Matching.html#sec-bootmatching",
    "title": "\n6  Matching\n",
    "section": "\n6.4 Bootstrap-Schätzung kausaler Effekte bei Matching",
    "text": "6.4 Bootstrap-Schätzung kausaler Effekte bei Matching\nEin Bootstrap-Verfahren generiert mit Resampling (wiederholtes Ziehen mit Zurücklegen) aus dem Original-Datensatz (viele) künstliche Datensätze, für die der Schätzer (d.h. das gesamte Verfahren inkl. Matching!) jeweils berechnet wird. Die Verteilung der so gewonnenen Bootstrap-Schätzwerte approximiert die wahre, unbekannte Stichprobenverteilung des Schätzers des Behandlungseffekts. Mit dieser simulierten Verteilung können wir Inferenz betreiben: Wir können einen Bootstrap-Punktschätzer des Behandlungseffekts (Stichprobenmittel der Bootstrap-Schätzungen) sowie Standardfehler (Standardabweichung der der Bootstrap-Schätzungen) und p-Werte berechnen.\nDer Bootstrap kann hilfreich sein, wenn unklar ist, wie Standardfehler für die Unsicherheit des Matching-Prozesses zu adjustieren sind, um gültige Inferenzsstatistiken zu erhalten. Abadie und Imbens (2008) zeigen analytisch, dass der Standard-Bootstrap die Stichprobenverteilung für Schätzer kausaler Effekte anhand von gematchten Datensätzen (d.h. bei Zuordnung/Selektion von Beobachtungen mit Matching) nicht korrekt abbilden kann. Grundsätzlich problematisch hierbei ist, wenn der Bootstrap eine verzerrte Schätzung produziert und/oder zu kleine Standardfehler liefert. Abadie und Imbens (2008) belegen die Tendenz des Bootstraps zu konservative (d.h. zu große) Standardfehler zu produzieren. Simulationsnachweise (Bodory u. a. 2020; Hill und Reiter 2006; P. C. Austin und Small 2014; P. C. Austin und Stuart 2017) finden, dass Bootstrap-Standardfehler u.a. bei Propensity Score Matching mit Zurücklegen leicht konservativ sind somit das gewünschte nominale Signifikanzniveau eines Bootstrap-Hypothesentests nicht überschritten wird, weshalb der Standard-Bootstrap trotz seiner Schwächen in der empirischen Forschung oft angewendet wird.\nWir betrachen als nächstes einen Bootstrap-Algorithmus für Inferenz bezüglich eines kausalen Effekts nach Matching und demonstrieren die Schätzung anhand unseres Website-Beispiels für den ATT nach Propensity-Score-Matching.\n\n\n\n\n\n\nAlgorithmus: Bootstrap-Schätzer für Matching mit Regression Adjustment\n\n\n\n\nGeneriere eine Bootstrap-Stichprobe durch \\(N\\) Züge mit Zurücklegen aus der \\(N\\)-elementigen originalen Stichprobe.\nWende das Matching-Verfahren für die Bootstrap-Stichprobe an. Schätze den Behandlungseffekt \\(\\beta\\) anhand der gematchten Stichprobe mit Regression. Speichere den Punktschätzer des Behandlungseffekts \\(\\widehat{\\beta}_b^*\\).\nFürhre die Schritte 1 und 2 für \\(b=1,\\dots,B\\) aus, wobei \\(B\\) eine hinreichend große Anzahl von Bootstrap-Replikationen ist.\nBerechne den Bootstrap-Schätzer des Behandlungseffekts \\(\\overline{\\beta}^* = \\frac{1}{B}\\sum_{b=1} \\widehat{\\beta}_b^*\\) und den Standardfehler \\(\\text{SE}(\\overline{\\beta}^*) = \\sqrt{\\frac{1}{B-1}\\sum_{b=1}^B(\\widehat{\\beta}_b^*-\\overline{\\beta}^*)^2}\\). Berechne Inferenz-Statistiken mit den üblichen Formeln.\n\n\n\nWir Implementieren nun einen Bootstrap-Schätzer des ATT im Website-Beispiel für Propensity-Score-Matching. Hierzu definieren wir eine R-Funktion boot_fun() für die Schritte 1 und 2 im obigen Algorithmus.\n\n# Bootstrap-Funktion für Schritte 1 und 2\nboot_fun &lt;- function(\n    data, # originale Stichprobe\n    i     # Indexmenge f. Bootstrap-Stichprobe\n) {\n  \n  # Bootstrap-Stichprobe\n  boot_data &lt;- data[i, ]\n  \n  # 1:1 PS Matching\n  match_res &lt;- matchit(\n    dark_mode ~ age + hours + male,\n    estimand = \"ATT\",\n    distance = \"glm\", \n    method = \"nearest\", \n    caliper = .25,\n    data = boot_data\n  ) \n  \n  # Gematchten Datensatz zuweisen\n  darkmode_matched &lt;- match.data(\n    object = match_res, \n    data = boot_data\n  )\n  \n  # Outcome-Modell schätzen\n  ATT_mod &lt;- lm(\n    formula = read_time ~ age + male + hours + dark_mode,\n    data = darkmode_matched, \n    weights = weights \n  )\n  \n  #  ATT-Schätzung zurückgeben\n  return(\n    ATT_mod$coefficients[\"dark_mode\"]  \n  )\n}\n\nWir berechnen nun eine Bootstrap-Schätzung des ATT von dark_mode auf readingtime nach Propensity Score Matching mit einem caliper von 0.25 sowie den zugehörigen Standardfehler und ein 95%-KI mit der zuvor definierten Funktion boot_fun.\n\nlibrary(\"boot\")\nset.seed(4321)\n\n# Anz. Bootstrap-Replikationen\nB &lt;- 999\n\n# Bootstrap durchführen\n(\n  boot_out &lt;- boot(darkmode, boot_fun, R = B)\n)\n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = darkmode, statistic = boot_fun, R = B)\n\n\nBootstrap Statistics :\n    original      bias    std. error\nt1* 1.634664 -0.08144129   0.5935746\n\n\nDen Bootstrap-Schätzer des ATT sowie den Bootstrap-Standardfehler berechnen wir mit mean() und sd() anhand der 999 Bootstrap-Replikationen in boot_out$t.\nBeachte, dass der Bootstrap-Schätzer des Behandlungseffekts nicht unmittelbar von boot() ausgegeben wird. original ist die Schätzung anhand der gesamten Stichprobe (d.h. ohne Bootstrap) und bias ist die Differenz zwischen dieser Schätzung und dem Mittelwert der Bootstrap-Schätzungen.\n\n# Bootstrap-Schätzer für den Treatment-Effekt\nmean(boot_out$t) \n\n[1] 1.553222\n\n# bootstrap - original = bias\nmean(boot_out$t) - boot_out$t0\n\n  dark_mode \n-0.08144129 \n\n\nWir können prüfen, dass die Berechnung des Standardfehlers dem Stichprobenstandardabweichung der Bootstrap-Schätzungen entspricht.\n\n# Bootstrap-Standardfehler\nsd(boot_out$t)\n\n[1] 0.5935746\n\n\nEin 95%-Konfidenzintervall für den kausalen Effekt erhalten wir mit boot::boot.ci().8\n8 type = \"bca\" (bias-corrected accelerated) ist eine gängige Implementierung für die Berechnung des Konfidenz-Intervalls.\n# 95% Bootstrap-KI für den Treatment-Effekt\nboot.ci(\n  boot.out = boot_out, \n  type = \"bca\", \n  conf = .95\n)\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 999 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = boot_out, conf = 0.95, type = \"bca\")\n\nIntervals : \nLevel       BCa          \n95%   ( 0.527,  2.839 )  \nCalculations and Intervals on Original Scale\n\n\nBeachte, dass der Bootstrap-Standardfehler sowie das Bootstrap-Konfidenzintervall nahe der mit avg_comarisons berechneten Werte für sum_PSC sind.\nBootstrap-Standardfehler für IPW-Schätzer des ATE berechnen\nDie Bootstrap-Funktion boot_fun kann leicht für eine Schätzung des Standardfehlers für den IPW-Schätzer des ATE aus Kapitel 6.1.3 angepasst werden. Statt einer Matching-Prozedur berechnen wir hierzu für \\(B\\) Bootstrap-Stichproben den Schätzer \\(\\widehat{\\tau}^\\text{IPW}\\) mit Trimming der Propensity Scores.\n\n# IPW estimation with regression adjustment\nIPW_boot &lt;- function(\n    data, \n    i\n) {\n  \n  # Bootstrap-Stichprobe erstellen\n  data_boot  &lt;- data %&gt;% \n    slice(i)\n  \n  # Logistischee Regression\n  glm_fit &lt;- glm(\n    formula = dark_mode ~ age + hours + male,\n    data = data_boot, \n    family = binomial\n  )\n  \n  # Propensity Scores berechnen\n  data_boot &lt;- data_boot %&gt;%\n    mutate(\n      ps = predict(glm_fit, type = 'response')\n    )\n  \n  # Beobachtungen anhand Propensity Scores trimmen\n  data_boot &lt;- data_boot %&gt;%\n    filter(\n      between(\n        x = ps,\n        left = .2,\n        right = .7\n      )\n    )\n  \n  # IPW berechnen\n  data_boot &lt;- data_boot %&gt;%\n    mutate(\n      ipw = case_when(\n        dark_mode == 1 ~ 1 / ps,\n        dark_mode == 0 ~ 1 / (1 - ps))\n    )\n  \n  # Gewichtete Mittelwerte der Gruppen   \n  w_means &lt;- data_boot %&gt;%\n    group_by(dark_mode) %&gt;%\n    summarize(m = weighted.mean(read_time, w = ipw)) %&gt;%\n    arrange(dark_mode)\n  \n  # ATT-Schätzwert\n  return(w_means$m[2] - w_means$m[1])\n}\n\n\nset.seed(1234)\n# Bootstrap für IPW durchführen\n(\n  b_IPW &lt;- boot(\n    data = darkmode,\n    statistic = IPW_boot, \n    R = 999\n  )\n)\n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = darkmode, statistic = IPW_boot, R = 999)\n\n\nBootstrap Statistics :\n    original     bias    std. error\nt1* 1.962849 0.06297654   0.6599891\n\n\n\n# Bootstrap-Schätzer und Standardfehler berechnen\nmean(b_IPW$t)\n\n[1] 2.025826\n\nsd(b_IPW$t)\n\n[1] 0.6599891\n\n\nIn diesem Fall ist der Bootstrap-Standardfehler von ca. 0.66 gut mit dem anhand von summary(model_ipw) berechneten Standardfehler vergleichbar. Ein 95%-Konfidenzintervall für den ATE erhalten wir wie zuvor mit boot.ci().\n\n# 95% Bootstrap-KI für den ATE\nboot.ci(b_IPW, type = \"bca\")\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 999 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = b_IPW, type = \"bca\")\n\nIntervals : \nLevel       BCa          \n95%   ( 0.563,  3.134 )  \nCalculations and Intervals on Original Scale",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Matching</span>"
    ]
  },
  {
    "objectID": "Matching.html#regression-matching-und-doubly-robust-schätzung",
    "href": "Matching.html#regression-matching-und-doubly-robust-schätzung",
    "title": "\n6  Matching\n",
    "section": "\n6.5 Regression, Matching und Doubly-Robust-Schätzung",
    "text": "6.5 Regression, Matching und Doubly-Robust-Schätzung\nAls Doubly-Robust-Schätzer bezeichnet man Methoden, die bei Fehlspezifikationen im Matching-Verfahrens oder der funktionalen Form der Regressionsfunktion für die Outcome-Variable eine zuverlässige Schätzungen des kausalen Effekts ermöglichen.9 Unter der Vorraussetzung, dass die verwendeten Matching-Variablen sämliche Backdoors schließen, ist so mit Doubly-Robust-Schätzung eine konsistente Schätzung des Behandlungseffekts unter abgeschwächten Annahmen gewähtleistet. Dies macht Doubly-Robust-Schätzer besonders nützlich in Forschungskontexten, in denen präzise Modellspezifikationen herausfordernd sind.\n9 Bspw. kann eine falsche funktionale Form bei logistischer Regression eine verzerrte Schätzung von Propensity Scores und damit eine unzureichende Balance bedeuten.Der von Wooldridge (2010) vorgeschlagene Doubly-Robust-Schätzer (IPWRA) für den ATE erreicht seine vorteilhaften Eigenschaften durch eine geschickte Kombination von IPW und Regression Adjustment.\n\n\n\n\n\n\nAlgorithmus: IPWRA-Schätzer des ATE\n\n\n\nVgl. Wooldridge (2010).\n\nBerechne IPW anhand von Propensity Score mit logistischer Regression unter Verwendung der Matching-Variablen.\n\nRegression Adjustment:\n\nSchätze lediglich für die Behandlungsgruppe eine mit den IPW gewichtete Regressionspezifikation der Outcome-Variable mit Kontrolle für die Matching-Variablen.\nWiederhole Schritt A für Kontrollgruppe.\n\n\nBerechne Vorhersagen der Outcome-Variable für die angepassten Modelle aus 2 (a) und 2 (b) anhand des gesamten Datensatzes.\nSchätze den ATE als Mittelwert-Differenz der Vorhersagen aus Schritt 3.\n\n\n\nWir implementieren den Doubly-Robust-Schätzer des ATE von Wooldridge (2010) für das Website-Beispiel in der Funktion IPWRA() under Adaption des Schemas von IPW_boot().\n\n# IPW estimation with regression adjustment\nIPWRA &lt;- function(\n    data, \n    i = i) {\n  \n    # Bootstrap-Stichprobe zuweisen\n    b_data &lt;- data %&gt;% \n      slice(i)\n    \n    # Logistische Regression\n    glm_fit &lt;- glm(\n      formula = dark_mode ~ age + hours + male,\n      data = b_data, \n      family = binomial(link = 'logit')\n    )\n    \n    # Propensity Scores berechnen\n    b_data &lt;- b_data %&gt;%\n        mutate(ps = predict(glm_fit, type = 'response'))\n    \n    # Propensity Scores trimmen\n    b_data &lt;- b_data %&gt;%\n      filter(\n        between(\n          x = ps,\n          left = .2,\n          right = .7\n          )\n    )\n    \n    # IPW berechnen\n    b_data &lt;- b_data %&gt;%\n      mutate(\n        IPW = case_when(\n          dark_mode == 1 ~ 1 / ps,\n          dark_mode == 0 ~ 1 / (1 - ps))\n      )\n    \n    # Regression Adjustment:\n    \n    # Schätzung des Behandlungseffekts für die ges. Stichprobe\n    # mit Modell für Behandlungsgruppe\n    mtreat &lt;- b_data %&gt;%\n      filter(dark_mode == 1) %&gt;%\n      lm(read_time ~ age + hours + male, data = ., weights = .$IPW) %&gt;%\n      predict(newdata = b_data) %&gt;%\n      mean()\n\n    # Schätzung des Behandlungseffekts für die ges. Stichprobe\n    # mit Modell für Kontrollgruppe   \n    mcont &lt;- b_data %&gt;%\n      filter(dark_mode == 0) %&gt;%\n      lm(read_time ~ age + hours + male, data = ., weights = .$ipw) %&gt;%\n      predict(newdata = b_data) %&gt;%\n      mean()\n    \n    # Regression adjusted ATE-Schätzer\n    return(mtreat - mcont)\n}\n\nSchätzung des ATE mit IPWRA():\n\nIPWRA(data = darkmode, i = 1:nrow(darkmode))\n\n[1] 1.96847\n\n\nWie bei \\(\\widehat{\\tau}^\\text{IPW}\\) gibt es keine formale Darstellung des Standardfehlers für den IPWRA-Schätzer, sodass auch hier der Bootstrap genutzt werden sollte.\n\nset.seed(1234)\n\n# Bootrstrap für IPWRA durchführen\n(\n  b_IPWRA &lt;- boot(\n  data = darkmode,\n  statistic = IPWRA,\n  R = B\n  )\n)\n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = darkmode, statistic = IPWRA, R = B)\n\n\nBootstrap Statistics :\n    original       bias    std. error\nt1*  1.96847 -0.001270721   0.5960465\n\n\nWir berechnen die interessierenden Statistiken analog zu der Vorgehensweise in Kapitel 6.4.\n\n# Bootstrap-IPWRA-Schätzer des ATE\nmean(b_IPWRA$t)\n\n[1] 1.967199\n\n# Bootstrap-Standardfehler\nsd(b_IPWRA$t)\n\n[1] 0.5960465\n\n\n\n# 95%-Bootstrap-KI für den ATE\nboot.ci(b_IPWRA, type = \"bca\")\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 999 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = b_IPWRA, type = \"bca\")\n\nIntervals : \nLevel       BCa          \n95%   ( 0.787,  3.098 )  \nCalculations and Intervals on Original Scale\n\n\nDie Bootstrap-Schätzung des ATE mit IPWRA ist mit den Ergebnissen für die Bootstrap-Variante von \\(\\widehat{\\tau}^\\text{IPW}\\) vergleichbar, hat allerdings einen etwas kleineren Standardfehler und ist somit genauer.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbadie, Alberto, und Guido W. Imbens. 2008. „On the Failure of the Bootstrap for Matching Estimators.“ Econometrica. Journal of the Econometric Society 76 (6): 1537–57. https://doi.org/10.3982/ECTA6474.\n\n\nAbadie, Alberto, und Jann Spiess. 2022. „Robust Post-Matching Inference.“ Journal of the American Statistical Association 117 (538): 983–95. https://doi.org/10.1080/01621459.2020.1840383.\n\n\nAustin, P. 2011. „An Introduction to Propensity Score Methods for Reducing the Effects of Confounding in Observational Studies“. Multivariate Behavioral Research 46 (3): 399–424. https://doi.org/10.1080/00273171.2011.568786.\n\n\nAustin, Peter C., und Dylan S. Small. 2014. „The use of bootstrapping when using propensity-score matching without replacement: A simulation study.“ Statistics in Medicine 33 (24): 4306–19. https://doi.org/10.1002/sim.6276.\n\n\nAustin, Peter C., und Elizabeth A. Stuart. 2017. „Estimating the Effect of Treatment on Binary Outcomes Using Full Matching on the Propensity Score.“ Statistical Methods in Medical Research 26 (6): 2505–25. https://doi.org/10.1177/0962280215601134.\n\n\nBodory, Hugo, Lorenzo Camponovo, Martin Huber, und Michael Lechner. 2020. „The Finite Sample Performance of Inference Methods for Propensity Score Matching and Weighting Estimators.“ Journal of Business & Economic Statistics. https://doi.org/10.2139/ssrn.2731969.\n\n\nHainmueller, Jens. 2012. „Entropy Balancing for Causal Effects: A Multivariate Reweighting Method to Produce Balanced Samples in Observational Studies“. Political Analysis 20 (1): 25–46. https://doi.org/10.1093/pan/mpr025.\n\n\nHájek, J. 1971. „Comment on ‚An essay on the logical foundations of survey sampling‘ by Basu, D“. Foundations of Statistical Inference 236.\n\n\nHill, Jennifer, und Jerome P. Reiter. 2006. „Interval estimation for treatment effects using propensity score matching. Statistics in Medicine“. Statistics in Medicine 25 (13): 2230–56. https://doi.org/10.1002/sim.2277.\n\n\nHirano, Keisuke, Guido Imbens, und Geert Ridder. 2003. „Efficient Estimation of Average Treatment Effects Using the Estimated Propensity Score.“ Econometrica 71 (4): 1161–89. https://doi.org/10.1111/1468-0262.00442.\n\n\nImbens. 2016. „Matching on the Estimated Propensity Score.“ Econometrica 84 (2): 781–807. https://doi.org/10.3982/ecta11293.\n\n\nLove, Thomas. 2004. „Graphical display of covariate balance“. Presentation.\n\n\nRosenbaum, Paul R., und Donald R. Rubin. 1983. „The central role of the propensity score in observational studies for causal effects“. Biometrika 70 (1): 170–84. https://doi.org/10.1017/cbo9780511810725.016.\n\n\nWooldridge, Jeffrey. 2010. Econometric Analysis of Cross Section and Panel Data. Second edition. Cambridge, Massachusetts: MIT.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Matching</span>"
    ]
  },
  {
    "objectID": "Matching.html#footnotes",
    "href": "Matching.html#footnotes",
    "title": "6  Matching",
    "section": "",
    "text": "Siehe P. Austin (2011) für einen Überblick zu Balance-Statistiken.↩︎\nEine Normalisierung der Gewichte reduziert die Varianz des Schätzers, vgl. Hirano, Imbens, und Ridder (2003)↩︎\nSiehe Hájek (1971).↩︎\nEs handelt sich hierbei um einen Spezialfall von Matching anhand der Mahalanobis-Distanz.↩︎\nDieses Schema zielt auf eine Schätzung des ATT ab.↩︎\nDiese Werte wurden ad-hoc gewählt da sie zu einem guten Ergebnis führen.↩︎\nDie durch caliper implizierte Obergrenze ergibt sich als .25 * sd(fitted(darkmode_ps_logit))).↩︎\ntype = \"bca\" (bias-corrected accelerated) ist eine gängige Implementierung für die Berechnung des Konfidenz-Intervalls.↩︎\nBspw. kann eine falsche funktionale Form bei logistischer Regression eine verzerrte Schätzung von Propensity Scores und damit eine unzureichende Balance bedeuten.↩︎",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Matching</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html",
    "href": "FixedEffects.html",
    "title": "7  Panel-Daten",
    "section": "",
    "text": "7.1 Pooled Regression und unbeobachtbare Heterogenität\nEin Panel-Datensatz enthält Beobachtungen von \\(n\\) Einheiten für (bis zu) \\(T\\) Zeitpunkte, wobei \\(t=1,\\dots,T\\). Betrachte das Panel-Modell\nwobei \\(U_i\\) unbeobachtete und \\(X_i\\) beobachtete, zeitlich-invariante Heterogenitäten zwischen den Beobachtungseinheiten \\(i=1,\\dots,n\\) sind. Wie zuvor ist \\(B_{it}\\) die Behandlungsvariable und \\(\\beta_1\\) der (für alle Beobachtungseinheiten identische) interessierende kausale Effekt einer Veränderung von \\(B_{it}\\) auf \\(Y_{it}\\).\nAngenommen wir beobachten \\(Y_{it}\\) und \\(B_{it}\\) für \\(T=1\\), also für eine Periode. Bei Korrelation zwischen den unbeobachtbaren zeit-invarianten Effekten \\(U_i\\) und der Behandlungsvariable \\(B_{it}\\) kann der kausale Effekt \\(\\beta_1\\) nicht identifiziert werden. Diese Situation ist in Abbildung 7.1 dargestellt.\nFE_dag_single_period\n\n\n\nU\n\nU\ni\n\n\n\nX\n\nX\ni\n\n\n\nU-&gt;X\n\n\n\n\n\nB\n\nB\nt=1\n\n\n\nU-&gt;B\n\n\n\n\n\nY\n\nY\nt=1\n\n\n\nU-&gt;Y\n\n\n\n\n\nX-&gt;B\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\nB-&gt;Y\n\n\n\n\n\n\n\n\nAbbildung 7.1: Backdoors durch beobachtete und unbeobachtete Variablen\nAbbildung 7.1 zeigt Backdoors durch die \\(U_i\\), die wir mit einer “naiven” KQ-Schätzung der fehlspezifizierten Regression \\[\\begin{align}\n  Y_{it} = \\beta_0 + \\beta_1 B_{it} + \\beta_2 X_i + \\varepsilon_{it},\\quad t=1,\\label{eq:femodelfail}\n\\end{align}\\] mit \\(\\varepsilon_{it} = U_i + \\epsilon_{it}\\) nicht schließen können.1\nWir betrachten nun eine Generalisierung von Abbildung 7.1 für \\(T=2\\) Perioden, dargestellt in Abbildung 7.2.\nFE_dag2\n\n\n\nU\n\nU\ni\n\n\n\nX\n\nX\ni\n\n\n\nU-&gt;X\n\n\n\n\n\nB1\n\nB\nt=1\n\n\n\nU-&gt;B1\n\n\n\n\n\nY1\n\nY\nt=1\n\n\n\nU-&gt;Y1\n\n\n\n\n\nB2\n\nB\nt=2\n\n\n\nU-&gt;B2\n\n\n\n\n\nY2\n\nY\nt=2\n\n\n\nU-&gt;Y2\n\n\n\n\n\nX-&gt;B1\n\n\n\n\n\nX-&gt;Y1\n\n\n\n\n\nX-&gt;B2\n\n\n\n\n\nX-&gt;Y2\n\n\n\n\n\nB1-&gt;Y1\n\n\n\n\n\nB1-&gt;B2\n\n\n\n\n\nB2-&gt;Y2\n\n\n\n\n\n\n\n\nAbbildung 7.2: Panel-Design mit Backdoors durch beobachtete und unbeobachtete zeit-invariante Variablen\nDer in Abbildung 7.2 gezeigte Zusammenhang führt (idealerweise) zwar zu einer Verdoppelung des Beobachtungsumfangs, jedoch besteht weiterhin das in Abbildung 7.1 gezeigte Endogenitätsproblem, falls die Regression \\(\\eqref{eq:femodelfail}\\) nun anhand einer Zusammenlegung (Pooling) aller Beobachtungen für \\(t\\in\\{1,2\\}\\) geschätzt wird:2 Die unbeobachteten zeit-invarianten Einflüsse \\(U_i\\) verursachen auch für Periode \\(t=2\\) Backdoor-Pfade.\nIn diesem Kapitel betrachten wir Panel-Verfahren, welche den kausalen Effekt in Abbildung 7.2 und Verallgemeinerungen hiervon schätzen können. Bevor wir diese Methoden betrachten, veranschaulichen wir die verzerrte Schätzung eines Behandlungseffekts mit Pooled Regression in Modell \\(\\eqref{eq:femodelfail}\\) bei unbeobachtbaren Heterogenitäten für einen simulierten Datensatz paneldata.csv. Der Datensatz enthält Beobachtungen von \\(n=12\\) Einheiten zu \\(T=8\\) Perioden. Alle Einheiten weisen unbeobachtbare zeit-invariante Heterogenitäten auf, die mit \\(B_{it}\\) korellieren. Der wahre Behandlungseffekt beträgt \\(\\beta_1 = -1\\).3\nWir lesen zunächst den Datensatz ein und selektieren die benötigten Variablen.\n# Datensatz 'paneldata.csv' einlesen\npaneldata &lt;- read_csv(\"datasets/paneldata.csv\") %&gt;% \n  select(X, Y, ID, time, col)\n# Panel-Dimensionen bestimmen\npaneldata %&gt;%\n  summarise(\n    N = unique(ID) %&gt;% length(),\n    T = unique(time) %&gt;% length()\n  )\n\n# A tibble: 1 × 2\n      N     T\n  &lt;int&gt; &lt;int&gt;\n1    12     8\nMit der Funktion plm::is.pbalanced() überprüfen wir, ob im Panel-Datensatz für alle beobachteten Einheiten die gleiche Anzahl an Beobachtungsperioden vorliegt (balanced panel).4\nlibrary(plm)\n\n# Datensatz balanced?\nis.pbalanced(\n  x = paneldata, \n  index = c(\"ID\", \"time\")\n)\n\n[1] TRUE\nZunächst schätzen wir eine Pooled Regression für die ersten beiden Zeitperioden, basierend auf einem entsprechend gefilterten Datensatz.5\n# Subsetting der Daten für 2 Perioden (t = {1, 2})\npaneldata_T2 &lt;- paneldata %&gt;% \n  filter(\n    dplyr::between(time, 1, 2)\n  )\nFür die Schätzung von \\(\\eqref{eq:femodelfail}\\) nutzen wir fixest::feols().\nlibrary(fixest)\n\n# Naive KQ-Schätzung für t = {1, 2}\npanel_KQ &lt;- feols(\n  fml = Y ~ X, \n  data = paneldata_T2\n)\n\n# Statistische Zusammenfassung\nsummary(panel_KQ)\n\nOLS estimation, Dep. Var.: Y\nObservations: 24\nStandard-errors: IID \n            Estimate Std. Error  t value   Pr(&gt;|t|)    \n(Intercept) -2.50547   1.481150 -1.69157 1.0485e-01    \nX            3.80692   0.194202 19.60295 2.0252e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 3.28785   Adj. R2: 0.943388\nDie Schätzung von \\(\\beta_1\\) ist 3.81 und weist auf eine deutliche Verzerrung hin. Wir illustrieren die Problematik in Abbildung 7.3, in dem wir die für die Regression verwendeten Daten (Kreise) sowie die Beobachtungen späterer Perioden (Kreuze) nach Gruppenzugehörigkeit einfärben und die Schätzung der Pooled Regression abtragen.\nlibrary(cowplot)\n\n# Plot: Naiver KQ-Schätzer für t = 1, 2\nggplot(\n  mapping = aes(x = X, y = Y)\n) +\n  geom_point(\n    data = paneldata %&gt;% \n      filter(time &gt; 2),\n    mapping = aes(color = col),\n    pch = 3,\n    show.legend = F\n  ) +\n  geom_point(\n    data = paneldata %&gt;% \n      filter(time %in% 1:2),\n    mapping = aes(color = col),\n    show.legend = F\n  ) +\n  # Naive KQ-Schätzung für t = 1, 2\n  geom_smooth(\n    data = paneldata %&gt;% \n      filter(time %in% 1),\n    method = \"lm\", \n    se = F,\n    col = \"black\"\n  ) +\n  scale_color_identity() +\n  theme_cowplot()\n\n\n\n\n\n\n\nAbbildung 7.3: paneldaten.csv – Pooled Regression für t = 1, 2\nAbbildung 7.3 zeigt einen negativen Verlauf des Zusammenhangs zwischen X und Y anhand der Variation der Beobachtungen innerhalb der farblich gekennzeichneten Gruppen. Dieser negative Zusammenhang kann aufgrund der Endogenität von \\(X\\) nicht erfasst werden.\nEine Erweiturung der Regression auf sämtliche Perioden (Pooling aller \\(n\\times T = 12 \\times 8 = 96\\) Beobachtungen) erhöht lediglich die Präzision der Schätzung (geringerer Standardfehler von \\(\\widehat{\\beta}_1\\)), nicht aber die Endogenität, vgl. Abbildung 7.4.\n# Naive KQ-Schätzung für t = 1,...,8\npanel_KQ &lt;- feols(\n  fml = Y ~ X, \n  data = paneldata \n)\n\n# Statistische Zusammenfassung\nsummary(panel_KQ)\n\nOLS estimation, Dep. Var.: Y\nObservations: 96\nStandard-errors: IID \n            Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept) -1.45318   1.008859 -1.44042   0.15307    \nX            3.76470   0.134364 28.01868 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 4.63461   Adj. R2: 0.891928\n# Plot: Naiver KQ-Schätzer für t = 1,...,8\nggplot(\n  data = paneldata,\n  mapping = aes(x = X, y = Y)\n) +\n  geom_point(\n    mapping = aes(color = col),\n    show.legend = F\n  ) +\n  # Pooled Schätzung\n  geom_smooth(\n    data = paneldata,\n    method = \"lm\", \n    se = F,\n    col = \"black\"\n  ) +\n  scale_color_identity() +\n  theme_cowplot()\n\n\n\n\n\n\n\nAbbildung 7.4: paneldaten.csv – Pooled Regression für t = 1, …, 8",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html#sec-panel-uh",
    "href": "FixedEffects.html#sec-panel-uh",
    "title": "7  Panel-Daten",
    "section": "",
    "text": "\\[\\begin{align}\n  Y_{it} = \\beta_0 + \\beta_1 B_{it} + \\beta_2 X_i + \\beta_3 U_i + \\epsilon_{it},\\label{eq:unobshetmodel}\n\\end{align}\\]",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html#regression-in-differenzen",
    "href": "FixedEffects.html#regression-in-differenzen",
    "title": "7  Panel-Daten",
    "section": "7.2 Regression in Differenzen",
    "text": "7.2 Regression in Differenzen\nWir betrachten erneut den in Abbildung 7.2 dargestellten DGP für \\(T=2\\) Zeitperioden. In dieser Situation können Backdoors durch die \\(U_i\\) anhand einer simplen Transformation von Modell \\(\\eqref{eq:femodel}\\) geschlossen werden: Regression der Zeit-Differenzen zwischen den Perioden \\(t=2\\) und \\(t=1\\), \\[\\begin{align}\n  \\Delta Y_{it} = \\beta_1 \\Delta B_{it} + e_{it}, \\qquad i=1,\\dots,n,\\qquad t=1,2 \\label{eq:femodeldiff},\n\\end{align}\\] wobei \\(\\Delta Y_{it} := Y_{i2} - Y_{i1}\\) und \\(\\Delta e_{it} := \\epsilon_{i2} - \\epsilon_{i1}\\) für \\(t=2\\). Beachte, dass \\(\\Delta U_i=\\Delta X_i=0\\). Differenzieren der Komponenten führt zu einem Modell, in dem weder für (beobachtbare) \\(X_i\\) noch für (unbeobachtbare) \\(U_i\\) kontrolliert werden muss, damit \\(\\beta_1\\) identifiziert werden kann.6 Der Behandlungseffekt \\(\\beta_1\\) kann mit KQ geschätzt werden.7\nZur Transformation der Regressoren in fixest::feols() verwenden wir den Operator d(). Dieser benötigt die im Argument panel.id als Formel spezifizierten Identifikationsvariablen für Einheiten (ID) und Zeitpunkte (time).\n\n# Panel-Schätzer: KQ-Regression in Differenzen\npanel_diff &lt;- feols(\n  fml = d(Y) ~ d(X) - 1, \n  data = paneldata %&gt;% \n      filter(\n        dplyr::between(time, 1, 2)\n      ),\n  panel.id = ~ ID + time\n)\n\n# Statistische Zusammenfassung\nsummary(panel_diff)\n\nOLS estimation, Dep. Var.: d(Y, 1)\nObservations: 12\nStandard-errors: Clustered (ID) \n        Estimate Std. Error  t value  Pr(&gt;|t|)    \nd(X, 1) -1.03205   0.326838 -3.15767 0.0091166 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.907432   Adj. R2: 0.509923\n\n\nDie Schätzung anhand der Regression in Differenzen liegt nahe beim wahren Behandlungseffekt \\(\\beta_1 = -1\\). Abbildung Abbildung 7.5 zeigt die ersten Differenzen der Daten und den mit KQ geschätzten Zusammenhang.\n\n# Transformation zu Differenzen\npaneldata_diff &lt;- paneldata %&gt;% \n  mutate(\n    DeltaX = X - dplyr::lag(X),\n    DeltaY = Y - dplyr::lag(Y)\n  ) %&gt;%\n  drop_na()\n\n# Plot: KQ-Schätzer für Differenzen  \n  ggplot(\n    mapping = aes(x = DeltaX, y = DeltaY)\n  ) + \n    geom_point(\n      data = paneldata_diff %&gt;% \n        filter(time &gt; 2),\n      mapping = aes(color = col),\n      pch = 3,\n      show.legend = F\n    ) +\n    geom_point(\n      data = paneldata_diff %&gt;% \n        filter(time == 2),\n      mapping = aes(color = col),\n      show.legend = F\n    ) +\n  geom_smooth(\n    data = paneldata_diff %&gt;% \n      filter(time == 2),\n    method = \"lm\", \n    se = F,\n    color = \"black\"\n  ) + \n  scale_color_identity() +\n  theme_cowplot()\n\n\n\n\n\n\n\nAbbildung 7.5: paneldaten.csv – Regression in Differenzen für t = 2\n\n\n\n\n\nWie bei Pooling können wir den Differenzen-Schätzer für den gesamten Datensatz berechnen.\n\n# Panel-Schätzer: KQ-Regression in Differenzen\npanel_diff &lt;- feols(\n  fml = d(Y) ~ d(X) - 1, \n  data = paneldata,\n  panel.id = ~ ID + time\n)\n\n# Statistische Zusammenfassung\nsummary(panel_diff)\n\nOLS estimation, Dep. Var.: d(Y, 1)\nObservations: 84\nStandard-errors: Clustered (ID) \n         Estimate Std. Error  t value   Pr(&gt;|t|)    \nd(X, 1) -0.982042   0.135217 -7.26269 1.6178e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 1.12641   Adj. R2: 0.571235\n\n\nBeachte, dass der Standardfehler der Schätzers etwas größer ist als für den KQ-Schätzer in der Pooled Regression. Gründe hierfür sind der Verlust von \\(12\\) Beobachtungen bei der Bildung der \\(T-1 = 7\\) Differenzen und die standardmäßige Verwenudung von cluster-robusten Standardfehlern, siehe auch Kapitel 7.5.\n\n# Plot: KQ-Schätzer in Differenzen (alle t)\nggplot(\n  data = paneldata_diff,\n  mapping = aes(x = DeltaX, y = DeltaY)\n) + \n  geom_point(\n    color = \"gray\",\n    show.legend = F\n  ) +\n  geom_point(\n    mapping = aes(color = col),\n    show.legend = F\n  ) +\n  geom_smooth(\n    method = \"lm\", \n    se = F,\n    color = \"black\"\n  ) + \n  scale_color_identity() +\n  theme_cowplot()\n\n\n\n\n\n\n\nAbbildung 7.6: paneldaten.csv – Regression in Differenzen für t = 2, …, 8",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html#fixed-effects-regression",
    "href": "FixedEffects.html#fixed-effects-regression",
    "title": "7  Panel-Daten",
    "section": "7.3 Fixed-Effects-Regression",
    "text": "7.3 Fixed-Effects-Regression\nDie KQ-Schätzung der Regression in Differenzen hat den Nachteil, dass die Koeffizienten von einheiten-spezifischen Variablen nicht geschätzt werden können. Weiterhin impliziert die Differenzbildung einen Verlust des Beobachtungsumfangs bei der Schätzung des kausalen Effekts.8 Für den Datensatz paneldata.csv verlieren wir \\(1/8\\) der Stichprobe. Abhängig von der empirischen Fragestellung und der Datenverfügbarkeit (Verhältnis von \\(T\\) und \\(n\\)) kann Fixed-Effects-Regression eine nützliche Alternative zu Regression in Differenzen sein.\nWir betrachten erneut Modell \\(\\eqref{eq:unobshetmodel}\\) und definieren \\[\\begin{align*}\n  \\alpha_i = \\beta_0 + \\beta_3 U_i.\n\\end{align*}\\] Nach einsetzen in \\(\\eqref{eq:unobshetmodel}\\) erhalten wir das Modell \\[\\begin{align}\n  Y_{it} = \\alpha_i + \\beta_1 B_{it} + \\beta_2 X_i + \\epsilon_{it} \\label{eq:femodel},\n\\end{align}\\] mit einheiten-spezifischen Konstanten (“feste Effekte”) \\(\\alpha_i\\) für \\(i=1,\\dots,n\\), die als individuelle Achsenabschnitte nterpretieren werden können. Das Modell \\(\\eqref{eq:femodel}\\) wird daher auch als Fixed-Effects-Modell bezeichnet.9\n\n7.3.1 Within- und LSDV-Schätzer\nFür die Vermeidung von Backdoors durch die \\(\\alpha_i\\) subtrahieren wir die einheiten-spezifischen Mittelwerte von den Komponenten (Within-Transformation)10, \\[\\begin{align}\n  Y_{it} - \\overline{Y}_i =&\\, (\\alpha_i - \\overline{\\alpha}_i) + \\beta_1 (B_{it} - \\overline{B}_i) + \\beta_2 (X_i - \\overline{X}_i) + (\\epsilon_{it} - \\overline{\\epsilon}_i)\\notag\\\\\n  \\tilde Y_{it} =&\\, \\beta_1 \\tilde B_{it} + \\tilde\\epsilon_{it}.\\label{eq:fewithin}\n\\end{align}\\] Der Within-Schätzer von \\(\\beta_1\\) ist der KQ-Schätzer in \\(\\eqref{eq:fewithin}\\). Dieser Schätzer nutzt die Variabilität innerhalb der Beobachtungseinheiten über die Zeit, um die Koeffizienten der unabhängigen Variablen zu schätzen. Ähnlich wie für den Differenzen-Schätzer eliminieren die Mittelwert-Differenzen \\(\\alpha_i - \\overline{\\alpha}_i=0\\) und \\(X_i - \\overline{X}_i=0\\) den Einfluss zeit-invarianter Variablen.\nDas Modell \\(\\eqref{eq:femodel}\\) kann weiterhin als eine Regression mit \\(n-1\\) Dummy-Variablen und einer Konstante geschrieben werden, \\[\\begin{align}\n  Y_{it} = \\beta_0 + \\beta_2 B_{it} + \\beta_2 X_i  + \\gamma_2 D^{(2)}_i + \\gamma_3 D^{(3)}_i + \\cdots + \\gamma_n D^{(n)}_i + \\epsilon_{it} \\label{eq:drmodel}.\n\\end{align}\\] Die Darstellung \\(\\eqref{eq:drmodel}\\) hat \\(n\\) verschiedene Achsenabschnitte – einen für jede Beobachtungseinheit – und kann ebenfalls mit KQ geschätzt werden.11 Der KQ-Schätzer ergibt für die Modelle \\(\\eqref{eq:femodel}\\) und \\(\\eqref{eq:drmodel}\\) numerisch äquivalente Schätzungen von \\(\\beta_1\\), wenn \\(X_i\\) in der Dummy-Regression ausgelassen wird.12 Die Schätzung von \\(\\eqref{eq:drmodel}\\) mit KQ wird in der Literatur auch als Least Squares Dummy Variables (LSDV) Regression bezeichnet.\nBeachte, dass die Schätzung der Koeffizienten beobachtbarer zeitlich konstanter Regressoren wie \\(X_{i}\\) lediglich in Modell \\(\\eqref{eq:drmodel}\\) möglich ist.\nFixed-Effects-Regressionen können mit fixest::feols() geschätzt werden.13 Je nach Spezifikation des Formula-Arguments (fml) wird ein effizienter Algorithmus für die entsprechende Transformation von \\(\\eqref{eq:femodel}\\) angwandt. Für paneldata.csv erhalten wir mit fml = Y ~ X | ID per Referenz des Indikators ID eine Variante des Within-Schätzers.\n\n# Fixed-Effects-Schätzung\npanel_FE &lt;- feols(\n  fml = Y ~ X | ID,  \n  data = paneldata\n)\n\n# Statistische Zusammenfassung\nsummary(panel_FE)\n\nOLS estimation, Dep. Var.: Y\nObservations: 96\nFixed-effects: ID: 12\nStandard-errors: Clustered (ID) \n  Estimate Std. Error  t value   Pr(&gt;|t|)    \nX -1.04507    0.10473 -9.97865 7.5526e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.746006     Adj. R2: 0.996829\n                 Within R2: 0.602694\n\n\nDie Zusammenfassung der Schätzung zeigt einen signifikanten Koeffizienten, der mit einer Schätzung von -1.05 nahe beim wahren Wert von \\(\\beta_1 = -1\\) liegt. Die geschätzten einheiten-spezifischen Effekte können mitfixest::fixef()\\ ausgelesen werden.\n\n# Geschätzte Fixed Effects (Einheiten) auslesen\nfixest::fixef(panel_FE)\n\n$ID\n        1         2         3         4         5         6         7         8 \n 3.814550  7.149097 12.716507 15.319130 23.458442 28.239634 33.659734 35.729516 \n        9        10        11        12 \n41.701817 47.911623 55.044052 59.445967 \n\nattr(,\"class\")\n[1] \"fixest.fixef\" \"list\"        \nattr(,\"exponential\")\n[1] FALSE\n\n\nMit fml = Y ~ X + factor(ID) erfolgt eine Schätzung der Dummy-Regression \\(\\eqref{eq:drmodel}\\) mit \\(n-1=11\\) Dummies. Der Referenzeinheit ist ID == 1. Wir sehen, dass der geschätzte Koeffizient von \\(X\\) mit dem Ergebnis des Within-Schätzers übereinstimmt.\n\n# LSDV-Schätzung\npanel_LSDV &lt;- feols(\n  fml = Y ~ X + factor(ID),  \n  data = paneldata\n)\n\n# Statistische Zusammenfassung\nsummary(panel_LSDV)\n\nOLS estimation, Dep. Var.: Y\nObservations: 96\nStandard-errors: IID \n             Estimate Std. Error   t value   Pr(&gt;|t|)    \n(Intercept)   3.81455   0.298907  12.76164  &lt; 2.2e-16 ***\nX            -1.04507   0.093136 -11.22082  &lt; 2.2e-16 ***\nfactor(ID)2   3.33455   0.427925   7.79236 1.6832e-11 ***\nfactor(ID)3   8.90196   0.446770  19.92516  &lt; 2.2e-16 ***\nfactor(ID)4  11.50458   0.487840  23.58267  &lt; 2.2e-16 ***\nfactor(ID)5  19.64389   0.552272  35.56923  &lt; 2.2e-16 ***\nfactor(ID)6  24.42508   0.601629  40.59826  &lt; 2.2e-16 ***\nfactor(ID)7  29.84518   0.719118  41.50248  &lt; 2.2e-16 ***\nfactor(ID)8  31.91497   0.753382  42.36225  &lt; 2.2e-16 ***\nfactor(ID)9  37.88727   0.833968  45.43012  &lt; 2.2e-16 ***\nfactor(ID)10 44.09707   0.910884  48.41127  &lt; 2.2e-16 ***\nfactor(ID)11 51.22950   1.049050  48.83416  &lt; 2.2e-16 ***\nfactor(ID)12 55.63142   1.128472  49.29801  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.746006   Adj. R2: 0.996829\n\n\n\n\n7.3.2 Zeit-Fixed-Effects\nNeben zeit-invarianten Heterogenitäten zwischen den Beobachtungseinheiten können beobachtbare und unbeobachtbare Einflüsse vorliegen, die nicht zwischen den Einheiten, jedoch über die Zeit variieren. Ein DGP mit solchen zeitabhängigen Heterogenitäten ist in Abbildung 7.7 für \\(T=2\\) dargestellt.14\n\n\n\n\n\n\n\n\nFE_dag3\n\n\n\nU1\n\nU\nt=1\n\n\n\nU2\n\nU\nt=2\n\n\n\nU1-&gt;U2\n\n\n\n\n\nX1\n\nX\nt=1\n\n\n\nU1-&gt;X1\n\n\n\n\n\nB1\n\nB\nt=1\n\n\n\nU1-&gt;B1\n\n\n\n\n\nY1\n\nY\nt=1\n\n\n\nU1-&gt;Y1\n\n\n\n\n\nX2\n\nX\nt=2\n\n\n\nU2-&gt;X2\n\n\n\n\n\nB2\n\nB\nt=2\n\n\n\nU2-&gt;B2\n\n\n\n\n\nY2\n\nY\nt=2\n\n\n\nU2-&gt;Y2\n\n\n\n\n\nX1-&gt;X2\n\n\n\n\n\nX1-&gt;B1\n\n\n\n\n\nX1-&gt;Y1\n\n\n\n\n\nX2-&gt;B2\n\n\n\n\n\nX2-&gt;Y2\n\n\n\n\n\nB1-&gt;Y1\n\n\n\n\n\nB1-&gt;B2\n\n\n\n\n\nB2-&gt;Y2\n\n\n\n\n\n\n\n\nAbbildung 7.7: Panel-Design mit Backdoors durch beobachtete und unbeobachtete zeitabhängige Variablen\n\n\n\n\n\nFür beobachtbare zeitabhängige Backdoor-Variablen \\(X_t\\) kann durch Aufnahme dieser in die Regression \\(\\eqref{eq:femodel}\\) kontrolliert werden. Analog zum Fixed-Effects-Ansatz mit einheiten-spezifischen Konstanten können Backdoors durch unbeobachtbare zeitabhängige Einflüsse \\(U_t\\) durch Kontrolle für perioden-spezifische Dummies \\(D_t^{(t)}\\) (Time Fixed Effects) vermieden werden. Das Modell lautet dann\n\\[\\begin{align*}\n  Y_{it} = \\beta_0 + \\beta_1 B_{it} + \\beta_2 X_t + \\lambda_2 D_t^{(2)} + \\cdots + \\lambda_T D_t^{(T)} + \\epsilon_{it}.\n\\end{align*}\\]\nIn empirischen Anwendung ist es häufig plausibel, für zeit- und einheiten-spezifische Effekte zu kontrollieren. Der entsprechende Regressionsansatz wird als Two Way Fixed Effects (TWFE) bezeichnet.\nEin TWFE-Modell für paneldata.csv kann mit feols() leicht unter Angabe der Identifikationsvariable für die Zeitperioden (time) innerhalb des fml-Arguments geschätzt werden.\n\n# TWFE-Schätzung\npanel_TWFE &lt;- feols(\n  fml = Y ~ X | ID + time,  \n  data = paneldata\n)\n\n# Statistische Zusammenfassung\nsummary(panel_TWFE)\n\nOLS estimation, Dep. Var.: Y\nObservations: 96\nFixed-effects: ID: 12,  time: 8\nStandard-errors: Clustered (ID) \n  Estimate Std. Error  t value   Pr(&gt;|t|)    \nX -1.01411   0.096129 -10.5495 4.3209e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.655695     Adj. R2: 0.997325\n                 Within R2: 0.636218\n\n\n\n# Geschätzte Fixed Effects (Einheiten + Zeit) auslesen\nfixest::fixef(panel_TWFE)\n\n$ID\n        1         2         3         4         5         6         7         8 \n 3.608414  6.893444 12.445006 15.020731 23.126151 27.884480 33.255238 35.311437 \n        9        10        11        12 \n41.252680 47.433690 54.515757 58.889276 \n\n$time\n          1           2           3           4           5           6 \n 0.00000000 -0.16836639  0.84624725  0.09109152  0.45843997 -0.38103581 \n          7           8 \n 0.24023573  0.31186366 \n\nattr(,\"class\")\n[1] \"fixest.fixef\" \"list\"        \nattr(,\"references\")\n  ID time \n   0    1 \nattr(,\"exponential\")\n[1] FALSE\n\n\n\n\n\n\n\n\nKey Facts zu Fixed-Effects-Regression\n\n\n\n\nEin Fixed-Effects-Designs betrachten unbeobachtete, mit den erklärenden Variablen korrelierte Heterogenitäten als konstante parameter. Korrigieren für diese Heterogenitäten ist Voraussetzung für eine verzerrungsfreie Schätzung kausaler Effekte.\nFixed-Effects-Schätzer schließen Backdoors aufgrund von Heterogenitäten zwischen Beobachtungseinheiten die über die Zeit konstant sind (einheiten-spezifische Effekte) und/oder für Heterogenitäten, die identisch für die Beobachtungseinheiten sind, jedoch über die Zeit variieren (Zeit-Effekte):\n\nKQ nach der Within-Transformation (Within-Schätzer) ist erwartungstreu und konsistent, solange die erklärenden Variablen zeitlich unkorreliert mit den Fehlertermen sind.\nLSDV-Regression ist eine Variante die Backdoors durch unbeobachtbare Heterogenitäten mit Dummy-Variablen schließt. In einer LSDV-Regression können die Koeffizienten zeitlich konstanter Variablen geschätzt werden.\n\nStatistische Inferenz für Fixed-Effects-Schätzer erfolgt anhand einer Approximation der asymptotischen Normalverteilung. Da die Fehlerterme heteroskedastisch und/oder über die Zeit korreliert sein können, sollten Cluster-robuste Standardfehler verwendet werden, vgl. Kapitel 7.5.\nFixed-Effects-Modelle können in R mit dem Paketen fixest oder plm berechnet werden.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html#random-effects",
    "href": "FixedEffects.html#random-effects",
    "title": "7  Panel-Daten",
    "section": "7.4 Random Effects",
    "text": "7.4 Random Effects\nDer Fixed-Effects-Ansatz behandelt die einheiten-spezifischen Effekte \\(\\alpha_i\\) in Modell \\(\\eqref{eq:femodel}\\) als konstante Parameter, für die korrigiert oder kontrolliert werden muss. Der Random-Effects-Ansatz betrachtet die \\(\\alpha_i\\) als Zufallsvariablen mit einer identischen Verteilung, unter der Annahme, dass die \\(\\alpha_i\\) nicht mit den erklärenden Variablen korellieren.15 Falls diese Annahmen erfüllt sind, ist der Random-Random-Effects-Schätzer effizienter als der Fixed-Effects-Schätzer: Der mittlere quadratische Fehler der Schätzung ist geringer.16\nDas einfache Random-Effects-Modell notieren wir als \\[\\begin{align*}\n  Y_{it} =&\\, \\beta_0 + \\beta_1 B_{it} + \\varepsilon_{it},\n\\end{align*}\\] wobei sich der Fehlerterm \\(\\varepsilon_{it}\\) aus dem zufälligen individuellen Effekt \\(\\alpha_i\\) und dem unabhängigen Fehler \\(\\epsilon_{it}\\) zusammensetzt, \\[\\begin{align*}\n  \\varepsilon_{it} = \\alpha_i + \\epsilon_{it}.\n\\end{align*}\\]\nFür ein Beispiel simulieren wir Daten gemäß der Vorschrift \\[\\begin{align}\n  Y_{it} = \\alpha_i + \\beta B_{it} + \\epsilon_{it}\\label{eq:resim}\n\\end{align}\\] und wählen \\[\\begin{align*}\n  & \\alpha_i \\overset{u.i.v}{\\sim} N(0,2.5^2), \\\\\n  & \\beta_1 = -1,\\\\\n  & B_{it} \\sim N(0,1),\\\\\n  & \\epsilon_{it} \\overset{u.i.v}{\\sim} N(0,0.75^2).\n\\end{align*}\\] Wie in paneldata.csv erzeugen wir Daten für \\(n=12\\) Individuen, die zu \\(T=8\\) Zeitperioden beobachtet werden. Mit diesen Komponenten wird die Outcome-Variable \\(Y_{it}\\) wie in \\(\\eqref{eq:resim}\\) generiert. Der nachstehende Code erzeugt die Daten als Matrizen B und Y, die anschließend in ein langes Datenformat (tibble) umgewandelt werden.\n\nlibrary(plm)\n\nset.seed(1234)\n\n# Parameter\nn &lt;- 12  # Individuen\nm &lt;- 8   # Perioden\nbeta &lt;- -1 # Behandlungseffekt\nsigma_alpha &lt;- 2.5 # SD für RE\nsigma_epsilon &lt;- 0.75 # SD für Fehler\n\n# Random Effects\nalpha &lt;- rnorm(n, mean = 0, sd = sigma_alpha)\n\n# Matrizen\nB &lt;- matrix(NA, nrow = m, ncol = n)\nY &lt;- matrix(NA, nrow = m, ncol = n)\n\n# Simulation\nfor (i in 1:n) {\n  for (t in 1:m) {\n    B[t, i] &lt;- rnorm(1, mean = 0, sd = 1)\n    epsilon_it &lt;- rnorm(1, mean = 0, sd = sigma_epsilon)\n    Y[t, i] &lt;- alpha[i] + beta * B[t, i] + epsilon_it\n  }\n}\n\n# tibble erzeugen\nRE_paneldata &lt;- tibble(\n  id = factor(rep(1:n, each = m)),\n  time = rep(1:m, times = n),\n  B = as.vector(B),\n  Y = as.vector(Y)\n)\n\nFür die Anpassung des Random-Effect-Schätzers an den simulierten Datensatz RE_paneldata nutzen wir plm::plm() mit model = \"random\". Mit effect = \"individual\" legen wir einheiten-spezifische Random Effects fest.17\n\n# Random-Effects-Modell anpassen\npanel_RE &lt;- plm(\n  formula = Y ~ B, \n  data = RE_paneldata, \n  index = c(\"id\", \"time\"),\n  effect = \"individual\",\n  model = \"random\"\n)\n\n# Statistische Zusammenfassung\nsummary(panel_RE)\n\nOneway (individual) effect Random Effect Model \n   (Swamy-Arora's transformation)\n\nCall:\nplm(formula = Y ~ B, data = RE_paneldata, effect = \"individual\", \n    model = \"random\", index = c(\"id\", \"time\"))\n\nBalanced Panel: n = 12, T = 8, N = 96\n\nEffects:\n                 var std.dev share\nidiosyncratic 0.5221  0.7226  0.13\nindividual    3.4801  1.8655  0.87\ntheta: 0.8643\n\nResiduals:\n     Min.   1st Qu.    Median   3rd Qu.      Max. \n-2.019439 -0.351116  0.017785  0.420719  2.109010 \n\nCoefficients:\n             Estimate Std. Error  z-value Pr(&gt;|z|)    \n(Intercept) -1.156573   0.552747  -2.0924   0.0364 *  \nB           -0.996175   0.075859 -13.1320   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    143.86\nResidual Sum of Squares: 50.753\nR-Squared:      0.64721\nAdj. R-Squared: 0.64346\nChisq: 172.45 on 1 DF, p-value: &lt; 2.22e-16\n\n\nDie Schätzung zeigt eine gute Anpassung an die Daten und der geschätzte Behandlungseffekt liegt mit -0.996 nahe am wahren Koeffizienten \\(\\beta_1 = -1\\).\nMit plm::ranef() erhalten wir Differenzen der geschätzten einheiten-spezifischen Effekte vom geschätzten Erwartungswert (Intercept).\n\n# Gesch. Random Effects auslesen:\n# Differenzen zur Konstante (Intercept)\nranef(panel_RE)\n\n          1           2           3           4           5           6 \n-1.92217199  1.24364147  3.27470045 -4.12524574  2.00235610  2.71903482 \n          7           8           9          10          11          12 \n-0.17492965 -0.50237866  0.01435925 -1.03252985  0.16092971 -1.65776590 \n\n\nFür die grafische Darstellung der Schätzung berechnen wir zunächst mit fitted() die angepassten Werte. Für ein mit plm() geschätztes Random-Effects-Modell werden die individuellen Effekte von fitted() nicht berücksichtigt und müssen daher manuell hinzugefügt werden. Hierfür lesen wir zunächst den geschätzten Erwartungswert der gemeinsamen Verteilung \\(\\widehat{\\beta}_0\\) aus und addieren anschließend die von ranef() ausgegebenen Differenzen der individuellen Effekte gruppenweise.\n\n# Intercept\nhat_beta_0 &lt;- panel_RE$coefficients[1]\n\n# Gesch. Random Effects jeweils berücksichtigen\nRE_paneldata &lt;- RE_paneldata %&gt;%\n  mutate(\n    fitted_RE = \n      fitted(panel_RE) \n    + hat_beta_0 \n    + rep(ranef(panel_RE), each = m)\n  )\n\n\n# Daten und geschätztes RE-Modell plotten\nggplot(\n  data = RE_paneldata, \n  mapping = \n    aes(\n      x = B, \n      y = Y, \n      col = id\n    )\n) + \n  geom_point(show.legend = F) +\n  geom_line(\n    mapping = aes(y = fitted_RE, group = id), \n    show.legend = F\n  ) +\n  theme_cowplot()\n\n\n\n\n\n\n\nAbbildung 7.8: RE_paneldata – Random-Effects-Schätzung für simulierte Daten\n\n\n\n\n\n\n7.4.1 Verzerrung bei Endogenität\nDie Random-Effects-Methode findet bei kausalen Analyse in empirischen Anwendungen selten Anwendung, weil die Annahme von Unkorreliertheit mit den erklärenden Regressoren oft unplausibel ist. Falls diese Annahme (wie in den DAGs Abbildung 7.1 und Abbildung 7.2) verletzt ist, kann Random Effects die ensprechenden Backdoors nicht schließen: Der Random-Effects-Schätzer ist dann verzerrt und inkonsistent, ähnlich wie der naive KQ-Schätzer in einer Pooled Regression. Im nächsten Abschnitt untersuchen wir Konsequenzen dieser Eigenschaft anhand simulierter Daten.\nZur Illustration der Verzerrung des Random-Effects-Schätzers bei Endogenität von erklärenden Variablen verwenden wir erneut den anhand eines Fixed-Effects-DGPs simulierten Datensatz paneldata.csv.\n\n# Random-Effects-Schätzung für `paneldata`\npanel_RE &lt;- plm(\n  formula = Y ~ X, \n  effect = \"individual\",\n  model = \"random\",\n  index = c(\"ID\", \"time\"),  \n  data = paneldata\n)\n\n# Statistische Zusammenfassung\nsummary(panel_RE)\n\nOneway (individual) effect Random Effect Model \n   (Swamy-Arora's transformation)\n\nCall:\nplm(formula = Y ~ X, data = paneldata, effect = \"individual\", \n    model = \"random\", index = c(\"ID\", \"time\"))\n\nBalanced Panel: n = 12, T = 8, N = 96\n\nEffects:\n                 var std.dev share\nidiosyncratic 0.6437  0.8023 0.229\nindividual    2.1732  1.4742 0.771\ntheta: 0.811\n\nResiduals:\n   Min. 1st Qu.  Median 3rd Qu.    Max. \n-6.0355 -1.9888 -0.1651  1.9196  6.4374 \n\nCoefficients:\n            Estimate Std. Error z-value  Pr(&gt;|z|)    \n(Intercept) 18.34586    2.31566  7.9225 2.328e-15 ***\nX            0.77031    0.26346  2.9238  0.003458 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    818.14\nResidual Sum of Squares: 749.94\nR-Squared:      0.083362\nAdj. R-Squared: 0.07361\nChisq: 8.54862 on 1 DF, p-value: 0.0034579\n\n\nOffenbar weicht der Random-Effects-Schätzer des Effects von \\(X\\) auf \\(Y\\) deutlich vom wahren Parameter \\(\\beta_1 = -1\\) ab. Diese Abweichung ist auf die Endogenität von \\(X\\) zurückzuführen.\nDie nächste Grafik vergleicht die Schätzungen des Behandlungseffekts für den Datensatz paneldata.csv mit Pooling (schwarze Linie), Fixed Effects (farbige Linien) und Random Effects (gestrichelte schwarze Linie). Vorab erweitern wir paneldata um die angepassten Werte für die Fixed- und die Random-Effects-Schätzung in panel_FE und panel_RE.18\n\npaneldata &lt;- paneldata %&gt;% \n  mutate(\n    # Vorhergesagte Werte für FE-Schätzung\n    yhat_FE = fitted(panel_FE),\n    # Vorhergesagte Werte für RE-Schätzung\n    yhat_RE = predict(panel_RE)\n  )\n\n\nggplot(\n  data = paneldata,\n  mapping = aes(x = X, y = Y)\n) +\n  # Beoachtungen\n  geom_point(\n    mapping = aes(color = col), \n    show.legend = F\n  ) +\n  # Pooling\n  geom_smooth(\n    method = \"lm\", \n    se = F,\n    col = \"black\"\n  ) +\n  # Fixed Effects\n  geom_line(\n    mapping = aes(\n      y = yhat_FE,\n      group = ID,\n      col = col\n    ), \n    show.legend = F\n  ) +\n  # Random Effects\n  geom_line(\n    mapping = aes(y = yhat_RE), \n    lty = \"dashed\", \n    show.legend = F\n  ) +\n  theme_cowplot()\n\n\n\n\n\n\n\nAbbildung 7.9: paneldaten.csv – Vergleich von Schätzern bei Einheiten mit endogeneen Effekten\n\n\n\n\n\n\n\n\n\n\n\nKey Facts zu Random-Effects-Regression\n\n\n\n\nRandom-Effects-Ansätze basieren auf der Annahme, dass (unbeobachtbare) Heterogenitäten zufällig sind. Wir nehmen an, dass die unbeobachteten Heterogenitäten nicht mit den erklärenden Variablen korreliert sind. Letzteres führt zu inkonsistenten Schätzern!\nIteratives GLS oder MLE ermöglichen eine effizientere Schätzung des Random-Effects-Modells als Pooling oder Fixed-Effects-Schätzer, da sowohl die Variation innerhalb als auch zwischen den Beoabchtungseinheiten Einheiten genutzt wird.\nIn Random-Effects-Modellen können die Effekte zeitlich konstanter Variablen geschätzt werden, da die einheiten-spezifischen Effekte als zufällig betrachtet werden.\nUnter den skizzierten Annahmen sind Random-Effects-Schätzer asymptotisch normalverteilt. Für Inferenzstatistiken sollten cluster-robuste Standardfehler verwendet werden, vgl. Kapitel 7.5.\nRandom-Effects-Modelle können in R mit den Paketen plm geschätzt werden.\n\n\n\n\nInteraktive Illustration von Panel-Schätzern\nDie nachfolgende interaktive Illustration erlaubt einen Vergleich der in Abbildung 7.9 geplotteten geschätzten Regressionsfunktionen für paneldata.csv mit dem wahren DGP (Show truth) unter Reproduktion der in Abbildung 7.9 gezeigten Komponenten.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html#sec-crse",
    "href": "FixedEffects.html#sec-crse",
    "title": "7  Panel-Daten",
    "section": "7.5 Cluster-robuste Standardfehler",
    "text": "7.5 Cluster-robuste Standardfehler\nAufgrund der Zeit-Dimension bei Panel-Datensätzen ist es in vielen empirischen Anwendungen plausibel, dass die Fehlerterme der bisher betrachteten Modelle nicht unabhängig sind: Beobachtungen einer Einheit (auch Cluster genannt), wie z.B. Individuen, Firmen oder geografische Regionen sind oftmals über die Zeit oft korreliert. Solche Abhängigkeit zwischen dem Fehlern führen zu verzerrten Standardfehlern, wenn diese anhand von Formeln berechnet werden, die unter der Annahme von u.i.v. Fehlertermen hergeleitet wurden: Standardfehler für Schätzer, die u.i.v. Fehler annehmen, können die tatsächliche Varianz unterschätzen, was zu falsch-positiven19 Ergebnissen bei Signifikanztests für die Modell-Koeffizienten und damit ungültiger Inferenz hinsichtlich kausaler Effekte führen kann.\nSogenannte Cluster-robuste Standardfehler korrigieren für zeitliche Korrelation und Heteroskedatizität und ermöglichen konservative Schätzungen hinsichtlich der Variabilität von Koeffizientenschätzern. fixest::feols() berechnet standardmäßig Cluster-robuste Standardfehler, wenn Einheiten- oder Perioden-Variablen innerhalb der Formel (bspw. Y ~ X | ID + time) oder separat im Argument index (etwa panel.id = ~ ID + time) angegeben werden. Für die Identifikation der Cluster wird stets die zuerst genannte Variable (hier ID) herangezogen. Details der zu verwendenen Standardfehler können über das Argument vcov festgelegt werden, siehe ?feols für weitere Hinweise hierzu.\nFür den LSDV-Schätzer in Kapitel 7.3.1 erreichen wir clustering nach ID mit vcov = ~ ID.\n\n# LSDV mit cluster-robusten Standardfehlern\npanel_LSDV_clust &lt;- feols(\n  fml = Y ~ X + factor(ID),  \n  data = paneldata,\n  vcov = ~ ID\n)\n\npanel_LSDV_clust\n\nOLS estimation, Dep. Var.: Y\nObservations: 96\nStandard-errors: Clustered (ID) \n             Estimate Std. Error  t value   Pr(&gt;|t|)    \n(Intercept)   3.81455   0.112794 33.81859 1.8081e-12 ***\nX            -1.04507   0.111454 -9.37663 1.4011e-06 ***\nfactor(ID)2   3.33455   0.178290 18.70292 1.0959e-09 ***\nfactor(ID)3   8.90196   0.235355 37.82357 5.3305e-13 ***\nfactor(ID)4  11.50458   0.332206 34.63086 1.3958e-12 ***\nfactor(ID)5  19.64389   0.454236 43.24597 1.2323e-13 ***\nfactor(ID)6  24.42508   0.536553 45.52218 7.0294e-14 ***\nfactor(ID)7  29.84518   0.714216 41.78733 1.7935e-13 ***\nfactor(ID)8  31.91497   0.763123 41.82152 1.7776e-13 ***\nfactor(ID)9  37.88727   0.874952 43.30213 1.2149e-13 ***\nfactor(ID)10 44.09707   0.978638 45.05965 7.8608e-14 ***\nfactor(ID)11 51.22950   1.159967 44.16462 9.7910e-14 ***\nfactor(ID)12 55.63142   1.262214 44.07448 1.0012e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.746006   Adj. R2: 0.996829\n\n\nBeachte, dass die Standradfehler der meisten Koeffizienten in panel_LSDV_clust etwas größer sind, als für das in Kapitel 7.3.1 geschätzte Modell panel_LSDV.\nFür Schätzungen mitplm::plm() werden von summary() grundsätzlich Standardfehler unter Annahme homoskedastischer u.i.v. Fehler berechnet. Für Cluster-robuste Standardfehler muss ein entsprechender Schätzer im Argument vcov = vcovHC() übergeben werden. Mit cluster = \"group\" wird Korrelation innerhalb der Beobachtungseinheiten über die Zeit berücksichtigt.20 Für die Random-Effects-Schätzung in panel_RE erreichen wir dies wiefolgt.\n\n# Zusammenfassung RE-Schätzung mit clustered-SEs\nsummary(\n  object = panel_RE, \n  vcov = vcovHC(\n    x = panel_RE, \n    type = \"HC1\", \n    cluster = \"group\"\n  )\n)\n\nOneway (individual) effect Random Effect Model \n   (Swamy-Arora's transformation)\n\nNote: Coefficient variance-covariance matrix supplied: vcovHC(x = panel_RE, type = \"HC1\", cluster = \"group\")\n\nCall:\nplm(formula = Y ~ X, data = paneldata, effect = \"individual\", \n    model = \"random\", index = c(\"ID\", \"time\"))\n\nBalanced Panel: n = 12, T = 8, N = 96\n\nEffects:\n                 var std.dev share\nidiosyncratic 0.6437  0.8023 0.229\nindividual    2.1732  1.4742 0.771\ntheta: 0.811\n\nResiduals:\n   Min. 1st Qu.  Median 3rd Qu.    Max. \n-6.0355 -1.9888 -0.1651  1.9196  6.4374 \n\nCoefficients:\n            Estimate Std. Error z-value Pr(&gt;|z|)    \n(Intercept) 18.34586    4.53330  4.0469 5.19e-05 ***\nX            0.77031    0.46177  1.6682  0.09529 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    818.14\nResidual Sum of Squares: 749.94\nR-Squared:      0.083362\nAdj. R-Squared: 0.07361\nChisq: 2.78274 on 1 DF, p-value: 0.095285",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html#dynamische-modelle",
    "href": "FixedEffects.html#dynamische-modelle",
    "title": "7  Panel-Daten",
    "section": "7.6 Dynamische Modelle",
    "text": "7.6 Dynamische Modelle\nViele ökonomische und soziale Prozesse sind autoregressiv: Der Zustand einer Variable in der Vergangenheit beeinflusst ihren aktuellen Zustand. Bei der Modellierung von Outcome-Variablen in Panel-Designs kann es notwendig sein, diese Abhängigkeit zu berücksichtigen, um die Identifizierbarkeit kausaler Effekte zu gewährleisten. Dynamische Panelmodelle verwenden hierzu vergangene Werte (lags) der Outcome-Variable, \\(Y_{it-j}\\) mit \\(j&gt;0\\) als (zusätzliche) Regressoren. Ein einfaches dynamisches Panelmodell ist \\[\\begin{align}\n  Y_{it} = \\rho Y_{it-1} + \\beta_1 B_{it} + \\epsilon_{it}, \\label{eq:dynpanel}\n\\end{align}\\] wobei \\(Y_{it-1}\\) der Wert von \\(Y_{it}\\) in der Periode \\(t-1\\) ist, \\(0\\neq\\lvert\\rho\\rvert&lt;1\\), und \\(\\epsilon_{i,t}\\) ein u.i.v. Fehlerterm ist. In diesem Modell ist \\(Y_{it-1}\\) kausal für \\(Y_{it}\\).\nDie Verwendung dynamischer Modelle hat folgende Motivationen:\n\nPräzisere Schätzung: Berücksichtigen von gelaggten abhängigen Variablen ermöglicht die Modellierung einer zeitabhängigen Dynamik von \\(Y_{it}\\). Die Autokorellation und damit die Varianz der Fehlerterme kann reduziert werden, da ein Teil dieser zeitlichen Abhängigkeiten direkt modelliert wird. Dies kann die Präzision der Schätzung des kausalen Effekts \\(\\beta_1\\) verbessern, vgl. Abbildung 7.10.\n\n\n\n\n\n\n\n\n\nLDVOK2\n\n\n\nBt\n\nB\nt\n\n\n\nYt\n\nY\nt\n\n\n\nBt-&gt;Yt\n\n\n\n\n\nYtm1\n\nY\nt-1\n\n\n\nYtm1-&gt;Yt\n\n\n\n\n\n\n\n\nAbbildung 7.10: Kontrolle für vergangenen Wert verbessert Präzision\n\n\n\n\n\n\nVermeidung von Endogenität: Nichtberücksichtigen von relevanten gelaggten abhängigen Variablen führt zu verzerrten und inkonsistenten Schätzern, vgl. Abbildung 7.11.\n\n\n\n\n\n\n\n\n\nLDVOK1\n\n\n\nBt\n\nB\nt\n\n\n\nYt\n\nY\nt\n\n\n\nBt-&gt;Yt\n\n\n\n\n\nV\n\nV\n\n\n\nV-&gt;Bt\n\n\n\n\n\nYtm1\n\nY\nt-1\n\n\n\nV-&gt;Ytm1\n\n\n\n\n\nYtm1-&gt;Yt\n\n\n\n\n\n\n\n\nAbbildung 7.11: Kontrolle für \\(y_{t-1}\\) schließt Backdoor-Pfad\n\n\n\n\n\nDie Entscheidung, ob Lags der Outcome-Variable als Regressoren aufgenommen werden, sollte sorgfältig und, falls möglich, unter Berücksichtigung von ökonomischer Theorie hinsichtlich der zeitlichen Dynamik von \\(Y_{it}\\) erfolgen. Beobachtete (Auto)Korrelation von \\(Y_{it}\\) und \\(Y_{it-1}\\) muss nicht ausschließlich durch einen (kausalen) autoregressiven Zusammenhang verursacht werden. Ein DGP bei dem unsere Regression nicht für \\(Y_{it-1}\\) kontrollieren sollte, ist in Abbildung 7.12 gezeigt.\n\n\n\n\n\n\n\n\nLDVnotOK\n\n\n\nBt\n\nB\nt\n\n\n\nYt\n\nY\nt\n\n\n\nBt-&gt;Yt\n\n\n\n\n\nV\n\nV\n\n\n\nV-&gt;Bt\n\n\n\n\n\nYtm1\n\nY\nt-1\n\n\n\nV-&gt;Ytm1\n\n\n\n\n\nU\n\nU\n\n\n\nU-&gt;Yt\n\n\n\n\n\nU-&gt;Ytm1\n\n\n\n\n\n\n\n\nAbbildung 7.12: Kontrolle für \\(y_{t-1}\\) öffnet Backdoor-Pfad\n\n\n\n\n\nHier ist \\(Y_{it-1}\\) nicht kausal für \\(Y_{it}\\) und ein Collider. Kontrollieren für \\(Y_{it-1}\\) öffnet also den Backdoor-Pfad\n\\[\\begin{align*}\n  B_{it} \\leftarrow V \\rightarrow Y_{it-1} \\leftarrow U \\rightarrow Y_{it}.\n\\end{align*}\\]\nEine ähnliche Problematik besteht bei der Schätzung dynamischer Panel-Modelle mit mit Fixed- oder Random-Effects-Ansätzen. Wir erläutern dies näher in Kapitel 7.6.1.\n\n7.6.1 Verzerrung in dynamischen Modellen\nEin zentrales Problem bei der Schätzung dynamischer Panelmodelle ist der sogenannte Nickell-Bias. Dieser tritt auf, wenn die Within-Transformation in Anwesenheit von gelagten abhängigen Variablen verwendet wird. Die Mittelwert-Differenzen eliminieren zwar die zeit-invarianten Effekte, führt aber zu Korrelation zwischen den gelagten abhängigen Variablen und den transformierten Fehlertermen: Der Nickell-Bias entsteht bei der Within-Transformation, weil der Regressor (\\(Y_{i,t-1} - \\overline{Y}_{i,-1}\\))21 mit dem transformierten Fehlerterm (\\(\\epsilon_{it} - \\overline{\\epsilon}_i\\)) korreliert ist, was zu einer verzerrten Schätzung führt.\nNickell (1981) zeigt, dass diese Verzerrung des Within-Schätzers \\(\\widehat{\\rho}^\\textup{Within}\\) nicht verschwindet, wenn die Anzahl der Beobachtungseinheiten (\\(n\\)) divergiert, solange die Zeitdimension (\\(T\\)) endlich ist.22 Der Nickell-Bias ist besonders bei kurzen Panelen (kleines \\(T\\)) problematisch. Es ist \\[\\begin{align*}\n  \\widehat{\\rho}^\\textup{Within} \\approx \\rho - \\frac{1 + \\rho}{T-1},\n\\end{align*}\\] d.h. die Verzerrung beträgt ungefähr \\(-\\frac{1+\\rho}{T-1}\\).\nHinzufügen von \\(Y_{it-1}\\) als Regressor in Fixed- und Random-Effects-Modellen ist jenseits der verzerrten Schätzung von \\(\\rho\\) problematisch, wenn \\(Y_{it-1}\\) mit \\(B_{it}\\) korreliert ist. Kontrollieren für \\(Y_{it-1}\\) öffnet dann Backdoor-Pfade, die wir mit FE- oder RE-Ansätzen schließen wollen. In sämtlichen dynamischen Varianten der Fixed- und Random-Effects-Modelle sind die in diesem Kapitel behandelten Schätzer eines kausalen Effekts \\(\\beta_1 \\neq 0\\) von \\(B_{it}\\) auf \\(Y_{it}\\) daher verzerrt.\nDer Arellano-Bond-Schätzer (Arellano und Bond 1991) ist eine Methode, für diese Form von Endogenität in dynamischen Panel-Modellen korrigiert. Das Verfahren betrachtet die Regression in Differenzen zur Korrektur für Heterogenitäten zwischen den Einheiten und schätzt die Koeffizienten anhand der generalisierten Momentenmethode (GMM). Hierbei werden vergangene Werte von \\(Y_{it}\\) als Instrumente für endogene Differenzen von \\(Y_{it}\\) genutzt. Siehe Wooldridge (2010) für Beispiele.\nAnalog zu Anwendungen mit Querschnittsdaten können die hier betrachteten Panel-Schätzer Endogenitäten aufgrund simultaner Kausalität nicht beheben. Zur Korrektur für simultante Kausalität können Panel-Methoden in Kombination mit einer Schätzstrategie basierend auf Instrument-Variablen hilfreich sein. Wir betrachten solche Schätzer in den empirischen Beispielen in Kapitel Kapitel 8.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html#case-study-einkommen-und-demokratie",
    "href": "FixedEffects.html#case-study-einkommen-und-demokratie",
    "title": "7  Panel-Daten",
    "section": "7.7 Case Study: Einkommen und Demokratie",
    "text": "7.7 Case Study: Einkommen und Demokratie\nEine Vielzahl polit-ökonomischer Standardwerke und Studien (bspw. Dahl 1971; Huntington 1991; Rueschemeyer, Stephens, und Stephens 1992) liefert vermeindliche Belege für einen zentralen Grundsatz der Modernisierungstheorie: Ein höheres Pro-Kopf-Einkommen erhöht die Nachfrage der Bevölkerung nach politischer Freiheit und demokratischen Insitutionen. Acemoglu u. a. (2008a) argumentieren, dass der in derartigen länderübergreifenden Analysen mit Pooling häufig als positiv geschätzte Zusammenhang zwischen Einkommen und Demokratisierung nicht kausal interpetiert werden sollte. Ein Grund hierfür ist, dass (unbeobachtbare) ausgelassene länderspezifische Faktoren, die sowohl die ökonomische Entwicklung als auch die Stärke demokratischer Institutionen beeinflussen, wahrscheinlich sind. Um diese mögliche Ursache für Endogenität des Einkommens im Modell \\[\\begin{align}\n  \\text{Demokratisierung}_{it} = \\beta_0 + \\beta_1\\,\\text{PK-Einkommen}_{it-1} + \\epsilon_{it}\n\\end{align}\\] zu adressieren, nutzen Acemoglu u. a. (2008a) Panel-Modelle und Schätzer, die insbesondere für länderspezifische zeit-invariante Einflüsse kontrollieren.\nDas Kernergebnis von Acemoglu u. a. (2008a) ist, dass es keinen kausalen Zusammenhang zwischen dem Einkommen (Wirtschaftswachstum) und der Demokratisierung gibt. Die Autoren zeigen, dass historische und geografische Faktoren, die sowohl das Einkommen als auch die politischen Institutionen beeinflussen, den vermeintlichen Zusammenhang erklären können.\nFür die nachfolgenden Code-Beispiele nutzen wir einen Auszug des Datensatzes aus dem Replikationspaket zu Acemoglu u. a. (2008a), siehe Acemoglu u. a. (2008b).\nWir lesen zunächst den Datensatz acemogluetal2008.csv ein.\n\ndeminc &lt;- read_csv(\"datasets/acemogluetal2008.csv\")\nglimpse(deminc)\n\nRows: 2,321\nColumns: 8\n$ fhpolrigaug  &lt;dbl&gt; NA, NA, NA, NA, 0.50, NA, NA, NA, NA, 1.00, 1.00, 0.12, 0…\n$ lrgdpch      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ country      &lt;chr&gt; \"Andorra\", \"Andorra\", \"Andorra\", \"Andorra\", \"Andorra\", \"A…\n$ year         &lt;dbl&gt; 1950, 1955, 1960, 1965, 1970, 1975, 1980, 1985, 1990, 199…\n$ year_numeric &lt;dbl&gt; 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 31, 32, 33, 3…\n$ sample       &lt;dbl&gt; 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, …\n$ code         &lt;chr&gt; \"ADO\", \"ADO\", \"ADO\", \"ADO\", \"ADO\", \"ADO\", \"ADO\", \"ADO\", \"…\n$ polity4      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0.00, 0.00, 0…\n\n\nTabelle 7.1 enthält Beschreibungen der in deminc verfügbaren Variablen.\n\n\n\nTabelle 7.1: deminc: Demokratisierung und Einkommen (Acemoglu u. a. 2008a)\n\n\n\n\n\n\n\n\n\nVariable\nBeschreibung\n\n\n\n\ncountry\nLand\n\n\ncode\nLänder-Code\n\n\nfhpolrigaug\nFreedom House Political Rights Index (FHPRI)\n\n\nlrgdpch\nLog(Reales-Pro-Kopf-Einkommen)\n\n\npolity4\nPolity Composite Democracy Index\n\n\nsample\nZugehörigkeit zur verwendeten Stichprobe (Indikator)\n\n\nyear\nJahr\n\n\nyear_numeric\nID-Variable f. Jahr\n\n\n\n\n\n\nWie der output von glimpse(deminc) zeigt, enthält der Datensatz in allen Modell-Variablen NA-Einträge und ist damit nicht ‘balanced’, da die entsprechenden Beobachtungen nicht bei der Schätzung berücksichigt werden können.\n\n# Bereinigter Datensatz ist nicht 'balanced'\nis.pbalanced(\n  x = deminc %&gt;% \n    drop_na(), \n  index = c(\"country\", \"year\")   \n)\n\n[1] FALSE\n\n\nWir vernachlässigen zunächst die Panel-Struktur der Daten und regressieren FHPRI auf das Pro-Kopf-Einkommen für die in Acemoglu u. a. (2008a) verwendete Stichprobe mit Beobachtungen in 5-Jahresschritten von 1955 bis 2000 (Beobachtungen mit sample == 1).\n\n# Pooled Regression\ndeminc_pooling1 &lt;- feols(\n  fml = fhpolrigaug ~ lrgdpch,\n  data = deminc %&gt;% \n    filter(sample == 1), \n)\n\nsummary(deminc_pooling1)\n\nOLS estimation, Dep. Var.: fhpolrigaug\nObservations: 960\nStandard-errors: IID \n             Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept) -1.339442   0.068767 -19.4780 &lt; 2.2e-16 ***\nlrgdpch      0.231010   0.008271  27.9287 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.268295   Adj. R2: 0.448221\n\n\nDieser naive Ansatz ingoriert konstante Heterogenitäten zwischen den Ländern und einen (plausiblen) zeitlich verzögerten Einfluss ökonomisch günstiger Bedingung auf die Demokratisierung. Der geschätzte Koeffizient von lrgdpch ist 0.23 (d.h. ein geschätzer positiver Zusammenhang) und signifikant.\nDie Regression von FHPRI auf das Einkommen in \\(t-1\\) (l(lrgdpch)) führt zu ähnlichen Schätzungen der Koeffizienten.23 Dies ist plausibel unter der Hypothese, dass es ausgelassende Faktoren gibt, welche die Demokratisierung und das Pro-Kopf-Einkommen in sämtlichen Perioden beeinflussion.\n\n# Pooling mit Einkommem_{t-1}\ndeminc_pooling_lag &lt;- feols(\n  fml = fhpolrigaug ~ l(lrgdpch),\n  panel.id = ~ country + year,\n  data = deminc %&gt;% \n    filter(sample == 1), \n)\n\nsummary(deminc_pooling_lag)\n\nOLS estimation, Dep. Var.: fhpolrigaug\nObservations: 831\nStandard-errors: Clustered (country) \n               Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept)   -1.412158   0.108044 -13.0702 &lt; 2.2e-16 ***\nl(lrgdpch, 1)  0.240773   0.012568  19.1582 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.270376   Adj. R2: 0.456289\n\n\nEin simpler Ansatz zur Kontrolle für fixe länderspezifische Effekte ist die KQ-Schätzung des Regressionsmodell in ersten Differenzen. Analog zu Abbildung 2 in Acemoglu u. a. (2008a) schätzen wir hierfür zunächst ein Modell der Differenzen zwischen den Perioden 1995 und 1970. Zur Schätzung und anschließenden Reproduktion der Grafik (siehe Abbildung 7.13) berechnen wir die Differenzen anhand eines gruppierten Datensatzes.\n\n# Zeit-Differenzen länderweise berechnen\ndeminc_f &lt;- deminc %&gt;%\n  filter(\n    year %in% c(1970, 1995)\n  ) %&gt;%\n  group_by(code) %&gt;%\n  summarise(\n    dlrgdpch = diff(lrgdpch),\n    dfhpolrigaug = diff(fhpolrigaug)\n    ) %&gt;%\n  drop_na()\n\n# Überblick\nglimpse(deminc_f)\n\nRows: 103\nColumns: 3\n$ code         &lt;chr&gt; \"ARG\", \"AUS\", \"AUT\", \"BDI\", \"BEL\", \"BEN\", \"BFA\", \"BGD\", \"…\n$ dlrgdpch     &lt;dbl&gt; 0.102619, 0.408201, 0.632017, -0.201549, 0.543716, -0.026…\n$ dfhpolrigaug &lt;dbl&gt; 0.6666666, 0.0000000, 0.0000000, 0.1666667, 0.0000000, 0.…\n\n\n\n# KQ-Schätzung für Differenzen 1995 - 1970\ndeminc_diff_7095 &lt;- feols(\n  fml = dfhpolrigaug ~ dlrgdpch,\n  data = deminc_f\n) \n\ndeminc_diff_7095 %&gt;% \n  summary()\n\nOLS estimation, Dep. Var.: dfhpolrigaug\nObservations: 103\nStandard-errors: IID \n            Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept) 0.126292   0.040080 3.150983 0.0021415 ** \ndlrgdpch    0.032981   0.063541 0.519045 0.6048649    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.338838   Adj. R2: -0.007214\n\n\nDie Ergebnisse in deminc_diff_7095 passen zu unserer Vermutung hinsichtlich ausgelassener länderspezifischer Heterogenitäten: Der geschätzte Koeffizient von dlrgdpch ist 0.03 und nicht signifikant von 0 verschieden.\n\nggplot(\n  data = deminc_f,\n  mapping = aes(\n    x = dlrgdpch,\n    y = dfhpolrigaug\n  ) \n  ) +\n  # Referenz-Linie (kein Effekt)\n  geom_hline(yintercept = 0, lty = 2) +\n  # Datenpunkte\n  geom_text(\n    mapping = aes(label = code),\n    position = position_jitter(\n      height = .05, \n      seed = 1234\n      )\n    ) +\n  # gesch. lineares Modell einzeichnen\n  geom_smooth(\n    method = \"lm\", \n    se = F) +\n  labs(\n    x = \"Diff. Log(Pro-Kopf-BIP) (1970 - 1995)\",\n    y = \"Diff. Demokratie-Index (1970 - 1995)\"\n  ) +\n  theme_cowplot()\n\n\n\n\n\n\n\nAbbildung 7.13: deminc – Regression der Zeit-Differenzen zwischen 1995 und 1970\n\n\n\n\n\nFür die KQ-Schätzung in ersten Differenzen bei Verwendung des gesamten Datensatzes ist das Ergebis noch deutlicher: Die Schätzungen beider Koeffizienten sind klein und insignifikant.\n\n# Panel-Schätzer: KQ-Regression in Differenzen\n# (Alle Perioden)\ndeminc_diff_mod &lt;- feols(\n  fml = d(fhpolrigaug) ~ d(lrgdpch), \n  data = deminc,\n  panel.id = ~ country + year\n)\n\nsummary(deminc_diff_mod)\n\nOLS estimation, Dep. Var.: d(fhpolrigaug, 1)\nObservations: 968\nStandard-errors: Clustered (country) \n               Estimate Std. Error   t value Pr(&gt;|t|) \n(Intercept)    0.005878   0.006013  0.977540  0.32992 \nd(lrgdpch, 1) -0.021539   0.040164 -0.536278  0.59258 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.213629   Adj. R2: -7.634e-4\n\n\nTabelle 2 in Acemoglu u. a. (2008a) vergleicht verschiedene Schätzer des dynamischen Modells\n\\[\\begin{align}\n  \\text{FHPRI}_{it} = \\beta_0 + \\alpha_i + \\lambda_t + \\beta_1 \\text{FHPRI}_{it-1} + \\beta_2 \\text{Einkommen}_{it-1}  + \\varepsilon_{it}\\label{eq:acemmod}\n\\end{align}\\]\nmit Länder- und Zeit-Effekten \\(\\alpha_i + \\lambda_t\\). Der Regressor \\text{FHPRI}_{it-1} soll die “Beständigkeit” der Demokratie zu erfassen und möglicherweise kurz- bis mittelfristige Dynamiken zu berücksichtigen (d.h. die Tendenz des Demokratie-Scores, zu einem Gleichgewichtswert zurückzukehren). Wir betrachten zunächst die Fixed-Effects-Schätzung von \\(\\eqref{eq:acemmod}\\).\n\n# Zeit + country Fixed Effects\ndeminc_FE_mod &lt;- feols(\n  fml = fhpolrigaug ~ \n    l(fhpolrigaug) \n  + l(lrgdpch) \n  | year + country,\n  panel.id = ~ country + year,\n  cluster = ~ country,\n  data = deminc, \n)\n\nsummary(deminc_FE_mod)\n\nOLS estimation, Dep. Var.: fhpolrigaug\nObservations: 988\nFixed-effects: year: 10,  country: 150\nStandard-errors: Clustered (country) \n                  Estimate Std. Error  t value   Pr(&gt;|t|)    \nl(fhpolrigaug, 1) 0.388762   0.048986 7.936204 4.6184e-13 ***\nl(lrgdpch, 1)     0.001137   0.031503 0.036088 9.7126e-01    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.165328     Adj. R2: 0.751359\n                 Within R2: 0.146859\n\n\nÄhnlich wie in der Differenzen-Regression deminc_diff_mod finden wir bei Kontrolle für Länder- und Zeit-Effekte keine Evidenz für einen Zusammenhang des Pro-Kopf-Einkommens (der Vorperiode) und dem Demokratie-Score. Mit fixef(deminc_FE_mod) lesen wir die gschätzten Effekte aus. Aufgrund der Vielzahl an Länder-Effekten empfiehlt sich eine grafischer Zusammenfassung anhand eines Histogramms mit absoluten Häufigkeiten.\n\n# Verteilung der gesch. Länder-Fixed-Effects\ntibble(\n    FE = fixef(deminc_FE_mod)$country, \n    country = names(fixef(deminc_FE_mod)$country)\n    ) %&gt;%\n\nggplot(aes(x = FE)) +\n  geom_histogram(\n    bins = 20,\n    fill = \"steelblue\",\n    color = \"white\"\n  ) +\n  theme_cowplot() +\n  coord_cartesian(expand = F)\n\n\n\n\n\n\n\nAbbildung 7.14: deminc – Verteilung von Länder-Fixed-Effects\n\n\n\n\n\nEine Random-Effects-Schätzung mit Länder- und Zeit-Effekten liefert ebenfalls keine Evidenz für einen kausalen Effekt des ökonomischen Wohlstands auf die Demokratisierung.\n\n# Datensatz für plm() formatieren\ndeminc_pdf &lt;- pdata.frame(\n  deminc %&gt;% filter(sample == 1) %&gt;% \n    drop_na(), \n  index = c(\"country\", \"year_numeric\")   \n)\n\n# Random-Effects-Modell\ndeminc_RE_mod &lt;- plm(\n  formula = fhpolrigaug ~ \n    lag(fhpolrigaug, 1) \n  + lag(lrgdpch, 1), \n  effect = \"twoways\",\n  model = \"random\",\n  data = deminc_pdf\n)\n\nsummary(deminc_RE_mod)\n\nTwoways effects Random Effect Model \n   (Swamy-Arora's transformation)\n\nCall:\nplm(formula = fhpolrigaug ~ lag(fhpolrigaug, 1) + lag(lrgdpch, \n    1), data = deminc_pdf, effect = \"twoways\", model = \"random\")\n\nUnbalanced Panel: n = 120, T = 1-8, N = 729\n\nEffects:\n                    var   std.dev share\nidiosyncratic 0.0333234 0.1825470 0.972\nindividual    0.0000000 0.0000000 0.000\ntime          0.0009577 0.0309460 0.028\ntheta:\n           Min.   1st Qu.    Median      Mean   3rd Qu.      Max.\nid    0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\ntime  0.3740041 0.4781926 0.4900268 0.4776474 0.5010907 0.5028656\ntotal 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\n\nResiduals:\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.88781 -0.09657  0.01010  0.00192  0.08642  0.79340 \n\nCoefficients:\n                     Estimate Std. Error z-value  Pr(&gt;|z|)    \n(Intercept)         -0.433112   0.365330 -1.1855    0.2358    \nlag(fhpolrigaug, 1)  0.697492   0.144153  4.8386 1.308e-06 ***\nlag(lrgdpch, 1)      0.073560   0.050011  1.4709    0.1413    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    98.912\nResidual Sum of Squares: 28.164\nR-Squared:      0.7153\nAdj. R-Squared: 0.71451\nChisq: 68.4006 on 2 DF, p-value: 1.4028e-15\n\n\nUm für Endogenität der Regressoren aufgrund des dynamischen Modells zu korrigieren, verwenden Acemoglu u. a. (2008a) weiterhin den Arellano-Bond-Schätzer. Dieser wird auf die Differenz-Transformation\n\\[\\begin{align}\n  \\Delta\\text{FHPRI}_{it} = \\beta_1 \\Delta\\text{FHPRI}_{it-1} + \\beta_2 \\Delta\\text{Einkommen}_{it-1} + \\Delta\\epsilon_{it}, \\quad t\\geq3,\\label{eq:acemabmod}\n\\end{align}\\]\nvon Modell \\(\\eqref{eq:acemmod}\\) angewendet und nutzt, dass \\(\\text{FHPRI}_{it-j}\\) und \\(\\text{Einkommen}_{it-j}\\) für \\(j\\geq2\\) nicht mit \\(\\Delta\\varepsilon_{it}\\) korelliert sind und damit als Instrumente in einem GMM-Ansatz verwendet werden können.24\nDer Arellano-Bond-Schätzer ist in der Funktion plm::pgmm() implementiert. Wir schätzen Modell \\(\\eqref{eq:acemabmod}\\) mit den zweiten und dritten Lags von \\(\\text{FHPRI}_{it}\\) und \\(\\text{Einkommen}_{it}\\) als Instrumente. Die Spezifikation erfolgt durch den Zusatz | lag(fhpolrigaug, 2:3) + lag(lrgdpch, 2:3) im Argument formula.\n\n# Arellano-Bond-Schätzer\ndeminc_AB_mod &lt;- pgmm(\n  formula = \n    fhpolrigaug ~ \n    lag(fhpolrigaug, 1) \n  + lag(lrgdpch, 1) \n  # Instrumente:\n  | lag(fhpolrigaug, 2:3)\n  + lag(lrgdpch, 2:3),\n    effect = \"twoways\", \n    model = \"twosteps\",\n    data = deminc_pdf\n) \n\nsummary(deminc_AB_mod)\n\nTwoways effects Two-steps model Difference GMM \n\nCall:\npgmm(formula = fhpolrigaug ~ lag(fhpolrigaug, 1) + lag(lrgdpch, \n    1) | lag(fhpolrigaug, 2:3) + lag(lrgdpch, 2:3), data = deminc_pdf, \n    effect = \"twoways\", model = \"twosteps\")\n\nUnbalanced Panel: n = 138, T = 1-9, N = 881\n\nNumber of Observations Used: 598\nResiduals:\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-1.280670 -0.031088  0.000000  0.002335  0.009490  0.993065 \n\nCoefficients:\n                    Estimate Std. Error z-value  Pr(&gt;|z|)    \nlag(fhpolrigaug, 1)  0.50943    0.11696  4.3555 1.327e-05 ***\nlag(lrgdpch, 1)     -0.17873    0.12092 -1.4781    0.1394    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSargan test: chisq(24) = 29.03412 (p-value = 0.21885)\nAutocorrelation test (1): normal = -3.828848 (p-value = 0.00012874)\nAutocorrelation test (2): normal = 0.474211 (p-value = 0.63535)\nWald test for coefficients: chisq(2) = 21.49026 (p-value = 2.155e-05)\nWald test for time dummies: chisq(7) = 18.08866 (p-value = 0.011576)\n\n\nAuch der Arellano-Bond-Schätzer liefert keine Evidenz für die Theorie eines positiven kausalen Effekts des Einkommens fürdie Stärke demokratischer Institutionen: Der interessierende geschätzte Koeffizient ist negativ und insignifikant.\nWeiterhin bekräftigen zusätzliche Inferenzstatistiken im Output von summary(deminc_AB_mod) die Adäquanz des GMM-Verfahrens:\n\nSargan test: Die Nullhypothese des Sargan-Tests25 ist, dass die Instrumente gültig, d.h. unkorreliert mit den Fehlertermen, sind. Diese Hypothese können wir zu keinem in der Praxis relevanten Signifikanzniveau ablehnen.\nAutocorrelation test (1): Test der Nullhypothese, dass die \\(\\Delta\\epsilon_{it}\\) keine AR(1)-Korellationsstruktur aufweisen. Für unkorrelierte \\(\\epsilon_{it}\\) sind die ersten Differenzen \\(\\Delta\\epsilon_{it}\\) AR(1)-korreliert. Tatsächlich können wir diese Nullhypothese ablehnen.\nAutocorrelation test (2): Test der Nullhypothese, dass die \\(\\Delta\\epsilon_{it}\\) keine AR(2)-Korellationsstruktur aufweisen. Dies ist relevant für die Gültigkeit des Arellano-Bond-Schätzers, da AR-Korellation zweiter (oder höherer) Ordnung darauf hinweisen würde, dass die verwendeten Instrumente ungültig sind.\nWald test for coefficients: Wir lehnen die Nullhypothese, dass \\(\\Delta\\text{FHPRI}_{it-1}\\) und \\(\\Delta\\text{Einkommen}_{it-1}\\) keine Erklärtungskraft für \\(\\Delta\\text{FHPRI}_{it}\\) haben, ab. Unter der Alternativ-Hypothese ist mindesten ein Koeffizient von null verschieden. Hierunter fällt das Szenario, dass \\(\\Delta\\text{FHPRI}_{it-1}\\) zeitliche Dynamik in der Outcome-Variable erklärt, jedoch \\(\\Delta\\text{Einkommen}_{it-1}\\) irrelevant ist (kein kausaler Effekt).\nWald test for time dummies: Die Nullhyothese, dass die Zeit-Fixed-Effects irrelevant sind, wird zum 5%-Niveau abgelehnt.\n\nMit modelsummary::modelsummary() stellen wir die Koeffizientenschätzungen tabellarisch dar. Für eine bessere Lesbarkeit formatieren wir die (andernfalls aus dem jeweiligen formula/fml-Argument übernommenen) Bezeichnungen der Koeffizienten anhand eines bennanten Vektors coef_map.\n\nlibrary(modelsummary)\n\n# Mapping für Koeffizienten festlegen\ncoef_map &lt;- c(\n  \"l(lrgdpch, 1)\" = \"Einkommen_{t-1}\",\n  \"lag(lrgdpch, 1)\" = \"Einkommen_{t-1}\",\n  \"l(fhpolrigaug, 1)\" = \"FHPRI_{t-1}\",\n  \"lag(fhpolrigaug, 1)\" = \"FHPRI_{t-1}\"\n)\n\n# Tabellarische Übersicht erzeugen\nmodelsummary(\n  models = list(\n    \"Pool\" = deminc_pooling_lag,\n    \"FE\" = deminc_FE_mod,\n    \"RE\" = deminc_RE_mod,\n    \"AB\" = deminc_AB_mod\n  ),\n  coef_omit = \"Intercept\",\n  coef_map = coef_map,\n  gof_omit = \"^(?!$).*\", \n  output = \"gt\",\n  stars = TRUE\n) %&gt;%\n  tabopts()\n\n\n\nTabelle 7.2: Schätzungen des Effekts von Einkommen auf Demokratisierung (Acemoglu u. a. 2008a)\n\n\n\n\n\n\n\n\n\n\nPool\nFE\nRE\nAB\n\n\n\n\nEinkommen_{t-1}\n0.241***\n0.001\n0.074\n-0.179+\n\n\n\n(0.013)\n(0.032)\n(0.050)\n(0.098)\n\n\nFHPRI_{t-1}\n\n0.389***\n0.697***\n0.509***\n\n\n\n\n(0.049)\n(0.144)\n(0.070)\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAcemoglu, Daron, Simon Johnson, James A. Robinson, und Pierre Yared. 2008a. „Income and Democracy“. American Economic Review 98 (3): 808–42. https://doi.org/10.1257/aer.98.3.808.\n\n\n———. 2008b. „Replication data for: Income and Democracy“. ICPSR - Interuniversity Consortium for Political; Social Research. https://doi.org/10.3886/E113251V1.\n\n\nArellano, Manuel, und Stephen Bond. 1991. „Some Tests of Specification for Panel Data: Monte Carlo Evidence and an Application to Employment Equations“. The Review of Economic Studies 58 (2): 277. https://doi.org/10.2307/2297968.\n\n\nDahl, Robert Alan. 1971. Polyarchy: Participation and Opposition: Participation and opposition. New Haven: Yale Univ. Press.\n\n\nHansen, Lars Peter. 1982. „Large Sample Properties of Generalized Method of Moments Estimators“. Econometrica 50 (4): 1029. https://doi.org/10.2307/1912775.\n\n\nHuntington, Samuel P. 1991. The Third Wave: Democratization in the Late Twentieth Century: Democratization in the late twentieth century. Norman, OK: Univ. of Oklahoma Press.\n\n\nNickell, Stephen. 1981. „Biases in Dynamic Models with Fixed Effects“. Econometrica 49 (6): 1417. https://doi.org/10.2307/1911408.\n\n\nRueschemeyer, Dietrich, Evelyne H. Stephens, und John D. Stephens. 1992. Capitalist development and democracy. Cambridge: Polity Pr.\n\n\nSargan, J. D. 1958. „The Estimation of Economic Relationships using Instrumental Variables“. Econometrica 26 (3): 393. https://doi.org/10.2307/1907619.\n\n\nWooldridge, Jeffrey. 2010. Econometric Analysis of Cross Section and Panel Data. Second edition. Cambridge, Massachusetts: MIT.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html#footnotes",
    "href": "FixedEffects.html#footnotes",
    "title": "7  Panel-Daten",
    "section": "",
    "text": "Wegen \\(E(\\varepsilon_{it}\\vert B_{it})\\neq 0\\) ist der KQ-Schätzer von \\(\\beta_1\\) nicht erwartungstreu und inkonsistent.↩︎\nPooled Regression kann auch berechnet werden, wenn nicht für alle \\(n\\) Einheiten jeweils \\(T\\) Beobachtungen vorliegen (unbalanced Panel).↩︎\nDer (R code für den) DGP ist diesem StackExchange-Post entnommen.↩︎\nFehlende Beobachtungen sind typischerweise mit einem NA-Wert gekennzeichnet. Der Differenz-Schätzer kann auch berechnet werden, wenn der Datensatz nicht ausgeglichen (unbalanced) ist.↩︎\nWir verweisen nachfolgend explizit auf Funktionen aus dplyr, falls Funktionen aus plm identische Namen haben.↩︎\nEin Nachteil der Differenzbildung ist also, dass wir die Koeffizienten der beobachtbaren, zeitlich konstanten Regressoren nicht schätzen können.↩︎\nDer Differenzen-Schätzer ist erwartungstreu und konsistent, wenn \\(E(\\epsilon_{is}\\vert B_{it})=0\\) für \\(s\\geq t\\).↩︎\nEine Reduktion des Beobachtungsumfangs erhöht die Varianz der Schätzung. Für \\(T=2\\) ist der Differenzen-Schätzer äquivalent zu den Schätzern im Fixed-Effects-Modell, ist jedoch ineffizient für \\(T&gt;2\\).↩︎\nBeachte, dass eine bessere Anpassung an die Daten bei der Modellierung von paneldata.csv mit einheiten-spezifischen Achsenabschnitten anhand von Abbildung 7.4 plausibel scheint.↩︎\nDie Durchschnitte werden hierbei also über die Zeitperioden berechnet.↩︎\nFür \\(n-1\\) Einheiten ist der individuelle Achsenabschnitt damit \\(\\beta_0 + \\gamma_i\\) und für eine Einheit \\(\\beta_0\\). Diese Einheit (hier \\(i=1\\)) wird auch als Referenzkategorie bezeichnet. Alternativ kann das Modell mit \\(n\\) Dummies und ohne die Konstante \\(\\beta_0\\) geschrieben werden.↩︎\nKQ ist hier erwartungstreu und konsistent, sofern \\(E(\\epsilon_{is}\\vert B_{it})=0\\) für alle \\(s\\) und \\(t\\).↩︎\nEine Alternative ist plm::plm() mit dem Argument method = \"within\".↩︎\nZur Vereinfachung der Interpretierbarkeit vernachlässigt das DAG in Abbildung 7.7 zeitlich konstante Variablen.↩︎\nErwartungstreue und Konsistenz und Effizienz erfordern \\(E(\\alpha_i\\vert B_{it})=0\\) und \\(E(\\epsilon_{it}\\vert\\alpha_i,B_{it})=0\\).↩︎\nDie Schätzung erfolgt meist mit der Generalized Least Squares (GLS) oder mit Maximum-Likelihood (ML).↩︎\nAnalog zu Fixed-Effects-Modellen können mit effect = \"twoway\" einheiten- und zeit-spezifische zufällige Effekte modelliert werden.↩︎\nFür bessere Lesbarkeit erzeugen wir hier mit predict() eine Regressionsgerade, deren Achsenabschnitt dem geschätzten Erwartungswert der Random-Effects-Verteilung entspricht.↩︎\nEin falsch-positiver Test zeigt einen “positiven” Zustand (hier ein von null verschiedener Koeffizient) an, obwohl dieser tatsächlich nicht vorliegt.↩︎\nClustering für Zeitperioden erfolgt mit group = time.↩︎\nHier ist \\(\\overline{Y}_{i,-1} = \\frac{1}{T-1}\\sum_{t=2}^T y_{it-1}\\).↩︎\nDies ist problematisch für Mikro-Studien: Die Querschnittsdimension des Panels kann oft “hinreichend” groß gewählt werden. Die Zeit-Dimension ist aus natürlichen Gegebenheiten jedoch oft klein.↩︎\nDie Verwendung von Lags mit l() in fml erfordert die Angabe von panel.id = ~ country + year, damit die Beobachtungen zugeordnet werden können.↩︎\nDamit die Lags gültige Instrumente sind, darf \\(\\epsilon_{it}\\) nicht seriell korelliert sein.↩︎\nAuch Sargan-Hansen-Test genannt (nach Sargan 1958; Hansen 1982).↩︎",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "IV.html",
    "href": "IV.html",
    "title": "8  IV-Regression",
    "section": "",
    "text": "8.1 Der einfache lineare IV-Schätzer\nIm folgenden nehmen wir an, dass sämtliche Zusammenhänge linear sind. Zunächst betrachten wir das einfache Regressionsmodell\n\\[\\begin{align}\n  Y_i = \\beta_0 + \\beta_1 B_i + u_i \\ \\ , \\ \\ i=1,\\dots,n, \\label{eq:simpleiv}\n\\end{align}\\]\nwobei der Fehlerterm \\(u_i\\) mit dem Regressor \\(B_i\\) korreliert ist (d.h. \\(B\\) ist ein endogener Regressor), sodass der KQ-Schätzer für den kausalen Effekt \\(\\beta_1\\) inkonsistent ist.\nDamit \\(Z\\) ein gültiges Instrument für \\(B\\) in dem in Abbildung 8.1 gezeigten Forschungsdesign ist, müssen die folgenden Bedingungen erfüllt sein:\nSei \\(\\text{Cov}(A,B)\\) die Kovarianz zwischen den Variablen \\(A\\) und \\(B\\). \\(Z\\) muss zwei Bedingungen erfüllen, um ein gültiges Instrument zu sein:\nUnter diesen Annahmen erlaubt das Forschungsdesign die Anwendung des einfachsten IV-Ansatzes, wobei eine endogene Variable \\(B\\) durch eine Instrumentvariable \\(Z\\) instrumentiert wird. Die folgende Umformung zeigt, warum der kausale Effekt von B auf Y anhand der (Ko)Variation in diesen Variablen identifiziert werden kann:\n\\[\\begin{alignat*}{2}\n  \\textup{Cov}(Z,Y) &= \\textup{Cov}(Z,\\beta_0 + \\beta_1 B + u) &\\quad& \\text{(Gl. \\eqref{eq:simpleiv})} \\\\\n  \\\\\n  \\textup{Cov}(Z,Y) &= \\textup{Cov}(Z, \\beta_1 B + u) &\\quad& \\text{($\\beta_0$ konstant)} \\\\\n  \\\\\n  \\textup{Cov}(Z,Y) &= \\beta_1\\textup{Cov}(Z,B) &\\quad& \\text{($\\beta_1$ konstant, $Z$ exogen)} \\\\\n  \\\\\n  \\beta_1 &= \\frac{\\textup{Cov}(Z,Y) }{\\textup{Cov}(Z,B)} &\\quad& \\text{($Z$ relevant)}\n\\end{alignat*}\\]\nEine naheliegende Implementierung gemäß dieses Identifikationsprinzips ist der einfache IV-Schätzer\n\\[\\begin{align}\n  \\widehat{\\beta}_{\\textup{IV}} = \\frac{\\widehat{\\textup{Cov}}(Z,Y) }{\\widehat{\\textup{Cov}}(Z,B)}, \\label{eq:simpleivest}\n\\end{align}\\]\nwobei lediglich die Kovarianzfunktion \\(\\textup{Cov}(\\cdot,\\cdot)\\) durch ihr Stichprobenäquivalent \\(\\widehat{\\textup{Cov}}(\\cdot,\\cdot)\\) ersetzt wird.\nErwartungswert und Konsistenz\nEine hilfreiche Darstellung von \\(\\eqref{eq:simpleivest}\\) ist\n\\[\\begin{align*}\n  \\widehat{\\beta}_\\textup{IV} = \\beta_1 + \\frac{\\sum_{i=1}^n (Z_i-\\overline Z) u_i}{\\sum_{i=1}^n (Z_i - \\overline{Z})B_i}.\n\\end{align*}\\]\nAnhand dieser Form kann der Erwartungswert sowie das Verhalten für große Stichproben untersucht werden. Eine wichtige Eigenschaft ist\n\\[\\begin{align}\n  \\textup{E}\\big(\\widehat{\\beta}_\\textup{IV}\\big) = \\beta_1 + \\underbrace{\\textup{E}\\bigg(\\frac{\\sum_{i=1}^n (Z_i-\\overline Z) u_i}{\\sum_{i=1}^n (Z_i - \\overline{Z})B_i}\\bigg)}_{\\neq0},\\label{eq:ivbiasterm}\n\\end{align}\\]\nsodass \\(\\widehat{\\beta}_\\textup{IV}\\) bei Endogenität von \\(X\\) ein verzerrter Schätzer von \\(\\beta_1\\) ist.1 Glücklicherweise kann man zeigen, dass\n\\[\\begin{align*}\n  \\frac{\\sum_{i=1}^n (Z_i-\\overline Z) u_i}{\\sum_{i=1}^n (Z_i - \\overline{Z})B_i}\\to 0 \\quad \\text{für} \\quad n\\to\\infty\n\\end{align*}\\]\nbei Gültigkeit der IV-Annahmen \\(\\eqref{eq:ivassum1}\\) und \\(\\eqref{eq:ivassum2}\\), d.h. \\(\\widehat{\\beta}_\\textup{IV}\\) ist ein konsistener Schätzer für \\(\\beta_1\\),\n\\[\\begin{align*}\n  \\widehat{\\beta}_\\textup{IV} \\to \\beta_1 \\quad \\text{für} \\quad n\\to\\infty.\n\\end{align*}\\]\nSchwache Instrumente\nBeachte, dass die Annahme der Relevanz des Instruments für die Herleitung des Identifikationsprinzips und des Schätzers \\(\\eqref{eq:simpleivest}\\) von entscheidender Bedeutung ist: Sind \\(Z\\) und \\(B\\) unkorreliert, so ist \\(\\text{Cov}(B,Z) = 0\\) und \\(\\beta_1\\) damit nicht identifizierbar. Weiterhin würde \\(\\widehat{\\text{Cov}}(B,Z)\\to0\\) wenn \\(n\\to\\infty\\), sodass \\(\\widehat{\\beta}_{\\textup{IV}}\\to\\infty\\)!\nIn empirischen Anwendungen ist \\(\\text{Cov}(B,Z) = 0\\) unwahrscheinlich. Die Kovarianz von \\(B\\) und \\(Z\\) kann jedoch gering sein. In diesem Fall bezeichnet man \\(Z\\) als ein schwaches Instrument. Anhand von Gleichung \\(\\eqref{eq:simpleivest}\\) können wir die Konsequenzen der Verwendung eines schachen Instruments ableiten: Ein sehr schwacher linearer Zusammenhang von \\(B\\) und \\(Z\\) — und damit tendenziell \\(\\widehat{\\text{Cov}}(B,Z) \\approx 0\\) — kann trotz Relevanz von \\(Z\\) zu einem Schätzer mit großer Varianz führen.\nDie Relevanz eines Instruments kann mit einem Hypothesentests geprüft werden. Wie die “Stärke” eines Instruments beurteilt werden sollte, ist eine nicht-triviale Frage. Wir betrachten diesen Aspekt näher in Kapitel 8.2.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>IV-Regression</span>"
    ]
  },
  {
    "objectID": "IV.html#der-einfache-lineare-iv-schätzer",
    "href": "IV.html#der-einfache-lineare-iv-schätzer",
    "title": "8  IV-Regression",
    "section": "",
    "text": "1. Relevanz des Instruments für die endogene Variable\n\\(B\\) und \\(Z\\) müssen korreliert sein (Pfeil von Z nach B in Abbildung 8.1): \\[\\begin{align}\n    \\text{Cov}(B,Z) \\neq 0 \\label{eq:ivassum1}\n  \\end{align}\\]\n2. Exogenität des Instruments hinsichtlich der Outcome-Variable\nDas Instrument \\(Z\\) darf nicht mit dem Fehlerterm \\(u\\) in der Modellgleichung \\(\\eqref{eq:simpleiv}\\) korreliert sein (keine Pfade von Z nach Y außer durch B in Abbildung 8.1): \\[\\begin{align}\n    \\text{Cov}(Z,u) = 0 \\label{eq:ivassum2}\n  \\end{align}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.1.1 Identifizierbarer Behandlungseffekt\nRegression ermöglicht in der Regel die Schätzung eines durchschnittlichen Behandlungseffekts (ATE) für eine betrachtete Population mit heterogenen Behandlungseffekten (in Modell \\(\\eqref{eq:simpleiv}\\) unterstellen wir den empirisch unwahrscheinlichen Fall eines einheitlichen kausalen Effekts \\(\\beta_1\\)). Das Adjustieren für Endogenität mit IV-Regression hat hier einen Preis: Beachte, dass im IV-Design ein Teil der beobachteten Variation der Behandlungsvariable \\(B\\) (wie in \\(\\eqref{eq:simpleiv}\\) angenommen) endogen ist und wir den Effekt von \\(B\\) auf \\(Y\\) anhand der exogenen Variation eines validen Instruments \\(Z\\) schätzen. Daher können wir grundsätzlich nur einen lokalen durchschnittlichen Behandlungseffekt (LATE) identifizieren: Der LATE ist eine gewichtete Variante des ATE, wobei Beobachtungen, deren Behandlung gut durch \\(Z\\) erklärt wird den größten Einfluss haben.2",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>IV-Regression</span>"
    ]
  },
  {
    "objectID": "IV.html#sec-2SLS",
    "href": "IV.html#sec-2SLS",
    "title": "8  IV-Regression",
    "section": "8.2 2SLS-Verfahren",
    "text": "8.2 2SLS-Verfahren\nDer einfache IV-Schätzer \\(\\eqref{eq:simpleivest}\\) ist ein Spezialfall eines allgemeineren Regressionsverfahrens, das in zwei Schritten Durchgeführt wird. Im fall von Modell \\(\\eqref{eq:simpleiv}\\) erfolgt die Schätzung anhand der folgenden einfachen Regressionen:\n\n1. Stufe: Regression von \\(B\\) auf \\(Z\\)\nRegressiere die endogene Variable \\(B\\) auf das Instrument \\(Z\\): \\[\\begin{align}\n    B_i = \\alpha_0 + \\alpha_1 Z_i + u_i, \\quad 1,\\dots,n.\n  \\end{align}\\] Berechne die geschätzten Werte \\[\\begin{align}\n    \\widehat{B}_i = \\widehat{\\alpha}_0 + \\widehat{\\alpha}_1 Z_i.\n  \\end{align}\\]\nDie \\(\\widehat{B}_i\\) aus dieser Regression sind “bereinigt”: Die Variation in den \\(\\widehat{B}_i\\) wird lediglich durch die exogene Variation in \\(Z\\) verursacht.\n2. Stufe: Regression von \\(Y\\) auf \\(\\widehat{B}\\)\nRegressiere die Beobachtungen der abhängigen Variable \\(Y_i\\) auf die geschätzten Werte \\(\\widehat{B}_i\\) aus der 1. Stufe: \\[\\begin{align}\n    Y_i = \\gamma_0 + \\gamma_1 \\widehat{B}_i + e_i.\n  \\end{align}\\] Der geschätzte Koeffizient \\(\\widehat{\\gamma}_1\\) aus dieser Regression ist der Two-Stage-Least-Squares-Schätzer (2SLS-Schätzer) von \\(\\beta_1\\).\n\n\n8.2.1 Äquivalenz von 2SLS und einfacher IV-Schätzer\nDer KQ-Schätzer von \\(\\gamma_1\\) in der 2. Stufe ist \\[\\begin{align}\n  \\widehat{\\gamma}_1 = \\frac{\\sum (\\widehat{B}_i - \\overline{\\widehat{B}})(Y_i - \\bar{Y})}{\\sum (\\widehat{B}_i - \\bar{\\widehat{B}})^2} = \\frac{\\widehat{\\text{Cov}}(\\widehat{B}, Y)}{\\widehat{\\textup{Var}}(\\widehat{B}_i)}.\n\\end{align}\\] Da \\(\\widehat{B}_i = \\widehat{\\alpha}_0 + \\widehat{\\alpha}_1 Z_i\\), die angepassten Werte aus der 1. Stufe, eine lineare Funktion von \\(Z_i\\) sind, können wir \\(\\widehat{\\text{Cov}}(\\widehat{B}, Y)\\) wie folgt schreiben: \\[\\begin{align}\n  \\widehat{\\text{Cov}}(\\widehat{B}, Y) = \\widehat{\\alpha}_1 \\widehat{\\text{Cov}}(Z, Y)\n\\end{align}\\] Eine ähnliche Umformung zeigt, dass \\[\\begin{align}\n  \\widehat{\\text{Var}}(\\widehat{B}) = \\widehat{\\alpha}_1^2 \\widehat{\\text{Var}}(Z).\n\\end{align}\\]\nKombinieren wir diese Ergebnisse, erhalten wir folgende Darstellung für den KQ-Schätzer von \\(\\gamma_1\\) in der 2. Stufe: \\[\\begin{align}\n  \\widehat{\\gamma}_1 = \\frac{\\widehat{\\text{Cov}}(\\widehat{B}, Y)}{\\widehat{\\text{Var}}(\\widehat{B})} = \\frac{\\widehat{\\alpha}_1 \\widehat{\\text{Cov}}(Z, Y)}{\\widehat{\\alpha}_1^2 \\widehat{\\text{Var}}(Z)} = \\frac{\\widehat{\\text{Cov}}(Z, Y)}{\\widehat{\\alpha}_1 \\widehat{\\text{Var}}(Z)}\n\\end{align}\\]\nDer KQ-Schätzer von \\(\\widehat{\\alpha}_1\\) in der 1. Stufe ist definiert als \\(\\widehat{\\alpha}_1 = \\frac{\\widehat{\\text{Cov}}(Z, B)}{\\widehat{\\text{Var}}(Z)}\\). Somit gilt \\[\\begin{align}\n  \\widehat{\\gamma}_1 = \\frac{\\widehat{\\text{Cov}}(Z, Y)}{\\frac{\\widehat{\\text{Cov}}(Z, B)}{\\widehat{\\text{Var}}(Z)} \\widehat{\\text{Var}}(Z)} = \\frac{\\widehat{\\text{Cov}}(Z, Y)}{\\widehat{\\text{Cov}}(Z, B)} = \\widehat{\\beta}_{\\textup{IV}}.\\label{eq:equiviv}\n\\end{align}\\]\n\n\n8.2.2 Wozu 2SLS?\n\n\n\n\n\n\n\n\nIV_DAG\n\n\n\nX\n\nX\n\n\n\nB\n\nB\n\n\n\nX-&gt;B\n\n\n\n\n\nY\n\nY\n\n\n\nX-&gt;Y\n\n\n\n\n\nZ\n\nZ\n\n\n\nX-&gt;Z\n\n\n\n\n\nU\n\nU\n\n\n\nU-&gt;B\n\n\n\n\n\nU-&gt;Y\n\n\n\n\n\nB-&gt;Y\n\n\n\n\n\nZ-&gt;B\n\n\n\n\n\n\n\n\nAbbildung 8.2: IV-Design mit beobachtbaren Confoundern\n\n\n\n\n\nIn der Praxis werden IV-Schätzungen mit statistischer Software häufig anhand einer Implementierung des 2SLS-Verfahren durchgeführt. Gründe hierfür sind:\n\nBedingte Exogenität. Für den in Abbildung 8.1 dargestellten DGP ist die Exogenität von Z gegeben. In empirischen Anwendungen kann es jedoch schwierig sein, ein Instrument Z zu finden, dass plausibel nur mit dem endogenen Regressor korreliert. Eine schwächere Bedingung als Exogenität ist Exogenität nach Kontrolle für beobachtbare gemeinsame Determinanten (X) von Z und Y.3\nDiese Situation ist in Abbildung 8.2 dargestellt: Aufgrund der Pfeile von X zu Z und Y ist die Bedingung \\(\\eqref{eq:ivassum2}\\) verletzt. Durch Kontrolle für X in beiden Regressionen des 2SLS-Verfahrens können die Pfade durch X geschlossen werden.\nMehrere endogene Variablen / Instrumente. Der 2SLS-Ansatz kann leicht für mehrere endogene Variablen (und mehrere Instrumentvariablen) erweitert werden. Für jede der endogenen Variablen erfolgt hierbei eine separate Regression in der ersten Stufe des 2SLS-Verfahrens, wobei jeweils mehrere Instrumente verwendet werden und zusätzlich für beobachtbare Kovariablen X kontrolliert werden kann.\nStatistische Inferenz. Die Berechnung von \\(\\widehat{\\beta}_\\textup{IV}\\) erfordert Sorgfalt bei der Konstruktion von Inferenzstatistiken. Die in Kapitel 8.2.1 gezeigte Äquivalenz impliziert, dass wir bei der Schätzung der Variabilität von \\(\\widehat{\\beta}_\\textup{IV}\\) die Unsicherheit aus den beiden KQ-Schätzungen des 2SLS-Verfahrens berücksichtigen müssen. Korrigierte Standardfehlerformeln können vergleichsweise einfach anhand der Regressionsdarstellung hergeleitet werden und sind statistischer Software implementiert (bspw. ivreg in R).\nWeiterhin ermöglicht das Regressions-Framework diagnostische Tests. So kann die Relevanz von Instrumenten anhand von F-Tests für die Koeffizienten in den Regressionen der ersten Stufe des 2SLS-Verfahrens überprüft werden. Sofern mehr Instrumente als endogene Variablen vorliegen, kann die Exogenität der Instrumente getestet werden.\n\n\n\n8.2.3 Interaktive Illustrationen: 2SLS-Verfahren\nDer DGP im nachfolgenden interaktiven Beispiel ist\n\\[\\begin{align}\n  \\begin{split}\n    X_i =&\\, \\gamma \\cdot Z_i + v_i,\\\\\n    Y_i =&\\, \\beta_1 \\cdot X_i + u_i,\n  \\end{split}\n  \\label{eq:OJSIVDGP}\n\\end{align}\\] wobei \\(Z_i \\sim N(0, .25^2)\\). Die Fehlerterme \\(v_i\\) und \\(u_i\\) sind \\(N(0,1)\\)-verteilt und folgen einer gemeinsam Normalverteilung mit Korrelationsparameter \\(\\rho\\), \\[\\begin{align}\n\\begin{pmatrix}\nv_i \\\\ u_i\n\\end{pmatrix}\n\\sim N\n\\bigg[\n\\begin{pmatrix}\n0 \\\\ 0\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & \\rho \\\\\n\\rho & 1\n\\end{pmatrix}\n\\bigg].\n\\end{align}\\]\nWir sind daran interessiert, den Parameter \\(\\beta_1\\) zu schätzen, um den Effekt von \\(X\\) auf \\(Y\\) zu bestimmen, wobei wir \\(n=1000\\) Beobachtungen von \\((X_i, Y_i, Z_i)\\) verwenden.\nBeachte, dass \\(X_i\\) eine Funktion der (exogenen) Variable \\(Z_i\\) und des Fehlerterms \\(v_i\\) ist. Wenn die Fehlerterme \\((v_i, u_i)’\\) im DGP \\(\\eqref{eq:OJSIVDGP}\\) korreliert sind (\\(\\rho\\neq0\\)), dann besteht Korrelation zwischen \\(X_i\\) und \\(u_i\\). Dies impliziert, dass \\(X\\) ein endogener Regressor im “naiven” Regressionsmodell \\[\\begin{align}\nY_i = \\beta_0 + \\beta_1 X_i + e_i, \\quad i = 1,\\dots,N.\n\\end{align}\\] Der KQ-Schätzer von \\(\\beta_1\\) ist dann verzerrt und inkonsistent.\nWenn \\(Z\\) Erklärungskraft für \\(X\\) hat, d.h. \\(\\gamma\\neq0\\) mit \\(|\\gamma|\\) nicht zu klein gewählt ist (\\(Z\\) ist relevant), und \\(Z\\) nur über \\(X\\) auf \\(Y\\) wirkt (\\(Z\\) ist exogen in der Gleichung von \\(Y_i\\)), dann kann der kausale Effekt von \\(X\\) auf \\(Y\\) anhand einer Instrumentvariablen-Regression mit \\(Z\\) konsistent geschätzt werden.\nDie folgende Interaktive Grafik berechnet den 2SLS-Schätzer Analog zu der in Kapitel 8.2 erläuterten Vorgehensweise:\n\nSchätze das Regressionsmodell\n\\[\\begin{align}\nX_i = \\alpha_0 + \\alpha_1 \\cdot Z_i + \\epsilon_i\n\\end{align}\\] und berechnen Sie die angepassten Werte \\(\\widehat{X}_i\\). Dieser Schritt isoliert die exogene Variation in \\(X_i\\), die auf \\(Z_i\\) zurückzuführen ist.\nSchätze den Effekt von \\(X\\) auf \\(Y\\) unter Verwendung von \\(\\widehat{X}_i\\), dem exogenen Teil von \\(X_i\\) aus 1., in der Regression\n\\[\\begin{align}\nY_i = \\delta_0 + \\delta_1 \\cdot \\widehat{X}_i  + \\varepsilon_i.\n\\end{align}\\] Der KQ-Schätzer \\(\\widehat{\\delta}_1\\) von \\(\\delta_1\\) ist der 2SLS-Schätzer von \\(\\beta_1\\).\n\nDie Grafik illustriert das Verhalten des IV-Schätzers (lila Grade) im Vergleich zum KQ-Schätzer (gestrichelte Grade) und zum wahren Zusammenhang (grüne Grade) für eine simulierte Stichprobe (gegeben der gewählten Parameter) anhand der geschätzten Regressionslinien. Die voreingestellten Parameter-Kombinationen zeigen\n\ndie Verzerrung von 2SLS, wenn \\(Z\\) ein schwaches Instrument für \\(X\\) ist,\neine Situation in der \\(X\\) exogen ist (KQ ist unverzerrt), was zu vergleichbaren Schätzungen führt (sofern \\(Z\\) kein Schwaches Instrument ist)\neine starke Verzerrung von KQ, wenn \\(X\\) endogen und irrelevant (\\(\\beta_1 = 0\\)) ist.\n\n\n\nAnhand der obigen interaktiven Grafik lässt sich zwar die Verzerrung der Schätzer einschätzen, jedoch nicht die Unsicherheit der Schätzung. Um die gesamte Verteilung der Schätzer in endlichen Stichproben zu illustrieren, zeigt die nachstehende Grafik Kerndichteschätzungen basierend auf \\(N\\) simulierte Stichproben der Größe \\(n\\) für den gewählten DGP.4 Die Applikation gibt weiterhin den R-Code für eine Simulation der Daten gemäß der gewählten Parameter aus.\nDie voreingestellten Parameter-Kombinationen zeigen:\n\nWenn \\(Z\\) ein schwaches Instrument ist, kann der IV-Schätzer auch in großen Stichproben eine hohe Verzerrung haben und eine deutlich größere Varianz als der KQ-Schätzer haben.\nWenn der interessierende Regressor (Behandlungsvariable) \\(X\\) exogen ist, hat der IV-Schätzer eine größere Varianz als der KQ-Schätzer.\nWenn die Endogenität von \\(X\\) “stark” ist (d.h. hohe Korrelation von \\(u\\) und \\(v\\)), kann der IV-Schätzer auch in kleinen Stichproben hilfreich sein sofern das Instrument \\(Z\\) nicht zu schwach ist: IV hat dann eine deutlich geringere Verzerrung als KQ, aber eine größere Varianz.\n\n\n\n\n\n8.2.4 Schätzung mit R\n\nlibrary(faux) # install.packages(\"faux\")\n\nset.seed(1234)\n\nn &lt;- 1000\n\nerrors &lt;- rnorm_multi(\n    n, mu = c(0, 0), sd = c(1, 1),\n    r = -0.8, varnames = c(\"u\", \"v\"), \n)\n\nZ &lt;- rnorm(n, sd = .25)\nX &lt;- 2 * Z + errors$v\nY &lt;- 0 * X + errors$u\n\nthe_data &lt;- data.frame(X, Y)\n\n\nlibrary(cowplot)\n\nthe_data %&gt;%\n  mutate(Xhat = lm(X ~ Z)$fitted) %&gt;%\n  \n  ggplot(aes(x = X, y = Y)) + \n  geom_point() +\n  geom_smooth(\n    method = \"lm\", \n    se  = FALSE, \n    col = \"red\"\n  ) +\n  geom_hline(\n    yintercept = 0, \n    col = \"darkgreen\"\n    ) +\n  geom_smooth(\n    mapping = aes(x = Xhat, y = Y), \n    method = \"lm\", \n    se  = FALSE,\n    col = \"steelblue\"\n    ) +\n  theme_cowplot()\n\n\n\n\n\n\n\n\n\nlibrary(AER)\n\nKQ_mod_sim &lt;- lm(\n  formula = Y ~ X,\n  data = the_data\n)\n\nsummary(KQ_mod_sim)\n\n\nCall:\nlm(formula = Y ~ X, data = the_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.10480 -0.48829  0.00025  0.49527  2.42887 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.01074    0.02254   0.476    0.634    \nX           -0.64579    0.02025 -31.889   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7128 on 998 degrees of freedom\nMultiple R-squared:  0.5047,    Adjusted R-squared:  0.5042 \nF-statistic:  1017 on 1 and 998 DF,  p-value: &lt; 2.2e-16\n\n\n\nlibrary(ivreg)\n\niv_mod_sim &lt;- ivreg(\n  formula = Y ~ X | Z,\n  data = the_data\n)\n\nsummary(iv_mod_sim)\n\n\nCall:\nivreg(formula = Y ~ X | Z, data = the_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3.24501 -0.67660  0.01894  0.69021  3.52318 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  0.020535   0.031863   0.644    0.519\nX           -0.007139   0.059949  -0.119    0.905\n\nDiagnostic tests:\n                 df1 df2 statistic p-value    \nWeak instruments   1 998     294.5  &lt;2e-16 ***\nWu-Hausman         1 997     415.3  &lt;2e-16 ***\nSargan             0  NA        NA      NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.007 on 998 degrees of freedom\nMultiple R-Squared: 0.0111, Adjusted R-squared: 0.01011 \nWald test: 0.01418 on 1 and 998 DF,  p-value: 0.9052",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>IV-Regression</span>"
    ]
  },
  {
    "objectID": "IV.html#beispiel-der-schwache-staat-die-bauern-und-die-mafia",
    "href": "IV.html#beispiel-der-schwache-staat-die-bauern-und-die-mafia",
    "title": "8  IV-Regression",
    "section": "8.3 Beispiel: Der schwache Staat, die Bauern und die Mafia",
    "text": "8.3 Beispiel: Der schwache Staat, die Bauern und die Mafia\nAcemoglu, De Feo, und De Luca (2020) untersuchen den Aufstieg und die Auswirkungen der sizilianischen Mafia gegen Ende des 19. Jahrhunderts. Die Studie argumentiert, dass die Verbreitung der Mafia teilweise auf das Aufkommen sozialistischer Bauern-Organisationen (Fasci siciliani) zurückzuführen ist, die in einem Umfeld schwacher staatlicher Präsenz die Rechte der Bauern verteidigten. Grundbesitzer, Verwalter und lokale Politiker wandten sich also an die Mafia, um diese sozialistische “Bedrohung” zu bekämpfen und die Kontrolle über die landwirtschaftlich arbeitende Bevölkerung zu behalten. Die Studie identifiziert einen signifikanten (positiven) kausalen Zusammenhang zwischen dem Aufstieg der Fasci und der Ausbreitung der Mafia in Sizilien.\n\n8.3.1 Identifikationsstrategie\nDie Beziehung zwischen dem Aufkommen der Fasci und der Mafia-Aktivität im einfachen Regressionsmodell \\[\\begin{align}\n  \\textup{Mafia-Aktivität} = \\beta_0 + \\beta_1 \\textup{Fasci siciliani} + \\varepsilon \\label{eq:fascimafiamod1}\n\\end{align}\\] ist wahrscheinlich aufgrund mehrerer Faktoren endogen:\n\nExterne Faktoren, die sowohl die Entstehung der Fasci siciliani als auch der Mafia beeinflussen sind wahrscheinlich. Beispielsweise könnten wirtschaftliche Notlagen und politische Instabilität sowohl die Organisation der Bauern als auch die Etablierung der Mafia begünstigen.\nSimultante Kasalität: Die Präsenz der Fasci könnte die Mafia-Aktivitäten beeinflussen und umgekehrt: Intensive Mafia-Aktivitäten könnten die Notwendigkeit für Bauernorganisationen erhöhen, was wiederum die Mafia stärkt. Außerdem erschwert die zeitliche Nähe zwischen der Entstehung der Fasci und der Verbreitung der Mafia die Identifizierung der Kausalrichtung.\n\nWir können das Modell \\(\\eqref{eq:fascimafiamod1}\\) um (messbare) unter 1. fallende Regressoren erweitern, um einer verzerrten Schätzung aufgrund relevanter ausgelassener Variablen vorzubeugen. Eine Verzerrung aufgrund der in 2. beschriebenen simultanen Kausalität kann jedoch nicht durch multiple Regression vermieden werden. Acemoglu, De Feo, und De Luca (2020) nutzen die folgende Identifikationsstrategie: Eine extreme Dürre im Jahr 1893 (insbesondere Regenausfall im Frühling) hatte einen erheblichen negativen Einfluss auf die landwirtschaftliche Produktion in Sizilien und verursachte große Not unter den Bauern, was die Entstehung der Fasci beförderte. Die Dürre kann als natürliches Experiment betrachtet werden, wobei durch die Variation in der Niederschlagsmenge (das Instrument) die Variation im Aufkommen von Fasci-Organisationen in verschiedenen Gemeinden, die unabhängig von der späteren Mafia-Aktivität ist, isoliert werden kann. Anhand dieser exogenen Variation im Organisationsgrad der Bauern kann der (lokale) kausale Effekt auf die Entwicklung der Mafia identifiziert werden.\n\n\n\n\n\n\n\n\nIV_DAG\n\n\n\nX\n\nMafia-\nFaktoren\n\n\n\nB\n\nFasci\n\n\n\nX-&gt;B\n\n\n\n\n\nY\n\nMafia in\n 1900\n\n\n\nX-&gt;Y\n\n\n\n\n\nX2\n\nFasci-\nFaktoren\n\n\n\nX2-&gt;B\n\n\n\n\n\nX3\n\nGeo-\nFaktoren\n\n\n\nX3-&gt;Y\n\n\n\n\n\nZ\n\nDürre\n\n\n\nX3-&gt;Z\n\n\n\n\n\nU\n\nU\n\n\n\nU-&gt;B\n\n\n\n\n\nU-&gt;Y\n\n\n\n\n\nB-&gt;Y\n\n\n\n\n\nY-&gt;B\n\n\n\n\n\nZ-&gt;X\n\n\n\n\n\nZ-&gt;X2\n\n\n\n\n\nZ-&gt;B\n\n\n\n\n\n\n\n\nAbbildung 8.3: Zulässiger DGP im IV-Design von Acemoglu, De Feo, und De Luca (2020)\n\n\n\n\n\n\n\n8.3.2 Reproduktion der Kernergebnisse mit R\nWir lesen zunächst den Datensatz ADD_Mafia_municipality.dta5 ein und verschaffen uns einen Überblick.\n\nlibrary(haven)\n\n# Datensatz einlesen\nADD_dat &lt;- read_stata(\n  file = \"datasets/ADD_Mafia_municipality.dta\"\n  )\n\nglimpse(ADD_dat)\n\nRows: 333\nColumns: 28\n$ peasants_fasci          &lt;dbl&gt; 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0…\n$ sp3m1893_n30            &lt;dbl&gt; 0.2025284, 1.0492120, 0.3623592, 0.4212372, 0.…\n$ cl1_stn_sp1893_n30      &lt;dbl&gt; 26, 4, 26, 5, 4, 26, 26, 4, 4, 4, 26, 5, 26, 4…\n$ predr_peas_fasci        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ ruralcentre1861         &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1…\n$ Rural_rent              &lt;dbl&gt; 5.099932, 3.597782, 2.558312, 7.590975, 4.1333…\n$ Urban_rent              &lt;dbl&gt; 0.0000000, 1.1374048, 0.3895219, 2.6512258, 0.…\n$ agricola_rel            &lt;dbl&gt; 0.9637574, 0.9701000, 0.9097173, 0.9832645, 1.…\n$ seminatoritot_rel       &lt;dbl&gt; 0.7835485, 0.8199988, 0.5116088, 0.7404211, 0.…\n$ sulfurproduction1868_70 &lt;dbl&gt; 0.0, 153.0, 0.0, 0.0, 0.0, 25.5, 0.0, 0.0, 117…\n$ Citrus_groves           &lt;dbl&gt; 5.555364e-03, 3.233516e-04, 5.223450e-04, 3.03…\n$ Olives_groves           &lt;dbl&gt; 0.0059671006, 0.0158138741, 0.0023271707, 0.04…\n$ Vineyards               &lt;dbl&gt; 0.048398037, 0.024294233, 0.006733574, 0.06361…\n$ Mafia1885               &lt;dbl&gt; 0, 3, 0, 0, 2, 3, 0, 0, 0, 0, 3, 0, 0, 2, 2, 1…\n$ Mafia1900               &lt;dbl&gt; 0, 3, 0, 0, 1, 3, 0, 0, 3, 0, 3, 3, 0, 0, 0, 3…\n$ lnpop1861               &lt;dbl&gt; 7.396335, 10.080754, 7.693937, 8.177516, 7.493…\n$ lnsurface               &lt;dbl&gt; 7.259003, 10.598988, 8.283580, 7.060150, 7.190…\n$ centreheight            &lt;dbl&gt; 554, 588, 292, 420, 720, 440, 740, 646, 625, 6…\n$ maxheight               &lt;dbl&gt; 723, 866, 621, 475, 821, 511, 899, 884, 704, 8…\n$ slope2                  &lt;dbl&gt; 176.0, 343.0, 250.0, 102.5, 235.5, 150.5, 364.…\n$ pa_pdist1856            &lt;dbl&gt; 71.0, 92.0, 74.0, 106.0, 68.0, 111.0, 68.0, 4.…\n$ port2_pdist1856         &lt;dbl&gt; 71, 34, 74, 48, 55, 85, 68, 4, 40, 46, 48, 48,…\n$ roads1799               &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1…\n$ ave_temp                &lt;dbl&gt; 14.60, 14.80, 16.40, 15.60, 14.10, 16.05, 13.9…\n$ sp3m_ave_n30            &lt;dbl&gt; 158.4963, 135.3397, 129.4469, 126.1981, 144.14…\n$ var_sp3m_n30            &lt;dbl&gt; 0.2702444, 0.4196214, 0.1592561, 0.1744232, 0.…\n$ distretto1853           &lt;chr&gt; \"caltanissetta\", \"caltanissetta\", \"caltanisset…\n$ provincia1853           &lt;chr&gt; \"caltanissetta\", \"caltanissetta\", \"caltanisset…\n\n\nDas tibble-Objekt ADD_dat enthält Variablenbschreibungen im Attribut label. Mit Funktionen aus dem tidyverse-Paket purrr können wir diese Einträge auslesen.\n\n# Attribut 'label' für die ersten 5 Variablen anzeigen\nmap_chr(\n  .x = ADD_dat, \n  .f = ~ attr_getter(\"label\")(.)\n) %&gt;%\n  .[1:5]\n\n                                                                   peasants_fasci \n              \"Dummy for the presence of a peasants fasci organization in 1893-4\" \n                                                                     sp3m1893_n30 \n\"Relative rainfall in spring 1893 interpolated from weather stations within 30km\" \n                                                               cl1_stn_sp1893_n30 \n                  \"Closest weather station active in the spring 1893 within 30km\" \n                                                                 predr_peas_fasci \n      \"Dummy for the presence of a peasants fasci organization before March 1893\" \n                                                                  ruralcentre1861 \n                                  \"Dummy for the municipality being an agro-town\" \n\n\nTabelle 8.1 gibt einen Überblick der in ADD_dat verfügbaren Variablen auf Gemeinde-Ebene und deren Definition.\n\n\n\n\nTabelle 8.1: ADD_dat — Charakteristika von sizilianischen Gemeinden im 19. Jahrhundert\n\n\n\n\n\n\n\n\n\nVariable\nBeschreibung\n\n\n\n\npeasants_fasci\nPräsenz Fasci in 1893-Q4 (Dummy)\n\n\nsp3m1893_n30\nDürre-Intensität: Relative Regenmenge im Frühling 1893 (ggü. Mittel v. 1841 bis 1881)\n\n\ncl1_stn_sp1893_n30\nNächste aktive Wetterstation (Frühling 1893)\n\n\npredr_peas_fasci\nPräsenz Fasci vor März 1893 (Dummy)\n\n\nruralcentre1861\nLandwirtschaftliche Gemeinde? (Dummy)\n\n\nRural_rent\nDurchschn. ländliche Pacht / Hektar in 1953\n\n\nUrban_rent\nDurchschn. städtische Pacht / Hektar in 1953\n\n\nagricola_rel\nAnteil bewirtschaftetes Land in 1853\n\n\nseminatoritot_rel\nAnteil Anbaufläche Getreide in 1853\n\n\nsulfurproduction1868_70\nDurschn. Schwefel-Produktion / Jahr für 1868-1870\n\n\nCitrus_groves\nAnteil Anbaufläche Zitrusfrüchte in 1853\n\n\nOlives_groves\nAnteil Anbaufläche Oliven in 1853\n\n\nVineyards\nAnteil Anbaufläche Wein in 1853\n\n\nMafia1885\nIntensität Mafia gem. Damiani (1885), Skala 0-3\n\n\nMafia1900\nIntensität Mafia gem. Cutrera (1900), Skala 0-3\n\n\nlnpop1861\nLog(Einwohner) in 1861\n\n\nlnsurface\nLog(Fläche) in 1853\n\n\ncentreheight\nHöhe des Gemeindezentrums (M.ü. NN)\n\n\nmaxheight\nMax. Höhe (M.ü. NN)\n\n\nslope2\nDurschn. Höhe (M.ü. NN)\n\n\npa_pdist1856\nEntfernung (Postweg) von Palermo in 1856\n\n\nport2_pdist1856\nEntfernung (Postweg) nächer Hafen in 1856\n\n\nroads1799\nDirekter Zugang Postweg in 1799 (Dummy)\n\n\nave_temp\nDurschn. Jahrestemperatur\n\n\nsp3m_ave_n30\nDurschn. Regenmenge im Frühling für 1881-1941\n\n\nvar_sp3m_n30\nVarianz Regenmenge im Frühling für 1881-1941\n\n\ndistretto1853\nDistrikt-Zugehörigkeit in 1853\n\n\nprovincia1853\nProvinz-Zugehörigkeit in 1853\n\n\n\n\n\n\n\n\n\n\nVor der Analyse filtern wir die Daten entsprechen der Vorgehensweise in Acemoglu, De Feo, und De Luca (2020): Es werden lediglich Gemeinden berücksichtigt, die in maximal 30km Entfernung zu einer Wetter-Station liegen (!is.na(sp3m1893_n30)) und für die eine Messung der Mafia-Aktivität gegen Ende des 19. Jahrhunderts (gemessen auf einer Skala von 0 bis 4, vgl. Cutrera (1900)) vorliegt (!is.na(Mafia1900)).\n\n# Datensatz filtern\nADD_dat &lt;- ADD_dat %&gt;%\n  filter(\n    # Nur Gemeinden mit Wetter-Station in 30km Umkreis\n    !is.na(sp3m1893_n30), \n    # Gemeinden mit Mafia-Präsenz Ende des 19. Jdt.\n    !is.na(Mafia1900)\n  )\n\n\n8.3.2.1 First-Stage-Regressionen\nTabelle 3 in Acemoglu, De Feo, und De Luca (2020) präsentiert First-Stage-Regressionen Für den endogenen Regressor \\(\\textup{Fasci siciliani}\\) in \\(\\eqref{eq:fascimafiamod1}\\): Die Auswirkungen der Dürre in 1893 (das Instrument) auf den Organisationsgrad der Bauern (der endogene Regressor). Hierbei werden verschiedene, aus dem DAG in Abbildung 8.3 abgeleitete Spezifikationen betrachtet:\n\nPanel A: Keine Fixed Effects\n\nModell ohne Kovariablen\nModell mit Kovariablen für Bildung von Bauernorganisationen\nModell mit Kovariablen für Bildung von Bauernorganisationen und Indikatoren für Mafia-Präsenz\nModell mit Kovariablen für Bildung von Bauernorganisationen, Indikatoren für Mafia-Präsenz und geologische Faktoren\n\nPanel B: Modelle wie in Panel A und Kontrolle für Provinz-Fixed-Effects\n\nWir schätzten nachfolgend sämtliche Regressionen mit feols und berechnen nach Distrikt-Zugehörigkeit (distretto1853) sowie nächstgelegener Wetterstation (cl1_stn_sp1893_n30) geclusterte Standardfehler.6 Hierzu setzen wir vcov = ~ distretto1853 + cl1_stn_sp1893_n30. Diese Spezifikation berücksichtigt, dass die Niederschlagsmenge in einer Gemeinde sowie viele Kovariablen eine Korrelation mit benachbarten Gemeinden aufweisen können. Cluster-robuste Standardfehler sind inbesondere nötig, weil die Niederschlagsdaten für viele Gemeinden aus benachbarten Wetterstationen interpoliert werden, was zu einer zusätzlichen Korrelation zwischen den Beobachtungen führt. Standardfehler mit Two-way-clustering sind eine gängige Methode zur Berücksichtigung derartiger Korrelation.\n\nlibrary(fixest)\n\n# First-Stage-Regression:\n# keine Kontroll-Variablen\nfasci_mod &lt;- feols(\n  peasants_fasci ~ sp3m1893_n30, \n  vcov = ~ distretto1853 + cl1_stn_sp1893_n30,\n  data = ADD_dat,\n  )\n\n# Statistische Zusammenfassung\nsummary(fasci_mod)\n\nOLS estimation, Dep. Var.: peasants_fasci\nObservations: 245\nStandard-errors: Clustered (distretto1853 & cl1_stn_sp1893_n30) \n              Estimate Std. Error  t value   Pr(&gt;|t|)    \n(Intercept)   0.950863   0.098323  9.67077 2.2119e-09 ***\nsp3m1893_n30 -1.003055   0.130752 -7.67142 1.1758e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.380736   Adj. R2: 0.353963\n\n\nDer obige Code-Chunk führt die First-Stage-Regression ohne Kovariablen aus. Wir finden einen signifikanten positiven Effekt der Niederschlagsmenge auf den Organisationsgrad der Bauern.\nAcemoglu, De Feo, und De Luca (2020) verwenden Bootstrap cluster-robuste Standardfehler (Cameron, Gelbach, und Miller 2008, 2011), die aufwendig zu implementieren sind, jedoch zu nahezu identischen Ergebnissen führen. Der nächste Code-Chunk zeigt, wie cluster-robuste Bootstrap-Inferenz für das geschätzte Modell fasci_mod berechnet werden können. Hierfür nutzen wir fwildclusterboot::boottest().7\n\n# Wild-Bootstrap-Standardfehler mit clustering\nlibrary(fwildclusterboot)\n\n# boottest-Objekt erzeugen\nfasci_mod_boot &lt;- boottest(\n  object = fasci_mod, \n  clustid = ~ distretto1853 + cl1_stn_sp1893_n30,\n  param = \"sp3m1893_n30\", # Koeffizient\n  B = 999 # Bootstrap-Züge\n)\n\n# Statistische Zusammenfassung des Bootstraps\nsummary(fasci_mod_boot)\n\nboottest.fixest(object = fasci_mod, param = \"sp3m1893_n30\", B = 999, \n    clustid = ~distretto1853 + cl1_stn_sp1893_n30)\n    \n Hypothesis: 1*sp3m1893_n30 = 0\n Observations: 245\n  Bootstr. Type: rademacher\n Clustering: 2-way\n Confidence Sets: 95%\n Number of Clusters: 23 30 63\n \n\n\n                term estimate statistic p.value conf.low conf.high\n1 1*sp3m1893_n30 = 0   -1.003    -7.659       0   -1.325    -0.675\n\n\nDie statistische Zusammenfassung umfasst die Punktschätzung, die robuste t-Statistik sowie das 95%-Konfidenzintervall für den Koeffizienten von sp3m1893_n30. Mit diesen Komponenten können wir den Bootstrap-Standardfehler beispielsweise durch die folgende Transformation berechnen:\n\n# Standardfehler über t-Statistik und\n# gesch. Koeffizienten berechnen\n1/fasci_mod_boot$t_stat * fasci_mod_boot$point_estimate\n\n[1] 0.1309592\n\n\nBei der Interpretation des geschätzten Koeffizienten (-1) berückstigen wir, dass die abhängige Variable binär ist: Die First-Stage-Regression ist ein lineares Wahrscheinlicheitsmodell. Eine positive Änderung der relativen Regenmenge um eine Einheit (100%) verringert die Wahrscheinlichkeit also um 100%. Diese Interpretation ist jedoch wenig aussagekräftig für einen Einordnung des Effekts der Dürre. Stattdessen betrachten wir die Verteilung relativen Regenmengen und vergleichen den Effekt für eine von starker Dürre betroffenen Gemeinden (25%-Quantil) und einer Gemeinde mit einem relativ geringen Rückgang des Niederschlags (75%-Quantil)\n\n# Relativer Effekt der Dürre im Frühling 1893\n(\n  ADD_dat %&gt;% \n  pull(sp3m1893_n30) %&gt;% \n  quantile(\n    probs = c(.25, .75), \n    na.rm = T\n    )\n) %&gt;% \n  diff() * fasci_mod_boot$point_estimate\n\n       75% \n-0.5174457 \n\n\nFür eine Gemeinde mit 75% des langjährigen mittleren Niederschlags ist die geschätzte Wahrscheinlichkeit der Bildung von Bauern-Organisationen nur etwa halb so groß, wie für eine von starker Dürre betroffene Gemeinde.\nZur Vermeidung von Backdoors durch ausgelassene Variablen betrachten Acemoglu, De Feo, und De Luca (2020) weitere Spezifikationen für die First- und Second-Stage-Regressionen, die zusätzlich für Determinanten der Fasci, der Mafia, sowie für geographische Faktoren kontrollieren. Weiterhin werden diese Regressionen mit Fixed Effekts auf der Provinz-Ebene gemäß der Grenzen von 1853 (provincia1853) wiederholt, um für unbeobachtbare Heteogenitäten zwischen den verschiedenen Provinzen zu kontrollieren. Die nachfolgenden Code-Chunks zeigen die Implementierung dieser Regressionen mit fixtest::feols(). Für eine bessere Übersicht der Ergebnisse verwenden wir in summary() das Argument n = 1, sodass jeweils nur die Schätzung des ersten Koeffizienten (Effekt der relativen Regenmenge) ausgegeben wird.\n\n# First-Stage-Regression:\n# + Fasci-Determinanten\nfasci_mod_F &lt;- feols(\n  peasants_fasci ~ \n    sp3m1893_n30 \n    # Fasci\n  + predr_peas_fasci\n  + ruralcentre1861\n  + Rural_rent\n  + Urban_rent\n  + agricola_rel\n  + seminatoritot_rel,\n  \n  vcov = ~ distretto1853 + cl1_stn_sp1893_n30,\n  data = ADD_dat \n  ) \n\n# Statistische Zusammenfassung\nsummary(fasci_mod_F, n = 1)\n\nOLS estimation, Dep. Var.: peasants_fasci\nObservations: 245\nStandard-errors: Clustered (distretto1853 & cl1_stn_sp1893_n30) \n            Estimate Std. Error t value Pr(&gt;|t|) \n(Intercept) 0.634719   0.426989  1.4865  0.15134 \n... 7 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.363148   Adj. R2: 0.397391\n\n\n\n# First-Stage-Regression:\n# + Fasci-Determinanten\n# + Mafia-Determinanten\nfasci_mod_FM &lt;- feols(\n  fml = peasants_fasci ~ \n    sp3m1893_n30\n    # Fasci\n  + predr_peas_fasci\n  + ruralcentre1861\n  + Rural_rent\n  + Urban_rent\n  + agricola_rel\n  + seminatoritot_rel\n    # Mafia\n  + sulfurproduction1868_70\n  + Citrus_groves\n  + Olives_groves\n  + Vineyards\n  + Mafia1885,\n  \n  vcov = ~ distretto1853 + cl1_stn_sp1893_n30,\n  data = ADD_dat \n) \n\n# Statistische Zusammenfassung\nsummary(fasci_mod_FM, n = 1)\n\nOLS estimation, Dep. Var.: peasants_fasci\nObservations: 245\nStandard-errors: Clustered (distretto1853 & cl1_stn_sp1893_n30) \n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   0.7415   0.396747 1.86895 0.075002 .  \n... 12 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.353698   Adj. R2: 0.416027\n\n\n\n# First-Stage-Regression:\n# + Fasci-Determinanten\n# + Mafia-Determinanten\n# + geographische Faktoren\nfasci_mod_FMG &lt;- feols(\n  peasants_fasci ~ \n    sp3m1893_n30\n    # Fasci\n  + predr_peas_fasci\n  + ruralcentre1861\n  + Rural_rent\n  + Urban_rent\n  + agricola_rel\n  + seminatoritot_rel\n    # Mafia\n  + sulfurproduction1868_70\n  + Citrus_groves\n  + Olives_groves\n  + Vineyards\n  + Mafia1885\n    # Geographie\n  + lnpop1861\n  + lnsurface\n  + centreheight\n  + maxheight\n  + slope2\n  + pa_pdist1856\n  + port2_pdist1856\n  + roads1799\n  + ave_temp\n  + sp3m_ave_n30\n  + var_sp3m_n30,\n  \n  vcov = ~ distretto1853 + cl1_stn_sp1893_n30,\n  data = ADD_dat \n) \n\n# Statistische Zusammenfassung\nsummary(fasci_mod_FMG, n = 1)\n\nOLS estimation, Dep. Var.: peasants_fasci\nObservations: 245\nStandard-errors: Clustered (distretto1853 & cl1_stn_sp1893_n30) \n            Estimate Std. Error  t value Pr(&gt;|t|) \n(Intercept) 0.016011    1.12144 0.014277  0.98874 \n... 23 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.347776   Adj. R2: 0.407315\n\n\n\n# First Stage\n# + Provinz-Fixed-Effects\nfasci_mod_FE &lt;- feols(\n  peasants_fasci ~ \n    sp3m1893_n30\n  | provincia1853, \n  vcov = ~ distretto1853 + cl1_stn_sp1893_n30,\n  data = ADD_dat,\n  ) \nsummary(fasci_mod_FE, n = 1)\n\nOLS estimation, Dep. Var.: peasants_fasci\nObservations: 245\nFixed-effects: provincia1853: 7\nStandard-errors: Clustered (distretto1853 & cl1_stn_sp1893_n30) \n              Estimate Std. Error  t value   Pr(&gt;|t|)    \nsp3m1893_n30 -0.762897   0.138668 -5.50162 1.5781e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.370663     Adj. R2: 0.372191\n                 Within R2: 0.119989\n\n\n\n# First Stage\n# + Provinz-Fixed-Effects\n# + Fasci-Determinanten\nfasci_mod_FE_F &lt;-feols(\n  fml = peasants_fasci ~ \n    sp3m1893_n30 \n  \n  + predr_peas_fasci\n  + ruralcentre1861\n  + Rural_rent\n  + Urban_rent\n  + agricola_rel\n  + seminatoritot_rel\n  \n  | provincia1853, \n  vcov = ~ distretto1853 + cl1_stn_sp1893_n30,\n  data = ADD_dat \n  ) \n\nsummary(fasci_mod_FE_F, n = 1)\n\nOLS estimation, Dep. Var.: peasants_fasci\nObservations: 245\nFixed-effects: provincia1853: 7\nStandard-errors: Clustered (distretto1853 & cl1_stn_sp1893_n30) \n              Estimate Std. Error  t value   Pr(&gt;|t|)    \nsp3m1893_n30 -0.813957   0.159025 -5.11842 3.9568e-05 ***\n... 6 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.356253     Adj. R2: 0.404994\n                 Within R2: 0.187084\n\n\n\n# First Stage\n# + Provinz-Fixed-Effects\n# + Fasci-Determinanten\n# + Mafia-Determinanten\nfasci_mod_FE_FM &lt;- feols(\n  fml = peasants_fasci ~ \n    sp3m1893_n30 \n  \n  + predr_peas_fasci\n  + ruralcentre1861\n  + Rural_rent\n  + Urban_rent\n  + agricola_rel\n  + seminatoritot_rel\n  \n  + sulfurproduction1868_70\n  + Citrus_groves\n  + Olives_groves\n  + Vineyards\n  + Mafia1885\n  \n  | provincia1853,\n  vcov = ~ distretto1853 + cl1_stn_sp1893_n30,\n  data = ADD_dat \n) \n\nsummary(fasci_mod_FE_FM, n = 1)\n\nOLS estimation, Dep. Var.: peasants_fasci\nObservations: 245\nFixed-effects: provincia1853: 7\nStandard-errors: Clustered (distretto1853 & cl1_stn_sp1893_n30) \n              Estimate Std. Error  t value  Pr(&gt;|t|)    \nsp3m1893_n30 -0.738703   0.165957 -4.45117 0.0002004 ***\n... 11 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.341461     Adj. R2: 0.441285\n                 Within R2: 0.253188\n\n\n\n# First Stage\n# + Provinz-Fixed-Effects\n# + Fasci-Determinanten\n# + Mafia-Determinanten\n# + geografische Faktoren\nfasci_mod_FE_FMG &lt;- feols(\n  peasants_fasci ~ sp3m1893_n30 \n  \n  + predr_peas_fasci\n  + ruralcentre1861\n  + Rural_rent\n  + Urban_rent\n  + agricola_rel\n  + seminatoritot_rel\n  \n  + sulfurproduction1868_70\n  + Citrus_groves\n  + Olives_groves\n  + Vineyards\n  + Mafia1885\n  \n  + lnpop1861\n  + lnsurface\n  + centreheight\n  + maxheight\n  + slope2\n  + pa_pdist1856\n  + port2_pdist1856\n  + roads1799\n  + ave_temp\n  + sp3m_ave_n30\n  + var_sp3m_n30\n  \n  | provincia1853,  \n  vcov = ~ distretto1853 + cl1_stn_sp1893_n30,\n  data = ADD_dat \n) \n\nsummary(fasci_mod_FE_FMG, n = 1)\n\nOLS estimation, Dep. Var.: peasants_fasci\nObservations: 245\nFixed-effects: provincia1853: 7\nStandard-errors: Clustered (distretto1853 & cl1_stn_sp1893_n30) \n              Estimate Std. Error  t value  Pr(&gt;|t|)    \nsp3m1893_n30 -0.718998   0.209917 -3.42515 0.0024214 ** \n... 22 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.338173     Adj. R2: 0.423955\n                 Within R2: 0.267501\n\n\nFür eine tabellarische Übersicht fassen wir die interessierenden Komponenten der Schätzungen mit modelsummary::modelsummary() zusammen. Hierfür sammeln wir zunächst jeweils die Modelle mit und ohne Provinz-Fixed-Effects in benannten Listen, sodass die Ergebnisse später in separaten Panelen dargestellt werden können. Für die Formatierung von Labels für die Fixed Effects und Koeffizienten definieren wir das tribble-Objekt gm und übergeben reguläre Ausdrücke für eine Auswahl an zusammenfassenden Statistiken.\n\nlibrary(modelsummary)\n\n# Modelle in benannten Listen sammeln\npanels &lt;- list(\n  \"Panel A\" = list(\n    \"Keine Controls\" = fasci_mod,\n    \"Fasci\" = fasci_mod_F,\n    \"Fasci + Mafia\" = fasci_mod_FM,\n    \"Fasci + Mafia + Geo\" = fasci_mod_FMG\n  ),\n  \"Panel B (Fixed Effects)\" = list(\n    \"Keine Controls\" = fasci_mod_FE,\n    \"Fasci\" = fasci_mod_FE_F,\n    \"Fasci + Mafia\" = fasci_mod_FE_FM,\n    \"Fasci + Mafia + Geo\" = fasci_mod_FE_FMG\n  )\n)\n\n# Format für FE-label\ngm &lt;- tribble(\n  ~raw, ~clean, ~fmt,\n  \"FE: provincia1853\", \"FE: Provinz\", ~fmt\n)\n\n# Tabellarische Zusammenfassung\nmodelsummary(\n  models = panels,\n  shape = \"rbind\",\n  coef_omit = \"^(?!(sp3m1893\\\\_n30*)$).*\",\n  stars = T,\n  gof_omit = \"^(?!(FE.*)$).*\",\n  coef_map = c(\n    \"sp3m1893_n30\" = \"Rel. Niederschlag 1893\"\n    ),\n  gof_map = gm, \n  notes = c(\n    \"Abhängige Variable: Peasants Fasci\", \n    \"Cluster-robuste Standardfehler: Naheste Wetterstation + Distrikt\"\n  ),\n  output = \"gt\"\n) %&gt;%\n  tabopts()\n\n\n\nTabelle 8.2: ADD_dat – First-Stage-Regressionen aus Acemoglu, De Feo, und De Luca (2020)\n\n\n\n\n\n\n\n\n\n\nKeine Controls\nFasci\nFasci + Mafia\nFasci + Mafia + Geo\n\n\n\n\nPanel A\n\n\nRel. Niederschlag 1893\n-1.003***\n-0.942***\n-0.934***\n-0.782***\n\n\n\n(0.131)\n(0.121)\n(0.128)\n(0.153)\n\n\nPanel B (Fixed Effects)\n\n\nRel. Niederschlag 1893\n-0.763***\n-0.814***\n-0.739***\n-0.719**\n\n\n\n(0.139)\n(0.159)\n(0.166)\n(0.210)\n\n\nFE: Provinz\nX\nX\nX\nX\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\nAbhängige Variable: Peasants Fasci\n\n\nCluster-robuste Standardfehler: Naheste Wetterstation + Distrikt\n\n\n\n\n\n\n\n\n\n\n\nDie Ergebnisse in Tabelle 8.2 bestätigen die Vermutung der Autoren, dass der Effekt des relativen Niederschlags auf den Organisationsgrad der Bauern ohne Kontrolle für die betrachteten Kovariablen tendenziell überschätzt wird. Tatsächlich führt multiple Regression mit Fixed Effects und sämtlichen Kovariablen (letzte Spalte in Panel B) zu einem etwa 30% kleineren geschätzten Effekt als für die einfache Regression in Panel A.\n\n\n8.3.2.2 Second-Stage-Regressionen\nMit fml = Mafia1900 ~ 1 | peasants_fasci ~ sp3m1893_n30 legen wir fest, dass Mafia1900 auf eine Konstante sowie die angepassten Werte des endogenen Regressors peasants_fasci aus der ersten Stufe (instrumentiert durch sp3m1893_n30) regressiert werden soll. Wie für die Regressionen in Tabelle 8.2 schätzen wir jeweils vier verschiedene Spezfikationen, unterscheiden zwischen Modellen mit und ohne Provinz-Fixed-Effects und berechnen cluster-robuste Standardfehler.\n\n# Second-Stage-Regression:\n# Keine Kontrollvariablen\n# (1)\nfasciIV_mod &lt;- feols(\n  fml = Mafia1900 ~ 1 \n  # IV-Spezifikation\n  | peasants_fasci ~ sp3m1893_n30,\n  vcov = ~ distretto1853 + cl1_stn_sp1893_n30,\n  data = ADD_dat\n)\n\nsummary(fasciIV_mod, n = 1)\n\nTSLS estimation - Dep. Var.: Mafia1900\n                  Endo.    : peasants_fasci\n                  Instr.   : sp3m1893_n30\nSecond stage: Dep. Var.: Mafia1900\nObservations: 245\nStandard-errors: Clustered (distretto1853 & cl1_stn_sp1893_n30) \n            Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept) 0.692647   0.203977 3.39571 0.0025978 ** \n... 1 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 1.16456   Adj. R2: -0.027853\nF-test (1st stage), peasants_fasci: stat = 134.7, p &lt; 2.2e-16 , on 1 and 243 DoF.\n                        Wu-Hausman: stat =  35.2, p = 1.013e-8, on 1 and 242 DoF.\n\n\n\n# Second-Stage-Regression:\n# + Fasci-Determinanten\nfasciIV_mod_F &lt;- feols(\n  fml = Mafia1900 ~ \n  # Fasci\n  predr_peas_fasci\n  + ruralcentre1861\n  + Rural_rent\n  + Urban_rent\n  + agricola_rel\n  + seminatoritot_rel\n  # IV-Spezifikation\n  | peasants_fasci ~ sp3m1893_n30,\n  vcov = ~ distretto1853 + cl1_stn_sp1893_n30,\n  data = ADD_dat\n) \n\nsummary(fasciIV_mod_F, n = 1)\n\nTSLS estimation - Dep. Var.: Mafia1900\n                  Endo.    : peasants_fasci\n                  Instr.   : sp3m1893_n30\nSecond stage: Dep. Var.: Mafia1900\nObservations: 245\nStandard-errors: Clustered (distretto1853 & cl1_stn_sp1893_n30) \n             Estimate Std. Error   t value Pr(&gt;|t|) \n(Intercept) -0.253013    1.03236 -0.245083  0.80866 \n... 7 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 1.14179   Adj. R2: -0.01306\nF-test (1st stage), peasants_fasci: stat = 115.1, p &lt; 2.2e-16 , on 1 and 237 DoF.\n                        Wu-Hausman: stat =  39.0, p = 1.931e-9, on 1 and 236 DoF.\n\n\n\n# Second-Stage-Regression:\n# + Fasci-Determinanten\n# + Mafia-Determinanten\nfasciIV_mod_FM &lt;- feols(\n  fml = Mafia1900 ~ \n    # Fasci\n    predr_peas_fasci\n  + ruralcentre1861\n  + Rural_rent\n  + Urban_rent\n  + agricola_rel\n  + seminatoritot_rel\n    # Mafia\n  + sulfurproduction1868_70\n  + Citrus_groves\n  + Olives_groves\n  + Vineyards\n  + Mafia1885\n    # IV-Spezifikation\n  | peasants_fasci ~ sp3m1893_n30,\n  vcov = ~ distretto1853 + cl1_stn_sp1893_n30,\n  data = ADD_dat\n) \n\nsummary(fasciIV_mod_FM, n = 1)\n\nTSLS estimation - Dep. Var.: Mafia1900\n                  Endo.    : peasants_fasci\n                  Instr.   : sp3m1893_n30\nSecond stage: Dep. Var.: Mafia1900\nObservations: 245\nStandard-errors: Clustered (distretto1853 & cl1_stn_sp1893_n30) \n             Estimate Std. Error   t value Pr(&gt;|t|) \n(Intercept) -0.272777    1.03221 -0.264266  0.79403 \n... 12 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 1.0177   Adj. R2: 0.177817\nF-test (1st stage), peasants_fasci: stat = 111.6, p &lt; 2.2e-16 , on 1 and 232 DoF.\n                        Wu-Hausman: stat =  30.9, p = 7.381e-8, on 1 and 231 DoF.\n\n\n\n# Second-Stage-Regression:\n# + Fasci-Determinanten\n# + Mafia-Determinanten\n# + Geographie\nfasciIV_mod_FMG &lt;- feols(\n  fml = Mafia1900 ~ \n    # Fasci\n    predr_peas_fasci\n  + ruralcentre1861\n  + Rural_rent\n  + Urban_rent\n  + agricola_rel\n  + seminatoritot_rel\n    # Mafia\n  + sulfurproduction1868_70\n  + Citrus_groves\n  + Olives_groves\n  + Vineyards\n  + Mafia1885\n    # Geographie\n  + lnpop1861\n  + lnsurface\n  + centreheight\n  + maxheight\n  + slope2\n  + pa_pdist1856\n  + port2_pdist1856\n  + roads1799\n  + ave_temp\n  + sp3m_ave_n30\n  + var_sp3m_n30\n   # IV-Spezifikation\n  | peasants_fasci ~ sp3m1893_n30,\n  vcov = ~ distretto1853 + cl1_stn_sp1893_n30,\n  data = ADD_dat\n) \n\nsummary(fasciIV_mod_FMG, n = 1)\n\nTSLS estimation - Dep. Var.: Mafia1900\n                  Endo.    : peasants_fasci\n                  Instr.   : sp3m1893_n30\nSecond stage: Dep. Var.: Mafia1900\nObservations: 245\nStandard-errors: Clustered (distretto1853 & cl1_stn_sp1893_n30) \n            Estimate Std. Error  t value Pr(&gt;|t|) \n(Intercept) 0.614509    2.70956 0.226793  0.82268 \n... 23 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.896696   Adj. R2: 0.329944\nF-test (1st stage), peasants_fasci: stat = 33.4, p = 2.528e-8, on 1 and 221 DoF.\n                        Wu-Hausman: stat = 12.2, p = 5.753e-4, on 1 and 220 DoF.\n\n\n\n# Second-Stage-Regression:\n# + Provinz-FE\nfasciIV_mod_FE &lt;- feols(\n  fml = Mafia1900 ~ 1 \n  # Fixed Effecs\n  | provincia1853 \n  # IV-Spezifikation\n  | peasants_fasci ~ sp3m1893_n30,\n  vcov = ~ distretto1853 + cl1_stn_sp1893_n30,\n  data = ADD_dat\n) \n\nsummary(fasciIV_mod_FE, n = 1)\n\nTSLS estimation - Dep. Var.: Mafia1900\n                  Endo.    : peasants_fasci\n                  Instr.   : sp3m1893_n30\nSecond stage: Dep. Var.: Mafia1900\nObservations: 245\nFixed-effects: provincia1853: 7\nStandard-errors: Clustered (distretto1853 & cl1_stn_sp1893_n30) \n                   Estimate Std. Error t value  Pr(&gt;|t|)    \nfit_peasants_fasci 0.866875   0.243571 3.55902 0.0017565 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.894467     Adj. R2:  0.378283\n                 Within R2: -0.059948\nF-test (1st stage), peasants_fasci: stat = 32.3    , p = 3.836e-8, on 1 and 237 DoF.\n                        Wu-Hausman: stat =  2.46207, p = 0.117965, on 1 and 236 DoF.\n\n\n\n# Second-Stage-Regression:\n# + Fasci-Determinanten\n# + Provinz-FE\nfasciIV_mod_FE_F &lt;- feols(\n  fml = Mafia1900 ~ \n    # Fasci\n    predr_peas_fasci\n  + ruralcentre1861\n  + Rural_rent\n  + Urban_rent\n  + agricola_rel\n  + seminatoritot_rel\n    # Fixed Effects\n  | provincia1853\n    # IV-Spezifikation\n  | peasants_fasci ~ sp3m1893_n30,\n  vcov = ~ distretto1853 + cl1_stn_sp1893_n30,\n  data = ADD_dat\n) \n\nsummary(fasciIV_mod_FE_F, n = 1)\n\nTSLS estimation - Dep. Var.: Mafia1900\n                  Endo.    : peasants_fasci\n                  Instr.   : sp3m1893_n30\nSecond stage: Dep. Var.: Mafia1900\nObservations: 245\nFixed-effects: provincia1853: 7\nStandard-errors: Clustered (distretto1853 & cl1_stn_sp1893_n30) \n                   Estimate Std. Error t value   Pr(&gt;|t|)    \nfit_peasants_fasci  1.02514   0.256786 3.99219 0.00061474 ***\n... 6 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.878524     Adj. R2:  0.384671\n                 Within R2: -0.0225  \nF-test (1st stage), peasants_fasci: stat = 37.2    , p = 4.42e-9 , on 1 and 231 DoF.\n                        Wu-Hausman: stat =  5.78115, p = 0.016991, on 1 and 230 DoF.\n\n\n\n# Second-Stage-Regression:\n# + Fasci-Determinanten\n# + Mafia-Determinanten\n# + Provinz-FE\nfasciIV_mod_FE_FM &lt;- feols(\n  fml = Mafia1900 ~ \n    # Fasci\n    predr_peas_fasci\n  + ruralcentre1861\n  + Rural_rent\n  + Urban_rent\n  + agricola_rel\n  + seminatoritot_rel\n    # Mafia\n  + sulfurproduction1868_70\n  + Citrus_groves\n  + Olives_groves\n  + Vineyards\n  + Mafia1885\n    # Fixed Effects\n  | provincia1853 \n    # IV-Spezifikation\n  | peasants_fasci ~ sp3m1893_n30,\n  vcov = ~ distretto1853 + cl1_stn_sp1893_n30,\n  data = ADD_dat\n) \n\nsummary(fasciIV_mod_FE_FM, n = 1)\n\nTSLS estimation - Dep. Var.: Mafia1900\n                  Endo.    : peasants_fasci\n                  Instr.   : sp3m1893_n30\nSecond stage: Dep. Var.: Mafia1900\nObservations: 245\nFixed-effects: provincia1853: 7\nStandard-errors: Clustered (distretto1853 & cl1_stn_sp1893_n30) \n                   Estimate Std. Error t value  Pr(&gt;|t|)    \nfit_peasants_fasci  1.33734     0.4272 3.13047 0.0048655 ** \n... 11 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.84824     Adj. R2: 0.41367 \n                Within R2: 0.046778\nF-test (1st stage), peasants_fasci: stat = 31.4    , p = 6.07e-8 , on 1 and 226 DoF.\n                        Wu-Hausman: stat =  6.49318, p = 0.011495, on 1 and 225 DoF.\n\n\n\n# Second-Stage-Regression:\n# + Fasci-Determinanten\n# + Mafia-Determinanten\n# + Geographische Faktoren\n# + Provinz-FE\nfasciIV_mod_FE_FMG &lt;- feols(\n  fml = Mafia1900 ~ \n    # Fasci\n    predr_peas_fasci\n  + ruralcentre1861\n  + Rural_rent\n  + Urban_rent\n  + agricola_rel\n  + seminatoritot_rel\n    # Mafia\n  + sulfurproduction1868_70\n  + Citrus_groves\n  + Olives_groves\n  + Vineyards\n  + Mafia1885\n    # Geo\n  + lnpop1861\n  + lnsurface\n  + centreheight\n  + maxheight\n  + slope2\n  + pa_pdist1856\n  + port2_pdist1856\n  + roads1799\n  + ave_temp\n  + sp3m_ave_n30\n  + var_sp3m_n30\n    # Fixed Effects\n  | provincia1853 \n    # IV-Spezifikation\n  | peasants_fasci ~ sp3m1893_n30,\n  vcov = ~ distretto1853 + cl1_stn_sp1893_n30,\n  data = ADD_dat\n)\n\nsummary(fasciIV_mod_FE_FMG, n = 1)\n\nTSLS estimation - Dep. Var.: Mafia1900\n                  Endo.    : peasants_fasci\n                  Instr.   : sp3m1893_n30\nSecond stage: Dep. Var.: Mafia1900\nObservations: 245\nFixed-effects: provincia1853: 7\nStandard-errors: Clustered (distretto1853 & cl1_stn_sp1893_n30) \n                   Estimate Std. Error t value Pr(&gt;|t|)    \nfit_peasants_fasci  1.56343   0.599753  2.6068 0.016101 *  \n... 22 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.857152     Adj. R2: 0.370653\n                 Within R2: 0.026644\nF-test (1st stage), peasants_fasci: stat = 20.8    , p = 8.72e-6 , on 1 and 215 DoF.\n                        Wu-Hausman: stat =  7.05768, p = 0.008487, on 1 and 214 DoF.\n\n\n\n# Modelle in benannten Listen sammeln\npanels &lt;- list(\n  \"Panel A\" = list(\n    \"Keine Controls\" = fasciIV_mod,\n    \"Fasci\" = fasciIV_mod_F,\n    \"Fasci + Mafia\" = fasciIV_mod_FM,\n    \"Fasci + Mafia + Geo\" = fasciIV_mod_FMG\n  ),\n  \"Panel B (Fixed Effects)\" = list(\n    \"Keine Controls\" = fasciIV_mod_FE,\n    \"Fasci\" = fasciIV_mod_FE_F,\n    \"Fasci + Mafia\" = fasciIV_mod_FE_FM,\n    \"Fasci + Mafia + Geo\" = fasciIV_mod_FE_FMG\n  )\n)\n\n# Tabellarische Zusammenfassung\nmodelsummary(\n  models = panels,\n  shape = \"rbind\",\n  coef_omit = \"^(?!(fit\\\\_peasants\\\\_fasci*)$).*\",\n  stars = T,\n  gof_omit = \"^(?!(FE.*)$).*\",\n  coef_map = c(\n    \"fit_peasants_fasci\" = \"Fasci\"\n    ),\n  gof_map = gm, \n  notes = c(\n    \"Abhängige Variable: Mafia-Präsenz in 1900\", \n    \"Instrument: Rel. Niederschlag 1893\", \n    \"Cluster-robuste Standardfehler: Naheste Wetterstation + Distrikt\"\n  ),\n  output = \"gt\"\n) %&gt;%\n  tabopts()\n\n\n\nTabelle 8.3: ADD_dat – Second-Stage-Regressionen aus Acemoglu, De Feo, und De Luca (2020)\n\n\n\n\n\n\n\n\n\n\nKeine Controls\nFasci\nFasci + Mafia\nFasci + Mafia + Geo\n\n\n\n\nPanel A\n\n\nFasci\n2.051***\n2.096***\n1.958***\n1.688**\n\n\n\n(0.383)\n(0.371)\n(0.332)\n(0.532)\n\n\nPanel B (Fixed Effects)\n\n\nFasci\n0.867**\n1.025***\n1.337**\n1.563*\n\n\n\n(0.244)\n(0.257)\n(0.427)\n(0.600)\n\n\nFE: Provinz\nX\nX\nX\nX\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\nAbhängige Variable: Mafia-Präsenz in 1900\n\n\nInstrument: Rel. Niederschlag 1893\n\n\nCluster-robuste Standardfehler: Naheste Wetterstation + Distrikt\n\n\n\n\n\n\n\n\n\n\n\nDie Ergebnisse für die IV-Schätzung des kausalen Effekts von Bauernorganisationen auf die Präsenz der Mafia zu Beginn des 20. Jahrhundert sind in Tabelle 8.3 dargestellt. Die LATE-Schätzung in Spalte 4 von Panel B hat folgende Interpretation: Die Präsenz der Fasci in einer Gemeinde erhöht die Intensität der Mafia-Aktivität um etwa 1.56 Punkte.8\nWie ist dieser Effekt einzuordnen? Wir berechnen zunächst die Anzahl an Gemeinden, in denen es im Jahr 1900 Fasci gibt.\n\n# Anz. Gemeinden mit Fasci im Jahr 1900\nADD_dat %&gt;% \n  drop_na() %&gt;% \n  filter(\n    peasants_fasci == 1\n  ) %&gt;% \n  count()\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1    84\n\n\nFür diese 84 Gemeinden erwarten wir jeweils einen Effekt von 1.56 Punkten auf die im Jahr 1900 beobachtete gesamte Intensität des Einflusses der Mafia in Sizilien, gemessen als gewichtete Summe.\n\n# Beitrag der Gemeinden mit Fasci im Jahr 1900\n84 * 1.56\n\n[1] 131.04\n\n\nDie gesamte Mafia-Intensität für Sizilien zu Beginn des 20. Jahrhunderts berechnen wir analog.\n\n# Mafia-Intensität in Sizilien im Jahr 1900\nADD_dat %&gt;% \n  drop_na() %&gt;% \n  count(Mafia1900) %&gt;% \n  mutate(Beitrag = Mafia1900 * n) %&gt;%\n  summarise(\n     Intensität = sum(Beitrag)\n  )\n\n# A tibble: 1 × 1\n  Intensität\n       &lt;dbl&gt;\n1        342\n\n\nDer Anteil der Gemeinden mit Bauernorganisationen im Jahr 1900 an dieser Summe erlaubt eine Einordnung des Effekts der Fasci auf die Verbreitung der Mafia.\n\n# Anteil des geschätzten Effekts\n84 * 1.56 / 342\n\n[1] 0.3831579\n\n\nDie Interpretation lautet, dass bis zu 38% der Stärke der Mafia im Jahr 1900 in Sizilien auf ihren Einsatz gegen die Fasci zurückzuführen sein könnte.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>IV-Regression</span>"
    ]
  },
  {
    "objectID": "IV.html#case-study-ökonomische-schocks-und-bürgerkriege",
    "href": "IV.html#case-study-ökonomische-schocks-und-bürgerkriege",
    "title": "8  IV-Regression",
    "section": "8.4 Case Study: Ökonomische Schocks und Bürgerkriege",
    "text": "8.4 Case Study: Ökonomische Schocks und Bürgerkriege\nEin Kernproblem bei der Schätzung der kausalen Beziehung zwischen wirtschaftlichen Schocks und dem Auftreten von kriegerischen Auseinandersetzungen ist die Endogenität von Variablen, die wirtschaftliche Stabilität messen (vgl. Fearon und Laitin 2003). Beispielsweise kann eine Verschlechterung der wirtschaftlichen Bedingungen eines Landes die Wahrscheinlichkeit eines Konflikts im Inland erhöhen. Gleichermaßen beeinflussen kriegerische Handlung im Inland die wirtschaftliche Situation einer Volkswirtschaft negativ.\n\n\n\n\n\n\n\n\nIV_DAG\n\n\n\nK\n\nK\n\n\n\nBIP\n\nBIP\n\n\n\nK-&gt;BIP\n\n\n\n\n\nKonflikt\n\nKonflikt\n\n\n\nK-&gt;Konflikt\n\n\n\n\n\nBIP-&gt;Konflikt\n\n\n\n\n\nKonflikt-&gt;BIP\n\n\n\n\n\n\n\n\nAbbildung 8.4: Simultane Kausalität zw. Kriegsrisiko und Wirtschaftslage\n\n\n\n\n\nIn der “Konfliktgleichung”\n\\[\\begin{align}\n  \\textup{Konflikt-Wsk.} = \\beta_0 + \\beta_1\\, \\Delta\\text{BIP} + \\text{Kontrollv.} + \\epsilon\\label{eq:rainconf1}\n\\end{align}\\]\nliegt dann Endogenität des Regressors für “wirtschaftliche Stabilität”, hier \\(\\Delta\\text{BIP}\\), aufgrund von simultanter Kausalität vor. Die multiple Regression \\(\\eqref{eq:rainconf1}\\) liefert dann eine verzerrte Schätzungen des interessierenden Effekts \\(\\beta_1\\).\nMiguel, Satyanath, und Sergenti (2004) untersuchen die kausale Beziehung zwischen wirtschaftlichen Schocks und dem Auftreten von Bürgerkriegen in 41 afrikanischen Sub-Sahara-Ländern für den Zeitraum von 1981 bis 1999.9 Hierbei adressieren die Autoren das Endogenitätsproblem in einem IV-Ansatz mit Instrumenten, die mit wirtschaftlichen Schocks korreliert sind, aber nicht unmittelbar mit der Wahrscheinlichkeit eines Bürgerkriegs zusammenhängen.\nDie Identifikationsstrategie basiert auf metereologischen Faktoren: In den betrachteten Agrarökonomien sind Schocks in den Niederschlägen entscheidend für die Entwicklung des Bruttoinlandsprodukts. Ungünstige Wetterbedingungen, die landwirtschaftliche Erträge negativ beeinflussen, haben einen direkten (negativen) Effekt auf die wirtschaftliche Situation. Variation in der Regenmenge ist jedoch keine unmittelbare Determinante der Konfliktwahrscheinlichkeit und folglich exogen in Modellgleichung \\(\\eqref{eq:rainconf1}\\). Maße für die Veränderungen in der Niederschlagsmenge sind somit plausible Instrumente für endogene Variablen, die Veränderungen im Bruttoinlandsprodukt messen.\n\n\n\n\n\n\n\n\nIV_DAG\n\n\n\nC\n\nC\n\n\n\nBIP\n\nBIP\n\n\n\nC-&gt;BIP\n\n\n\n\n\nKonflikt\n\nKonflikt\n\n\n\nC-&gt;Konflikt\n\n\n\n\n\nNiederschlag\n\nNiederschlag\n\n\n\nNiederschlag-&gt;BIP\n\n\n\n\n\nBIP-&gt;Konflikt\n\n\n\n\n\nKonflikt-&gt;BIP\n\n\n\n\n\n\n\n\nAbbildung 8.5: IV-Design bei simultaner Kausalität zw. Kriegsrisiko und Wirtschaftslage\n\n\n\n\n\nAnhand von Länder-Paneldaten mit Informationen über wirtschaftliche Indikatoren, Konfliktereignisse und Niederschläge, isolieren Miguel, Satyanath, und Sergenti (2004) in einem IV-Ansatz die exogene Variation der wirtschaftlichen Entwicklung, d.h. Variation in \\(\\Delta\\text{BIP}\\) die nicht mit dem Fehlerterm in der Konfliktgleichung korreliert ist. Die Ergebnisse ihrer 2SLS-Schätzungen zeigen, dass negative ökonomische Schocks die Wahrscheinlichkeit eines Bürgerkriegs signifikant erhöhen. Miguel, Satyanath, und Sergenti (2004) zeigen weiterhin, dass ihre Ergebnisse robust gegenüber verschiedenen Modell-Spezifikationen unter Berücksichtigung diverser Kontrollvariablen sind.\nWir reproduzieren nachfolgend die zentralen Ergebnisse von Miguel, Satyanath, und Sergenti (2004) anhand eines Auszugs (rainconflict.csv) aus dem der Studie zugrundeliegenden Datensatz. Der vollständige Datensatz ist, nach Registrierung, hier verfügbar.\n\nlibrary(readr)\n\n# Datensatz 'rainconflict' einlesen\nrainconflict &lt;- read_csv2(\n  file = \"datasets/rainconflict.csv\"\n)\n\n\n# Überblick verschaffen\nglimpse(rainconflict)\n\nRows: 743\nColumns: 19\n$ any_prio   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,…\n$ war_prio   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,…\n$ ccode      &lt;dbl&gt; 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404,…\n$ country    &lt;chr&gt; \"Guinea-Bissau\", \"Guinea-Bissau\", \"Guinea-Bissau\", \"Guinea-…\n$ gdp_g      &lt;dbl&gt; 0.216560572, 0.104712047, -0.042654045, 0.034653414, 0.0366…\n$ gdp_g_l    &lt;dbl&gt; -0.152877718, 0.216560572, 0.104712047, -0.042654045, 0.034…\n$ GPCP_g     &lt;dbl&gt; 0.170644149, 0.023161817, -0.215036541, 0.098459557, 0.0185…\n$ GPCP_g_l   &lt;dbl&gt; -0.048803251, 0.170644149, 0.023161817, -0.215036541, 0.098…\n$ GPCP_g_fl  &lt;dbl&gt; 0.023161817, -0.215036541, 0.098459557, 0.018551834, 0.0545…\n$ gdp_1979   &lt;dbl&gt; 0.556, 0.556, 0.556, 0.556, 0.556, 0.556, 0.556, 0.556, 0.5…\n$ polity2l   &lt;dbl&gt; -7, -7, -7, -7, -8, -8, -8, -8, -8, -8, -6, -6, -6, -6, 5, …\n$ polity2_IV &lt;dbl&gt; -7, -7, -7, -8, -8, -8, -8, -8, -8, -6, -6, -6, -6, 5, 5, 5…\n$ ethfrac    &lt;dbl&gt; 0.8037570, 0.8037570, 0.8037570, 0.8037570, 0.8037570, 0.80…\n$ relfrac    &lt;dbl&gt; 0.5450, 0.5450, 0.5450, 0.5450, 0.5450, 0.5450, 0.5450, 0.5…\n$ oil        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ lmtnest    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ lpopl1     &lt;dbl&gt; 6.695799, 6.714170, 6.732211, 6.749931, 6.768493, 6.786717,…\n$ tot_100_g  &lt;dbl&gt; 0.3326812088, -0.0604966730, 0.0235692672, 0.6656700373, -0…\n$ year       &lt;dbl&gt; 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990,…\n\n\n\n\n\n\nTabelle 8.4: rainconflict – Polit-ökonomische Charakteristika afrikanischer Länder v. 1981 bis 1999\n\n\n\n\n\n\n\n\n\nVariable\nBeschreibung\n\n\n\n\nany_prior\nDummyvariable: Konflikt mit mind. 25 Toten im Jahr t\n\n\nwar_prio\nDummyvariable: Konflikt mit mind. 1000 Toten im Jahr t\n\n\nccode\nLänderkennung (numerisch)\n\n\ncountry\nName des Landes\n\n\ngdp_g\n(BIP_t - BIP_t-1) / BIP_t-1\n\n\ngdp_g_l\n(BIP_t-1 - BIP_t-2) / BIP_t-2\n\n\nGPCP_g\n(Niederschlag_t - Niederschlag_t-1) / Niederschlag_t-1\n\n\nGPCP_g_l\nGPCP_g in t-1\n\n\nGPCP_g_fl\nGPCP_g in t+1\n\n\ngdp_1979\nLog Pro-Kopf-BIP in 1979\n\n\npolity2_IV\nDiff. zw. Demokratie- und Autokrarie-Score im Jahr t (Skala v. -10 bis 10)\n\n\npolity2l\npolity2_IV im Jahr t-1 (Skala v. -10 bis 10)\n\n\nethfrac\nEthno-linguistische Fragmentierung (Anteil)\n\n\nrelfrac\nReligiöse Fragmentierung (Anteil)\n\n\noil\nDummy für Öl-exportierendes Land\n\n\nlmtnest\nLog Anteil Gebirgsregionen an Landesfläche\n\n\nlpopl1\nLog Bevölkerung im Jahr t-1\n\n\ntot_100_g\nHandelsbedingungen (Index, 1995 = 100)\n\n\nyear\nJahr der Beobachtung\n\n\n\n\n\n\n\n\n\n\n\n# ccode zu Typ 'factor' transformieren\nrainconflict &lt;- rainconflict %&gt;% \n  mutate(\n    ccode = as.factor(ccode)\n  )\n\n\nlibrary(modelsummary)\n\n# Statistische Zusammenfassung\ndatasummary(\n  formula = All( rainconflict %&gt;% select(-ccode, -year) )   \n    ~ (mean + sd) * Arguments(na.rm = TRUE) \n    + N, \n  fmt = 4,\n  data = rainconflict \n) \n\n\n\nTabelle 8.5: rainconflict – Statistische Zusammenfassung\n\n\n\n \n\n  \n    \n    \n    tinytable_9tur4t73u2ptbm2uko1h\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                mean\n                sd\n                N\n              \n        \n        \n        \n                \n                  any_prio  \n                  0.2678 \n                  0.4431\n                  743\n                \n                \n                  war_prio  \n                  0.1669 \n                  0.3731\n                  743\n                \n                \n                  gdp_g     \n                  -0.0048\n                  0.0707\n                  743\n                \n                \n                  gdp_g_l   \n                  -0.0056\n                  0.0724\n                  743\n                \n                \n                  GPCP_g    \n                  0.0182 \n                  0.2094\n                  743\n                \n                \n                  GPCP_g_l  \n                  0.0113 \n                  0.2067\n                  743\n                \n                \n                  GPCP_g_fl \n                  0.0150 \n                  0.2107\n                  743\n                \n                \n                  gdp_1979  \n                  1.1639 \n                  0.9009\n                  743\n                \n                \n                  polity2l  \n                  -3.6083\n                  5.5543\n                  743\n                \n                \n                  polity2_IV\n                  -3.4035\n                  5.5766\n                  736\n                \n                \n                  ethfrac   \n                  0.6546 \n                  0.2374\n                  743\n                \n                \n                  relfrac   \n                  0.4868 \n                  0.1857\n                  743\n                \n                \n                  oil       \n                  0.1184 \n                  0.3233\n                  743\n                \n                \n                  lmtnest   \n                  1.5783 \n                  1.4334\n                  743\n                \n                \n                  lpopl1    \n                  8.7497 \n                  1.2068\n                  743\n                \n                \n                  tot_100_g \n                  -0.0068\n                  0.1552\n                  661\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\n\n\n\nlibrary(fixest)\n\n# (1)\n(\n  rncnf_mod1 &lt;- feols(\n    fml = gdp_g ~ GPCP_g + GPCP_g_l,\n    data = rainconflict,\n    vcov = ~ ccode\n  )\n)\n\nOLS estimation, Dep. Var.: gdp_g\nObservations: 743\nStandard-errors: Clustered (ccode) \n             Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept) -0.006147   0.002460 -2.49856 0.0166787 *  \nGPCP_g       0.055430   0.016301  3.40029 0.0015378 ** \nGPCP_g_l     0.034058   0.013213  2.57761 0.0137398 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.069815   Adj. R2: 0.02088\n\n\n\n# (2)\nrncnf_mod2 &lt;- feols(\n  fml = gdp_g ~ GPCP_g + GPCP_g_l\n  + gdp_1979\n  + polity2l \n  + ethfrac \n  + relfrac \n  + oil \n  + lmtnest \n  + lpopl1\n  + year:ccode,\n  data = rainconflict,\n  vcov = ~ ccode\n) \n\nrncnf_mod2 %&gt;% \n  print(n = 10)\n\nOLS estimation, Dep. Var.: gdp_g\nObservations: 743\nStandard-errors: Clustered (ccode) \n             Estimate Std. Error   t value  Pr(&gt;|t|)    \n(Intercept) -8.380394   7.836789 -1.069366 0.2913157    \nGPCP_g       0.053402   0.016788  3.180892 0.0028359 ** \nGPCP_g_l     0.031518   0.013739  2.294105 0.0271135 *  \ngdp_1979    -0.568562   0.933728 -0.608916 0.5460230    \npolity2l    -0.000462   0.000697 -0.661827 0.5118772    \nethfrac     -0.290995   5.315419 -0.054745 0.9566138    \nrelfrac      6.344474   6.277193  1.010718 0.3182264    \noil         -0.022946   0.011735 -1.955363 0.0575517 .  \nlmtnest     -0.154883   0.950072 -0.163022 0.8713219    \nlpopl1      -0.103898   0.140671 -0.738588 0.4644693    \n... 41 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.067787   Adj. R2: 0.012893\n\n\n\n# (3)\nrncnf_mod3 &lt;- feols(\n  fml = gdp_g ~ GPCP_g + GPCP_g_l \n  + year:ccode\n  | ccode,\n  data = rainconflict,\n  vcov = ~ ccode\n) \n\nrncnf_mod3 %&gt;% \n  print(n = 2)\n\nOLS estimation, Dep. Var.: gdp_g\nObservations: 743\nFixed-effects: ccode: 41\nStandard-errors: Clustered (ccode) \n         Estimate Std. Error t value  Pr(&gt;|t|)    \nGPCP_g   0.048582   0.016523 2.94024 0.0054275 ** \nGPCP_g_l 0.028004   0.013779 2.03236 0.0487938 *  \n... 41 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.065802     Adj. R2: 0.023299\n                 Within R2: 0.086915\n\n\n\n# (4)\nrncnf_mod4 &lt;- feols(\n  fml = gdp_g ~ GPCP_g + GPCP_g_l + GPCP_g_fl\n  + year:ccode \n  | ccode,\n  data = rainconflict,\n  vcov = ~ ccode\n) \n\nrncnf_mod4 %&gt;% \n  print(n = 3)\n\nOLS estimation, Dep. Var.: gdp_g\nObservations: 743\nFixed-effects: ccode: 41\nStandard-errors: Clustered (ccode) \n          Estimate Std. Error  t value  Pr(&gt;|t|)    \nGPCP_g    0.048944   0.017837 2.743919 0.0090443 ** \nGPCP_g_l  0.028235   0.013783 2.048544 0.0471081 *  \nGPCP_g_fl 0.000617   0.018501 0.033337 0.9735719    \n... 41 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.065801     Adj. R2: 0.021818\n                 Within R2: 0.086917\n\n\n\n# (5)\nrncnf_mod5 &lt;- feols(\n  fml = gdp_g ~ GPCP_g + GPCP_g_l \n  + tot_100_g \n  + year:ccode \n  | ccode,\n  data = rainconflict,\n  vcov = ~ ccode\n) \n\nrncnf_mod5 %&gt;%\n  print(n = 3)\n\nOLS estimation, Dep. Var.: gdp_g\nObservations: 661\nFixed-effects: ccode: 37\nStandard-errors: Clustered (ccode) \n           Estimate Std. Error   t value  Pr(&gt;|t|)    \nGPCP_g     0.053124   0.017432  3.047509 0.0043049 ** \nGPCP_g_l   0.036616   0.014705  2.490060 0.0175258 *  \ntot_100_g -0.002280   0.022286 -0.102318 0.9190722    \n... 37 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.059582     Adj. R2: 0.052542\n                 Within R2: 0.114693\n\n\n\n# Tabellarischer Vergleich mit modelsummary()\n# (Tabelle 3 in Ditella und Schargrodsky, 2004)\nmodelsummary(\n  models = list(\n    \"(1)\" = rncnf_mod1, \n    \"(2)\" = rncnf_mod2, \n    \"(3)\" = rncnf_mod3, \n    \"(4)\" = rncnf_mod4, \n    \"(5)\" = rncnf_mod5\n  ),\n  stars = T, \n  coef_omit = \"^year.*$\",\n  gof_omit = \"^(?!(R2|Num.Obs.|FE.*)$).*\",\n  output = \"gt\"\n) %&gt;%\n  tabopts()\n\n\n\nTabelle 8.6: First-Stage-Regressionen für gdp_g\n\n\n\n\n\n\n\n\n\n\n(1)\n(2)\n(3)\n(4)\n(5)\n\n\n\n\n(Intercept)\n-0.006*\n-8.380\n\n\n\n\n\n\n(0.002)\n(7.837)\n\n\n\n\n\nGPCP_g\n0.055**\n0.053**\n0.049**\n0.049**\n0.053**\n\n\n\n(0.016)\n(0.017)\n(0.017)\n(0.018)\n(0.017)\n\n\nGPCP_g_l\n0.034*\n0.032*\n0.028*\n0.028*\n0.037*\n\n\n\n(0.013)\n(0.014)\n(0.014)\n(0.014)\n(0.015)\n\n\ngdp_1979\n\n-0.569\n\n\n\n\n\n\n\n(0.934)\n\n\n\n\n\npolity2l\n\n0.000\n\n\n\n\n\n\n\n(0.001)\n\n\n\n\n\nethfrac\n\n-0.291\n\n\n\n\n\n\n\n(5.315)\n\n\n\n\n\nrelfrac\n\n6.344\n\n\n\n\n\n\n\n(6.277)\n\n\n\n\n\noil\n\n-0.023+\n\n\n\n\n\n\n\n(0.012)\n\n\n\n\n\nlmtnest\n\n-0.155\n\n\n\n\n\n\n\n(0.950)\n\n\n\n\n\nlpopl1\n\n-0.104\n\n\n\n\n\n\n\n(0.141)\n\n\n\n\n\nGPCP_g_fl\n\n\n\n0.001\n\n\n\n\n\n\n\n(0.019)\n\n\n\ntot_100_g\n\n\n\n\n-0.002\n\n\n\n\n\n\n\n(0.022)\n\n\nNum.Obs.\n743\n743\n743\n743\n661\n\n\nR2\n0.024\n0.079\n0.133\n0.133\n0.162\n\n\nFE: ccode\n\n\nX\nX\nX\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n\n\nS1_res &lt;- tibble(\n\n  x = residuals(\n    feols(\n      fml = GPCP_g ~ GPCP_g_l\n      + year:ccode\n      | ccode,\n      data = rainconflict\n    )\n  ),\n  \n  y = residuals(\n    feols(\n      fml = gdp_g ~ GPCP_g_l\n      + year:ccode\n      | ccode,\n      data = rainconflict\n    )\n  )\n  \n)\n\n\nlibrary(ggplot2)\nlibrary(cowplot)\n\nggplot(\n  data = S1_res,\n  mapping = aes(x = x, y = y)) +\n  geom_point(\n    size = .75, \n    alpha = .5\n  ) +\n  geom_smooth(method = \"loess\", span = .5) +\n  coord_cartesian(\n    xlim = c(-.4, .4), \n    ylim = c(-.1, .1)\n  ) +\n  theme_cowplot()\n\n\n\n\n\n\n\n\n\nfeols(\n  fml = any_prio ~ GPCP_g + GPCP_g_l \n  + year:ccode\n  | ccode,\n  data = rainconflict,\n  vcov = ~ ccode\n) %&gt;% \n  print(n = 2)\n\nOLS estimation, Dep. Var.: any_prio\nObservations: 743\nFixed-effects: ccode: 41\nStandard-errors: Clustered (ccode) \n          Estimate Std. Error   t value Pr(&gt;|t|)    \nGPCP_g   -0.023770   0.041969 -0.566373  0.57430    \nGPCP_g_l -0.121936   0.050328 -2.422836  0.02002 *  \n... 41 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.239168     Adj. R2: 0.671564\n                 Within R2: 0.374052\n\n\n\nfeols(\n  fml = war_prio ~ GPCP_g + GPCP_g_l \n  + year:ccode\n  | ccode,\n  data = rainconflict,\n  vcov = ~ ccode\n) %&gt;% \n  print(n = 2)\n\nOLS estimation, Dep. Var.: war_prio\nObservations: 743\nFixed-effects: ccode: 41\nStandard-errors: Clustered (ccode) \n          Estimate Std. Error  t value Pr(&gt;|t|)    \nGPCP_g   -0.062476   0.029051 -2.15060 0.037605 *  \nGPCP_g_l -0.068689   0.030678 -2.23904 0.030783 *  \n... 41 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.204541     Adj. R2: 0.661198\n                 Within R2: 0.385205\n\n\n\nrf_res &lt;- tibble(\n  \n  x = residuals(\n    feols(\n      fml = GPCP_g_l ~ GPCP_g\n      + year:ccode\n      | ccode,\n      data = rainconflict\n    )\n  ),\n  \n  y = residuals(\n    feols(\n      fml = any_prio ~ GPCP_g\n      + year:ccode\n      | ccode,\n      data = rainconflict\n    )\n  )\n  \n)\n\n\nggplot(\n  data = rf_res , \n  mapping = aes(x = x, y = y)) +\n  geom_point(pch = 19) +\n  geom_smooth(method = \"loess\") +\n  coord_cartesian(\n    xlim = c(-.4, .4), \n    ylim = c(-.2, .4)\n  ) +\n  theme_cowplot()\n\n\n\n\n\n\n\n\n\n# (1)\nmod_conf_probit &lt;- feglm(\n  fml = any_prio ~\n    gdp_g + \n    gdp_g_l\n  + gdp_1979\n  + polity2l \n  + ethfrac \n  + relfrac \n  + oil \n  + lmtnest \n  + lpopl1 \n  + year,\n  data = rainconflict,\n  vcov = ~ ccode, \n  family = binomial(link = \"probit\")\n) \n\nlibrary(marginaleffects)\n\nmod_conf_probit_avge &lt;- mod_conf_probit %&gt;% \n  avg_slopes() \n\n# (2)\n(\nmod_conf_ols &lt;- feols(\n  fml = any_prio ~\n    gdp_g + \n    gdp_g_l\n  + gdp_1979\n  + polity2l \n  + ethfrac \n  + relfrac \n  + oil \n  + lmtnest \n  + lpopl1 \n  + year,\n  data = rainconflict,\n  vcov = ~ ccode\n) \n)\n\nOLS estimation, Dep. Var.: any_prio\nObservations: 743\nStandard-errors: Clustered (ccode) \n             Estimate Std. Error   t value Pr(&gt;|t|)    \n(Intercept) -5.381928  12.515620 -0.430017 0.669491    \ngdp_g       -0.332716   0.263400 -1.263157 0.213846    \ngdp_g_l     -0.084997   0.240857 -0.352894 0.726021    \ngdp_1979    -0.040662   0.049894 -0.814961 0.419921    \npolity2l     0.000642   0.004515  0.142164 0.887664    \nethfrac      0.230431   0.271367  0.849151 0.400851    \nrelfrac     -0.237764   0.241595 -0.984144 0.330961    \noil          0.045297   0.211526  0.214144 0.831523    \nlmtnest      0.075811   0.039371  1.925548 0.061291 .  \nlpopl1       0.068052   0.051102  1.331675 0.190506    \nyear         0.002483   0.006366  0.390106 0.698528    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.414086   Adj. R2: 0.113662\n\n# (3)\nfeols(\n  fml = any_prio ~ -1\n  +  gdp_g + \n    gdp_g_l\n  + gdp_1979\n  + polity2l \n  + ethfrac \n  + relfrac \n  + oil \n  + lmtnest \n  + lpopl1 \n  + i(ccode, year),\n  data = rainconflict,\n  vcov = ~ ccode\n) %&gt;% \n  summary(n = 10)\n\nOLS estimation, Dep. Var.: any_prio\nObservations: 743\nStandard-errors: Clustered (ccode) \n                 Estimate Std. Error   t value Pr(&gt;|t|)    \ngdp_g           -0.387996   0.208988 -1.856550 0.070751 .  \ngdp_g_l         -0.086461   0.212442 -0.406986 0.686188    \ngdp_1979         2.287334   9.856030  0.232075 0.817663    \npolity2l        -0.001355   0.004148 -0.326768 0.745547    \nethfrac         43.124761  50.926744  0.846800 0.402145    \nrelfrac         39.765573  63.751088  0.623763 0.536324    \noil              0.006172   0.086301  0.071511 0.943347    \nlmtnest         -3.835094   7.462461 -0.513918 0.610137    \nlpopl1           1.211169   0.671842  1.802760 0.078964 .  \nccode::404:year -0.033077   0.019564 -1.690721 0.098669 .  \n... 40 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.294151   Adj. R2: 0.526933\n\n# (4)\nfeols(\n  fml = any_prio ~ -1\n  +  gdp_g \n  +  gdp_g_l\n  + i(ccode, year)\n  | ccode,\n  data = rainconflict,\n  vcov = ~ ccode\n) %&gt;% \n  summary(n = 10)\n\nOLS estimation, Dep. Var.: any_prio\nObservations: 743\nFixed-effects: ccode: 41\nStandard-errors: Clustered (ccode) \n                 Estimate Std. Error    t value  Pr(&gt;|t|)    \ngdp_g           -0.210909   0.156046  -1.351587   0.18410    \ngdp_g_l          0.066801   0.158944   0.420279   0.67653    \nccode::404:year  0.028626   0.001635  17.510274 &lt; 2.2e-16 ***\nccode::420:year -0.015243   0.000745 -20.452968 &lt; 2.2e-16 ***\nccode::432:year  0.007220   0.000373  19.349039 &lt; 2.2e-16 ***\nccode::433:year  0.059746   0.000225 265.584211 &lt; 2.2e-16 ***\nccode::434:year  0.000449   0.000485   0.924683   0.36068    \nccode::435:year  0.000223   0.000544   0.410843   0.68338    \nccode::436:year  0.035483   0.000574  61.802750 &lt; 2.2e-16 ***\nccode::437:year  0.000284   0.001085   0.261893   0.79475    \n... 33 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.239816     Adj. R2: 0.669782\n                 Within R2: 0.370655\n\n#### IV models ####\n\n# (5)\nfeols(\n  fml = any_prio ~\n  + gdp_1979\n  + polity2l \n  + ethfrac \n  + relfrac \n  + oil \n  + lmtnest \n  + lpopl1 \n  + i(ccode, year)\n  | gdp_g + gdp_g_l ~ GPCP_g + GPCP_g_l, \n  data = rainconflict,\n  vcov = ~ ccode\n) %&gt;% \n  summary(n = 10)\n\nTSLS estimation - Dep. Var.: any_prio\n                  Endo.    : gdp_g, gdp_g_l\n                  Instr.   : GPCP_g, GPCP_g_l\nSecond stage: Dep. Var.: any_prio\nObservations: 743\nStandard-errors: Clustered (ccode) \n               Estimate Std. Error   t value Pr(&gt;|t|)    \n(Intercept) -153.157460  60.518562 -2.530752 0.015419 *  \nfit_gdp_g     -1.343217   1.462578 -0.918390 0.363920    \nfit_gdp_g_l   -2.714015   1.036990 -2.617205 0.012453 *  \ngdp_1979       9.446193  11.069500  0.853353 0.398545    \npolity2l      -0.005806   0.004843 -1.198875 0.237631    \nethfrac       83.847478  47.883805  1.751061 0.087601 .  \nrelfrac       95.038889  64.178048  1.480863 0.146478    \noil           -0.058890   0.066111 -0.890779 0.378375    \nlmtnest        2.159746   7.025786  0.307403 0.760132    \nlpopl1        -0.336984   0.868944 -0.387809 0.700213    \n... 41 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.346685   Adj. R2: 0.342806\nF-test (1st stage), gdp_g  : stat = 7.81825, p = 4.389e-4, on 2 and 692 DoF.\nF-test (1st stage), gdp_g_l: stat = 5.56598, p = 0.003999, on 2 and 692 DoF.\n                 Wu-Hausman: stat = 2.56365, p = 0.077756, on 2 and 690 DoF.\n\n# (6)\nfeols(\n  fml = any_prio ~ \n  + i(ccode, year)\n  | ccode\n  | gdp_g + gdp_g_l ~ GPCP_g + GPCP_g_l, \n  data = rainconflict,\n  vcov = ~ ccode\n) %&gt;% \n  summary(n = 10)\n\nTSLS estimation - Dep. Var.: any_prio\n                  Endo.    : gdp_g, gdp_g_l\n                  Instr.   : GPCP_g, GPCP_g_l\nSecond stage: Dep. Var.: any_prio\nObservations: 743\nFixed-effects: ccode: 41\nStandard-errors: Clustered (ccode) \n                 Estimate Std. Error   t value   Pr(&gt;|t|)    \nfit_gdp_g       -1.131763   1.362254 -0.830802 4.1102e-01    \nfit_gdp_g_l     -2.546473   1.070475 -2.378825 2.2230e-02 *  \nccode::404:year  0.006632   0.013806  0.480372 6.3358e-01    \nccode::420:year -0.005215   0.006294 -0.828648 4.1222e-01    \nccode::432:year  0.012689   0.003059  4.148704 1.6945e-04 ***\nccode::433:year  0.063170   0.001807 34.960834  &lt; 2.2e-16 ***\nccode::434:year  0.006202   0.004195  1.478344 1.4715e-01    \nccode::435:year  0.008547   0.004353  1.963488 5.6568e-02 .  \nccode::436:year  0.043387   0.004817  9.007338 3.5998e-11 ***\nccode::437:year  0.017506   0.008435  2.075379 4.4425e-02 *  \n... 33 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.302046     Adj. R2: 0.476172\n                 Within R2: 0.001663\nF-test (1st stage), gdp_g  : stat = 6.67399, p = 0.001345, on 2 and 699 DoF.\nF-test (1st stage), gdp_g_l: stat = 5.70442, p = 0.003488, on 2 and 699 DoF.\n                 Wu-Hausman: stat = 3.14562, p = 0.043689, on 2 and 657 DoF.\n\n# (7)\nfeols(\n  fml = war_prio ~ \n    + i(ccode, year)\n  | ccode\n  | gdp_g + gdp_g_l ~ GPCP_g + GPCP_g_l, \n  data = rainconflict,\n  vcov = ~ ccode\n) %&gt;% \n  summary(n = 10)\n\nTSLS estimation - Dep. Var.: war_prio\n                  Endo.    : gdp_g, gdp_g_l\n                  Instr.   : GPCP_g, GPCP_g_l\nSecond stage: Dep. Var.: war_prio\nObservations: 743\nFixed-effects: ccode: 41\nStandard-errors: Clustered (ccode) \n                 Estimate Std. Error   t value  Pr(&gt;|t|)    \nfit_gdp_g       -1.479970   0.800386 -1.849071  0.071848 .  \nfit_gdp_g_l     -0.768785   0.678533 -1.133010  0.263956    \nccode::404:year -0.001514   0.007526 -0.201188  0.841571    \nccode::420:year  0.007088   0.003431  2.066077  0.045340 *  \nccode::432:year  0.003375   0.001670  2.020730  0.050037 .  \nccode::433:year  0.015992   0.000992 16.119071 &lt; 2.2e-16 ***\nccode::434:year  0.004765   0.002306  2.065964  0.045351 *  \nccode::435:year  0.004698   0.002393  1.963229  0.056599 .  \nccode::436:year  0.005405   0.002624  2.059408  0.046005 *  \nccode::437:year  0.008802   0.004699  1.872980  0.068392 .  \n... 33 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.228949     Adj. R2: 0.575516\n                 Within R2: 0.229726\nF-test (1st stage), gdp_g  : stat = 6.67399, p = 0.001345, on 2 and 699 DoF.\nF-test (1st stage), gdp_g_l: stat = 5.70442, p = 0.003488, on 2 and 699 DoF.\n                 Wu-Hausman: stat = 1.46546, p = 0.231725, on 2 and 657 DoF.\n\nlibrary(modelsummary)\n\nmodelsummary(\n  models = list(\n    mod_conf_probit_avge, \n    mod_conf_ols\n    )\n  )\n\n \n\n  \n    \n    \n    tinytable_1k91f2rr4kc2az6a073x\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n              \n        \n        \n        \n                \n                  ethfrac    \n                  0.220  \n                  0.230    \n                \n                \n                             \n                  (0.242)\n                  (0.271)  \n                \n                \n                  gdp_1979   \n                  -0.063 \n                  -0.041   \n                \n                \n                             \n                  (0.058)\n                  (0.050)  \n                \n                \n                  gdp_g      \n                  -0.350 \n                  -0.333   \n                \n                \n                             \n                  (0.301)\n                  (0.263)  \n                \n                \n                  gdp_g_l    \n                  -0.127 \n                  -0.085   \n                \n                \n                             \n                  (0.251)\n                  (0.241)  \n                \n                \n                  lmtnest    \n                  0.072  \n                  0.076    \n                \n                \n                             \n                  (0.036)\n                  (0.039)  \n                \n                \n                  lpopl1     \n                  0.074  \n                  0.068    \n                \n                \n                             \n                  (0.049)\n                  (0.051)  \n                \n                \n                  oil        \n                  0.015  \n                  0.045    \n                \n                \n                             \n                  (0.210)\n                  (0.212)  \n                \n                \n                  polity2l   \n                  0.001  \n                  0.001    \n                \n                \n                             \n                  (0.005)\n                  (0.005)  \n                \n                \n                  relfrac    \n                  -0.271 \n                  -0.238   \n                \n                \n                             \n                  (0.241)\n                  (0.242)  \n                \n                \n                  year       \n                  0.003  \n                  0.002    \n                \n                \n                             \n                  (0.006)\n                  (0.006)  \n                \n                \n                  (Intercept)\n                         \n                  -5.382   \n                \n                \n                             \n                         \n                  (12.516) \n                \n                \n                  Num.Obs.   \n                  743    \n                  743      \n                \n                \n                  R2         \n                  0.122  \n                  0.126    \n                \n                \n                  R2 Adj.    \n                  0.099  \n                  0.114    \n                \n                \n                  AIC        \n                  779.8  \n                  820.4    \n                \n                \n                  BIC        \n                  830.6  \n                  871.1    \n                \n                \n                  RMSE       \n                  0.42   \n                  0.41     \n                \n                \n                  Std.Errors \n                         \n                  by: ccode\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\n\n\n\nAcemoglu, Daron, Giuseppe De Feo, und Giacomo Davide De Luca. 2020. „Weak States: Causes and Consequences of the Sicilian Mafia“. The Review of Economic Studies. https://doi.org/10.1093/restud/rdz009.\n\n\nCameron, A. Colin, Jonah B. Gelbach, und Douglas L. Miller. 2008. „Bootstrap-Based Improvements for Inference with Clustered Errors“. Review of Economics and Statistics 90 (3): 414–27. https://doi.org/10.1162/rest.90.3.414.\n\n\n———. 2011. „Robust Inference With Multiway Clustering“. Journal of Business &amp; Economic Statistics 29 (2): 238–49. https://doi.org/10.1198/jbes.2010.07136.\n\n\nCutrera, Antonino. 1900. La Mafia E I Mafiosi. (Palermo, IT: Reber).\n\n\nFearon, James D., und David D. Laitin. 2003. „Ethnicity, Insurgency, and Civil War.“ American Political Science Review 97 (01): 75–90. https://doi.org/10.1017/s0003055403000534.\n\n\nHuntington-Klein, Nick. 2021. The Effect: An Introduction to Research Design and Causality. Chapman; Hall/CRC. https://doi.org/10.1201/9781003226055.\n\n\nLiu, Regina Y. 1988. „Bootstrap Procedures under some Non-I.I.D. Models“. The Annals of Statistics 16 (4): 1696–1708. https://doi.org/10.1214/aos/1176351062.\n\n\nMiguel, Edward, Shanker Satyanath, und Ernest Sergenti. 2004. „Economic Shocks and Civil Conflict: An Instrumental Variables Approach“. Journal of Political Economy 112 (4): 725–53. https://doi.org/10.1086/421174.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>IV-Regression</span>"
    ]
  },
  {
    "objectID": "IV.html#footnotes",
    "href": "IV.html#footnotes",
    "title": "8  IV-Regression",
    "section": "",
    "text": "Beachte, dass der endogene Regressor \\(B_i\\) mit \\(u_i\\) korreliert, sodass der Erwartungswert des Bruchs in \\(\\eqref{eq:ivbiasterm}\\) ungleich \\(0\\) ist.↩︎\nSiehe Kapitel 10 und 19 in Huntington-Klein (2021) für nicht-technische Erläuterungen und Beispiel zu LATE.↩︎\nFormal: \\(\\textup{Cov}(Z,u\\vert X) = 0\\).↩︎\nBeachte, dass die Simulation insbesondere für große \\(N\\) und \\(n\\) einige Sekunden dauern kann (grauer Balken am linken Rand zeigt laufende Berechnung an).↩︎\nDer Datensatz stammt aus dem MIT Economics Data Archive und liegt im STATA-Format .dta vor.↩︎\nSiehe Kapitel Kapitel 7 für Erläuterungen zu Fixed-Effects und cluster-robusten Standardfehlern.↩︎\nfwildclusterboot implementiert Varianten des Wild Bootstrap (Liu 1988).↩︎\nNach Cutrera (1900) entspricht eine Erhöhung des Mafia-Index von 1 auf 2 einem Sprung von einer geringen Präsenz der Mafia zu einer signifikanten Präsenz.↩︎\nSiehe rainconflict$country %&gt;% unique().↩︎",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>IV-Regression</span>"
    ]
  },
  {
    "objectID": "DiD.html",
    "href": "DiD.html",
    "title": "9  Difference-in-Differences",
    "section": "",
    "text": "9.1 Einordnung im Potential Outcomes Framework\nIm Potential Outcomes Framework nehmen wir an, dass jede Einheit \\(i\\) in Abhänigkeit ihres Behandlungsstatus zwei potentielle Ergebnisse hat. Wir unterscheiden zwischen Beobachtungen in Behandlungs- und Kontrollgruppe:\nIn einem DID-Forschungsdesign hängen tatsächliche und potentielle Outcomes von der Zeit \\(t\\) ab: Die Behandlungsgruppe wird zwischen den Zeitpunkten \\(t = 0\\) und \\(t = 1\\) behandelt, während die Kontrollgruppe unbehandelt bleibt. Für die Identifizierung des Behandlungseffekts wird unterstellt, dass \\(Y\\) sich zwischen \\(t=0\\) und \\(t=1\\) in der Behandlungsgruppe ohne eine Behandlung (im Erwartungswert) mit demselben Trend entwickelt hätte, mit dem sich die Kontrollgruppe tatsächlich entwickelt hat (parallele Trends). Die Gültigkeit paralleler Trends ist entscheidend für die Validität der DID-Methode, da so sicherstellt ist, dass die beobachteten Unterschiede in den Ergebnissen auf die Behandlung zurückzuführen sind und nicht auf andere zeitgleich auftretende Faktoren. Der Behandlungseffekt kann dann als eine Differenz von Differenzen geschrieben werden:\n\\[\\begin{align}\n  \\begin{split}\n    \\beta_\\textup{DID} =& \\, \\bigg({\\color{red}\\textup{E}\\big[Y_B(1)\\vert t=1\\big] - \\textup{E}\\big[Y_B(0)\\vert t=0\\big]} \\bigg)\\\\\n  -&\\, \\bigg({\\color{blue}\\textup{E}\\big[Y_K(0)\\vert t=1\\big] -  \\textup{E}\\big[Y_K(0)\\vert t=0\\big]} \\bigg)\n  \\end{split}\\label{eq:DID-ATT1}\n\\end{align}\\]\nDer Effekt \\(\\beta_\\textup{DID}\\) ist ein ATT, der über das Schließen der Backdoor in der Zeit (rote und blaue Differenzen der Erwartungswerte zwischen \\(t=0\\) und \\(t=1\\)) sowie der Backdoor in der Gruppenzugehörigkeit (Differenz der Erwartungswert-Differenzen) identifiziert wird.\nEine Null-Ergänzung von \\(\\eqref{eq:DID-ATT1}\\) mit \\({\\color{blue}\\textup{E}\\big[Y_K(0)\\vert t=1\\big] -  \\textup{E}\\big[Y_K(0)\\vert t=1\\big]}\\) zeigt die Wichtigkeit der Gültigkeit paralleler Trends:\n\\[\\begin{align*}\n    \\beta_\\textup{DID} =& \\, \\bigg({\\color{red}\\textup{E}\\big[Y_B(1)\\vert t=1\\big] - \\textup{E}\\big[Y_B(0)\\vert t=0\\big]} \\bigg)\n  - \\bigg({\\color{blue}\\textup{E}\\big[Y_K(0)\\vert t=1\\big] -  \\textup{E}\\big[Y_K(0)\\vert t=0\\big]} \\bigg)\\\\ + &\\,\n{\\color{blue}\\textup{E}\\big[Y_K(0)\\vert t=1\\big] -  \\textup{E}\\big[Y_K(0)\\vert t=1\\big]}\\\\\n    \\\\\n    =&\\, \\underbrace{{\\color{red}\\textup{E}\\big[Y_B(1)\\vert t=1\\big]} - {\\color{blue}\\textup{E}\\big[Y_B(1)\\vert t=1\\big]}}_{=\\textup{ATT}}\\\\\n    +&\\, \\underbrace{\\bigg({\\color{red}\\textup{E}\\big[Y_B(0)\\vert t=1\\big] - \\textup{E}\\big[Y_B(0)\\vert t=0\\big]} \\bigg) - \\bigg({\\color{blue}\\textup{E}\\big[Y_K(0)\\vert t=1\\big] -  \\textup{E}\\big[Y_K(0)\\vert t=0\\big]} \\bigg)}_{ = \\textup{Verzerrung durch nicht-parallele Trends}}\n\\end{align*}\\]\nDiese Zerlegung zeigt, dass der ATT nur bei parallelen Trends identifziert werden kann, d.h. wir benötigen\n\\[\\begin{align*}\n{\\color{red}\\textup{E}\\big[Y_B(0)\\vert t=1\\big] - \\textup{E}\\big[Y_B(0)\\vert t=0\\big]} = {\\color{blue}\\textup{E}\\big[Y_K(0)\\vert t=1\\big] -  \\textup{E}\\big[Y_K(0)\\vert t=0\\big]}.\n\\end{align*}\\]\nBeachte, dass \\({\\color{red}\\textup{E}\\big[Y_B(0)\\vert t=1\\big]}\\) der Erwartungswert des potentiellen Outcomes einer unbehandelten Behandlungsgruppe in \\(t=1\\) ist. Somit kann die Verzerrung durch nicht-parallele Trends nicht empirisch überprüft werden und muss ausschließlich durch das Forschungsdesign gewährleistet sein. In Anwendungen kann die Plausibilität der Annahme graphisch anhand geschätzter Trends in der Outcome-Variable oder durch Placebo-Tests untersucht werden.\nAnnahmen für DID",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Difference-in-Differences</span>"
    ]
  },
  {
    "objectID": "DiD.html#einordnung-im-potential-outcomes-framework",
    "href": "DiD.html#einordnung-im-potential-outcomes-framework",
    "title": "9  Difference-in-Differences",
    "section": "",
    "text": "\\(Y_{i,B}(1)\\): \\(Y\\) für Einheit \\(i\\) in der Behandlungsgruppe, wenn diese behandelt wird.\n\\(Y_{i,B}(0)\\): \\(Y\\) für Einheit \\(i\\) in der Behandlungsgruppe, wenn diese nicht behandelt wird.\n\\(Y_{i,K}(1)\\): \\(Y\\) für Einheit \\(i\\) in der Kontrollgruppe, wenn diese behandelt wird.\n\\(Y_{i,K}(0)\\): \\(Y\\) für Einheit \\(i\\) in der Kontrollgruppe, wenn diese nicht behandelt wird.\n\n\n\n\n\n\n\n\n\n\n\nParallele Trends: Die Trends in der Outcome Variable \\(Y\\) in Behandlungs- und Kontrollgruppe würden bis einschließlich \\(t=1\\) parallel verlaufen, wenn es keine Behandlung gäbe. Diese Annahme ist Voraussetzung dafür, dass Veränderungen im Outcome \\(Y\\) für die Behandlungsgruppe, die sich von \\(Y\\) für die Kontrollgruppe unterscheidet, auschließlich dem Effekt der Behandlung zugeschrieben werden kann.\nKeine Interferenz und konsistente Behandlung (SUTVA):\n\nKeine Interferenz: Die Behandlung eines Individums hat keinen Einfluss auf das potentielle Outcome anderer Individuen, unabhängig von der Gruppenzugehörigkeit.\nKonsistete Behandlung: Es gibt keine Variation in der Intensität oder Art der Behandlung innerhalb der Behandlungsgruppe.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Difference-in-Differences</span>"
    ]
  },
  {
    "objectID": "DiD.html#schätzung-des-att-mit-did",
    "href": "DiD.html#schätzung-des-att-mit-did",
    "title": "9  Difference-in-Differences",
    "section": "9.2 Schätzung des ATT mit DID",
    "text": "9.2 Schätzung des ATT mit DID\nFür die Schätzung von \\(\\beta_\\text{DID}\\) ersetzen wir die Erwartungswerte in \\(\\eqref{eq:DID-ATT1}\\) durch ihre Stichprobenmomente. Dies liefert den Schätzer\n\\[\\begin{align}\n  \\widehat{\\beta}_\\textup{DID} = \\bigg({\\color{red}\\overline{Y_B(1)\\vert t=1} - \\overline{Y_B(0)\\vert t=0}} \\bigg) -  \\bigg({\\color{blue}\\overline{Y_K(0)\\vert t=1} - \\overline{Y_K(0)\\vert t=0}}\\bigg). \\label{eq:DIDMOMENTS}\n\\end{align}\\]\nDie Implementierung von DID-Schätzern erfolgt meist anhand linearer Regression. Das Modell für zwei Zeitperioden ist\n\\[\\begin{align}\n  Y_{i,\\,t} = \\alpha + \\beta_1 B_i + \\beta_2 Z_t + \\beta_3 (B_i \\times Z_t) + \\epsilon_{i,\\,t}, \\quad t\\in\\{0,1\\}, \\label{eq:DIDREG}\n\\end{align}\\]\nwobei \\(\\beta_3\\) der interessierende Behandlungseffekt ist. Der Regressor \\(B_i \\times Z_t\\) ist die Interaktion zwischen der Behandlungsgruppenzugehörigkeit \\(B_i\\) und einem Indikator für den Zeitpunkt nach der Intervention, \\(Z_i = \\mathbb{I}_{\\{t=1\\}}\\). Beachte, dass wir in Modell \\(\\eqref{eq:DIDREG}\\) für Zeiteffekte und Gruppenzugehörig kontrollieren und damit die sich durch das Forschungsdesign ergebenden Backdoors (vgl. Abbildung 9.1) schließen.\nEs ist \\(\\widehat\\beta_3 = \\widehat{\\beta}_\\text{DID}\\), d.h. der KQ-Schätzer von \\(\\beta_3\\) ist der DID-Schätzer des ATT und numerisch äquivalent zu \\(\\eqref{eq:DIDMOMENTS}\\). Die Berechnung von \\(\\widehat\\beta_\\text{DID}\\) anhand von Modell \\(\\eqref{eq:DIDREG}\\) ist praktisch, da wir so Inferenzstatistiken mit etablierten R-Funktionen wie summary() und lmtest::coeftest() wie gewohnt berechnen können.\nIn empirischen Anwendungen stehen oft Datensätze mit mehreren Gruppen und mehr als zwei Beobachtungsperioden zur Verfügung. Beachte, dass das Modell \\(\\eqref{eq:DIDREG}\\) ein Spezialfall des allgemeinen Forschungsdesigns mit \\(t=1,\\dots,T\\) für \\(T\\geq2\\) Beobachtungsperioden und mehr als zwei Gruppen (mehrere Kontroll- und Behandlungsgruppen) ist. Eine dann häufig genutzte Modellspezifikation für die Schätzung des ATT mit DID ist eine Panel-Regression mit Two-way Fixed Effects,\n\\[\\begin{align}\n  Y_{i,\\,t} =  \\theta_i + \\eta_t + \\beta_\\text{DID}^\\text{TWFE} D_{i,\\, t} + \\epsilon_{i,\\,t}, \\quad t = 1,\\dots,T, \\label{eq:TWFEDIDREG}\n\\end{align}\\]\nwobei \\(\\theta_i\\) und \\(\\eta_t\\) Dummy-Variablen für Gruppen und Zeitperioden sind und \\(D_{i,\\, t}\\) der Behandlungsindikator ist. Dieses lineare Paneldaten-Modell kann komfortabel mit dem R-Paket fixest (s. fixtest::feols()) implementiert werden. Bei mehreren Gruppen sollten cluster-robuste Standardfehler auf Gruppen-Ebene verwendet werden.\nIn Modell \\(\\eqref{eq:TWFEDIDREG}\\) indentifiziert \\(\\beta_\\text{DID}^\\text{TWFE}\\) den ATE, sofern die Annahmen 1 (parallele Trends) und 2 (SUTVA) gelten. Damit die Annahme paralleler Trends gewährleistet ist, dürfen keine heterogenen Behandlungseffekte vorliegen, d.h. die Behandlungseffekte\n\nvariieren nicht zwischen verschiedenen Gruppen\nsind unabhängig vom Zeitpunkt der Behandlung (relevant bei unterschiedlichen Behandlungszeitpunkten)\nentwickeln sich nicht dynamisch über die Zeit1\n\nDer Umgang mit heterogenen Behandlungseffekten ist Gegenstand der aktuellen ökonometrischen Forschung zu DID-Schätzern. Callaway und Sant’Anna (2021) schlagen eine nicht-parametrische Schätzung von gruppenspezifischen ATE zu veschiedenen Zeitpunkten vor, die zu einem globalen ATT zusammengefasst werden können.2\n\n\n\n\n\n\nKey Facts zum einfachen DID-Schätzer\n\n\n\n\nIm DID-Forschungsdesign kann der ATT durch einen Vergleich von Differenzen in den Ergebnissen vor und nach einer Behandlung zwischen Behandlungs- und Kontrollgruppen identifiziert werden.\nDID benötigt Beobachtungen einer Behandlungs- und einer Kontrollgruppe zu mindestens zwei verschiedenen Zeitpunkten, wobei der Behandlung zwischen diesen Zeitpunkten erfolgt.\nDID ist empfindlich gegenüber Verletzungen der Annahme, dass die zeitlichen Trends in der Outcome-Variable für die Behandlungs- und die Kontrollgruppen vor der Intervention parallel verlaufen.\nDID-Schätzer können in linearen Interaktionsmodellen mit Fixed Effects für Zeitperioden und Gruppenzugehörigkeit implementiert werden. Der interessierenden Effekt sind die Koeffizienten von Interaktionstermem zwischen den Indikatoren für die Nachbehandlungsperioden und für die Zugehörigkeit zu einer Behandlungsgruppe.\nIn R können DID-Modelle mit lm() oder, in Fällen mit mehr als zwei Beobachtungsperioden, mit fixest::feols() geschätzt werden. In Forschungsdesigns mit mehreren Gruppen sollten cluster-robuste Standardfehler verwendet werden.\n\n\n\n\nDie nachfolgende interaktive Grafik illustriert die Schätzung des ATT mit DID sowie die Verletzung der Annahme paralleler Trends anhand simulierte Daten für mehrere Zeitperioden. Der verwendete DID-Schätzer ist der KQ-Schätzer in Modell \\(\\eqref{eq:DIDREG}\\), d.h. wir betrachten ein Forschungsdesign in dem zwei Zeitperioden für die Schätzung verwendet werden, wobei die Behandlung zwischen diesen Perioden erfolgt.\nInteraktive Elemente der Visualisierung\n\nDie Beobachtungen der Individuen zu 6 verschiedenen Zeitpunkten werden als Punkte dargestellt. Die Datenpunkte könn mit Zeige Daten ein- und ausgeblendet werden.\nDie geschätzten Trends beider Gruppen für den gesamten Beobachtungszeitraum und die Gruppenzugehörigkeit können mit Zeige Trends ein- und ausgeblendet werden. Die Auswahl Parallele Trends stellt sicher, dass beide Gruppen (mit Ausnahme des Behandlungseffekts in der Behandlungsgruppe) dem selben zeitlichen Trend folgen. Bei nicht-parallelen Trends folgt die Behandlungsgruppe einem positiven Trend mit größerer positiver Steigung als in der Kontrollgruppe.\nDie Behandlung erfolgt zwischen der mit dem Slider Zeitpunkt ausgewählten und der darauf folgenden Periode. Der tatsächliche Behandlungseffekt kann über den Slider Effekt festgelegt werden.\n\nAnatomie der Schätzung des ATT bei parallelen Trends\n\nWir illustrieren die Schätzen des ATT mit Formel \\(\\eqref{eq:DIDMOMENTS}\\). Kreise zeigen Mittelwerte für Kontroll- und Behandlungsgruppe vor der Intervention. Dreiecke zeigen Mittelwerte nach der Intervention.\nDie gestrichelte rote Linie zeigt den (kontrafaktischen) Verlauf der Behandlungsgruppe ohne Behandlung. Hierbei wird unterstellt, dass sich die Behandlungsgruppe mit demselben Trend wie die Kontrollgruppe entwickelt hätte (blaue Linie).\nDer geschätzte Behandlungseffekt wird als orangene vertikale Linie dargestellt. Dies ist die Differenz zwischen dem tatsächlichen post-Behandlungs-Mittelwert und dem kontrafaktischen Mittelwert der Behandlungsgruppe.\n\nAnatomie der Schätzung des ATT bei nicht-parallelen Trends\n\nFür nicht-parallele Trends zeigt die Grafik den unterstellten kontrafaktischen Trend der Behandlungsgruppe als gestrichelte blaue linie. Der” “tatsächliche” kontrafaktische Verlauf der Behandlungsgruppe wird als gestrichelte rote Linie dargestellt.\nAufgrund des steileren (positiven) Trends in der Behandlungsgruppe ergibt sich eine positive Verzerrung von \\(\\color{orange}\\widehat{\\beta}_\\text{DID}\\). Diese Verzerrung wird durch die gestrichelte vertikale schwarze Linie kenntlich gemacht.\n\nFür positive Behandlungseffekte wird der ATT überschätzt: die Verzerrung entspricht der Überlagerung der gestrichelten schwarzen linie mit der orangenen Linie des geschätzten Effekts.\nFür negative Behandlungseffekte wird der ATT unterschätzt: die Verzerrung entspricht der gestrichelten schwarzen Linie oberhalb der orangenen Linie des geschätzten Effekts.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Difference-in-Differences</span>"
    ]
  },
  {
    "objectID": "DiD.html#schätzung-von-did-forschungsdesigns-mit-r",
    "href": "DiD.html#schätzung-von-did-forschungsdesigns-mit-r",
    "title": "9  Difference-in-Differences",
    "section": "9.3 Schätzung von DID-Forschungsdesigns mit R",
    "text": "9.3 Schätzung von DID-Forschungsdesigns mit R\nWir erläutern nachfolgend die Schätzung von DID-Designs mit zwei Zeitperioden mit R und visualisieren die geschätzten Komponenten von \\(\\widehat{\\beta}_\\text{DID}\\) ähnlich wie in der interaktiven Visualisierung. Hierzu erzeugen wir simulierte Daten gemäß der Vorschrift\n\\[\\begin{align*}\n  Y_{i,t} &= 2 + 3 \\cdot Z_t + 5 \\cdot B_i + 4 \\cdot (Z_t \\cdot B_i) + \\epsilon_{i,t}\\\\\n  \\epsilon_{i,t} &\\sim N(0, 1)\\\\\n  Z_t &= \\mathbb{I}_{\\{ t = 1 \\}} \\\\\n  B_i &= \\mathbb{I}_{\\{ i \\in \\textup{Behandlungsgruppe} \\}},\n\\end{align*}\\] wobei wir jeweils \\(100\\) Beobachtungen beider Gruppen zu beiden Zeitpunkten generieren.\n\nlibrary(tibble)\nlibrary(dplyr)\n\n# Seed setzen\nset.seed(1234)\n\n# Anzahl der Beobachtungen (pro Gruppe u. Zeitpunkt)\nn &lt;- 100\n\n# Daten simulieren\ndid_data &lt;- tibble(\n  Z = rep(rep(c(0, 1), each = n), times = 2),\n  B = rep(c(0, 1), each = 2 * n),\n  epsilon = rnorm(4 * n),\n  outcome = 2 + 3 * Z + 5 * B + 4 * Z * B + epsilon\n)\n\n# Überblick\nglimpse(did_data)\n\nRows: 400\nColumns: 4\n$ Z       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ B       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ epsilon &lt;dbl&gt; -1.20706575, 0.27742924, 1.08444118, -2.34569770, 0.42912469, …\n$ outcome &lt;dbl&gt; 0.7929343, 2.2774292, 3.0844412, -0.3456977, 2.4291247, 2.5060…\n\n\nMit lm() implementieren wir ein einfaches Interaktionsmodell und lesen den geschätzten Effekt aus.\n\n# Modell mit Regression schätzen\ndid_model &lt;- lm(\n  formula = outcome ~ Z * B, \n  data = did_data\n)\n\n# Geschätzten ATE auslesen\n(\n  estimated_effect &lt;- coef(did_model)[\"Z:B\"]\n)\n\n     Z:B \n3.639286 \n\n\nDie Schätzung des Behandlungseffekts von \\(3.64\\) liegt nahe beim wahren Effekt von \\(4\\). Eine äquivalente Schätzung können wir mit fixest::feols() erhalten.\n\nlibrary(fixest)\n\n# Interaktionsmodell mit feols() schätzen\nfeols(\n  fml = outcome ~ Z * B,\n  data = did_data\n)\n\nOLS estimation, Dep. Var.: outcome\nObservations: 400\nStandard-errors: IID \n            Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  1.84324   0.101233 18.2078 &lt; 2.2e-16 ***\nZ            3.19800   0.143166 22.3378 &lt; 2.2e-16 ***\nB            5.31137   0.143166 37.0994 &lt; 2.2e-16 ***\nZ:B          3.63929   0.202467 17.9747 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 1.00726   Adj. R2: 0.950969\n\n\nFür eine Schätzung mit Two-way-fixed-effects modifizieren wir den Funktionsaufruf von feols()\n\n# Two-way-FE-Regression\nfeols(\n  fml = outcome ~ I(Z * B) | B + Z,\n  data = did_data\n)\n\nOLS estimation, Dep. Var.: outcome\nObservations: 400\nFixed-effects: B: 2,  Z: 2\nStandard-errors: Clustered (B) \n         Estimate Std. Error      t value   Pr(&gt;|t|)    \nI(Z * B)  3.63929    4.2e-15 8.666101e+14 7.3461e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 1.00726     Adj. R2: 0.950969\n                Within R2: 0.449304\n\n\nBeachte, dass im Formel-Argument fml mit I(Z * B) lediglich der Interaktionseffekt als Regressor festgelegt wird. Fixe Effekte für Gruppenzugehörigkeit und Zeitpunkte werden durch den Zusatz | B + Z spezifiziert.3 Diese Reihenfolge führt zur Berechnung von cluster-robusten Standardfehlern auf Gruppen-Ebene (B). Wie erwartet können wir anhand des \\(t\\)-Tests die Nullhypothese \\(H_0:\\,\\beta_\\text{DID} = 0\\) zu jeden relevanten Signifikanzniveau ablehnen.\nFür die Visualisierung der Schätzung mit ggplot2::ggplot() berechnen wir zunächst Stichprobenmittelwerte für die Outcome-Variable y beider Gruppen zu beiden Zeitpunkten.\n\n# Stichprobenmittelwerte berechnen\noptions(digits = 4)\n(\n  means &lt;- did_data %&gt;%\n  group_by(Z, B) %&gt;%\n  summarize(\n    mean_outcome = mean(outcome), \n   .groups = 'drop'\n  )\n)\n\n# A tibble: 4 × 3\n      Z     B mean_outcome\n  &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;\n1     0     0          1.8\n2     0     1          7.2\n3     1     0          5.0\n4     1     1         14. \n\n\nDie Stichprobenmittelwerte in means ermöglichen uns die Schätzung von \\(\\textcolor{red}{E(Y_B(0)|t=2)}\\), das kontrafaktische erwartete Outcome (counterfactual) der Behandlungsgruppe zum Zeitpunkt \\(t=2\\),\n\\[\\begin{align*}\n  \\textcolor{red}{\\overline{Y_B(0)|t=2}} =&\\, \\textcolor{red}{\\overline{Y_B(0)|t=1}}\n  + \\bigg( \\textcolor{blue}{\\overline{Y_K(0)|t=2}} - \\textcolor{blue}{\\overline{Y_K(0)|t=1}} \\bigg)\\\\\n  =&\\, \\textcolor{red}{7.2} + (\\textcolor{blue}{5.0} - \\textcolor{blue}{1.8}) \\\\\n  =&\\, \\textcolor{red}{10.4}.\n\\end{align*}\\]\n\n# Counterfactual für Behandlungsgruppe in t=1\n(\n  counterfactual &lt;- means %&gt;%\n  filter(Z == 0 & B == 1) %&gt;%\n  pull(mean_outcome) +\n  \n  (\n    means %&gt;%\n     filter(Z == 1 & B == 0) %&gt;%\n     pull(mean_outcome) -\n   \n    means %&gt;%\n     filter(Z == 0 & B == 0) %&gt;%\n     pull(mean_outcome)\n   )\n)\n\n[1] 10.35\n\n\nDer geschätzte Behandlungseffekt ist \\[\\begin{align*}\n\\textcolor{orange}{\\widehat{\\beta}_\\text{DID}} =&\\, \\textcolor{red}{\\overline{Y_B(1)\\vert t=2}} - \\textcolor{red}{\\overline{Y_B(0)\\vert t=2}}\\\\\n=&\\,\\textcolor{red}{14} - \\textcolor{red}{10.4}\\\\\n=&\\, \\textcolor{orange}{3.6}.\n\\end{align*}\\]\nWir plotten die Daten mit ggplot2 und zeichnen die Trends sowie den geschätzten Behandlungseffekt ein.\n\n# Simulierte daten plotten\ndid_data %&gt;%\n  ggplot(\n    mapping = aes(\n      x = factor(Z), \n      y = outcome, \n      color = factor(B), \n      group = factor(B))\n    ) +\n  geom_point(\n    position = position_jitter(\n      width = .1, \n      seed = 1234\n      )\n    ) +\n  labs(\n    x = \"Zeitpunkt\",\n    y = \"Outcome Y\",\n    color = \"B\"\n  ) +\n  scale_color_manual(\n    values = c(\"1\" = \"red\", \"0\" = \"blue\")\n  ) +\n  # Trendlinien einzeichnen\n  stat_summary(\n    fun = mean, \n    geom = \"line\", \n    size = 1.5\n    ) +\n  # Counterfactual für B-Gruppe einzeichnen\n  geom_segment(\n    mapping = aes(\n      x = 1, \n      xend = 2, \n      y = means$mean_outcome[\n        means$Z == 0 & means$B == 1\n        ],\n      yend = counterfactual\n    ),\n    linetype = \"dashed\", \n    color = \"red\", \n    size = 1\n    ) +\n  # gesch. Behandlungseffekt einzeichnen\n  geom_segment(\n    mapping = aes(\n      x = 2, \n      xend = 2, \n      y = counterfactual,\n      yend = counterfactual + estimated_effect\n    ),\n    linetype = \"dashed\", \n    color = \"orange\", \n    size = 1) +\n  theme_cowplot() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\nAbbildung 9.2: Einfache DID-Schätzung mit R für simulierte Daten",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Difference-in-Differences</span>"
    ]
  },
  {
    "objectID": "DiD.html#case-study-effekt-von-steuererleichterungen-auf-erwerbsbeteilligung",
    "href": "DiD.html#case-study-effekt-von-steuererleichterungen-auf-erwerbsbeteilligung",
    "title": "9  Difference-in-Differences",
    "section": "9.4 Case Study: Effekt von Steuererleichterungen auf Erwerbsbeteilligung",
    "text": "9.4 Case Study: Effekt von Steuererleichterungen auf Erwerbsbeteilligung\nDer Earned Income Tax Credit (EITC) ist ein Steuerguthaben für US-Amerkanische Familien, die unterhalb einer gesetztlich festgelegten Einkoemmnsgrenze liegen. Der genaue Betrag des EITC hängt gestaffelt vom Einkommen ab und, ähnlich zum Kindergeld in Deutschland, steigt mit der Anzahl der zu versorgenden Kinder. Ein wichtiger Unterschied zum Kindergeld ist, dass der EITC nicht beantragt werden muss: Qualifizierten Familien wird der Betrag automatisch durch die Behörden im Jahressteuerausgleich gutgeschrieben. Somit kann Selbstselektion in die Behandlungsgruppe ausgeschlossen werden, da sich die Behandlung ausschließlich durch die im Rahmen der EITC-Ausweitung geänderten Anspruchsgrundlagen ergibt.\nEissa und Liebman (1996) betrachten Veränderungen in der EITC-Gesetzgebung als Intervention, deren Auswirkungen mit sozio-ökonomischen Paneldaten in einem DID-Ansatz untersucht werden können. Die Studie analysiert die Auswirkungen der ersten Ausweitung des EITC im Jahr 1986 auf die Erwerbsbeteiligung und die Löhne von Müttern im erwerbsfähigen Alter. Diese Erweiterung erhöhte die gewährten Steuererleichterungen und die zur Qualifikation für das Programm zu unterschreitende Einkommensgrenze.\nEin zentraler Befund der Studie ist, dass die EITC-Ausweitung von 1986 einen statistisch signifikanten Anstieg der Arbeitsbeteiligung alleinerziehender Frauen von geschätzten 3% bewirkt hat. Eissa und Liebman (1996) finden weiterhin signifikante positive Effekte auf die geleisteten Arbeitsstunden und Evidenz für Einkommensverbesserungen in dieser Gruppe. Die Studienergebnisse sind starke Evidenz, dass Maßnahmen wie der EITC effektiv dazu beitragen können, die Erwerbssituation in der Zielgruppe zu steigern und somit die wirtsschafts- und sozialpolitische Ziele derartiger Programme realisierbar sind.\nIm Jahr 1993 wurde das Programm erneut ausgweitet: Vor 1993 gab es lediglich eine Einkommensstufe für Familien mit Kindern. 1993 wurde eine zusätzliche Stufe für Familien mit zwei oder mehr Kindern eigeführt, die damit einen höheren maximalen Kreditbetrag erhalten konnten als Familien mit nur einem Kind. Dies führte zu einer größeren steuerlichen Entlastung armutsbedrohter Familien.\nAdireksombat (2010) untersucht die Effekte der zweiten EITC-Ausweitung ebenfalls mit einem DID Ansatz und findet Evidenz für einen Anstieg der Arbeitbeteiligung von etwa 5% in der Zielgruppe alleinerziehender Frauen mit mindestens 2 Kindern.\nZur Illustration der empirischen Anwendung von DID mit R untersuchen wir Effekte der EITC-Ausweitung von 1993 nachfolgend anhand eines ähnlichen Datensatzes aus dem CPS wie in der Studie von Adireksombat (2010). Diese Daten umfassen jährliche sozio-ökonomische Merkmale für US-amerikanische Frauen im Zeitraum von 1991 bis 1996 und sind in der Datei eitc_data.csv verfügbar.\nWir lesen den Datensatz zunächst ein.\n\nlibrary(readr)\n\n# EITC-Datensatz einlesen\neitc_data &lt;- read_csv(\"datasets/eitc_data.csv\")\n\nEine Übersicht des Datensatzes eitc_data ist in Tabelle 9.1 dargestellt.\n\n\n\n\nTabelle 9.1: Sozi-ökomonische Variablen zu US-Familien aus dem CPS\n\n\n\n\n\n\n\n\n\nVariable\nBeschreibung\n\n\n\n\nstate\nID-Code Bundesstaat\n\n\nyear\nSteuerjahr\n\n\nurate\nArbeitslosenquote im Bundesstaat (%)\n\n\nchildren\nAnz. Kinder der Frau\n\n\nnonwhite\nDummy für nicht-weiße Frauen\n\n\nfinc\nHaushaltseinkommen im Steuerjahr (US-$)\n\n\nearn\nEinkommen der Frau im Steuerjahr (US-$)\n\n\nage\nAlter\n\n\ned\nAusbildungsniveau der Frau (Jahre)\n\n\nwork\nDummy für Berufstätigkeit\n\n\nunearn\n= Haushaltseinkommen - Einkommen der Frau (Tsd. US-$)\n\n\n\n\n\n\n\n\n\n\nWir erweitern das tibble-Objekt zunächst um eine Dummy-Variable für Mütter (anykids), sowie spezifischere Dummies für Frauen mit einem Kind (onechild) oder mit zwei oder mehr Kindern (twomorekids). Weiterhin erzeugen wir einen Indikator für Beobachtungen nach der EITC-Ausweitung im Jahr 1993 (after1993).\n\n# Dummies für Frauen mit Kindern\n# und Post-Interventionsprediode hinzufügen \neitc_data &lt;- eitc_data %&gt;%\n  mutate(\n    onechild = if_else(children == 1, TRUE, FALSE),\n    twomorekids = if_else(children &gt;= 2, TRUE, FALSE),\n    anykids = if_else(children &gt; 0, TRUE, FALSE),\n    after1993 = if_else(year &gt; 1993, TRUE, FALSE)\n  )\n\nEinen Überblick über den modifizierten Datensatz erhalten wir mit glimpse().\n\n# Modifikationen kontrollieren\nglimpse(eitc_data)\n\nRows: 13,746\nColumns: 15\n$ state       &lt;dbl&gt; 11, 12, 13, 14, 15, 16, 21, 22, 23, 31, 32, 33, 34, 35, 41…\n$ year        &lt;dbl&gt; 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991…\n$ urate       &lt;dbl&gt; 7.6, 7.2, 6.4, 9.1, 8.6, 6.8, 7.3, 6.7, 7.0, 6.4, 6.0, 7.2…\n$ children    &lt;dbl&gt; 0, 1, 2, 0, 3, 1, 0, 0, 1, 2, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0…\n$ nonwhite    &lt;dbl&gt; 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ finc        &lt;dbl&gt; 18714, 4839, 8178, 9370, 14707, 21605, 19147, 64312, 17676…\n$ earn        &lt;dbl&gt; 18714.4, 471.4, 0.0, 0.0, 14706.6, 18854.6, 14141.0, 63802…\n$ age         &lt;dbl&gt; 26, 22, 33, 43, 23, 53, 52, 51, 20, 32, 51, 29, 54, 28, 27…\n$ ed          &lt;dbl&gt; 10, 9, 11, 11, 7, 7, 11, 11, 11, 11, 9, 10, 9, 11, 11, 7, …\n$ work        &lt;dbl&gt; 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1…\n$ unearn      &lt;dbl&gt; 0.0000, 4.3672, 8.1782, 9.3696, 0.0000, 2.7504, 5.0059, 0.…\n$ onechild    &lt;lgl&gt; FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, TRUE…\n$ twomorekids &lt;lgl&gt; FALSE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, FALS…\n$ anykids     &lt;lgl&gt; FALSE, TRUE, TRUE, FALSE, TRUE, TRUE, FALSE, FALSE, TRUE, …\n$ after1993   &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA…\n\n\nDie Plausibilität der Annahme paralleler Trends können wir graphisch anhand einer Gegenüberstellung der Beschäftigungsquote (avg.work = mean(work)) für Frauen mit und ohne Kindern (anykids) über die Zeit (year) einschätzen. Wir gruppieren hierzu den Datensatz entsprechend und fassen die Outcome-Variable (work) gruppenweise zusammen.\n\n# Zeitpunkt-Gruppen-Mittelwerte berechnen\n(\n  eitc_summarised &lt;- eitc_data %&gt;%\n  group_by(year, anykids) %&gt;%\n  summarise(\n    avg.work = mean(work)\n  )\n)\n\n# A tibble: 12 × 3\n# Groups:   year [6]\n    year anykids avg.work\n   &lt;dbl&gt; &lt;lgl&gt;      &lt;dbl&gt;\n 1  1991 FALSE       0.58\n 2  1991 TRUE        0.46\n 3  1992 FALSE       0.57\n 4  1992 TRUE        0.44\n 5  1993 FALSE       0.57\n 6  1993 TRUE        0.44\n 7  1994 FALSE       0.59\n 8  1994 TRUE        0.46\n 9  1995 FALSE       0.57\n10  1995 TRUE        0.51\n11  1996 FALSE       0.55\n12  1996 TRUE        0.50\n\n\n\n# Graphischer Vergleich der Trends\nggplot(data = eitc_summarised) +\n  geom_line(\n    mapping = aes(\n      x = year, \n      y = avg.work, \n      col = anykids\n    )\n  ) +\n  # Indikator für EITC-Erweiterung 1993\n  geom_vline(\n    xintercept = 1993, \n    lty = \"dashed\"\n  ) +\n  scale_x_continuous(\"Jahr\") +\n  scale_y_continuous(\"Beschäftigungsquote\") +\n  scale_color_manual(\n    values = c(\"TRUE\" = \"red\", \"FALSE\" = \"blue\")\n  ) +\n  guides(color = guide_legend(title = \"Kinder?\")) +\n  theme_cowplot()\n\n\n\n\n\n\n\nAbbildung 9.3: Trends in der Erwerbsbeteiligung US-amerikanischer Frauen im CPS-Datensatz\n\n\n\n\n\nAbbildung 9.3 zeigt, dass die Beschäftigungsquote für kinderlose Frauen deutlich oberhalb der Quote für Mütter verläuft. Die Trends vor der EITC-Ausweitung im Jahr 1993 sind sehr ähnlich, sodass eine parallele Entwicklung plausibel scheint.\n\n9.4.1 Schätzungen des ATT mit linearen Modellen\nWir berechnen Zunächst den Behandlungseffekt der für Frauen mit Kindern relativ zu kinderlosen Frauen gemäß \\(\\eqref{eq:DIDMOMENTS}\\), wobei wir jeweils sämtliche Perioden vor und nach der Behandlung einbeziehen. Dies führt zu den Ergebnissen in Tabelle 9.2, wobei \\[\\begin{align}\n  \\textcolor{orange}{\\widehat\\beta_\\text{DID}} = (\\textcolor{red}{B} - \\textcolor{red}{A}) - (\\textcolor{blue}{D} - \\textcolor{blue}{C})\n\\end{align}\\] der geschätzte Behandlungseffekt ist.\n\n\n\nTabelle 9.2: eitc_data: Stichprobenmittelwerte für work\n\n\n\n\n\n\n\n\n\n\n\n\nv. EITC-Ausweitung\nn. EITC-Ausweitung\nDifferenz\n\n\n\n\nKinder\n\\(\\textcolor{red}{A = .446}\\)\n\\(\\textcolor{red}{B = .491}\\)\n\\(\\textcolor{red}{.045}\\)\n\n\nk. Kinder\n\\(\\textcolor{blue}{C = .575}\\)\n\\(\\textcolor{blue}{D = .573}\\)\n\\(\\textcolor{blue}{-.002}\\)\n\n\n\\(\\textcolor{orange}{\\widehat{\\beta}_\\text{DID}}\\)\n\n\n\\(\\textcolor{orange}{.047}\\)\n\n\n\n\n\n\nDie nachfolgenden Code-Chunks zeigen die Schritte zur Berechnung von \\(\\widehat{\\beta}_\\text{DID}\\) mit R.\n\n# A, B, C und D berechnen\n(\n  ABCD &lt;- eitc_data %&gt;%\n    group_by(after1993, anykids) %&gt;%\n    summarise(avg.work = mean(work))\n)\n\n# A tibble: 4 × 3\n# Groups:   after1993 [2]\n  after1993 anykids avg.work\n  &lt;lgl&gt;     &lt;lgl&gt;      &lt;dbl&gt;\n1 FALSE     FALSE       0.58\n2 FALSE     TRUE        0.45\n3 TRUE      FALSE       0.57\n4 TRUE      TRUE        0.49\n\n\n\n# Differenzen bilden\nDminusC &lt;- ABCD %&gt;%\n    filter(anykids == FALSE) %&gt;%\n    pull(avg.work) %&gt;%\n    diff()\n\nBminusA &lt;- ABCD %&gt;%\n    filter(anykids == TRUE) %&gt;%\n    pull(avg.work) %&gt;%\n    diff()\n\n\n# DID-Schätzung: Differenz der Stichprobenmittel-Differenzen\nbeta_DID_means &lt;- BminusA - DminusC\nbeta_DID_means\n\n[1] 0.04687\n\n\nDurch Iteration von summarise() können wir diese Rechenschritte effizienter ausführen.\n\n# Effizienter:\neitc_data  %&gt;% \n    group_by(after1993, anykids) %&gt;% \n    summarise(avg.work = mean(work)) %&gt;%\n    summarise(diff_time = diff(avg.work)) %&gt;%\n    summarise(beta_DID_means = diff(diff_time)) %&gt;%\n    pull(beta_DID_means)\n\n[1] 0.04687\n\n\nWir erhalten also eine positive Schätzung des Behandlungseffekts. Die Interpretation ist, dass die Ausweitung des EITC im Jahr 1993 zu einem Anstieg der Erwerbsbeteiligung in der Gruppe der Frauen mit Kindern von durchschittlich \\(4.69\\%\\) in den Folgeperioden geführt hat.\nFür die Berechnung von Inferenzstatistiken bezüglich \\(\\beta_\\text{DID}\\) schätzen wir ein lineares Interaktionsmodell gemäß \\(\\eqref{eq:DIDREG}\\),\n\\[\\begin{align}\n  \\begin{split}\n    \\text{work}_{i,t} =&\\, \\beta_0 + \\beta_1 \\text{anykids}_{i,t} + \\beta_2 \\text{after1993}_t \\\\\n  +&\\, \\beta_3 (\\text{anykids}_{i,t} \\times \\text{after1993}_t) + \\epsilon_{i,t}.\n  \\end{split}\\label{eq:eitcmod}\n\\end{align}\\]\n\n# Equivalente Schätzung u. Inferenz \n# mit linearem Interaktionsmodell\nDiD_reg &lt;- lm(\n  formula = work ~ anykids * after1993, \n  data = eitc_data\n)\n\nDer geschätzte Koeffizient des Interkationsterms stimmt mit der händisch berechneten Schätzung überein.\n\ntidy(DiD_reg) %&gt;% \n  filter(term == \"anykidsTRUE:after1993TRUE\") %&gt;% \n  pull(estimate)\n\n[1] 0.04687\n\n\nMit coeftest() berechnen wir heteroskedastie-robuste Inferenzstatistiken.\n\n# Robuste Inferenzstatistiken\ncoeftest(\n  x = DiD_reg, \n  vcov. = vcovHC, \n  type = \"HC1\"\n)\n\n\nt test of coefficients:\n\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                0.57546    0.00880   65.38   &lt;2e-16 ***\nanykidsTRUE               -0.12950    0.01165  -11.12   &lt;2e-16 ***\nafter1993TRUE             -0.00207    0.01287   -0.16   0.8720    \nanykidsTRUE:after1993TRUE  0.04687    0.01714    2.73   0.0063 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDer Koeffizient des Interaktionsterms ist zum 1%-Niveau signifikant. fixest::feols() liefert eine identische Schätzung.\n\nlibrary(fixest)\n(\n  DID_twoway &lt;- feols(\n    fml = work ~ anykids * after1993,\n    data = eitc_data, \n    vcov = \"HC1\"\n  )\n)\n\nOLS estimation, Dep. Var.: work\nObservations: 13,746\nStandard-errors: Heteroskedasticity-robust \n                           Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept)                0.575460   0.008802  65.3756 &lt; 2.2e-16 ***\nanykidsTRUE               -0.129498   0.011648 -11.1176 &lt; 2.2e-16 ***\nafter1993TRUE             -0.002074   0.012873  -0.1611 0.8720396    \nanykidsTRUE:after1993TRUE  0.046873   0.017144   2.7342 0.0062619 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.496672   Adj. R2: 0.012384\n\n\nWir erweitern Modell \\(\\eqref{eq:eitcmod}\\) nun um Fixed Effekts für den US-Bundesstaat sowie das Jahr,\n\\[\\begin{align}\n  \\begin{split}\n    \\text{work}_{i,t} =&\\, \\theta_\\text{Staat} + \\eta_t \\\\\n    +&\\, \\beta_1 \\text{anykids}_{i,t} + \\beta_2 (\\text{anykids}_{i,t} \\times \\text{after1993}_t) + \\epsilon_{i,t}.\n    \\end{split}\\label{eq:eitcmodfe}\n\\end{align}\\]\nAnhand der Dummy-Variablen für Bundesstaaten (\\(\\theta_\\text{Staat}\\)) und Jahre (\\(\\eta_t\\)) kontrollieren wir für unbeobachtete zeitinvariante Unterschiede zwischen den Bundesstaaten sowie für allgemeine zeitliche Trends und Schocks, die alle Bundesstaaten in einem bestimmten Jahr betreffen. Dies schließt etwaige Backdoor-Pfade durch den Einfluss spezifischer Eigenschaften der Bundesstaaten (Kultur, Geografie, langfristige politische Einstellungen, etc.) und gemeinsamer zeitlicher Einflüsse.\n\nlibrary(fixest)\n(\n  DID_twoway &lt;- feols(\n    fml = work ~ anykids + I(anykids * after1993) \n    | state + year,\n    data = eitc_data\n  )\n)\n\nOLS estimation, Dep. Var.: work\nObservations: 13,746\nFixed-effects: state: 51,  year: 6\nStandard-errors: Clustered (state) \n                       Estimate Std. Error t value   Pr(&gt;|t|)    \nanykidsTRUE            -0.12391    0.01593  -7.776 3.6952e-10 ***\nI(anykids * after1993)  0.04579    0.01656   2.765 7.9497e-03 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.489063     Adj. R2: 0.038633\n                 Within R2: 0.011101\n\n\nDie Schätzung des ATT bei Kontrolle für Zeit- und Bundesstaat-Effekte in \\(\\eqref{eq:eitcmodfe}\\) unterscheidet sich nur geringfügig gegenüber dem Ergebnis für das Modell \\(\\eqref{eq:eitcmod}\\). Beachte, dass der Behandlungseffekt auch bei geclusterten Standardfehlern auf Bundesstaaten-Ebene (| state + year) signifikant ist.\nEin weiterer Vorteil von DID-Schätzungen mit Regression ist die Möglichkeit zur Kontrolle für individuen-spezifische Kovariablen, um Backdoors aufgrund systematischer Unterschiede zwischen Kontroll- und Behandlungsgruppen zu vermeiden.\nWir erweitern Modell \\(\\eqref{eq:eitcmodfec}\\) um sozio-ökonomische Charakteristika der Frauen: Einen Dummy für nicht-weiße Frauen (nonwhite), quadratische Terme in Alter (age) und Ausbildungsniveau (ed) sowie weitere Einkünfte des Haushalts (unearn),\n\\[\\begin{align}\n  \\begin{split}\n    \\text{work}_{i,t} =&\\, \\theta_\\text{Staat} + \\eta_t \\\\\n    +&\\, \\beta_1 \\text{anykids}_{i,t} + \\beta_2 (\\text{anykids}_{i,t} \\times \\text{after1993}_t) \\\\\n    +&\\, \\beta_3 \\text{unearn} + \\beta_4 \\text{nonwhite} \\\\\n    +&\\, \\beta_5 \\text{age} + \\beta_6 \\text{age}^2 + \\beta_7 \\text{ed} + \\beta_8 \\text{ed}^2 \\\\\n    +&\\, \\epsilon_{i,t}.\n    \\end{split}\\label{eq:eitcmodfec}\n\\end{align}\\]\n\n# Year-FE + State-FE + Kontrollvariablen\n(\n  DID_FE_controls &lt;- feols(\n    fml = work ~ anykids + I(anykids * after1993) \n    \n    + unearn + nonwhite \n    + age + I(age^2)\n    + ed + I(ed^2)\n    \n    | state + year, \n    \n    data = eitc_data\n  )\n)\n\nOLS estimation, Dep. Var.: work\nObservations: 13,746\nFixed-effects: state: 51,  year: 6\nStandard-errors: Clustered (state) \n                        Estimate Std. Error  t value   Pr(&gt;|t|)    \nanykidsTRUE            -0.119221   0.010673 -11.1709 3.4010e-15 ***\nI(anykids * after1993)  0.055755   0.014385   3.8759 3.1021e-04 ***\nunearn                 -0.017695   0.000959 -18.4575  &lt; 2.2e-16 ***\nnonwhite               -0.080399   0.028048  -2.8665 6.0589e-03 ** \nage                     0.026323   0.003664   7.1847 3.0857e-09 ***\nI(age^2)               -0.000316   0.000052  -6.0298 1.9673e-07 ***\ned                     -0.004160   0.006270  -0.6634 5.1013e-01    \nI(ed^2)                 0.001536   0.000535   2.8701 6.0002e-03 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.46896     Adj. R2: 0.115657\n                Within R2: 0.090729\n\n\nDie Schätzung von \\(\\eqref{eq:eitcmodfec}\\) ergibt mit \\(0.0558\\) eine etwas größere Schätzung eines positiven signifikanten Effekt der EITC-Ausweitung auf die Erwerbsbeteiligung von Müttern.\nWie oben erläutert, führte die EITC-Ausweitung von 1993 unter anderem ein Stufensystem für die Höhe des EITC in Ahängigkeit der Kinder-Anzahl ein, sodass unterschiedlich starke Anreize zur Aufnahme einer Beschäftigung für Mütter mit nur einem Kind und mehreren Kindern plausibel sind. Anhand der Dummy-Variablen für (genau) ein Kind (onechild) sowie zwei oder mehr Kinder (twomorekids) können wir eine differenziertere Schätzung des Effekts hinsichtlich des Betreuungsaufwands erhalten. Hierzu modifizieren wir Modell \\(\\eqref{eq:eitcmodfec}\\) entsprechend:\n\\[\\begin{align}\n  \\begin{split}\n    \\text{work}_{i,t} =&\\, \\theta_\\text{Staat} + \\eta_t \\\\\n    +&\\, \\beta_1 \\text{onechild}_{i,t} + \\beta_2 (\\text{onechild}_{i,t} \\times \\text{after1993}_t) \\\\\n    +&\\, \\beta_3 \\text{twomorechild}_{i,t} + \\beta_4 (\\text{twomorechild}_{i,t} \\times \\text{after1993}_t) \\\\\n    +&\\, \\beta_5 \\text{unearn} + \\beta_6 \\text{nonwhite} + \\beta_7 \\text{age} + \\beta_8 \\text{age}^2 + \\beta_9 \\text{ed} + \\beta_{10} \\text{ed}^2 \\\\\n    +&\\, \\epsilon_{i,t}.\n  \\end{split}\\label{eq:eitcmodfecd}\n\\end{align}\\]\n\n# Differenzierung: onechild / twomorekids\n(\n  DID_FE_spec_controls &lt;- feols(\n    fml = work ~ \n      onechild + I(onechild * after1993) \n    + twomorekids + I(twomorekids * after1993) \n    \n    + unearn + nonwhite \n    + age + I(age^2)\n    + ed + I(ed^2)\n    \n    | state + year,\n    \n    data = eitc_data\n  )\n)\n\nOLS estimation, Dep. Var.: work\nObservations: 13,746\nFixed-effects: state: 51,  year: 6\nStandard-errors: Clustered (state) \n                            Estimate Std. Error  t value   Pr(&gt;|t|)    \nonechildTRUE               -0.063581   0.013327  -4.7708 1.6319e-05 ***\nI(onechild * after1993)     0.040539   0.017829   2.2737 2.7311e-02 *  \ntwomorekidsTRUE            -0.161675   0.013127 -12.3166  &lt; 2.2e-16 ***\nI(twomorekids * after1993)  0.064799   0.016411   3.9485 2.4649e-04 ***\nunearn                     -0.017334   0.000992 -17.4790  &lt; 2.2e-16 ***\nnonwhite                   -0.073759   0.027833  -2.6501 1.0745e-02 *  \nage                         0.028990   0.003475   8.3433 4.9204e-11 ***\nI(age^2)                   -0.000357   0.000049  -7.2889 2.1209e-09 ***\ned                         -0.003765   0.006350  -0.5929 5.5595e-01    \nI(ed^2)                     0.001517   0.000552   2.7474 8.3318e-03 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.467886     Adj. R2: 0.119572\n                 Within R2: 0.094887\n\n\nDie interessierenden geschätzten Koeffizienten von I(onechild * after1993) und I(twomorekids * after1993) sind \\(0.0405\\) und \\(0.0648\\). Auch hier sind die Koeffizienten signifikant von null verschieden. Der größere Koeffizient für den Effekt auf Mütter mit zwei oder mehr Kinder liefert Evidenz dafür, dass die Einführung der Zahlstufe für größere Familien im Rahmen der EITC-Ausweitung von 1993 tatsächlich einen etwas stärkeren Anreiz auf die Zielgruppe mit mehreren Kindern hatte.\n\n\n9.4.2 Probit-Spezifikationen\nIn sämtlichen Modellen in Kapitel 9.4.1 haben wir \\(\\text{work}_{i,t}\\) als kontinulierliche Variable behandelt und den bedingten Erwartungswert als lineare Funktion modelliert. Da \\(\\text{work}_{i,t}\\) eine binäre Variable ist, haben wir damit implizit die bedingte Wahrscheinlichkeit der Erwerbsbeteiligung \\(P(\\text{work}_{i,t} = 1\\vert \\boldsymbol{x}_{i,t})\\) modelliert. Wie in Kapitel 4.2.1 erläutert, kann ein solches lineares Wahrscheinlichkeitsmodell (LPM) einen nicht-linearen Verlauf der Wahrscheinlichkeitsfunktion \\(P(\\text{work}_{i,t} = 1\\vert \\boldsymbol{x}_{i,t})\\) nicht exakt abbilden, wobei tatsächliche Behandlungseffekte unter- oder überschätzt werden können. In manchen Fällen können geschätzte Wahrscheinlichkeiten sogar außerhalb des Intervalls \\([0,1]\\) liegen. Statt eines LPM sollte ein generalisiertes lineares Modell (GLM) verwendet werden.\nWir modellieren nachfolgend den Effekt der EITC-Anpassung auf die Wahrscheinlichkeit einer Erwerbsbeteiligung von Müttern mit Probit-Regression. Anstatt stats::glm() verwenden wir fixest::feglm().4 Analog zu fixest::feols() erlaubt fixest::feglm() die Schätzung von Probit-Regressionen mit Fixed Effekts. Partielle Effekte können mit dem Paket marginaleffects berechnet werden. Wir schätzen zunächst eine Fixed-Effects-Probit-Regression analog zu \\(\\eqref{eq:eitcmodfe}\\), d.h.\n\\[\\begin{align}\n  \\begin{split}\n    \\Phi^{-1}\\bigg[P(\\text{work}_{i,t} = 1\\vert \\boldsymbol{x}_{i,t})\\bigg]\n    =&\\, \\eta_t + \\theta_\\text{Staat} + \\beta_1 \\text{anykids}_{i,t}\\\\\n    +&\\, \\beta_2 (\\text{anykids}_{i,t} \\times \\text{after1993}_{i,t}).\\\\\n  \\end{split}\n\\end{align}\\]\nFür die Berechnung der partiellen Effekte mit marginaleffects::avg_slopes() definieren wir die interargierten Regressoren direkt im Datensatz.\n\n# Interagierte Regressoren definieren\neitc_data &lt;- eitc_data %&gt;% \n  mutate(\n    int_anykids = anykids * after1993,\n    int_onechild = onechild * after1993,\n    int_twomore = twomorekids * after1993\n  )\n\nDie Struktur von feglm() folgt dem selben Schema wie feols(). Das zusätzliche Argument family = binomial(\"probit\") legt die entsprechende Link-Funktion fest.\n\n# Probit-Regression mit TWFE\n(\n  EITC_DID_probit &lt;- feglm(\n    fml = work ~ anykids + int_anykids\n    | state + year, \n    family = binomial(\"probit\"),\n    data = eitc_data\n  )\n)\n\nGLM estimation, family = binomial, Dep. Var.: work\nObservations: 13,746\nFixed-effects: state: 51,  year: 6\nStandard-errors: Clustered (state) \n            Estimate Std. Error z value   Pr(&gt;|z|)    \nanykidsTRUE  -0.3204    0.04212  -7.606 2.8361e-14 ***\nint_anykids   0.1189    0.04276   2.780 5.4308e-03 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nLog-Likelihood: -9,224.4   Adj. Pseudo R2: 0.025402\n           BIC: 19,001.5     Squared Cor.: 0.042557\n\n\nDie Schätzung ergibt einen positiven Effekt für int_anykids. Wie im linearen Modell ist der Koeffizient von int_anykids signifikant. Beachte, dass dieser Koeffizient die geschätzte Änderung der latenten Variable des Probit-Modells misst und nicht direkt als Behandlungseffekt interpretiert werden darf. Stattdessen können wir mit marginaleffects::avg_slopes() den durchschnittlichen partiellen Effekt des Interaktionsterms für Frauen in der Behandlungsgruppe für die Jahre 1994 bis 1996 berechnen. marginaleffects::datagrid() setzt Variablen ohne spezifizierte Werte auf ihren Mittelwert (kontinuierlich) oder Modus (kategorisch). Der Modus von state ist 93 (California).\n\nlibrary(marginaleffects)\n\nEITC_DID_probit %&gt;% \n  avg_slopes(\n    variables = \"int_anykids\", \n    newdata = datagrid(\n      anykids = 1, \n      year = 1994:1996\n    )\n  )\n\n\n        Term          Contrast Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 %\n int_anykids mean(1) - mean(0)   0.0456     0.0161 2.83  0.00465 7.7 0.014\n 97.5 %\n 0.0771\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\nDer geschätzte durchschnittliche partielle Effekt der EITC-Ausweitung für Mütter im Bundesstaat California für die Jahre 1994 bis 1996 ist eine Erhöhung der Wahrscheinlichkeit der Erwerbsbeteiligung um etwa \\(4.57\\%\\).\nAnalog zu Modell \\(\\eqref{eq:eitcmodfecd}\\) kontrollieren wir in einer weiteren Regression zusätzlich für sozio-ökonomische Charakteristika und differenzieren zwischen dem Effekt für Frauen mit einem Kind und Müttern mit zwei oder mehr Kindern anhand des Modells\n\\[\\begin{align}\n  \\begin{split}\n    \\Phi^{-1}\\bigg[P(\\text{work}_{i,t} = 1)\\bigg] =&\\, \\theta_\\text{Staat} + \\eta_t \\\\\n    +&\\, \\beta_1 \\text{onechild}_{i,t} + \\beta_2 (\\text{onechild}_{i,t} \\times \\text{after1993}_t) \\\\\n    +&\\, \\beta_3 \\text{twomorechild}_{i,t} + \\beta_4 (\\text{twomorechild}_{i,t} \\times \\text{after1993}_t) \\\\\n    +&\\, \\beta_5 \\text{unearn} + \\beta_6 \\text{nonwhite} + \\beta_7 \\text{age} + \\beta_8 \\text{age}^2 + \\beta_9 \\text{ed} + \\beta_{10} \\text{ed}^2 \\\\\n    +&\\, \\epsilon_{i,t}.\n  \\end{split}\n\\end{align}\\]\n\n# Probit-FE-Regression mit Kontrollvariablen\n# und Differenzierung des Effekts\n(\n  EITC_DID_probit &lt;- feglm(\n    fml = work ~ onechild + int_onechild\n    + twomorekids + int_twomore\n    \n    + unearn + nonwhite + age + ed \n    + I(ed^2) + I(age^2)\n    \n    | year + state, \n    family = binomial(\"probit\"),\n    data = eitc_data\n  )\n)\n\nGLM estimation, family = binomial, Dep. Var.: work\nObservations: 13,746\nFixed-effects: year: 6,  state: 51\nStandard-errors: Clustered (year) \n                 Estimate Std. Error  z value   Pr(&gt;|z|)    \nonechildTRUE    -0.180374   0.029751  -6.0628 1.3378e-09 ***\nint_onechild     0.120223   0.041680   2.8844 3.9218e-03 ** \ntwomorekidsTRUE -0.436599   0.022144 -19.7165  &lt; 2.2e-16 ***\nint_twomore      0.183897   0.072453   2.5381 1.1144e-02 *  \nunearn          -0.053551   0.003109 -17.2227  &lt; 2.2e-16 ***\nnonwhite        -0.206060   0.026744  -7.7048 1.3105e-14 ***\nage              0.078925   0.006161  12.8110  &lt; 2.2e-16 ***\ned              -0.009102   0.028450  -0.3199 7.4903e-01    \nI(ed^2)          0.004198   0.001867   2.2479 2.4580e-02 *  \nI(age^2)        -0.000966   0.000082 -11.8142  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nLog-Likelihood: -8,586.0   Adj. Pseudo R2: 0.091602\n           BIC: 17,800.9     Squared Cor.: 0.145969\n\n\nWir können nun zwei partielle Effekte berechnen: 1. für int_onechild und 2. für int_twomore. Hierzu setzten wir jeweils die übrigen Dummy-Variablen mit Bezug zur Anzahl der Kinder auf null. Weiterhin setzen wir nonwhite = 0, d.h. wir betrachten den Effekt für weiße Frauen im Bundesstaat California, wobei die übrigen Regressoren den Wert der jeweiligen Stichprobenmittel haben.\n\n# 1. Durchschn. Partieller Effekt onechild\nEITC_DID_probit %&gt;% \n  avg_slopes(\n    variable = \"int_onechild\",\n    datagrid(\n      onechild = 1, \n      twomorekids = 0, \n      int_twomore = 0,\n      year = 1994:1996,\n      nonwhite = 0\n    )\n  )\n\n\n         Term          Contrast Estimate Std. Error   z Pr(&gt;|z|)    S  2.5 %\n int_onechild mean(1) - mean(0)   0.0411     0.0117 3.5   &lt;0.001 11.1 0.0181\n 97.5 %\n 0.0641\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\n# 1. Durchschn. Partieller Effekt twomore\nEITC_DID_probit %&gt;% \n  avg_slopes(\n    variable = \"int_twomore\",\n    datagrid(\n      int_onechild = 0, \n      onechild = 0, \n      twomorekids = 1, \n      year = 1994:1996,\n      nonwhite = 0\n    )\n  )\n\n\n        Term          Contrast Estimate Std. Error   z Pr(&gt;|z|)   S  2.5 %\n int_twomore mean(1) - mean(0)   0.0616     0.0228 2.7  0.00687 7.2 0.0169\n 97.5 %\n  0.106\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\nÄhnlich wie in Modell \\(\\eqref{eq:eitcmodfecd}\\) erhalten wir signifikante positive Schätzungen. Der durchschnittliche Effekt für int_twomore ist mit einer Erhöhung der Wahrscheinlichkeit zur Aufnahme einer Beschäftigung von etwa \\(6.16\\%\\) etwas höher als die \\(4.11\\%\\) für int_onechild.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Difference-in-Differences</span>"
    ]
  },
  {
    "objectID": "DiD.html#case-study-effekt-von-polizeipräsenz-auf-autodiebstähle",
    "href": "DiD.html#case-study-effekt-von-polizeipräsenz-auf-autodiebstähle",
    "title": "9  Difference-in-Differences",
    "section": "9.5 Case Study: Effekt von Polizeipräsenz auf Autodiebstähle",
    "text": "9.5 Case Study: Effekt von Polizeipräsenz auf Autodiebstähle\nNach einem Terroranschlag auf das größte jüdische Gemeindezentrum in Buenos Aires am 18. Juli 1994 wurden sämtliche jüdische und muslimische Einrichtungen in der Stadt rund um die Uhr von der argentinischen Polizei geschützt. Somit führte dieses Ereignis zu einer geografischen quasi-experimentellen Allokation von Polizeikräften in Gegenden mit entsprechenden Einrichtungen. In einem Forschungsdesign, dass die lokale Straßenkriminalität Kriminalität erklären soll, kann die sich aus der Allokation ergebende Variation in der Polizeipräsenz als exogen angenommen werden. Di Tella und Schargrodsky (2004) nutzen diesen Umstand, um anhand von Polizeistatistiken und Daten zu Autodiebstählen in Buenos Aires vor und nach dem Terroranschlag den Effekt erhöhter Polizeipräsenz auf die Kriminalität in einem Difference-in-Differences-Ansatz zu untersuchen. Die Studienergebnisse deuten darauf hin, dass es einen starken abschreckenden Effekt von Polizeistreifen gibt, der sich nur in einem engen Umkreis um Häuserblocks in denen die Polizeipräsenz erhöht wurde, auswirkt.\nIn diesem Kapitel reproduzieren wir Kernergebnisse der Studie mit R. Die benötigten Daten sind auf der Webseite der American Economic Association verfügbar. Die Daten stammen aus drei nicht zusammenhängenden Stadtvierteln von Buenos Aires die etwa \\(3.2\\%\\) der Stadtfläche ausmachen und \\(6.9\\%\\) der Bevölkerung beherbergen, wobei sich jedem Viertel eine Polizeistation befindet. Bei den untersuchten Stadtvierteln handelt es sich um die Viertel mit der größten Anzahl jüdischer Einrichtungen in der Stadt. Der Großteil der Häuserblocks in diesen Vierteln (insgesamt 876 Blocks) liegen nicht in der Nähe einer geschützten Einrichtung. Blocks die mehr als zwei Blocks von einer geschützten Einrichtung entfernt liegen, bilden die Kontrollgruppe.\nWir verwenden nachfolgend den modifizierten Datensatz polizeipraesenz.RDS.\n\n# Datensatz einlesen\npolizeipraesenz &lt;- readRDS(\"datasets/polizeipraesenz.RDS\")\n\n\n\n\nTabelle 9.3: polizeipraesenz: Autodiebstähle in Buenos Aires\n\n\n\n\n\nVariable\nBeschreibung\n\n\n\n\ninstitut\nJüdische Einrichtung im Block\n\n\nbarrio\nStadtviertel\n\n\ndistanz\nEntf. zu Block mit Einrichtung (in Blocks)\n\n\nmonat\nMonat der Beobachtung\n\n\nobserv\nID-Variable für Block\n\n\ntotrob\nDiebstähle pro Monat (normalisiert)\n\n\n\n\n\n\n\n9.5.1 Trend-Vergleich\nZur Einschätzung der Annahme paralleler Trends berechnen wir zunächst die Durschnittliche Anzahl an Autodiebstählen Blocks mit bzw. ohne jüdische Institutionen für die Monate April bis Dezember. Beachte, dass die Variable monat zwei Ausprägungen für den Monat des Anschlags aufweist: Juli (1 - 17) für die Juli-Tage vor dem Anschlag und für die verbleibenden Tage Juli (18 - 31).\n\n# Trends berechnen\n(\n  polizeipraesenz_Trends &lt;- polizeipraesenz %&gt;%\n    mutate(institut = as.factor(institut)) %&gt;%\n    group_by(monat, institut) %&gt;%\n    summarise(\n      `Durchschn. Diebstähle` = mean(totrob)\n    )\n)\n\n# A tibble: 20 × 3\n# Groups:   monat [10]\n   monat          institut `Durchschn. Diebstähle`\n   &lt;ord&gt;          &lt;fct&gt;                      &lt;dbl&gt;\n 1 April          0                          0.11 \n 2 April          1                          0.12 \n 3 Mai            0                          0.10 \n 4 Mai            1                          0.088\n 5 Juni           0                          0.076\n 6 Juni           1                          0.13 \n 7 Juli (1 - 17)  0                          0.041\n 8 Juli (1 - 17)  1                          0.020\n 9 Juli (18 - 31) 0                          0.054\n10 Juli (18 - 31) 1                          0.027\n11 August         0                          0.11 \n12 August         1                          0.047\n13 September      0                          0.099\n14 September      1                          0.014\n15 Oktober        0                          0.11 \n16 Oktober        1                          0.061\n17 November       0                          0.10 \n18 November       1                          0.027\n19 Dezember       0                          0.11 \n20 Dezember       1                          0.027\n\n\nDie in polizeipraesenz_Trends erfasste Trendentwicklung für Blocks in der Behandlungsgruppe (institut == 1) und in der Kontrollgruppe (institut == 0) plotten wir mit ggplot2().\n\n# Trends plotten\npolizeipraesenz_Trends %&gt;%\n  ggplot(\n    mapping = aes(\n      x = monat, \n      y = `Durchschn. Diebstähle`, \n      color = institut, \n      group = institut\n    )\n  ) +\n  geom_line() +\n  geom_vline(\n    xintercept = \"Juli (18 - 31)\", \n    lty = \"dashed\") +\n  geom_point() +\n  labs(\n    x = \"Monat\",\n    y = \"Durchschn. Anz. Diebstähle / Monat\"\n  ) +\n  theme_cowplot() +\n  theme(\n    axis.text.x = element_text(\n      angle = 45, \n      hjust = 1\n    ), \n    legend.position = \"top\"\n  )\n\n\n\n\n\n\n\nAbbildung 9.4: Geschätzte Trends für Autodiebstähle in Buenos Aires im Jahr 1994\n\n\n\n\n\nAbbildung 9.4 zeigt einen ähnlichen Verlauf der Trends für den Zeitraum unmittelbar vor dem Anschalg am 18. Juli.\nTabelle 2 in Di Tella und Schargrodsky (2004) präsentiert t-Tests für Unterschiede in der Mittleren Anzahl der Diebstähle pro Monat zwischen Blocks mit jüdischen Einrichtungen und verschiedenen distanz-basierten Untergruppen von Blocks ohne eine jüdische Einrichtungen für jede Periode. Zur Reproduktion dieser Ergebnisse erstellen zunächst eine Listen-Spalten für die beobachteten Diebstähle in Abhängigkeit der Distanz zum nächsten Block mit einer jüdischen Einrichtung.\n\nd2more Zwei oder mehr Blocks entfernt\nd2: Zwei Blocks entfernt\nd1: Ein Block entfernt\nsame: Jüdische Einrichtung im selben Block\n\n\n(\n  dat_listcol &lt;- polizeipraesenz %&gt;% \n    group_by(observ, monat) %&gt;%\n    transmute(\n      d2more = list(totrob[distanz &gt; 2]),\n      d2 = list(totrob[distanz == 2]),\n      d1 = list(totrob[distanz == 1]),\n      same = list(totrob[institut == 1])\n    )\n)\n\n# A tibble: 8,760 × 6\n# Groups:   observ, monat [8,760]\n   observ monat d2more    d2        d1        same     \n    &lt;dbl&gt; &lt;ord&gt; &lt;list&gt;    &lt;list&gt;    &lt;list&gt;    &lt;list&gt;   \n 1    870 April &lt;dbl [0]&gt; &lt;dbl [0]&gt; &lt;dbl [1]&gt; &lt;dbl [0]&gt;\n 2    851 April &lt;dbl [0]&gt; &lt;dbl [1]&gt; &lt;dbl [0]&gt; &lt;dbl [0]&gt;\n 3    843 April &lt;dbl [0]&gt; &lt;dbl [0]&gt; &lt;dbl [0]&gt; &lt;dbl [1]&gt;\n 4    796 April &lt;dbl [0]&gt; &lt;dbl [0]&gt; &lt;dbl [1]&gt; &lt;dbl [0]&gt;\n 5    790 April &lt;dbl [0]&gt; &lt;dbl [0]&gt; &lt;dbl [0]&gt; &lt;dbl [1]&gt;\n 6    789 April &lt;dbl [0]&gt; &lt;dbl [0]&gt; &lt;dbl [1]&gt; &lt;dbl [0]&gt;\n 7    844 April &lt;dbl [0]&gt; &lt;dbl [0]&gt; &lt;dbl [0]&gt; &lt;dbl [1]&gt;\n 8    858 April &lt;dbl [0]&gt; &lt;dbl [0]&gt; &lt;dbl [1]&gt; &lt;dbl [0]&gt;\n 9    787 April &lt;dbl [0]&gt; &lt;dbl [0]&gt; &lt;dbl [1]&gt; &lt;dbl [0]&gt;\n10    850 April &lt;dbl [0]&gt; &lt;dbl [0]&gt; &lt;dbl [1]&gt; &lt;dbl [0]&gt;\n# ℹ 8,750 more rows\n\n\nMit summarise() können wir Stichprobenmittel und Standardabweichungen der Diebstähle in Blocks dieser Kategorien für alle Perioden berechnen. Anschließend kombinieren wir die Ergebnisse jeweils mit sprintf() und formatieren das Ergebnis mit modelsummary::modelsummary_df().5 Tabelle 9.4 Zeit die Spalten A bis D aus Tabelle 2 in Di Tella und Schargrodsky (2004).\n\nlibrary(modelsummary)\n\n# Mittelwerte und Standardabweichungen\nmean_sd &lt;- dat_listcol %&gt;%\n  group_by(monat) %&gt;%\n  summarise(\n    across(\n      d2more:same,\n      .fns = list(\n        mean = ~ mean(unlist(.)), \n        sd = ~ sd(unlist(.))\n      )\n    ),\n    .groups = \"keep\"\n  )\n\n# Desk. Statistiken kombinieren\nformatted_mean_sd &lt;- mean_sd %&gt;%\n  transmute(\n    monat,\n    \"D&gt;2 (A)\" = sprintf(\"%.4f\\n(%.4f)\", d2more_mean, d2more_sd),\n    \"same (B)\" = sprintf(\"%.4f\\n(%.4f)\", same_mean, same_sd),\n    \"D1 (C)\" = sprintf(\"%.4f\\n(%.4f)\", d1_mean, d1_sd),\n    \"D2 (D)\" = sprintf(\"%.4f\\n(%.4f)\", d2_mean, d2_sd)\n  )\n\n# Tabelle mit modelsummary_df() ausgeben\nmodelsummary::datasummary_df(formatted_mean_sd)\n\n\n\nTabelle 9.4: Deskriptive Statistiken für Diebstähle nach Entfernung zur nächsten jüdischen Einrichtung\n\n\n\n \n\n  \n    \n    \n    tinytable_wc8umcv2bg4i97l7rga6\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                monat\n                D&gt;2 (A)\n                same (B)\n                D1 (C)\n                D2 (D)\n              \n        \n        \n        \n                \n                  April         \n                  0.0996\n(0.2481)\n                  0.1216\n(0.3614)\n                  0.1211\n(0.2879)\n                  0.1228\n(0.2974)\n                \n                \n                  Mai           \n                  0.1084\n(0.2357)\n                  0.0878\n(0.2060)\n                  0.0776\n(0.1817)\n                  0.0973\n(0.2591)\n                \n                \n                  Juni          \n                  0.0785\n(0.1961)\n                  0.1284\n(0.2864)\n                  0.0776\n(0.2151)\n                  0.0697\n(0.1867)\n                \n                \n                  Juli (1 - 17) \n                  0.0393\n(0.1451)\n                  0.0203\n(0.0692)\n                  0.0590\n(0.2101)\n                  0.0310\n(0.1419)\n                \n                \n                  Juli (18 - 31)\n                  0.0393\n(0.1460)\n                  0.0270\n(0.0787)\n                  0.0730\n(0.2177)\n                  0.0686\n(0.2386)\n                \n                \n                  August        \n                  0.1184\n(0.2871)\n                  0.0473\n(0.1752)\n                  0.0668\n(0.2197)\n                  0.1272\n(0.3048)\n                \n                \n                  September     \n                  0.1018\n(0.2566)\n                  0.0135\n(0.0573)\n                  0.0901\n(0.2761)\n                  0.0985\n(0.2483)\n                \n                \n                  Oktober       \n                  0.1211\n(0.2671)\n                  0.0608\n(0.2157)\n                  0.0978\n(0.2610)\n                  0.0885\n(0.2367)\n                \n                \n                  November      \n                  0.0962\n(0.2404)\n                  0.0270\n(0.0787)\n                  0.1102\n(0.2889)\n                  0.1018\n(0.2177)\n                \n                \n                  Dezember      \n                  0.1018\n(0.2682)\n                  0.0270\n(0.0787)\n                  0.1165\n(0.2782)\n                  0.1062\n(0.2256)\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\n\n\nDer nächste Chunk reproduziert die Spalten E bis F von Tabelle 2 in Di Tella und Schargrodsky (2004). Die Einträge sind Mittelwertdifferenzen (Standardfehler in Klammern) zwischen den betrachteten Gruppen von Blocks sowie Ergebnisse für t-Tests (Signifikanz-Sternchen) der Hypothese, dass die jeweilige mittlere Anzahl an Autodiebstählen nicht verschieden ist.\nWir definieren zunächst eine Funktion format_ttest(), die die gewünschen Statistiken aus einem mit t.test() berechneten Objekte ausliest und entsprechend formatiert. Anschließend nutzen wir diese Funktion, um die Daten in dat_listcol entsprechend der Definition in Di Tella und Schargrodsky (2004) für jeden Monat zusammenzufassen. Die Ergebnisse formatieren wir wieder mit datasummary_df().\n\n# Funktion: Ergebnisse von t.test() \n# mit Signifikanzsternchen\nformat_ttest &lt;- function(ttest_result) {\n  estimate &lt;- diff(ttest_result$estimate)\n  stderr &lt;- ttest_result$stderr\n  p_value &lt;- ttest_result$p.value\n  \n  stars &lt;- if (p_value &lt; 0.001) {\n    \"***\"\n  } else if (p_value &lt; 0.01) {\n    \"**\"\n  } else if (p_value &lt; 0.05) {\n    \"*\"\n  } else {\n    \"\"\n  }\n  \n  sprintf(\"%.4f (%.4f)%s\", estimate, stderr, stars)\n}\n\n# Berechnung der t-Tests, Formatierung der Ergebnisse\nresults &lt;- dat_listcol %&gt;%\n  group_by(monat) %&gt;%\n  summarise(\n    \"(E) Diff: B - A\" = format_ttest(t.test(unlist(d2more), unlist(same))),\n    \"(F) Diff: C - A\" = format_ttest(t.test(unlist(d2more), unlist(d1))),\n    \"(G) Diff: D - A\" = format_ttest(t.test(unlist(d2more), unlist(d2)))\n  )\n\n# Formatierung der Tabelle mit modelsummary_df()\nmodelsummary::datasummary_df(results)\n\n\n\nTabelle 9.5: Mittelwertdifferenzen in Autodiebstählen und t-Tests\n\n\n\n \n\n  \n    \n    \n    tinytable_ltusa8xn0rz3yptjlp7n\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                monat\n                (E) Diff: B - A\n                (F) Diff: C - A\n                (G) Diff: D - A\n              \n        \n        \n        \n                \n                  April         \n                  0.0221 (0.0606)    \n                  0.0216 (0.0255)  \n                  0.0232 (0.0230) \n                \n                \n                  Mai           \n                  -0.0206 (0.0356)   \n                  -0.0308 (0.0181) \n                  -0.0111 (0.0205)\n                \n                \n                  Juni          \n                  0.0498 (0.0480)    \n                  -0.0009 (0.0193) \n                  -0.0088 (0.0155)\n                \n                \n                  Juli (1 - 17) \n                  -0.0190 (0.0133)   \n                  0.0197 (0.0179)  \n                  -0.0083 (0.0116)\n                \n                \n                  Juli (18 - 31)\n                  -0.0122 (0.0146)   \n                  0.0337 (0.0185)  \n                  0.0293 (0.0173) \n                \n                \n                  August        \n                  -0.0711 (0.0318)*  \n                  -0.0516 (0.0220)*\n                  0.0088 (0.0244) \n                \n                \n                  September     \n                  -0.0883 (0.0153)***\n                  -0.0117 (0.0249) \n                  -0.0033 (0.0205)\n                \n                \n                  Oktober       \n                  -0.0603 (0.0376)   \n                  -0.0233 (0.0241) \n                  -0.0326 (0.0201)\n                \n                \n                  November      \n                  -0.0692 (0.0172)***\n                  0.0140 (0.0254)  \n                  0.0055 (0.0184) \n                \n                \n                  Dezember      \n                  -0.0747 (0.0181)***\n                  0.0147 (0.0253)  \n                  0.0044 (0.0196) \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\n\n\nTabelle 9.5 zeigt eine einschlägige Entwicklung der Differenzen über die Zeit: In den Monaten vor dem Anschlag (und der anschließenden Allokation von Polizeipräsenz) bestehen weder zwischen weit entfernten Blocks und solchen mit einer jüdischen Einrichtung (Spalte E) noch zwischen Blocks ohne eine Einrichtung (Spalten F und G) signifikante unterschiede in der Anzahl der Autodiebstähle. Nach der politischen Intervention ergibt sich ein anderes Bild: In Spalte (E) von Tabelle 9.5 finden wir signifikante negative Differenzen. Dies ist Evidenz, das die Kriminalität in besonders gut bewachten Blocks (Spalte B in Tabelle 9.4) in den Folgeperioden des Anschlags geringer war als in Blocks die, mehr als zwei Blocks von einer bewachteten Einrichtung entfernt sind (Spalte A in Tabelle 9.4). Mit Ausnahme einer Signifikanten Differenz im August 1994 finden wir keine Hinweise auf derartige Unterschiede zwischen Blocks in den Kontrollgruppen (Spalten F und G).\n\n\n9.5.2 Two-Way-Fixed-Effects-Schätzungen\nDi Tella und Schargrodsky (2004) betrachten (Sub-Modelle) der folgenden Regressionsspezifikation für die Schätzung des Effekts von Polizeipräsenz auf die Anzahl der Autodiebstähle.\n\\[\\begin{align}\n  \\begin{split}\n  \\text{totrob}_{i,t} =&\\, \\text{monat}_t + \\text{block}_i \\\\\n  + &\\, \\alpha_0 \\text{same}_{i,t} + \\alpha_1 \\text{oneblock}_{i,t} \\\\\n  + &\\, \\alpha_2 \\text{twoblocks}_{i,t} + \\epsilon_{i,t}\n  \\end{split}\\label{eq:ppbase}\n\\end{align}\\]\nHierbei sind \\(\\text{monat}_t\\) und \\(\\text{block}_i\\) Fixed Effekte für den Monat sowie den Block. Die übrigen Variablen sind für Beobachtungen ab dem Anschlag am 18. Juli 1994 und in Abhäbgigkeit der Distanz zur nächsten jüdischen Einrichtnug definiert:\n\n\\(\\text{same}_{i,t}\\): Dummy-Variable für jüdische Einrichtung im Block und Beobachtung nach dem 17. Juli 1994\n\\(\\text{oneblock}_{i,t}\\): Dummy-Variable für Blocks mit einem Block Entfernung zum nächsten Block mit einer jüdischen Einrichtung und Beobachtung nach dem 17. Juli 1994\n\\(\\text{twoblocks}_{i,t}\\): Dummy-Variable für Blocks mit einer Entfernung von zwei Blocks zum nächsten Block mit einer jüdischen Einrichtung und Beobachtung nach dem 17. Juli 1994\n\nIm nächsten Code-Chunk definieren wir diese Variablen und, gemäß der Vorgehensweise in Di Tella und Schargrodsky (2004), entfernen Beobachtungen für den Zeitraum im Juli nach dem Anschlag (18.07.1994 bis 31.07.1994).\n\n# Variablen definieren und Beobachtungen subsetten\ndat_DID &lt;- polizeipraesenz %&gt;%\n  mutate(\n    same = institut == 1 & monat &gt; \"Juli (1 - 17)\",\n    oneblock = distanz == 1 &  monat &gt; \"Juli (1 - 17)\",\n    twoblocks = distanz == 2 &  monat &gt; \"Juli (1 - 17)\"\n  ) %&gt;% \n  filter(monat != \"Juli (18 - 31)\")\n\nDie Kernergebnisse der Studie werden in Tabelle 3 im Paper präsentiert. Hier werden fünf Regressionen betrachtet:\n\nRegression (A)\n\\[\\begin{align}\n    \\begin{split}\n      \\text{totrob}_{i,t}\n        =&\\, \\text{monat}_t + \\text{block}_i \\\\\n       + &\\, \\alpha_0 \\text{same}_{i,t} \\\\\n       + &\\, \\epsilon_{i,t}\n    \\end{split}\\label{eq:ppbaseA}\n\\end{align}\\]\nModell \\(\\eqref{eq:ppbaseA}\\) betrachtet lediglich die geographisch “engste” Definition des Behandlungseffekts: \\(\\alpha_0\\) ist der ATT für Blocks mit einer jüdischen Einrichtung. Die Kontrollgruppe besteht aus sämtlichen Blocks ohne jüdische Einrichtung.\nRegression (B)\n\\[\\begin{align}\n    \\begin{split}\n      \\text{totrob}_{i,t}\n        =&\\, \\text{monat}_t + \\text{block}_i \\\\\n       + &\\, \\alpha_0 \\text{same}_{i,t} \\\\\n       + &\\, \\alpha_1 \\text{oneblock}_{i,t} \\\\\n       + &\\, \\epsilon_{i,t}\n    \\end{split}\\label{eq:ppbaseB}\n\\end{align}\\]\nModell \\(\\eqref{eq:ppbaseB}\\) erweitert die Behandlungsgruppe um Blocks, die genau einen Block von einem Block mit erhötem Polizeischutz entfernt sind. Die Kontrollgruppe besteht aus Blocks mit einer Entfernung von zwei oder mehr Blocks bis zur nächsten jüdischen Einrichtung.\nRegression (C)\n\\[\\begin{align}\n    \\begin{split}\n      \\text{totrob}_{i,t}\n        =&\\, \\text{monat}_t + \\text{block}_i \\\\\n       + &\\, \\alpha_0 \\text{same}_{i,t} \\\\\n       + &\\, \\alpha_1 \\text{oneblock}_{i,t} \\\\\n       + &\\, \\alpha_1 \\text{twoblocks}_{i,t} \\\\\n       + &\\, \\epsilon_{i,t}\n    \\end{split}\\label{eq:ppbaseC}\n\\end{align}\\]\nModell \\(\\eqref{eq:ppbaseC}\\) betrachtet zusätzlich den Behandlungseffekt in Blocks mit zwei Blocks entfernung zu einem Block mir erhöhter Polizeipräsenz. Die Kontrollgruppe besteht aus Blocks mit einer Entfernung von mehr als zwei Blocks bis zur nächsten jüdischen Einrichtung.\nRegression (D) – Querschnitts-Variation\nDa Di Tella und Schargrodsky (2004) eine große Ähnlichkeit hinsichtlich demografischer Merkmale und Autodiebstahlsraten vor der Intervention in Gebieten mit und ohne jüdische Einrichtungen beobachten, betrachten sie auch einen einfachen Querschnittsschätzer. Regression (D) nutzt die Spezifikation \\(\\eqref{eq:ppbaseC}\\), aber berücksichtigt nur Beobachtungen für den Zeitraum nach dem Anschlag (August bis Dezember) und nutzt lediglich Fixed Effekts für die Monate.\nRegression (E) – Zeitreihen-Variation\nRegression (E) ist eine alternative Spezifikation zu \\(\\eqref{eq:ppbaseC}\\) bei der lediglich die zeitliche Variation in der Behandlungsgruppe (Entfernung zur nächsten Einrichtung \\(\\leq\\) zwei Blocks) genutzt wird. Hierzu werden Fixed Effekts nur für die Blocks, jedoch nicht für die Monate berechnet.\n\nWie implementieren nachfolgend die Regressionen (A) bis (E) mit fixest::feols() unter Verwendung heteroskedastie-robuster Standardfehler (vcov = \"HC1\"). Alle Regressionen nutzen den oben definierten Datensatz dat_DID, wobei wir für die Schätzungen in (D) und (E) mit filter() die entsprechenden Subsets auswählen.\n\n# Regression (A)\n(\n  T3A &lt;- feols(\n    fml = totrob ~ \n      same\n    | observ + monat, \n    data = dat_DID, \n    vcov = \"HC1\"\n  )\n)\n\nOLS estimation, Dep. Var.: totrob\nObservations: 7,884\nFixed-effects: observ: 876,  monat: 9\nStandard-errors: Heteroskedasticity-robust \n         Estimate Std. Error t value   Pr(&gt;|t|)    \nsameTRUE -0.07753    0.02244  -3.456 0.00055241 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.216676     Adj. R2: 0.097072\n                 Within R2: 0.001277\n\n# Regression (B)\n(\n  T3B &lt;- feols(\n    fml = totrob ~ \n      same  \n    + oneblock \n    | observ + monat, \n    data = dat_DID, \n    vcov = \"HC1\"\n  )\n)\n\nOLS estimation, Dep. Var.: totrob\nObservations: 7,884\nFixed-effects: observ: 876,  monat: 9\nStandard-errors: Heteroskedasticity-robust \n             Estimate Std. Error t value   Pr(&gt;|t|)    \nsameTRUE     -0.08007    0.02257 -3.5480 0.00039068 ***\noneblockTRUE -0.01326    0.01386 -0.9564 0.33889333    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.216661     Adj. R2: 0.097067\n                 Within R2: 0.001414\n\n# Regression (C)\n(\n  T3C &lt;- feols(\n    fml = totrob ~ \n      same\n    + oneblock \n    + twoblocks \n    | observ + monat, \n    data = dat_DID, \n    vcov = \"HC1\"\n  )\n)\n\nOLS estimation, Dep. Var.: totrob\nObservations: 7,884\nFixed-effects: observ: 876,  monat: 9\nStandard-errors: Heteroskedasticity-robust \n               Estimate Std. Error t value   Pr(&gt;|t|)    \nsameTRUE      -0.080802    0.02295 -3.5216 0.00043173 ***\noneblockTRUE  -0.013988    0.01447 -0.9669 0.33362749    \ntwoblocksTRUE -0.002185    0.01232 -0.1774 0.85920503    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.21666     Adj. R2: 0.096942\n                Within R2: 0.001419\n\n# Regression (D)\n(\n  T3D &lt;- feols(\n    fml = totrob ~ \n      same\n    + oneblock\n    + twoblocks \n    | monat,\n    data = dat_DID %&gt;% \n      filter(\n        monat &gt;= \"August\"\n      ),\n    vcov = \"HC1\"\n  )\n)\n\nOLS estimation, Dep. Var.: totrob\nObservations: 4,380\nFixed-effects: monat: 5\nStandard-errors: Heteroskedasticity-robust \n               Estimate Std. Error t value   Pr(&gt;|t|)    \nsameTRUE      -0.072719    0.01139 -6.3852 1.8897e-10 ***\noneblockTRUE  -0.011581    0.01090 -1.0623 2.8815e-01    \ntwoblocksTRUE -0.003429    0.00925 -0.3707 7.1086e-01    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.256214     Adj. R2: 0.002028\n                 Within R2: 0.00325 \n\n# Regression (E)\n(\n  T3E &lt;- feols(\n    fml = totrob ~\n      same \n    + oneblock \n    + twoblocks \n    | observ,\n    data = dat_DID %&gt;% \n      filter(\n        distanz &lt;= 2\n      ), \n    vcov = \"HC1\"\n  )\n)\n\nOLS estimation, Dep. Var.: totrob\nObservations: 3,816\nFixed-effects: observ: 424\nStandard-errors: Heteroskedasticity-robust \n              Estimate Std. Error t value Pr(&gt;|t|)    \nsameTRUE      -0.05439    0.02201 -2.4713 0.013510 *  \noneblockTRUE   0.01242    0.01260  0.9861 0.324146    \ntwoblocksTRUE  0.02423    0.01011  2.3972 0.016577 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.216568     Adj. R2: 0.093304\n                 Within R2: 0.003304\n\n\nZur Reproduktion von Tabelle 3 in Di Tella und Schargrodsky (2004) sammeln wir die geschätzten Modelle und erzeugen einen tabelarrische Zusammenfassung mit modelsummary::modelsummary(). Über das Argument gof_omit = \"^(?!(R2|Num.Obs.|FE.*)$).*\" wählen wir unter den Goodness-of-Fit-Statistiken \\(R^2\\), die Anzahl der Beobachtungen, sowie Indikatoren für die verwendeten Fixed Effekts mit einem Regular Expression aus.6\n\n# Tabellarischer Vergleich mit modelsummary()\n# (Tabelle 3 in Ditella und Schargrodsky, 2004)\nmodelsummary(\n  models = list(\n    \"(3A)\" = T3A, \n    \"(3B)\" = T3B, \n    \"(3C)\" = T3C, \n    \"(3D)\" = T3D, \n    \"(3E)\" = T3E\n  ),\n  stars = T,\n  gof_omit = \"^(?!(R2|Num.Obs.|FE.*)$).*\", \n  output = \"gt\"\n)\n\n\n\nTabelle 9.6: Schätzungen des Effekts von Polizeipräsenz auf Autodiebstähle\n\n\n\n\n\n\n\n\n\n\n(3A)\n(3B)\n(3C)\n(3D)\n(3E)\n\n\n\n\nsameTRUE\n-0.078***\n-0.080***\n-0.081***\n-0.073***\n-0.054*\n\n\n\n(0.022)\n(0.023)\n(0.023)\n(0.011)\n(0.022)\n\n\noneblockTRUE\n\n-0.013\n-0.014\n-0.012\n0.012\n\n\n\n\n(0.014)\n(0.014)\n(0.011)\n(0.013)\n\n\ntwoblocksTRUE\n\n\n-0.002\n-0.003\n0.024*\n\n\n\n\n\n(0.012)\n(0.009)\n(0.010)\n\n\nNum.Obs.\n7884\n7884\n7884\n4380\n3816\n\n\nR2\n0.198\n0.198\n0.198\n0.004\n0.195\n\n\nFE: observ\nX\nX\nX\n\nX\n\n\nFE: monat\nX\nX\nX\nX\n\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n\nTabelle 9.6 präsentiert die Ergebnisse. Der Koeffizient von same ist jeweils in den Regressionen (3A), (3B) und (3C) negativ und hoch-signifikant. Die Stärke des geschätzten Effekt (und der Standardfehler) unterscheidet sich kaum zwischen den Modellen. Weiterhin sind die Koeffizienten von oneblock und twoblocks jeweils nicht signifikant von null verschieden. Die Interpretation dieser Ergebnisse ist, dass es einen lokal-beschränkten Effekt der erhöhten Polizeipräsenz auf Autodiebstähle in Blocks mit Polizeischutz gab: Die Polizeipräsenz verringerte die durchschnittliche Anzahl der Diebstähle in diesen Blocks um etwa \\(.08\\) Diebstähle pro Monat.\nDie Ergebnisse für die Modelle (3D) und (3E) zeigen ebenfalls signifikante negative Effekte des Polizeischutz anhand von Querschnitts- und Zeitreihenvariation und untermauern damit die Robustheit des gewählten Forschungsdesigns.\nZur besseren Interpretation des geschätzten Effekt in Modell (C) vergleichen wir mit der durchschnittlichen Anzahl der Diebstähle pro Monat in der Kontrollgruppe (Blocks mit einer Entfernung von mehr als zwei Blocks zum nächsten geschützten Block) für den Zeitraum von August 1994 bis Dezember 1994:7\n\n# Vergl. Effekt mit durchschnittlicher Anz. Diebstähle \n# in der Kontrollgruppe\n( \n  # gesch. Effekt\n  T3C %&gt;% \n    coefficients() %&gt;% \n    .[\"sameTRUE\"] \n) / \n  ( # Durchschnittt\n    polizeipraesenz %&gt;% \n      filter(\n        monat &gt;= \"August\" & monat &lt;= \"Dezember\",\n        distanz &gt; 2\n      ) %&gt;%\n      summarise(\n        m_totrob = mean(totrob)\n      ) %&gt;% \n      pull(m_totrob)\n  ) * 100\n\nsameTRUE \n  -74.92 \n\n\nDie Rechnung zeigt, dass es in dem betrachten Zeitraum durch die Behandlung mit zusätzlicher Polizeipräsenz zu einem Rückgang der Anzahl an Autodiebstählen um durchschnittlich \\(75\\%\\) in Blocks mit jüdischen Einrichtungen kam.\n\n\n9.5.3 Placebo-Tests\nPlacebo-Tests sind nützlich, um zu überprüfen, ob der geschätzte Zusammenhang zwischen der Erhöhung der Polizeipräsenz und der Verringerung der Kriminalität tatsächlich kausal ist oder ob andere Faktoren eine Rolle spielen. Ein möglicher Einfluss könnte beispielsweise durch zufällige temporäre Schwankungen in den Kriminalitätsraten entstehen. Di Tella und Schargrodsky (2004) wiederholen hierzu die Analyse anhand der Spezifikationen (3A), (3B) und (3C) für fiktive Interventionszeitpunkte vor dem Anschlag. Hierbei werden Ende April (4A), Ende Mai (4B) und Ende Juni (4C) als fiktive Zeitpunkte für die Placebo-Behandlung gewählt. Wenn diese Placebo-Tests ähnliche Ergebnisse (signifikante negative Schätzungen) wie die ursprüngliche Untersuchung liefern, könnte dies darauf hindeuten, dass die in Tabelle 9.6 geschätzten Effekte nicht kausal sind.\nWir replizieren diese Ergebnisse, indem wir die Schätzungen von (3A), (3B) und (3C) mit entsprechender Definition des Behandlungsindikators (group) jeweils für modifizierte Datensätze mit sämtlichen \\(3504\\) Beobachtungen vor dem Anschlag (filter(monat &lt;= \"Juli (1 - 17)\")) wiederholen.\n\n# (4A)\n# Placebo-Schätzung für \ndat_T4A &lt;- polizeipraesenz %&gt;%\n  mutate(\n    group = monat &gt;= \"Mai\" & monat &lt;= \"Juli (1 - 17)\",\n    same = (institut == 1) * group,\n    oneblock = (distanz == 1) * group,\n    twoblocks = (distanz == 2) * group\n  ) %&gt;% \n  filter(monat &lt;= \"Juli (1 - 17)\")\n\n(\n  T4A &lt;- feols(\n    fml = totrob ~ \n      same +\n      oneblock +\n      twoblocks \n    | observ + monat, \n    data = dat_T4A, \n    vcov = \"HC1\"\n  )\n)\n\nOLS estimation, Dep. Var.: totrob\nObservations: 3,504\nFixed-effects: observ: 876,  monat: 4\nStandard-errors: Heteroskedasticity-robust \n          Estimate Std. Error t value Pr(&gt;|t|) \nsame      -0.01864    0.05323 -0.3502  0.72622 \noneblock  -0.02554    0.02519 -1.0138  0.31075 \ntwoblocks -0.03263    0.02264 -1.4410  0.14969 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.18282     Adj. R2: 0.092254\n                Within R2: 0.001211\n\n# (4B)\ndat_T4B &lt;- dat_T4A %&gt;%\n  mutate(\n    group = monat &gt;= \"Juni\" & monat &lt;= \"Juli (1 - 17)\",\n    same = (institut == 1) * group,\n    oneblock = (distanz == 1) * group,\n    twoblocks = (distanz == 2) * group\n  ) \n\n(\n  T4B &lt;- feols(\n    fml = totrob ~ \n      same\n    + oneblock\n    + twoblocks \n    | observ + monat, \n    data = dat_T4B, \n    vcov = \"HC1\"\n  )\n)\n\nOLS estimation, Dep. Var.: totrob\nObservations: 3,504\nFixed-effects: observ: 876,  monat: 4\nStandard-errors: Heteroskedasticity-robust \n          Estimate Std. Error t value Pr(&gt;|t|) \nsame       0.01467    0.04011  0.3658  0.71451 \noneblock   0.01402    0.01976  0.7096  0.47799 \ntwoblocks -0.01466    0.01736 -0.8443  0.39856 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.182863     Adj. R2: 0.091835\n                 Within R2: 7.494e-4\n\n# (4C)\ndat_T4C &lt;- dat_T4A %&gt;%\n  mutate(\n    group = monat %in% c(\"Juli (1 - 17)\"),\n    same = (institut == 1) * group,\n    oneblock = (distanz == 1) * group,\n    twoblocks = (distanz == 2) * group\n  ) \n\n(\n  T4C &lt;- feols(\n    fml = totrob ~ \n      same\n    + oneblock\n    + twoblocks\n    | observ + monat, \n    data = dat_T4C, \n    vcov = \"HC1\"\n  )\n)\n\nOLS estimation, Dep. Var.: totrob\nObservations: 3,504\nFixed-effects: observ: 876,  monat: 4\nStandard-errors: Heteroskedasticity-robust \n           Estimate Std. Error t value Pr(&gt;|t|) \nsame      -0.036111    0.03858 -0.9361  0.34933 \noneblock   0.023105    0.02245  1.0294  0.30340 \ntwoblocks -0.009403    0.01693 -0.5554  0.57870 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.182841     Adj. R2: 0.09205 \n                 Within R2: 9.857e-4\n\n\n\n# Tabellarische Zusamenfassung mit modelsummary()\n# (Tabelle 4 in Ditella und Schargrodsky, 2004)\nmodelsummary(\n  models = list(\n    \"(4A)\" = T4A,\n    \"(4B)\" = T4B,\n    \"(4C)\" = T4C\n  ), \n  stars = T,\n  gof_omit = \"^(?!(R2|Num.Obs.|FE.*)$).*\", \n  notes = \"Fiktive Interventionen: (4A) Ende April. (4B): Ende Mai. (4C): Ende Juni.\",\n  output = \"gt\"\n) \n\n\n\nTabelle 9.7: Placebo-Tests für fiktive Anschlagszeitpunkte bis Ende Juni\n\n\n\n\n\n\n\n\n\n\n(4A)\n(4B)\n(4C)\n\n\n\n\nsame\n-0.019\n0.015\n-0.036\n\n\n\n(0.053)\n(0.040)\n(0.039)\n\n\noneblock\n-0.026\n0.014\n0.023\n\n\n\n(0.025)\n(0.020)\n(0.022)\n\n\ntwoblocks\n-0.033\n-0.015\n-0.009\n\n\n\n(0.023)\n(0.017)\n(0.017)\n\n\nNum.Obs.\n3504\n3504\n3504\n\n\nR2\n0.321\n0.320\n0.320\n\n\nFE: observ\nX\nX\nX\n\n\nFE: monat\nX\nX\nX\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\nFiktive Interventionen: (4A) Ende April. (4B): Ende Mai. (4C): Ende Juni.\n\n\n\n\n\n\n\n\n\n\n\nDie Ergebnisse in Tabelle 9.7 stützen die kausale Interpretation der Regressionen in Tabelle 9.6: Für keinen der fiktiven Zeitpunkte einer Intervention vor dem tatsächlichen Anschlag im Juli 1994 finden wir signifikante Unterschiede in der beobachteten Diebstahlrate zwischen Blocks mit einer jüdischen Einrichtung und solchen ohne.\n\n\n9.5.4 Weitere Robustness-Checks\nDi Tella und Schargrodsky (2004) betrachten weitere Robustness-Checks. Die Autoren merken zunächst an, dass (positive) Korrelation innerhalb der Block-spezifischen Fehlerterme über die Zeit (und zwischen den Blocks eines Viertels) zu einer Unterschätzung der Unsicherheit der Treatment-Effekt-Schätzer in den DID-Regressionen mit herkömmlichen Standardfehler-Formeln führen kann. In DID-Designs kann dieses Problem durch die Korrelation der Behandlung über die Zeit noch verstärkt werden. Daher werden alternative Spezifikationen betrachtet, um die Robustheit der Interenzstatistiken in Tabelle 9.6 hinsichtlich Korrelation in den Fehlerterme zu überprüfen. Dies geschieht in den Regressionen (T5A) bis (T5C). Weitere Modelle kontrollieren für Stadtviertel-spezifische Effekte (T5D), verwenden eine um Blocks ohne gemeldete Diebstähle reduzierten Datensatz (T5E) und nutzen eine Poisson-Spezifikation. Wir fassen diese Ansätze kurz zusammen:\n\nRegression (T5A): Entfernen der Zeitvariation von \\(\\textit{totrob}_{i,t}\\) innerhalb der Blocks durch Verwendung von Durchschnittswerten für die Monate vor und nach dem Anschlag. Regression dieser Durchschnittswerte auf die Behandlungsvariablen, wie in \\(\\eqref{eq:ppbaseC}\\).\nRegression (T5B): Schätzung der Spezifikation \\(\\eqref{eq:ppbaseC}\\) und Berechnung von Inferenzstatistiken mit cluster-robusten Standardfehlern (Clustering auf Block-Ebene).\nRegression (T5C): Um in Regression \\(\\eqref{eq:ppbaseC}\\) möglicher Korrelation zwischen den Blocks innerhalb eines Standviertel und Korrelation Stadtviertel-spezifischer Schocks über die Zeit zu begegnen, clustern Di Tella und Schargrodsky (2004) Standardfehler auf Stadtviertel-Monats-Ebene.\nRegression (T5D): Diese Regression ersetzt in \\(\\eqref{eq:ppbaseC}\\) die Fixed Effects für die Monate durch Stadtviertel-spezifische Zeit-Effekte (anhand von Indikatorvariablen zur Berechenung der geclusterten Standardfehler in T5C). Wenn keine Stadtviertel-spezifischen Einflüsse vorliegen, sollten die geschätzten Koeffizienten mit denen für das Modell \\(\\eqref{eq:ppbaseC}\\) vergleichbar sein.\nRegresion (T5E): Regression \\(\\eqref{eq:ppbaseC}\\) ohne Blocks in denen keine Diebstähle im Beobachtungszeitraum erfasst wurden. Auslassen dieser Beobachtungen sollte die Signifikanz des ATT-Schätzer nicht beeinflussen, jedoch zu einem stärkeren (negativen) Effekt führen, da die Kontrollgruppe dann ausschließlich aus Blocks mit gemeldeten Auto-Diebstählen besteht.\nRegresion (T5F): Die Daten erfassen das Aufkommen von Ereignissen (Diebstähle) innerhalb eines bestimmten Raum-Zeitbezugs (pro Block und Monat) beschreiben. Solche Daten können mit Modellen für Zählvariablen beschrieben werden. Di Tella und Schargrodsky (2004) schätzen eine Poisson-Regression. Hierbei wird der (log) Poisson-Parameter \\(\\lambda_{i,t}\\) (die Inzidenzrate) durch die lineare Funktion in \\(\\eqref{eq:ppbaseC}\\) modelliert, d.h.\n\\[\\begin{align}\n  \\begin{split}\n    \\log(\\lambda_{i,t})\n      =&\\, \\text{monat}_t + \\text{block}_i \\\\\n      + &\\, \\alpha_0 \\text{same}_{i,t} \\\\\n      + &\\, \\alpha_1 \\text{oneblock}_{i,t} \\\\\n      + &\\, \\alpha_1 \\text{twoblocks}_{i,t} \\\\\n      + &\\, \\epsilon_{i,t}.\n    \\end{split}\\label{eq:pppois}\n  \\end{align}\\]\nEine Schätzung des Behandlungseffekts anhand von Poisson-Regression sollte zu ähnlichen Schlussfolgerungen führen, wie die lineare Regression \\(\\eqref{eq:ppbaseC}\\).\n\nFür die Reproduktion der Robustness-Checks mit R erweitern wir dat_DID um eine Indikatorvariable für den Zeitraum vor dem Anschlag (pre) und eine kategorische Variable für Stadtviertel-Monat-Effekte mbc.\n\n# Datensatz für weitere Robustness-Checks\ndat_DID_T5 &lt;- dat_DID %&gt;%\n  mutate(\n    # Indikator: vor Anschlag\n    pre = monat &lt; \"Juli (18 - 31)\",\n    # Interaktion: Stadtviertel x Monat\n    mbc = paste0(barrio, \"_\", monat)\n  )\n\nDie Spezifikationen (T5A) bis (T5E) implementieren wir wie zuvor mit fixest::feols() unter Anpassung des Datensatzes, sofern relevant. Für cluster-robuste Standardfehler kann das Argument vcov = ~ cluster gesetzt werden, wobei cluster zu verwendende Ebene ist. Die Poisson-Spezifikation \\(\\eqref{eq:pppois}\\) in (T5F) schätzen wir mit fixest::feglm().8\n\n# (5A)\n(\n  T5A &lt;- feols(\n    fml = totrob ~ \n      same\n    + oneblock\n    + twoblocks\n    | observ + monat,\n    data = dat_DID_T5 %&gt;%\n      group_by(observ, pre) %&gt;%\n      mutate(\n        totrob = mean(totrob)\n      )\n  )\n)\n\nOLS estimation, Dep. Var.: totrob\nObservations: 7,884\nFixed-effects: observ: 876,  monat: 9\nStandard-errors: Clustered (observ) \n               Estimate Std. Error t value   Pr(&gt;|t|)    \nsameTRUE      -0.080802    0.02394 -3.3752 0.00077008 ***\noneblockTRUE  -0.013988    0.01509 -0.9272 0.35406278    \ntwoblocksTRUE -0.002185    0.01239 -0.1763 0.86008157    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.07623     Adj. R2: 0.617109\n                Within R2: 0.011346\n\n# (5B)\n(\n  T5B &lt;- feols(\n    fml = totrob ~ \n      same\n    + oneblock\n    + twoblocks\n    | observ + monat,\n    data = dat_DID_T5, \n    vcov = ~ observ\n  )\n)\n\nOLS estimation, Dep. Var.: totrob\nObservations: 7,884\nFixed-effects: observ: 876,  monat: 9\nStandard-errors: Clustered (observ) \n               Estimate Std. Error t value   Pr(&gt;|t|)    \nsameTRUE      -0.080802    0.02394 -3.3752 0.00077008 ***\noneblockTRUE  -0.013988    0.01509 -0.9272 0.35406278    \ntwoblocksTRUE -0.002185    0.01239 -0.1763 0.86008157    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.21666     Adj. R2: 0.096942\n                Within R2: 0.001419\n\n# (5C)\n(\n  T5C &lt;- feols(\n    fml = totrob ~ \n      same\n    + oneblock\n    + twoblocks\n    | observ + monat,\n    data = dat_DID_T5, \n    vcov = ~ mbc\n  )\n)\n\nOLS estimation, Dep. Var.: totrob\nObservations: 7,884\nFixed-effects: observ: 876,  monat: 9\nStandard-errors: Clustered (mbc) \n               Estimate Std. Error t value  Pr(&gt;|t|)    \nsameTRUE      -0.080802    0.02206 -3.6630 0.0011186 ** \noneblockTRUE  -0.013988    0.01631 -0.8576 0.3989448    \ntwoblocksTRUE -0.002185    0.01702 -0.1284 0.8988318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.21666     Adj. R2: 0.096942\n                Within R2: 0.001419\n\n# (5D)\n(\n  T5D &lt;- feols(\n    fml = totrob ~ \n      same \n    + oneblock \n    + twoblocks \n    | observ + mbc,\n    data = dat_DID_T5,\n    vcov = \"HC1\"\n  )\n)\n\nOLS estimation, Dep. Var.: totrob\nObservations: 7,884\nFixed-effects: observ: 876,  mbc: 27\nStandard-errors: Heteroskedasticity-robust \n               Estimate Std. Error t value  Pr(&gt;|t|)    \nsameTRUE      -0.083449    0.02434  -3.429 0.0006096 ***\noneblockTRUE  -0.016584    0.01571  -1.056 0.2912270    \ntwoblocksTRUE -0.002437    0.01289  -0.189 0.8500732    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.216318     Adj. R2: 0.09747 \n                 Within R2: 0.001412\n\n# (5E)\n(\n  T5E &lt;- feols(\n    fml = totrob ~ \n      same\n    + oneblock\n    + twoblocks\n    | observ + monat,\n    data = dat_DID_T5 %&gt;% \n      group_by(observ) %&gt;% \n      filter(\n        sum(totrob) &gt; 0\n      ),\n    vcov = \"HC1\"\n  )\n)\n\nOLS estimation, Dep. Var.: totrob\nObservations: 5,967\nFixed-effects: observ: 663,  monat: 9\nStandard-errors: Heteroskedasticity-robust \n               Estimate Std. Error t value   Pr(&gt;|t|)    \nsameTRUE      -0.126179    0.03742 -3.3719 0.00075199 ***\noneblockTRUE  -0.017895    0.01942 -0.9213 0.35692825    \ntwoblocksTRUE -0.003944    0.01579 -0.2498 0.80278849    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.248595     Adj. R2: 0.054989\n                 Within R2: 0.002067\n\n# (5F) \n(\n  T5F &lt;- feglm(\n    fml = totrob ~ \n      same\n    + oneblock\n    + twoblocks\n    | observ + monat,\n    data = dat_DID_T5 %&gt;% \n      group_by(observ) %&gt;% \n      filter(\n        sum(totrob) &gt; 0\n      ), \n    family = \"poisson\", \n    vcov = \"HC1\"\n  )\n)\n\nGLM estimation, family = poisson, Dep. Var.: totrob\nObservations: 5,967\nFixed-effects: observ: 663,  monat: 9\nStandard-errors: Heteroskedasticity-robust \n              Estimate Std. Error z value   Pr(&gt;|z|)    \nsameTRUE      -1.21621     0.3525 -3.4502 0.00056013 ***\noneblockTRUE  -0.14272     0.1593 -0.8956 0.37044224    \ntwoblocksTRUE -0.01691     0.1347 -0.1255 0.90009545    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nLog-Likelihood: -1,902.7   Adj. Pseudo R2: -0.193316\n           BIC:  9,665.2     Squared Cor.:  0.172849\n\n\n\n# Tabellarische Zusamenfassung\n# (Tabelle 5 in Di Tella und Schargrodsky, 2004)\nmodelsummary(\n  models = list(\n    \"(T5A)\" = T5A,\n    \"(T5B)\" = T5B,\n    \"(T5C)\" = T5C,\n    \"(T5D)\" = T5D,\n    \"(T5E)\" = T5E,\n    \"(T5F)\" = T5F\n  ), \n  stars = T,\n  gof_omit = \"^(?!(R2|Std.Errors|Num.Obs.|FE.*)$).*\", \n  exponentiate = c(rep(F, 5), T),\n  vcov = list(\"HC1\", ~observ, ~mbc, \"HC1\", \"HC1\", \"HC1\"),  \n  output = \"gt\"\n) \n\n\n\nTabelle 9.8: Weitere Robustness-Checks\n\n\n\n\n\n\n\n\n\n\n(T5A)\n(T5B)\n(T5C)\n(T5D)\n(T5E)\n(T5F)\n\n\n\n\nsameTRUE\n-0.081***\n-0.081***\n-0.081**\n-0.083***\n-0.126***\n0.296***\n\n\n\n(0.009)\n(0.024)\n(0.022)\n(0.024)\n(0.037)\n(0.104)\n\n\noneblockTRUE\n-0.014*\n-0.014\n-0.014\n-0.017\n-0.018\n0.867\n\n\n\n(0.005)\n(0.015)\n(0.016)\n(0.016)\n(0.019)\n(0.138)\n\n\ntwoblocksTRUE\n-0.002\n-0.002\n-0.002\n-0.002\n-0.004\n0.983\n\n\n\n(0.004)\n(0.012)\n(0.017)\n(0.013)\n(0.016)\n(0.132)\n\n\nNum.Obs.\n7884\n7884\n7884\n7884\n5967\n5967\n\n\nR2\n0.660\n0.198\n0.198\n0.201\n0.162\n0.118\n\n\nStd.Errors\nHC1\nby: observ\nby: mbc\nHC1\nHC1\nHC1\n\n\nFE: observ\nX\nX\nX\nX\nX\nX\n\n\nFE: monat\nX\nX\nX\n\nX\nX\n\n\nFE: mbc\n\n\n\nX\n\n\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n\nAnhand von Tabelle 9.8 finden wir weitere Evidenz für die Robustheit der DID-Schätzung (T3C) in Tabelle 9.6:\n\nDie Schlussfolgerungen anhand der Inferenzstatistiken sind nicht sensibel gegenüber den unterschiedlichen Spezifikationen für die Berechnung der Standardfehler in (T5A) bis (T5C).\nDie Alternative Spezifikation von Fixed Effects für Kombination von Stadtviertel und Monat (mbc) in (T5D) beeinflusst den Koeffizientenschätzer von same nur marginal. Auch hier ist der geschätzte ATT signifikant.\nWie erwartet führt die Verkleinerung der Kontrollgruppe auf Blocks mit gemeldeten Diebstählen in (T5E) zu einer größeren Schätzung des Effekts. Der Effekt bleibt signifikant.\nIn der Poisson-Regression in (T5F) finden wir ebenfalls einen signifikanten Effekt von same. Beachte das dieser Koeffizient den multiplikativen Einfluss von Polizeipräsenz auf die Inzidenzrate (durchschnittliche Anzahl an Diebstählen pro Monat pro Block) angibt. Die Interpretation des Schätzwerts von etwa \\(0.3\\) bedeutet also eine Reduktion der Inzidenz um eta \\(70\\%\\) in Blocks mit erhöhter Polizeipräsenz gegenüber der Kontrollgruppe (Blocks mit mehr als zwei Blocks Entfernung zur nächsten jüdischen Einrichtung). Diese Schätzung stimmt also gut überein mit unserer Interpretation der Ergebnisse in Tabelle 9.6.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Difference-in-Differences</span>"
    ]
  },
  {
    "objectID": "DiD.html#zusammenfassung",
    "href": "DiD.html#zusammenfassung",
    "title": "9  Difference-in-Differences",
    "section": "9.6 Zusammenfassung",
    "text": "9.6 Zusammenfassung\nDer DID-Schätzer liefert uns eine Schätzung des ATT, indem er die Veränderung der Ergebnisse in der Behandlungsgruppe vor und nach der Intervention mit der entsprechenden Veränderung in der Kontrollgruppe vergleicht. Die Annahme paralleler Trends ist entscheidend: Nur wenn diese Annahme gilt, können wir sicher sein, dass die Differenz in den Differenzen tatsächlich den kausalen Effekt der Behandlung widerspiegelt und nicht durch andere zeitgleiche Faktoren beeinflusst wird.\nZusammenfassend bietet der DID-Ansatz im Potential Outcomes Framework eine robuste Methode zur Schätzung kausaler Effekte, insbesondere wenn randomisierte Experimente nicht durchführbar sind. Durch den Vergleich von Zeitverläufen in Behandlungs- und Kontrollgruppen unter der Annahme paralleler Trends können wir verlässliche Schätzungen des ATT gewinnen.\n\n\n\n\nAdireksombat, Kampon. 2010. „The Effects of the 1993 Earned Income Tax Credit Expansion on the Labor Supply of Unmarried Women“. Public Finance Review 38 (1): 11–40. https://doi.org/https://doi.org/10.1177/1091142109358626.\n\n\nCallaway, Brantly, und Pedro H. C. Sant’Anna. 2021. „Difference-in-Differences with Multiple Time Periods.“ Journal of Econometrics 225 (2): 200–230. https://doi.org/10.1016/j.jeconom.2020.12.001.\n\n\nDi Tella, Rafael, und Ernesto Schargrodsky. 2004. „Do Police Reduce Crime? Estimates Using the Allocation of Police Forces After a Terrorist Attack“. American Economic Review 94 (1): 115–33. https://doi.org/10.1257/000282804322970733.\n\n\nEissa, N., und J. B. Liebman. 1996. „Labor Supply Response to the Earned Income Tax Credit“. The Quarterly Journal of Economics 111 (2): 605–37. https://doi.org/10.2307/2946689.\n\n\nGoodman-Bacon, Andrew. 2021. „Difference-in-Differences with Variation in Treatment Timing.“ Journal of Econometrics 225 (2): 254–77. https://doi.org/10.1016/j.jeconom.2021.03.014.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Difference-in-Differences</span>"
    ]
  },
  {
    "objectID": "DiD.html#footnotes",
    "href": "DiD.html#footnotes",
    "title": "9  Difference-in-Differences",
    "section": "",
    "text": "Siehe bspw. Goodman-Bacon (2021) für eine detaillierte Diskussion dieser Problematik.↩︎\nDie Methoden von Callaway und Sant’Anna (2021) sind im R-Paket did implementiert.↩︎\nI(Z * B) statt Z * B stellt sicher, dass perferkte Multikollinearität aufgrund der Fixed-Effekts für B und Z vermieden wird.↩︎\nEine weitere Option ist alpaca::feglm().↩︎\n\"%.4f\\n(%.4f)\" gibt das Format des resultierenden character an: Mittelwerte und SDs (in Klammern), gerundet auf vier Nachkommastellen. \\n bewirkt einen Zeilenumbruch.↩︎\nDer Ausdruck ^(?!(R2|Num.Obs.|FE.*)$).* matcht jede Zeichenkette, außer sie ist “R2”, “Num.Obs.” oder beginnt mit “FE”. Andere Statistiken als diese Matches werden also in der Tabelle ausgelassen.↩︎\nWir berechnen also \\(\\widehat{\\alpha}_0 / \\overline{\\text{Diebstahlrate}} \\cdot 100\\).↩︎\nDer R-Befehl hierfür ist ähnlich wie für die Probit-Regressionen in Kapitel 9.4.2.↩︎",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Difference-in-Differences</span>"
    ]
  },
  {
    "objectID": "EventStudies.html",
    "href": "EventStudies.html",
    "title": "10  Event Studies",
    "section": "",
    "text": "10.1 Counterfactuals und Regression\nEvent Studies sind hilfreich, weil sie die Identifizierung kausaler Zusammenhänge in komplexen Situationen mit vielen potentiellen (unbeobachtbaren) Backdoor-Variablen ermöglichen können. Durch die Fokussierung auf einen klar definierten Zeitraum um das Ereignis und die Anwendung zusätzlicher Kontrollmechanismen (Regression) kann der interessierende Effekt oftmals plausibel identifiziert werden.\nFür die Schätzug des Behandlungseffekts ist es nötig, einen plausiblen (kontrafaktischen) Vergleichswert für die nach der Intervention beobachteten Werte der Outcome-Variable zu finden. Hierbei gibt es drei wesentliche Vorgehensweisen:\nIn vielem polit-ökonomischen Anwendungen ist es plausibel, dass eine Intervention einen längerfristigen (konstanten) Effekt hat. In solchen Fällen kann ein Interkationsmodell1 geschätzt werden: \\[\\begin{align}\n  Y_t = \\beta_0 + \\beta_1 t + \\beta_2 \\textup{post}_t + \\beta_3 \\cdot t \\cdot \\textup{post}_t + \\epsilon_t.\\label{eq:eslinint}\n\\end{align}\\] Hier ist \\(t\\) die Zeit-Variable und \\(\\textup{post}_t\\) ein Dummy-Regressor für Perioden nach dem Event. Die Regression \\(\\eqref{eq:eslinint}\\) modelliert also einen linearen Trend in der Outcome-Variable \\(Y\\), der sich vor und nach dem Event unterscheiden kann. Eine Schätzung mit Regressions ist außerdem hilfreich, weil für beobachtbare Determinanten von \\(Y\\), die möglicherweise durch das Event beeinflusst werden, kontrolliert werden kann. Solche “robusten” Spezifikationen erhöhen die plausibilität der Identifikationsstrategie und können eine präzisere Schätzung des Behandlungseffekts gewährleisten.\nModell \\(\\eqref{eq:eslinint}\\) kann leicht auf Panel-Daten erweitert werden, wobei die zusätzliche Information aus der Querschnittsdimension die Schätzung eines zeitlichen Verlaufs des Interventionseffekts ermöglicht. Bei Verfügbarkeit können Beobachtungseinheiten, die nicht von der Intervention betroffen sind als Counterfactuals herangezogen werden. Wir betrachten die Anwendung einer Event-Study-Methodik mit Panel-Daten-Modellen in der Case Study in Kapitel 10.3.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Event Studies</span>"
    ]
  },
  {
    "objectID": "EventStudies.html#counterfactuals-und-regression",
    "href": "EventStudies.html#counterfactuals-und-regression",
    "title": "10  Event Studies",
    "section": "",
    "text": "Durschnittlichen Entwicklung als Counterfactual: Hierbei werden Mittelwerte der Outcome Variable vor und nach der Intervention vergleichen. Diese Methode ignoriert mögliche Zeiteffekte in der Outcome-Variable und sollte nur für kleine Zeiträume vor und nach der Intervention angewendet werden.\nVorhersage mit Vor-Event-Daten: Modelliere die Outcome-Variable basierend auf Daten vor dem Event und erhalte Vorhersagen für Perioden (unmittelbar) nach dem Event.\nVorhersage mit Nach-Event-Daten: Modelliere die Outcome basierend auf Daten vor dem Event unter Berücksichtigung weiterer Regressoren. Erhalte Vorhersagen für Perioden (unmittelbar) nach dem Event unter Einbezug der nach dem Event beobachteten Regressor-Werte.\n\n\n\n\n\n\n\n\n\nKey Facts zu Event Studies\n\n\n\n\nEine Event Study misst Auswirkungen eines Ereignisses oder Interventionen auf eine über mehrere Perioden beobachtete Outcome-Variable.\nZiel ist die Schätzung des kausalen Effekt der Intervention durch die Analyse der beobachteten Variation in der Outcome-Variable über die Zeit, meist für Zeitpunkte nahe des Events.\nAnnahme: Das Event ist exogen. In empirischen Studien werden häufig quasi-experimentelle Forschungsdesigns verwendet (Events sind natürliche Schocks).\nRegressionsmodelle können genutzt werden, um den Effekt der Intervention über die Zeit zu schätzen. Hierbei gewährleistet die Kontrolle für potentielle Confounder die Robustheit und Präzision der Schätzung des interessierenden Effekts.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Event Studies</span>"
    ]
  },
  {
    "objectID": "EventStudies.html#beispiel-strukturbruch-in-zeitreihe",
    "href": "EventStudies.html#beispiel-strukturbruch-in-zeitreihe",
    "title": "10  Event Studies",
    "section": "10.2 Beispiel: Strukturbruch in Zeitreihe",
    "text": "10.2 Beispiel: Strukturbruch in Zeitreihe\nZur Illustration der Methodik simulieren wir Zeitreihendaten mit einem durch ein Ereignis in der Mitte des Beobachtungszeitraums ausgelösten Strukturbruch im Erwartungswert (der kausale Effekt des Events). Wir interessieren uns für den Effekt des Events auf die Variablen \\(X_t\\) und \\(Y_t\\).\nDer hierfür verwendete DGP lautet \\[\\begin{align*}\n  X_t = &\\, \\alpha_1 \\textup{post}_t + \\epsilon_t,\\\\\n  \\\\\n  Y_t = &\\, \\beta_1 X_t + \\beta_2 \\textup{post}_t + \\varepsilon_t,\n\\end{align*}\\] für \\(t=1,\\dots,n\\) mit \\(\\epsilon_t,\\ \\varepsilon_t \\sim\\,u.i.v. N(0,1)\\). Der Dummy-Regressor \\(\\textup{post}_t\\) ist definiert als \\[\\begin{align*}\n  \\textup{post}_t =\n  \\begin{cases}\n     1 \\ \\ \\textup{für}  &t &gt; t_\\textup{Event},\\\\\n     0 \\ \\ &\\textup{sonst}\n  \\end{cases}\n\\end{align*}\\] wobei \\(t_\\textup{Event} = \\lfloor n/2 \\rfloor\\). Für den Effekt des Events auf \\(X_t\\) und \\(Y_t\\) wählen wir \\(\\alpha_1 = 2\\) und \\(\\beta_2 = 2\\). Weiterhin ist \\(\\beta_1 = .75\\). Wir generieren beide Zeitreihen für \\(n=200\\) Perioden.\nBeachte das \\(X_t\\) ein Confounder bei der Ermittlung des Effekts auf \\(Y_t\\) ist: Das Event zum Zeitpunkt \\(t=100\\) hat einen kausalen Effekt von \\(\\alpha_1 = \\beta_2 = 2\\) auf beide Variablen. Da \\(X_t\\) einen Einfluss von \\(\\beta_1\\cdot X_t = .75\\cdot X_t\\) auf \\(Y_t\\) hat, müssen wir für \\(X_t\\) kontrollieren, um die back door durch \\(X_t\\) zu schließen. Für \\(X_t\\) hingegen ist der Event-Regressor \\(\\textup{post}_t\\) exogen.\n\nlibrary(ggplot2)\nlibrary(cowplot)\n# Daten simulieren\nset.seed(123)\n\n# Parameter der Simulation\nn &lt;- 200  # Anzahl der Beobachtungen\nt_event &lt;- floor(n/2)  # Zeitpunkt des Ereignisses\neffect_size &lt;- 2  # Größe des Effekts nach dem Ereignis\n\n# Zeitindex\ntime &lt;- 1:n\n\n# X generieren \nx &lt;- ifelse(\n  test = time &lt;= t_event, \n  yes = rnorm(n, mean = 0), \n  no = rnorm(n, mean = effect_size)\n)\n\n# Y generieren\npre_event_mean &lt;- .75 * x\npost_event_mean &lt;- pre_event_mean + effect_size\n\ny &lt;- ifelse(\n  test = time &lt;= t_event, \n  yes = rnorm(n, mean = pre_event_mean), \n  no = rnorm(n, mean = post_event_mean)\n)\n\n# Zusammenführen der Daten\ndata &lt;- tibble(\n  time = time, \n  x = x,\n  y = y, \n  # Event bei t_event\n  post = ifelse(\n    test = time &gt; t_event, \n    yes = TRUE, \n    no = FALSE\n  )\n)\n\n# Überblick\nhead(data)\n\n# A tibble: 6 × 4\n   time       x       y post \n  &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;lgl&gt;\n1     1 -0.560  -0.494  FALSE\n2     2 -0.230  -1.34   FALSE\n3     3  1.56    0.534  FALSE\n4     4  0.0705  0.0240 FALSE\n5     5  0.129   0.768  FALSE\n6     6  1.72   -0.364  FALSE\n\n\n\n# Plotten der Zielvariable und Regressor\nggplot(data, aes(x = time)) +\n  geom_line(aes(y = y, linetype = \"Outcome-Variable\"), size = 1) +\n  geom_vline(xintercept = t_event, linetype = \"dashed\", color = \"red\") +\n  geom_line(aes(y = x, linetype = \"Regressor\")) +\n  labs(x = \"Zeit\", y = \"Wert\", color = \"Legende\") +\n  scale_linetype_discrete(\"\") +\n  theme_cowplot() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\n10.2.1 Event-Study-Schätzung: Kausaler Effekt für \\(X_t\\)\nWir schätzen zunächst den Effekt des Events auf \\(X_t\\). Die Differenz der Mittelwerte nach und vor des Events ist ein erwartungstreuer und konistenter Schätzer für \\(\\alpha_1\\). Dieser Schätzer ist äquivalent zum KQ-Schätzer von \\(\\alpha_1\\) im Modell \\[\\begin{align}\n  X_t = \\alpha_1 \\textup{post}_t + u.\n\\end{align}\\]\n\n# Effekt-Schätzung für X\n\n# Post-mean vs. Pre-Mean\ndata %&gt;% \n  group_by(post) %&gt;% \n  summarise(x_mean = mean(x)) %&gt;%\n  pull(x_mean) %&gt;%\n  diff()\n\n[1] 1.873371\n\n# ...ist äquivalent zum KQ-Schätzer\nlm(\n  formula = x ~ post,\n  data = data\n) %&gt;%\n  summary()\n\n\nCall:\nlm(formula = x ~ post, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.42968 -0.64741  0.01173  0.69143  2.60768 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.09041    0.09778   0.925    0.356    \npostTRUE     1.87337    0.13829  13.547   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9778 on 198 degrees of freedom\nMultiple R-squared:  0.481, Adjusted R-squared:  0.4784 \nF-statistic: 183.5 on 1 and 198 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n10.2.2 Event-Study-Schätzung: Kausaler Effekt für \\(Y_t\\)\nFür die Schätzung von \\(\\beta_2\\) liefert diese Vorgehensweise einen verzerrten Schätzer des kausalen Effekts des Events auf \\(Y_t\\).\n\n# Verzerrte Effekt-Schätzung für Y\n# Post-mean vs. Pre-Mean\ndata %&gt;% \n  group_by(post) %&gt;% \n  summarise(y_mean = mean(y)) %&gt;%\n  pull(y_mean) %&gt;%\n  diff()\n\n[1] 3.405051\n\n# ...ist äquivalent zum KQ-Schätzer\nlm(\n  formula = y ~ post,\n  data = data\n) %&gt;%\n  summary()\n\n\nCall:\nlm(formula = y ~ post, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.9658 -0.8354  0.0923  0.8565  3.5575 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   0.1737     0.1241    1.40    0.163    \npostTRUE      3.4051     0.1754   19.41   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.241 on 198 degrees of freedom\nMultiple R-squared:  0.6555,    Adjusted R-squared:  0.6537 \nF-statistic: 376.7 on 1 and 198 DF,  p-value: &lt; 2.2e-16\n\n\nEine bessere Alternative ist die Schätzung des Effekts anhand der Vorhersage von \\(Y_t\\) durch \\(X_t\\) für Beobachtungen von \\(X_t\\) nach dem Event. Hierfür schätzen wir das Modell \\[\\begin{align}\n  Y_t = \\beta_0 + \\beta_1 X_t + e_t\\label{eq:xpredy}\n\\end{align}\\] mit Beobachtungen vor dem Event und berechnen vorhergesagte Werte \\(\\widehat{Y}_t\\) mit Beobachtungen \\(X_t\\) nach dem Event.\n\n# Modell zur Vorhersage von Y mit X\nmodel_pre_event &lt;- lm(\n  formula = y ~ x, \n  # Beobachtungen vor dem Ereignis\n  data = data %&gt;% \n    filter(!post)\n)\n\n# Vorhersage von Y mit X\ndata &lt;- data %&gt;%\n  mutate(\n    predicted = predict(\n      object = model_pre_event, \n      newdata = data\n    )\n  )\n\nDie nachfolgende Grafik zeigt die mit \\(X_t\\) vorhergesagte Entwicklung von \\(Y_t\\) nach dem Event.\n\n# Vorhersage von Y und X plotten\nggplot(data, aes(x = time)) +\n  geom_line(aes(y = y, color = \"Outcome Y\"), size = 1) +\n  geom_vline(xintercept = t_event, color = \"red\", linetype = \"dashed\") +\n  geom_line(\n    data = data %&gt;% filter(post), \n    mapping = aes(y = predicted, color = \"Counterfactual Y\"),\n    size = 1\n  ) +\n  labs(x = \"Zeit\", y = \"Zielvariable\") +\n  scale_color_manual(\n    \"\",\n    values = c(\n      \"Outcome Y\" = \"black\", \n      \"Counterfactual Y\" = \"steelblue\"\n    )\n  ) +\n  theme_cowplot() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\nEin Schätzer des Effekts basierend auf dieser Vorhersage ist die Differenz zwischen dem mittleren beobachteten und vorhersagten Werten von \\(Y_t\\) (counterfactual).\n\n# mean(Y) - mean(gesch. counterfactual)\ndata %&gt;% \n  filter(post) %&gt;% \n  summarise(\n    effect = mean(y) - mean(predicted)\n  )\n\n# A tibble: 1 × 1\n  effect\n   &lt;dbl&gt;\n1   2.39\n\n\nUnter der Annahme, dass der kausale Effekt des Events langfristig (für sämtliche Beobachtungen mit \\(t&gt;t_\\textup{Event}\\)) auf \\(Y_t\\) wirkt, können wir \\(\\beta_2\\) effizienter mit einem Interaktionsmodell schätzen. Hierbei vermeiden wir die Unsicherheit in den vorhergesagten Werten \\(\\widehat{Y}_t\\), die aus der Schätzung des Modells \\(\\eqref{eq:xpredy}\\) resultiert.\n\nlm(\n  formula = y ~ x + post,\n  data = data\n) %&gt;%\n  summary()\n\n\nCall:\nlm(formula = y ~ x + post, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.7683 -0.5012  0.1047  0.6146  2.5857 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.10575    0.10044   1.053    0.294    \nx            0.75111    0.07284  10.311   &lt;2e-16 ***\npostTRUE     1.99795    0.19675  10.155   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.002 on 197 degrees of freedom\nMultiple R-squared:  0.7762,    Adjusted R-squared:  0.774 \nF-statistic: 341.7 on 2 and 197 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Event Studies</span>"
    ]
  },
  {
    "objectID": "EventStudies.html#sec-deterrance",
    "href": "EventStudies.html#sec-deterrance",
    "title": "10  Event Studies",
    "section": "10.3 Case Study: Abschreckungseffekte durch Strafgesetzgebung",
    "text": "10.3 Case Study: Abschreckungseffekte durch Strafgesetzgebung\nDavid S. Abrams (2012a) untersucht den Abschreckungseffekt drohender Inhaftierung für Straftaten anhand von Daten zu verschärfter Strafgesetzgebung (“Add-on laws”) in den USA. Solche Gesetze erhöhen in der Regel die Strafen für Delikte, insbesondere wenn nachweißlich Schusswaffen verwendet werden. Die Studie nutzt eine Event-Study-Methodik, um die Auswirkungen dieser Gesetzesänderung auf die Kriminalitätsraten für verschiedene Straftaten zu analysieren. Dabei wird der Zeitpunkt der tatsächlichen Gesetzeseinführung in verschiedenen US-Bundesstaaten herangezogen, um den kausalen Abschreckungseffekt einer drohenden Gefängnisstrafe anhand von Statistiken in den unmittelbaren Folgeperioden zu isolieren.\n\n10.3.1 Identifikationsstrategie\nDer Fokus des Forschungsdesigns liegt auf der Unterscheidung zwischen zwei wesentlichen Wirkungskanälen von verschärften Strafgesetzen auf die Kriminalitätsrate:\n\nAbschreckungseffekt: Die Aussicht auf eine längere Inhaftierung erzielt einen Abschreckungseffekt, der sich ‘positiv’ auf die Kriminalitätsrate auswirkt (im Sinne einer verringerten Kriminalität). Dies ist der vermutete (kausale) Effekt.\nInhaftierungseffekt: Inhaftierte Individuen können keine Straftaten begehen und verringern daher die Kriminalitätsrate. Dieser Effekt ist insbesondere für Straftaten mit großer Rückfälligkeit plausibel (etwa Beschaffungskriminalität). Für längere Haftstrafen erwarten wir daher einen Rückgang dieser Kriminalitätsraten nach der Verschärfung der Gesetze.\n\nDer in 2. beschriebene Effekt der Gesetzesverschärfung kann sich erst nach der im Rahmen der alten Gesetzgebung verhängten durchschnitlichen Mindesthaftstrafe einstellen: Der verringernde Effekt auf die Kriminalitätsrate zeigt sich erst in den Daten, nachdem Straftäter länger als gemäß der alten Gesetzgebung üblich inhaftiert sind. Rückgänge der Kriminalitätrate die in diesem Zeitraum unmittelbar nach der Gesetztesverschärfung gemessen werden, können also auf den Abschreckungseffekt zurückgeführt werden. Anhand von Statistiken zu verhängten Strafen für Überfälle mit Schusswaffen ermittelt David S. Abrams (2012a) ein mittleres Mindest-Strafmaß von drei Jahren.\nDie Exogenität der Verabschiedung von Add-On-Gesetzen wird in David S. Abrams (2012a) wiefolgt begründet: Obwohl die meisten Zusatzgesetze zu Schusswaffen in den 1970er Jahren erlassen wurden und es gemeinsame Trends in den Kriminalitäsraten der Bundesstaaten gibt, sind die genauen Zeitpunkte der Einführung solcher Gesetze aufgrund einer Vielzahl von Eigenheiten des politischen Prozesses in den Bundesstaaten weitgehend zufällig. Die Exogenität ist plausibel, wenn wir (durch Regression) Backdoors aufgrund Bundesstaat-spezifischer (konstanter und zeit-variierender) Faktoren schließen.\n\n\n10.3.2 Replikation mit R\nDer Datensatz Abrams2012.dta ist ein Auszug der Daten aus dem Replikationspaket (David S. Abrams 2012b), welches hier eingesehen werden kann. Die Daten liegen im STATA-Format .dta vor und können mit haven::read_dta() eingelesen werden.\n#| autorun: true\nlibrary(haven)\nlibrary(dplyr)\n\n# Datensatz einlesen\nabrams &lt;- read_dta(file = \"datasets/Abrams2012.dta\")\n\n# Überblick\nglimpse(abrams)\nDie Beobachtungen (Zeilen) in abrams sind Kriminalstatistiken von staatlichen Rechtsberichterstattungsagenturen, die im Rahmen der Uniform Crime Reports des FBI landesweit für den Zeitraum 1965 bis 2002 zusammengetragen wurden. Eine Erläuterung der verfügbaren (ausschließlich numerischen) Variablen erfolgt in Tabelle 10.1.\n\n\n\n\nTabelle 10.1: Abrams2012.dta – Kriminalität in US-Bundesstaaten.\n\n\n\n\n\n\n\n\n\nVariable\nBeschreibung\n\n\n\n\npcralloffense\nPro-Kopf-Kriminalitätsrate\n\n\npcrrobgun\nPro-Kopf-Rate Raubüberfälle mit Schusswaffen\n\n\npcrasltgun\nPro-Kopf-Rate Angriff mit Schusswaffen\n\n\npcrburgtot\nEinbruch\n\n\npcrmurder\nMord\n\n\nlnpcrrobgun\nLog Pro-Kopf-Rate Raubüberfälle mit Schusswaffen\n\n\nFSTATE\nBundesstaat\n\n\nyear\nJahr\n\n\nymm\nGesetzliche Mindeststrafe in Kraft\n\n\nrelyr\nPerioden rel. zur Einführung von Add-On-Law\n\n\neveraddon\nDummy: Jemals Add-on-Law?\n\n\nyaddon\nDummy: 1 Jahr nach Einführung Add-On-Law\n\n\ntwoyears_add\nDummy: 2 Jahre nach Einführung Add-On-Law\n\n\nthreeyears_add\nDummy: 3 Jahre nach Einführung Add-On-Law\n\n\ndcpoverty\nArmutsquote\n\n\ndcunemp\nArbeitlosenquote\n\n\ndcblack_per\nBevölkerungsstruktur\n\n\ndcp15t17\nAnteil 15 bis 17 Jährige\n\n\ndcp18t24\nAnteil 18 bis 24 Jährige\n\n\ndcp25t34\nAnteil 25 bis 34 Jährige\n\n\ndcpolice_per1\nAnteil Polizeikräfte an Bevölkerung\n\n\ndcprison_per1\nAnteil Inhaftierte an der Bevölkerung\n\n\npost74\nDummy: Beobachtung nach 1974\n\n\nstatepop\nBevölkerung\n\n\n\n\n\n\n\n\n\n\nWir replizieren nachfolgend Kernergebnisse aus David S. Abrams (2012a) hinsichtlich des Abschreckungseffekts von drohenden Gefängnisstrafen auf die Begehung von Raubüberfällen mit Schusswaffen.\nFür einen ersten Eindruck der Entwicklung von Kriminalitätsraten in US-Bundesstaaten, die über den Beobachutungszeitraum Add-On-Gesetze erlassen haben, berechnen wir zunächst mit der Population (statepop) gewichtete Mittelwerte vor und nach der Einführung dieser Gesetzte.2 Hierzu verwenden wir eine Teilmenge des Panel-Datensatzes abrams mit Beobachtungen zu 7 Zeitpunkten vor sowie 6 Zeitpunkten nach dem Inkraftreten der Gesetzesverschärfung.\n\n# Datensatz für Vergleich mittlerer Kriminalität vorbereiten\nabrams_t1 &lt;- abrams %&gt;% \n  mutate(\n    before = case_when(\n      relyr &gt; 0 ~ \"Danach\",\n      T ~ \"Bevor\"\n    )\n  ) %&gt;% \n  filter(relyr &gt;= -7 & relyr &lt;= 6) %&gt;%\n  rename(\n    `Angriff mit Schusswaffen` = pcrasltgun,\n    `Einbruch` = pcrburgtot,\n    `Raubüberfall mit Schusswaffe` = pcrrobgun,\n    `Mord` = pcrmurder\n  )\n\nFür die tabellarische Zusammenfassung nutzen wir modelsummary::datasummary(). Über das Argument formula definieren wir die zu berechnenden Statistiken diagis::weighted_mean und diagis::weighted_se für vier Kategorien von Delikten. Der Operator * bewirkt eine gruppierte Berechnung dieser Statistiken (gemäß before).\n\nlibrary(modelsummary)\n\n# Tabellarische Zusammenfassung\ndatasummary(\n  formula =\n    `Angriff mit Schusswaffen`\n  + `Einbruch`\n  + `Mord`\n  + `Raubüberfall mit Schusswaffe`\n  \n  ~ (Factor(before) \n     * (\n        (\n          (mean = diagis::weighted_mean) + (SE = diagis::weighted_se) \n        )\n        * Arguments(na.rm = TRUE, w = statepop)\n       )\n     ), \n  \n  data = abrams_t1\n  )\n\n\n\nTabelle 10.2: Mittlere Kriminalitätsraten je 100k Einwohner vor und nach Einführung strafverschärfender Gesetze\n\n\n\n \n\n  \n    \n    \n    tinytable_mot3g5pvqakw7gtdn62w\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n \nBevor\nDanach\n\n        \n              \n                 \n                mean\n                SE\n                mean\n                SE\n              \n        \n        \n        \n                \n                  Angriff mit Schusswaffen    \n                  108.50 \n                  6.15 \n                  98.13  \n                  5.13 \n                \n                \n                  Einbruch                    \n                  1760.60\n                  44.36\n                  1692.76\n                  96.91\n                \n                \n                  Mord                        \n                  15.77  \n                  0.80 \n                  13.21  \n                  1.12 \n                \n                \n                  Raubüberfall mit Schusswaffe\n                  218.59 \n                  15.91\n                  130.72 \n                  7.93 \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\n\n\nTabelle 10.2 zeigt, dass es in den Zeiträumen nach Gesetzesverschärfungen im Mittel zu einer Verringerung der betrachteten Pro-Kopf-Kriminalitätsraten kommt.3 Da David S. Abrams (2012a) sich auf die Analyse des Effekts auf Delikte unter Gebrauch von Schusswaffen fokussiert, berechnen wir weiterhin Trends in der allgemeinen Pro-Kopf-Kriminalität (pcralloffense) und Raubüberfälle mit Schusswaffen, (pcrrobgun). Wir unterscheiden hierbei zusätzlich zwischen Bundesstaaten, die im Beobachtungszeitraum Add-On-Gesetzte verabschiedet haben (everaddon) und solchen ohne.\n\nlibrary(tidyr)\n\n# Populationsgewichtete Trends berechnen\nplot_dat &lt;- abrams %&gt;% \n  select(\n    year, \n    everaddon, \n    pcralloffense, \n    pcrrobgun, \n    statepop\n  ) %&gt;%\n  mutate(\n    # Skalierung für 2. Y-Achse\n    pcrrobgun = pcrrobgun * 33.3\n  ) %&gt;%\n  rename(\n    Schusswaffen = pcrrobgun, \n    Gesamt = pcralloffense,\n    AddOnGesetze = everaddon\n  ) %&gt;%\n  pivot_longer(\n    cols = Schusswaffen:Gesamt, \n    names_to = \"Verbrechen\", \n    values_to = \"Wert\"\n  ) %&gt;%\n  group_by(year, AddOnGesetze, Verbrechen) %&gt;% \n  mutate(\n    AddOnGesetze = as.factor(AddOnGesetze),\n  ) %&gt;%\n  # Gewichtete Mittelwerte\n  summarise(\n    Wert = weighted.mean(\n      Wert, \n      w = statepop, \n      na.rm = T\n    )\n  ) \n\nWir plotten die berechneten Trends in plot_dat mit entsprechender Farbgebung mit ggplot2(). Das Ergebnis (Abbildung 10.1) ist eine Reproduktion von Abbildung 2 in David S. Abrams (2012a).\n\nlibrary(ggplot2)\nlibrary(cowplot)\n\n# Trendverlauf plotten\nggplot(\n  data = plot_dat,\n  mapping = aes(\n    x = year, \n    y = Wert, \n    color = Verbrechen, \n    lty = AddOnGesetze\n  )\n) +\n  geom_line() +\n  scale_y_continuous(\n    name = \"Gesamte Anzeigen / 100k Einw.\",\n    sec.axis = sec_axis(\n      transform = ~ . / 33.3, \n      name = \"Raubüberfälle Schusswaffen / 100k Einw.\"\n    )\n  ) +\n  theme_cowplot() +\n  theme(\n    legend.position = \"bottom\", \n    axis.title.y.left = element_text(color = \"#F8766D\"),\n    axis.title.y.right = element_text(color = \"#00BFC4\")\n  )\n\n\n\n\n\n\n\nAbbildung 10.1: Populations-gewichtete mittlere Pro-Kopf-Kriminalitätsraten für US-Bundesstaaten (1965–2002)\n\n\n\n\n\nAbbildung 10.1 zeigt einen starken Anstieg der Kriminalität in den 1960er und 1970er Jahren, insbesondere für Rabüberfälle mit Schusswaffen. Weiterhin sind die Trends in Staaten mit und ohne Zusatzstrafen deutlich korreliert. Die Entwicklung der Pro-Kopf-Kriminalität insgesamt schwächt sich anschließend ab und folgt ab den 1990er Jahren einem rückläufigen Trend. Es ist auffällig, dass sowohl die bewaffneten Raubüberfälle als auch die allgemeine Kriminalität zu Beginn des Beobachtungszeitraums für Staaten mit Add-on-Gesetzen höher sind, sich dies aber im letzten Jahrzehnt ebenfalls umkehrt. Wie in David S. Abrams (2012a) erläutert, könnte dies sowohl auf verschäfte Gesetze als auch auf Variation zwischen den Bundesstaaten zurückzuführen sein. Statistische Verfahren zur Schätzung des Effekts also sollten zwischen diesen Möglichkeiten unterscheiden können, bspw. durch die Kontrolle für Fixed Effects und Zeit-Trends.\n\n10.3.2.1 Basis-Spezifikation\nWir folgen David S. Abrams (2012a) und schätzen zunächst eine Basis-Spezifikation für eine balancierte Teilstichprobe aus abrams. Hierbei werden lediglich Bundesstaaten mit Datenpunkten mindestens 7 Jahre vor und maximal 6 Jahre nach der Einfühung eines Add-On-Gesetzes berücksichtigt. Das Regressionsmodell ist \\[\\begin{align}\n  \\log\\textup{Rob}_{at} = \\beta \\textup{AddOn}^i_{st} + \\lambda_s + \\gamma_t + x_{st} + \\epsilon_{at},\\label{eq:abramsbase}\n\\end{align}\\] wobei \\(\\log\\textup{Rob}_{at}\\) die logarithmierte Pro-Kopf-Rate für Überfälle mit Schusswaffe (lnpcrrobgun). \\(\\textup{AddOn}^i_{st}\\) ist eine Dummy-Variable die 1 ist für Beobachtungen des Bundesstaats \\(s\\) in Jahr \\(t\\), wenn die Einführung des Add-On-Gesetzes \\(i\\) Jahre zurückliegt. Wir folgen David S. Abrams (2012a) und betrachten Modelle mit \\(i\\in\\{1,2,3\\}\\), d.h. wir unterscheiden zwischen Effekten bis zu drei Jahren (durchschnittliche Mindeststrafe nach alter Gesetzgebung) nach Einführung eines Add-On-Gesetzes.\n\\(\\lambda_s\\) und \\(\\gamma_t\\) sind Fixed Effects für Bundesstaaten und Perioden. \\(x_{st}\\) repräsentiert alle Kontrollvariablen auf Bundesstaatenebene. Hierbei werden stets sämtliche Variablen mit einer Bezeichnung beginnend mit dc berücksichtigt, vgl. Tabelle 10.1. Weiterhin wird mit ymm für den Effekt eines aktiven Gesetzes für eine Mindeststrafe kontrolliert.\nEine Erweiterung von \\(\\eqref{eq:abramsbase}\\) kontrolliert für Bundesstaat-spezifische Zeit-Trends4 \\(\\omega_s\\cdot t\\), \\[\\begin{align}\n  \\log\\textup{Rob}_{at} = \\beta \\textup{AddOn}^i_{st} + \\lambda_s + \\gamma_t + \\omega_s\\cdot t + x_{st} + \\epsilon_{at}.\\label{eq:abramstrend}\n\\end{align}\\]\nAnhand von \\(\\eqref{eq:abramstrend}\\) kontrollieren wir zusätzlich für über die Zeit variierende Faktoren in \\(\\log\\textup{Rob}_{at}\\) welche die Wahrscheinlichkeit einer Verabschiedung von Add-On in den jeweiligen Bundesstaaten beeinflussen. Diese Spezifikation ist also etwas konservativer als Modell \\(\\eqref{eq:abramsbase}\\), da hier lediglich der Zeitpunkt der Einführung der Gesetze exogen sein muss, siehe die Diskussion in Abschnitt II in David S. Abrams (2012a).\nFür die komfortable Schätzung von Modellen mit Fixed Effects und die Berechnung von cluster-robusten Standardfehlern (Clustering auf Bundesstaaten-Ebene) verwenden wir fixest::feols(), siehe Kapitel 7 für Details zur Schätzung von Panel-Daten-Modellen.\nAufgrund eine Diskontinuität in Daten für die Beobachtungen mehrerer Variablen im Jahr 1974 Schätzen wir \\(\\eqref{eq:abramsbase}\\) und \\(\\eqref{eq:abramstrend}\\) jeweils zusätzlich für Daten nach 1974. Insgesamt schätzen wir also neun Modelle:\n\nSpezifikation \\(\\eqref{eq:abramsbase}\\), jeweils einmal für \\(i\\in\\{1,2,3\\}\\)\nSpezifikation \\(\\eqref{eq:abramstrend}\\), jeweils einmal für \\(i\\in\\{1,2,3\\}\\)\nSpezifikation \\(\\eqref{eq:abramstrend}\\), jeweils einmal für \\(i\\in\\{1,2,3\\}\\) und für Beobachtungen mit \\(t&gt;1974\\).\n\n\nlibrary(fixest)\n\n# Basis-Spezifikation (1): 1 Jahr\nmod_basis_1J &lt;- feols(\n  fml = lnpcrrobgun ~\n   # Effekt 1 Jahr nach Add-on law              \n   yaddon\n   # Ges. Mindeststrafe?\n   + ymm\n   # Kontrollvariablen\n   + dcpoverty\n   + dcunemp\n   + dcblack_per\n   + dcp15t17\n   + dcp18t24 \n   + dcp25t34\n   + dcpolice_per1\n   + dcprison_per1\n   # Fixed Effects\n   | FSTATE + year,\n   data = abrams %&gt;% \n     filter(relyr &gt;= -7 & relyr &lt;= 6), \n   weights = ~ statepop,\n   vcov = ~ FSTATE\n)\n\nsummary(mod_basis_1J)\n\nOLS estimation, Dep. Var.: lnpcrrobgun\nObservations: 2,975\nWeights: statepop\nFixed-effects: FSTATE: 24,  year: 30\nStandard-errors: Clustered (FSTATE) \n               Estimate Std. Error   t value  Pr(&gt;|t|)    \nyaddon        -0.047700   0.030857 -1.545837 0.1357937    \nymm           -0.119297   0.098727 -1.208357 0.2391873    \ndcpoverty     -0.038550   0.032352 -1.191557 0.2455858    \ndcunemp       -0.031828   0.018550 -1.715780 0.0996445 .  \ndcblack_per   -0.286705   0.080383 -3.566730 0.0016382 ** \ndcp15t17       0.117641   0.180309  0.652440 0.5205854    \ndcp18t24      -0.132965   0.088240 -1.506851 0.1454617    \ndcp25t34       0.104971   0.091479  1.147480 0.2629797    \ndcpolice_per1 -0.003242   0.001738 -1.865732 0.0748846 .  \ndcprison_per1 -0.000759   0.001088 -0.697450 0.4925122    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 480.2     Adj. R2: 0.164734\n              Within R2: 0.014269\n\n\n\n# Basis-Spezifikation (1): 2 Jahre\nmod_basis_2J &lt;- feols(\n  fml = lnpcrrobgun ~\n   # Effekt 2 Jahre nach Add-on law              \n   twoyears_add\n   # Ges. Mindeststrafe?\n   + ymm\n   # Kontrollvariablen\n   + dcpoverty\n   + dcunemp\n   + dcblack_per\n   + dcp15t17\n   + dcp18t24 \n   + dcp25t34\n   + dcpolice_per1\n   + dcprison_per1\n   # Fixed Effects\n   | FSTATE + year,\n   data = abrams %&gt;% \n     filter(relyr &gt;= -7 & relyr &lt;= 6), \n   weights = ~ statepop,\n   vcov = ~ FSTATE\n)\n\nsummary(mod_basis_2J)\n\nOLS estimation, Dep. Var.: lnpcrrobgun\nObservations: 2,975\nWeights: statepop\nFixed-effects: FSTATE: 24,  year: 30\nStandard-errors: Clustered (FSTATE) \n               Estimate Std. Error   t value  Pr(&gt;|t|)    \ntwoyears_add  -0.109812   0.033449 -3.282986 0.0032610 ** \nymm           -0.098116   0.095971 -1.022343 0.3172519    \ndcpoverty     -0.039720   0.031852 -1.247004 0.2249458    \ndcunemp       -0.027034   0.018671 -1.447940 0.1611292    \ndcblack_per   -0.287151   0.077470 -3.706630 0.0011622 ** \ndcp15t17       0.104298   0.177361  0.588054 0.5622266    \ndcp18t24      -0.131530   0.085887 -1.531434 0.1393021    \ndcp25t34       0.107675   0.092675  1.161865 0.2572057    \ndcpolice_per1 -0.003150   0.001688 -1.865982 0.0748482 .  \ndcprison_per1 -0.000812   0.001090 -0.745006 0.4638138    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 480.0     Adj. R2: 0.165212\n              Within R2: 0.014833\n\n\n\n# Basis-Spezifikation (1): 3 Jahre\nmod_basis_3J &lt;- feols(\n  fml = lnpcrrobgun ~\n   # Effekt 2 Jahre nach Add-on law              \n   threeyears_add\n   # Ges. Mindeststrafe?\n   + ymm\n   # Kontrollvariablen\n   + dcpoverty\n   + dcunemp\n   + dcblack_per\n   + dcp15t17\n   + dcp18t24 \n   + dcp25t34\n   + dcpolice_per1\n   + dcprison_per1\n   # Fixed Effects\n   | FSTATE + year,\n   data = abrams %&gt;% \n     filter(relyr &gt;= -7 & relyr &lt;= 6), \n   weights = ~ statepop,\n   vcov = ~ FSTATE\n)\n\nsummary(mod_basis_3J)\n\nOLS estimation, Dep. Var.: lnpcrrobgun\nObservations: 2,975\nWeights: statepop\nFixed-effects: FSTATE: 24,  year: 30\nStandard-errors: Clustered (FSTATE) \n                Estimate Std. Error   t value  Pr(&gt;|t|)    \nthreeyears_add -0.127331   0.040448 -3.148030 0.0045036 ** \nymm            -0.095616   0.095467 -1.001551 0.3269818    \ndcpoverty      -0.045294   0.031315 -1.446383 0.1615611    \ndcunemp        -0.016640   0.018875 -0.881588 0.3871200    \ndcblack_per    -0.285791   0.076026 -3.759110 0.0010212 ** \ndcp15t17        0.090905   0.172412  0.527256 0.6030654    \ndcp18t24       -0.125009   0.083438 -1.498217 0.1476771    \ndcp25t34        0.111274   0.094319  1.179770 0.2501510    \ndcpolice_per1  -0.003071   0.001621 -1.894852 0.0707516 .  \ndcprison_per1  -0.000955   0.001085 -0.879803 0.3880665    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 480.0     Adj. R2: 0.165456\n              Within R2: 0.015121\n\n\nVor der Schätzung der Spezifikationen mit Trends transformieren wir FSTATE zu einer Variable des kategorischen Typs factor, damit Bundesstaat-spezifische Trends mit FSTATE:year über das Argument fml in feols() definiert werden können.\n\n# 'FSTATE' zu factor transformieren\nabrams &lt;- abrams %&gt;%\n  mutate(\n    FSTATE = factor(FSTATE)\n  )\n\n# Spezifikation (2): 1 Jahr\nmod_trends_1J &lt;- feols(\n    fml = lnpcrrobgun ~\n        # Effekt 1 Jahr nach Add-on law              \n        yaddon\n        # Ges. Mindeststrafe?\n      + ymm\n        # Kontrollvariablen\n      + dcpoverty\n      + dcunemp\n      + dcblack_per\n      + dcp15t17\n      + dcp18t24 \n      + dcp25t34\n      + dcpolice_per1\n      + dcprison_per1\n      # Trends: Bundesstaat\n      + FSTATE:year\n      # Fixed Effects\n      | FSTATE + year,\n      data = abrams %&gt;% \n        filter(relyr &gt;= -7 & relyr &lt;= 6), \n      weights = ~ statepop,\n      vcov = ~ FSTATE\n)\n\nsummary(mod_trends_1J, n = 10)\n\nOLS estimation, Dep. Var.: lnpcrrobgun\nObservations: 2,975\nWeights: statepop\nFixed-effects: FSTATE: 24,  year: 30\nStandard-errors: Clustered (FSTATE) \n               Estimate Std. Error   t value   Pr(&gt;|t|)    \nyaddon        -0.022295   0.019188 -1.161916 2.5719e-01    \nymm           -0.127650   0.091537 -1.394509 1.7649e-01    \ndcpoverty      0.021620   0.019026  1.136332 2.6752e-01    \ndcunemp       -0.028313   0.012685 -2.232041 3.5641e-02 *  \ndcblack_per   -0.093720   0.109882 -0.852918 4.0250e-01    \ndcp15t17       0.046466   0.112684  0.412356 6.8390e-01    \ndcp18t24      -0.070860   0.075561 -0.937793 3.5810e-01    \ndcp25t34       0.382635   0.080705  4.741160 8.8739e-05 ***\ndcpolice_per1 -0.001901   0.001714 -1.109019 2.7888e-01    \ndcprison_per1 -0.002372   0.001363 -1.740044 9.5217e-02 .  \n... 24 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 477.7     Adj. R2: 0.166344\n              Within R2: 0.024278\n\n\n\n# Spezifikation (2): 2 Jahre\nmod_trends_2J &lt;- feols(\n    fml = lnpcrrobgun ~\n        # Effekt 1 Jahr nach Add-on law              \n        twoyears_add\n        # Ges. Mindeststrafe?\n      + ymm\n        # Kontrollvariablen\n      + dcpoverty\n      + dcunemp\n      + dcblack_per\n      + dcp15t17\n      + dcp18t24 \n      + dcp25t34\n      + dcpolice_per1\n      + dcprison_per1\n      # Trends: Bundesstaat\n      + FSTATE:year\n      # Fixed Effects\n      | FSTATE + year,\n      data = abrams %&gt;% \n        filter(relyr &gt;= -7 & relyr &lt;= 6), \n      weights = ~ statepop,\n      vcov = ~ FSTATE\n)\n\nsummary(mod_trends_2J, n = 10)\n\nOLS estimation, Dep. Var.: lnpcrrobgun\nObservations: 2,975\nWeights: statepop\nFixed-effects: FSTATE: 24,  year: 30\nStandard-errors: Clustered (FSTATE) \n               Estimate Std. Error   t value   Pr(&gt;|t|)    \ntwoyears_add  -0.078236   0.019048 -4.107316 4.3082e-04 ***\nymm           -0.105409   0.090612 -1.163301 2.5663e-01    \ndcpoverty      0.019495   0.018733  1.040651 3.0885e-01    \ndcunemp       -0.025263   0.013386 -1.887274 7.1808e-02 .  \ndcblack_per   -0.110638   0.104057 -1.063240 2.9871e-01    \ndcp15t17       0.053882   0.113732  0.473759 6.4014e-01    \ndcp18t24      -0.064687   0.074996 -0.862542 3.9729e-01    \ndcp25t34       0.388108   0.081850  4.741677 8.8625e-05 ***\ndcpolice_per1 -0.001887   0.001611 -1.171315 2.5346e-01    \ndcprison_per1 -0.002287   0.001365 -1.675131 1.0745e-01    \n... 24 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 477.7     Adj. R2: 0.166579\n              Within R2: 0.024552\n\n\n\n# Spezifikation (2): 3 Jahre\nmod_trends_3J &lt;- feols(\n    fml = lnpcrrobgun ~\n        # Effekt 1 Jahr nach Add-on law              \n        threeyears_add\n        # Ges. Mindeststrafe?\n      + ymm\n        # Kontrollvariablen\n      + dcpoverty\n      + dcunemp\n      + dcblack_per\n      + dcp15t17\n      + dcp18t24 \n      + dcp25t34\n      + dcpolice_per1\n      + dcprison_per1\n      # Trends: Bundesstaat\n      + FSTATE:year\n      # Fixed Effects\n      | FSTATE + year,\n      data = abrams %&gt;% \n        filter(relyr &gt;= -7 & relyr &lt;= 6), \n      weights = ~ statepop,\n      vcov = ~ FSTATE\n)\n\nsummary(mod_trends_3J, n = 10)\n\nOLS estimation, Dep. Var.: lnpcrrobgun\nObservations: 2,975\nWeights: statepop\nFixed-effects: FSTATE: 24,  year: 30\nStandard-errors: Clustered (FSTATE) \n                Estimate Std. Error   t value   Pr(&gt;|t|)    \nthreeyears_add -0.090290   0.024423 -3.696920 1.1903e-03 ** \nymm            -0.102912   0.090398 -1.138435 2.6666e-01    \ndcpoverty       0.009749   0.016776  0.581161 5.6678e-01    \ndcunemp        -0.016103   0.013425 -1.199424 2.4257e-01    \ndcblack_per    -0.125781   0.093385 -1.346908 1.9113e-01    \ndcp15t17        0.058783   0.107066  0.549033 5.8827e-01    \ndcp18t24       -0.057551   0.074109 -0.776579 4.4532e-01    \ndcp25t34        0.395196   0.082790  4.773470 8.1882e-05 ***\ndcpolice_per1  -0.001767   0.001525 -1.158920 2.5838e-01    \ndcprison_per1  -0.002324   0.001380 -1.683925 1.0572e-01    \n... 24 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 477.6     Adj. R2: 0.166659\n              Within R2: 0.024646\n\n\n\n# Spezifikation (2): 1 Jahr\n# Post 1974\nmod_trends_1J_post &lt;- feols(\n  fml = lnpcrrobgun ~\n        # Effekt 1 Jahr nach Add-on law\n        yaddon\n        # Ges. Mindeststrafe?\n      + ymm\n        # Kontrollvariablen\n      + dcpoverty\n      + dcunemp\n      + dcblack_per\n      + dcp15t17\n      + dcp18t24 \n      + dcp25t34\n      + dcpolice_per1\n      + dcprison_per1\n      # Trends: Bundesstaat\n      + FSTATE:year\n      # Fixed Effects\n      | FSTATE + year,\n      data = abrams %&gt;% \n        filter(\n          relyr &gt;= -7 & relyr &lt;= 6, \n          post74 == 1\n        ), \n      weights = ~ statepop, \n      vcov = ~ FSTATE\n)\n\nsummary(mod_trends_1J_post, n = 10)\n\nOLS estimation, Dep. Var.: lnpcrrobgun\nObservations: 2,234\nWeights: statepop\nFixed-effects: FSTATE: 24,  year: 25\nStandard-errors: Clustered (FSTATE) \n               Estimate Std. Error   t value   Pr(&gt;|t|)    \nyaddon        -0.012520   0.021549 -0.581025 5.6687e-01    \nymm           -0.099381   0.102139 -0.972996 3.4068e-01    \ndcpoverty      0.026379   0.018485  1.427072 1.6700e-01    \ndcunemp       -0.023182   0.019778 -1.172133 2.5314e-01    \ndcblack_per    0.009251   0.141698  0.065288 9.4851e-01    \ndcp15t17       0.695952   0.300633  2.314960 2.9889e-02 *  \ndcp18t24      -0.038216   0.114322 -0.334287 7.4119e-01    \ndcp25t34       0.425447   0.081624  5.212300 2.7592e-05 ***\ndcpolice_per1 -0.001801   0.001954 -0.921672 3.6627e-01    \ndcprison_per1 -0.002203   0.001437 -1.532561 1.3903e-01    \n... 24 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 498.0     Adj. R2: 0.1559  \n              Within R2: 0.020362\n\n\n\n# Spezifikation (2): 2 Jahre\n# Post 1974\nmod_trends_2J_post &lt;- feols(\n  fml = lnpcrrobgun ~\n        # Effekt 1 Jahr nach Add-on law\n        twoyears_add\n        # Ges. Mindeststrafe?\n      + ymm\n        # Kontrollvariablen\n      + dcpoverty\n      + dcunemp\n      + dcblack_per\n      + dcp15t17\n      + dcp18t24 \n      + dcp25t34\n      + dcpolice_per1\n      + dcprison_per1\n      # Trends: Bundesstaat\n      + FSTATE:year\n      # Fixed Effects\n      | FSTATE + year,\n      data = abrams %&gt;% \n        filter(\n          relyr &gt;= -7 & relyr &lt;= 6, \n          post74 == 1\n        ), \n      weights = ~ statepop, \n      vcov = ~ FSTATE\n)\n\nsummary(mod_trends_2J_post, n = 10)\n\nOLS estimation, Dep. Var.: lnpcrrobgun\nObservations: 2,234\nWeights: statepop\nFixed-effects: FSTATE: 24,  year: 25\nStandard-errors: Clustered (FSTATE) \n               Estimate Std. Error   t value   Pr(&gt;|t|)    \ntwoyears_add  -0.057761   0.021975 -2.628446 1.5020e-02 *  \nymm           -0.092985   0.103750 -0.896241 3.7941e-01    \ndcpoverty      0.025632   0.018109  1.415400 1.7035e-01    \ndcunemp       -0.022002   0.020771 -1.059252 3.0048e-01    \ndcblack_per   -0.004794   0.137603 -0.034839 9.7251e-01    \ndcp15t17       0.724109   0.299988  2.413794 2.4150e-02 *  \ndcp18t24      -0.007445   0.118881 -0.062626 9.5061e-01    \ndcp25t34       0.436252   0.086625  5.036094 4.2653e-05 ***\ndcpolice_per1 -0.001837   0.001635 -1.123379 2.7287e-01    \ndcprison_per1 -0.002027   0.001460 -1.388716 1.7822e-01    \n... 24 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 498.0     Adj. R2: 0.156042\n              Within R2: 0.020527\n\n\n\n# Spezifikation (2): 3 Jahre\n# Post 1974\nmod_trends_3J_post &lt;- feols(\n  fml = lnpcrrobgun ~\n        # Effekt 1 Jahr nach Add-on law\n        threeyears_add\n        # Ges. Mindeststrafe?\n      + ymm\n        # Kontrollvariablen\n      + dcpoverty\n      + dcunemp\n      + dcblack_per\n      + dcp15t17\n      + dcp18t24 \n      + dcp25t34\n      + dcpolice_per1\n      + dcprison_per1\n      # Trends: Bundesstaat\n      + FSTATE:year\n      # Fixed Effects\n      | FSTATE + year,\n      data = abrams %&gt;% \n        filter(\n          relyr &gt;= -7 & relyr &lt;= 6, \n          post74 == 1\n        ), \n      weights = ~ statepop, \n      vcov = ~ FSTATE\n)\n\nsummary(mod_trends_3J_post, n = 10)\n\nOLS estimation, Dep. Var.: lnpcrrobgun\nObservations: 2,234\nWeights: statepop\nFixed-effects: FSTATE: 24,  year: 25\nStandard-errors: Clustered (FSTATE) \n                Estimate Std. Error   t value   Pr(&gt;|t|)    \nthreeyears_add -0.054133   0.024312 -2.226590 3.6052e-02 *  \nymm            -0.096420   0.104109 -0.926147 3.6399e-01    \ndcpoverty       0.019571   0.016847  1.161689 2.5728e-01    \ndcunemp        -0.014320   0.018187 -0.787381 4.3910e-01    \ndcblack_per    -0.017284   0.132031 -0.130910 8.9699e-01    \ndcp15t17        0.695999   0.288290  2.414235 2.4127e-02 *  \ndcp18t24       -0.003553   0.118611 -0.029952 9.7636e-01    \ndcp25t34        0.445096   0.089471  4.974763 4.9655e-05 ***\ndcpolice_per1  -0.001663   0.001610 -1.033066 3.1231e-01    \ndcprison_per1  -0.002079   0.001462 -1.422004 1.6845e-01    \n... 24 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 498.0     Adj. R2: 0.15601\n              Within R2: 0.02049\n\n\nWir fassen die Ergebnisse mit tabellarisch mit modelsummary::modelsummary() zusammen. Hierzu sammeln wir die Modell-Objekte gemäß der Struktur der zugrundeliegenden Spezifikation in benannten Listen und erzeugen eine nach dem Zeithorizont nach der Einführung eines Add-On-Gesetzes gruppierte Tabelle. Für eine bessere Übersicht berücksichtigen wir hierbei jeweils nur die Koeffizienten für den Zeitpunkt der Gesetzesverschärfung und die Dummyvariable für gesetzliche Mindeststrafen (ymm). Über das Argument coef_map definieren wir entsprechende Labels für diese geschätzten Koeffizienten.\n\nlibrary(modelsummary)\n\n# Modelle in benannten Listen sammeln\npanels &lt;- list(\n  \"1 Jahr nach Add-On\" = list(\n    \"(1) Basis\" = mod_basis_1J,\n    \"(2) Trends\" = mod_trends_1J,\n    \"(2) Nach 74\" = mod_trends_1J_post\n  ),\n  \"2 Jahre nach Add-On\" = list(\n    \"(1) Basis\" = mod_basis_2J,\n    \"(2) Trends\" = mod_trends_2J,\n    \"(2) Nach 74\" = mod_trends_2J_post\n  ),\n  \"3 Jahre nach Add-On\" = list(\n    \"(1) Basis\" = mod_basis_3J,\n    \"(2) Trends\" = mod_trends_3J,\n    \"(2) Nach 74\" = mod_trends_3J_post\n  )\n)\n\n# Tabellarische Zusammenfassung\nmodelsummary(\n  models = panels,\n  shape = \"rbind\",\n  coef_omit = \"^(?!.*(add|ymm)).*$\",\n  stars = T,\n  gof_omit = \"^(?!(R2*)$).*\",\n  coef_map = c(\n    \"yaddon\" = \"Add-On\",\n    \"twoyears_add\" = \"Add-On\",\n    \"threeyears_add\" = \"Add-On\",\n    \"ymm\" = \"Mindeststrafe\"\n    ),\n  notes = c(\n    \"Abh. Var.: Log Kriminalitätsrate: Raubüberfälle mit Schusswaffen\", \n    \"Cluster-robuste Standardfehler: Bundesstaat\",\n    \"Fixed Effects: Bundesstaat + Jahr\"\n  ),\n  output = \"gt\"\n) %&gt;%\n  tabopts()\n\n\n\nTabelle 10.3: abrams – Einfluss von Add-on-Gesetzen auf Kriminalitätsrate: Raubüberfälle mit Waffen (David S. Abrams 2012a)\n\n\n\n\n\n\n\n\n\n\n(1) Basis\n(2) Trends\n(2) Nach 74\n\n\n\n\n1 Jahr nach Add-On\n\n\nAdd-On\n-0.048\n-0.022\n-0.013\n\n\n\n(0.031)\n(0.019)\n(0.022)\n\n\nMindeststrafe\n-0.119\n-0.128\n-0.099\n\n\n\n(0.099)\n(0.092)\n(0.102)\n\n\nR2\n0.182\n0.190\n0.187\n\n\n2 Jahre nach Add-On\n\n\nAdd-On\n-0.110**\n-0.078***\n-0.058*\n\n\n\n(0.033)\n(0.019)\n(0.022)\n\n\nMindeststrafe\n-0.098\n-0.105\n-0.093\n\n\n\n(0.096)\n(0.091)\n(0.104)\n\n\nR2\n0.183\n0.191\n0.187\n\n\n3 Jahre nach Add-On\n\n\nAdd-On\n-0.127**\n-0.090**\n-0.054*\n\n\n\n(0.040)\n(0.024)\n(0.024)\n\n\nMindeststrafe\n-0.096\n-0.103\n-0.096\n\n\n\n(0.095)\n(0.090)\n(0.104)\n\n\nR2\n0.183\n0.191\n0.187\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\nAbh. Var.: Log Kriminalitätsrate: Raubüberfälle mit Schusswaffen\n\n\nCluster-robuste Standardfehler: Bundesstaat\n\n\nFixed Effects: Bundesstaat + Jahr\n\n\n\n\n\n\n\n\n\n\n\nDie in Tabelle 10.3 zusammengefassten Ergebnisse deuten darauf, dass es im ersten Jahr nach der Einführung eines Add-On-Gesetzes keinen Signifikanten Effekt auf die Kriminalitätsrate für Raubüberfälle mit Schusswaffen gibt, wenngleich der geschätzte Koeffizient in sämtlichen Modellen negativ ist und damit konsistent mit dem vermuteten Abschreckungseffekt ist.In den Folgeperioden finden wir signifikante negative Effekte verschärfter Gesetze auf die Kriminalitätsrate von bis zu 12.7% (Effekt in Modell \\(\\eqref{eq:abramsbase}\\) nach drei Jahren). Die konservativste Spezifikation (Modell \\(\\eqref{eq:abramstrend}\\) mit Beobachtungen nach 1974) liefert Evidenz eines Rückgangs der Kriminalität durch Abschreckungseffekte in Höhe von etwa 5% innerhalb der ersten drei Jahre nach der Gesetzesänderung. Weiterhin ist der geschätzte Effekt von gesetzlichen Vorschriften zu Mindeststrafen zwar durchweg negativ, jedoch insignifikant.\n\n\n10.3.2.2 Event-Study-Regression\nFür eine detalliertere Einschätzung des zeitlichen Verlaufs des Effekts verschärfender Gesetze betrachtet David S. Abrams (2012a) eine Spezifikation ähnlich zu Jacobson, LaLonde, und Sullivan (1993), \\[\\begin{align}\n  \\log\\textup{Rob}_{at} = \\sum_{i\\in[-6,6]} \\beta_i\\cdot\\textup{AddOn}^i_{st} + \\lambda_s + \\gamma_t + \\omega_s\\cdot t + x_{st} + \\epsilon_{at},\\label{eq:abramsesreg}\n\\end{align}\\] mit perioden-spezifischen Effekten \\(\\beta_i\\) in einem Zeitfenster von sechs Jahren vor und nach Gesetzesänderungen, wobei die \\(\\textup{AddOn}^i_{st}\\) definiert sind wie in \\(\\eqref{eq:abramsbase}\\) Für die Schätzung von Modell \\(\\eqref{eq:abramsesreg}\\) mit R zeigen wir zunächst, wie diese Dummies anhand der Variable relyr effizient erzeugt werden können.\n\n# Ausprägungen von 'relyr'\nabrams %&gt;% \n  pull(relyr) %&gt;% \n  table()\n\n.\n-31 -30 -29 -28 -27 -26 -25 -24 -23 -22 -21 -20 -19 -18 -17 -16 -15 -14 -13 -12 \n 23  23  36  43  43  43  43  43  43  43  43  46  61  81  81  84  84  87  90 119 \n-11 -10  -9  -8  -7  -6  -5  -4  -3  -2  -1   0   1   2   3   4   5   6   7   8 \n160 215 226 233 236 236 236 236 236 236 236 236 236 236 236 236 236 236 213 213 \n  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28 \n200 193 193 193 193 193 193 193 193 190 175 155 155 152 152 149 146 117  76  21 \n 29  30 \n 10   3 \n\n\nHierfür generieren wir mit tidyr::pivot_wider() eine Variante des Datensatzes, abrams_es, in der Beobachtungen von relyr spaltenweise in binärer Kodierung abgetragen sind. Diese Variablen erhalten das Präfix D. Für leichtere Handhabung der Variablennamen innerhalb von feols() wird das negative Vorzeichen wird druch dplyr::rename_with() in einen Underscore umgewandelt.\n\n# Dummy-Variablen für Event-Study-Regression erzeugen\nabrams_es &lt;- abrams %&gt;%\n    pivot_wider(\n        names_from = relyr, \n        values_from = relyr, \n        names_prefix = \"D\", \n        values_fn = list(relyr = ~ 1), \n        values_fill = 0\n    ) %&gt;%\n    rename_with(\n        .fn = ~ gsub(\"-\", \"_\", .), \n        .cols = starts_with(\"D\")\n    )\n\nWir schätzen nun die Regression \\(\\eqref{eq:abramsesreg}\\), sowohl mit als auch ohne Bundesstaat-spezifische Zeit-Trends und fassen die Ergebnisse anschließend mit modelsummary() zusammen.\n\n# Event-Study-Regression ohne Zeit-Trends\nabrams_mod_es &lt;- feols(\n  fml = lnpcrrobgun ~\n      # Rel. Zeitpunkt-Dummies\n      + D_6\n      + D_5\n      + D_4\n      + D_3\n      + D_2\n      + D_1\n      + D0      \n      + D1\n      + D2\n      + D3\n      + D4\n      + D5\n      + D6\n      # Kontrollvariablen\n      + dcpoverty\n      + dcunemp\n      + dcblack_per\n      + dcp15t17\n      + dcp18t24 \n      + dcp25t34\n      + dcpolice_per1\n      + dcprison_per1\n      # Fixed Effects\n      | FSTATE + year,\n       data = abrams_es,\n      weights = ~ statepop, \n      vcov = ~ FSTATE\n)\n\nsummary(abrams_mod_es, n = 13)\n\nOLS estimation, Dep. Var.: lnpcrrobgun\nObservations: 15,516\nWeights: statepop\nFixed-effects: FSTATE: 50,  year: 30\nStandard-errors: Clustered (FSTATE) \n     Estimate Std. Error   t value  Pr(&gt;|t|)    \nD_6  0.253235   0.080335  3.152231 0.0027641 ** \nD_5  0.179108   0.074765  2.395614 0.0204573 *  \nD_4  0.192102   0.068453  2.806330 0.0071697 ** \nD_3  0.194081   0.065261  2.973925 0.0045520 ** \nD_2  0.215373   0.072131  2.985876 0.0044045 ** \nD_1  0.175359   0.086515  2.026920 0.0481297 *  \nD0   0.092910   0.078156  1.188769 0.2402598    \nD1  -0.019041   0.077510 -0.245663 0.8069694    \nD2  -0.134279   0.081576 -1.646061 0.1061512    \nD3  -0.119129   0.095480 -1.247685 0.2180765    \nD4  -0.014835   0.097611 -0.151980 0.8798269    \nD5   0.026076   0.087216  0.298984 0.7662169    \nD6   0.026764   0.065641  0.407732 0.6852466    \n... 8 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 508.6     Adj. R2: 0.163961\n              Within R2: 0.008215\n\n\n\n# Event-Study-Regression mit Zeit-Trends\nabrams_mod_es_trends &lt;- feols(\n  fml = lnpcrrobgun ~\n      # Rel. Zeitpunkt-Dummies\n      + D_6\n      + D_5\n      + D_4\n      + D_3\n      + D_2\n      + D_1\n      + D0      \n      + D1\n      + D2\n      + D3\n      + D4\n      + D5\n      + D6\n      # Kontrollvariablen\n      + dcpoverty\n      + dcunemp\n      + dcblack_per\n      + dcp15t17\n      + dcp18t24 \n      + dcp25t34\n      + dcpolice_per1\n      + dcprison_per1\n      # Trends: Bundesstaaten\n      + FSTATE:year\n      # Fixed Effects\n      | FSTATE + year,\n       data = abrams_es,\n      weights = ~ statepop, \n      vcov = ~ FSTATE\n)\n\nsummary(abrams_mod_es_trends, n = 13)\n\nOLS estimation, Dep. Var.: lnpcrrobgun\nObservations: 15,516\nWeights: statepop\nFixed-effects: FSTATE: 50,  year: 30\nStandard-errors: Clustered (FSTATE) \n     Estimate Std. Error   t value   Pr(&gt;|t|)    \nD_6  0.178623   0.061206  2.918420 0.00529961 ** \nD_5  0.117266   0.071136  1.648468 0.10565467    \nD_4  0.140018   0.070565  1.984236 0.05284502 .  \nD_3  0.173958   0.080586  2.158664 0.03580156 *  \nD_2  0.194643   0.054801  3.551842 0.00085685 ***\nD_1  0.168404   0.048365  3.481958 0.00105685 ** \nD0   0.088229   0.058647  1.504399 0.13889772    \nD1  -0.019122   0.060257 -0.317339 0.75233449    \nD2  -0.133242   0.062953 -2.116535 0.03940246 *  \nD3  -0.100628   0.074838 -1.344623 0.18493860    \nD4  -0.048074   0.090217 -0.532869 0.59653275    \nD5  -0.018161   0.066668 -0.272405 0.78645555    \nD6   0.030971   0.045143  0.686059 0.49590930    \n... 57 coefficients remaining\n... 1 variable was removed because of collinearity (FSTATE50:year)\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 505.3     Adj. R2: 0.171869\n              Within R2: 0.020719\n\n\n\n# Modelle in benannten Listen sammeln\nmodelle &lt;- list(\n  \"Ohne Trends\" = abrams_mod_es,\n  \"Zeit-Trends\" = abrams_mod_es_trends\n)\n\n# Tabellarische Zusammenfassung\nmodelsummary(\n  models = modelle,\n  coef_omit = \"^(?!.*(D|D\\\\_)).*$\",\n  stars = T,\n  gof_omit = \"^(?!(R2*)$).*\",\n  notes = c(\n    \"Abh. Var.: Log Kriminalitätsrate: Raubüberfälle mit Schusswaffen\", \n    \"Cluster-robuste Standardfehler: Bundesstaat\",\n    \"Fixed Effects: Bundesstaat + Jahr\"\n  ),\n  output = \"gt\"\n) %&gt;%\n  tabopts()\n\n\n\nTabelle 10.4: KQ-Schätzung der Event-Study-Spezifikation: Koeffizienten der Dummies (David S. Abrams 2012a)\n\n\n\n\n\n\n\n\n\n\nOhne Trends\nZeit-Trends\n\n\n\n\nD_6\n0.253**\n0.179**\n\n\n\n(0.080)\n(0.061)\n\n\nD_5\n0.179*\n0.117\n\n\n\n(0.075)\n(0.071)\n\n\nD_4\n0.192**\n0.140+\n\n\n\n(0.068)\n(0.071)\n\n\nD_3\n0.194**\n0.174*\n\n\n\n(0.065)\n(0.081)\n\n\nD_2\n0.215**\n0.195***\n\n\n\n(0.072)\n(0.055)\n\n\nD_1\n0.175*\n0.168**\n\n\n\n(0.087)\n(0.048)\n\n\nD0\n0.093\n0.088\n\n\n\n(0.078)\n(0.059)\n\n\nD1\n-0.019\n-0.019\n\n\n\n(0.078)\n(0.060)\n\n\nD2\n-0.134\n-0.133*\n\n\n\n(0.082)\n(0.063)\n\n\nD3\n-0.119\n-0.101\n\n\n\n(0.095)\n(0.075)\n\n\nD4\n-0.015\n-0.048\n\n\n\n(0.098)\n(0.090)\n\n\nD5\n0.026\n-0.018\n\n\n\n(0.087)\n(0.067)\n\n\nD6\n0.027\n0.031\n\n\n\n(0.066)\n(0.045)\n\n\nR2\n0.169\n0.180\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\nAbh. Var.: Log Kriminalitätsrate: Raubüberfälle mit Schusswaffen\n\n\nCluster-robuste Standardfehler: Bundesstaat\n\n\nFixed Effects: Bundesstaat + Jahr\n\n\n\n\n\n\n\n\n\n\n\nDie statistische Zusammenfassung beider Event-Study-Spezifikationen in Tabelle 10.4 untermauern die Ergebnisse aus Tabelle 10.3:\n\nDie positiven geschätzten Koeffizienten der Dummies für Zeitpunkte vor der Einführung von Add-On-Gesetzen (\\(i=-6,\\dots,-1\\)) sind signifikant und zeigen einen stabilen Verlauf der Kriminalitätsrate an.\nDie negativen, nicht-signifikant von 0 verschiedenen geschätzten Koeffizienten nach der Einführung von Add-On-Gesetzen (\\(i=0,\\dots,6\\)) sind Evidenz für einen Rückgang der Pro-Kopf-Kriminalitätsrate für Raubüberfälle mit Schusswaffen im Folgezeitraum.\n\nFür eine grafische Veranschaulichung der zeitlichen Entwicklung des geschätzten Effekts plotten wir die Schätzungen aus Tabelle 10.4 zusammen mit einem 1-Standardfehler-Intervall.5 Hierzu lesen wir zunächst die geschätzten Koeffizienten und Standardfehler aus dem Objekten abrams_mod_es und abrams_mod_es_trends aus, berechnen die zugehörigen Konfidenzintervalle und sammeln die Ergebnisse unter Verwendung einer Indikatorvariable für das zugrundeliegende Modell in einem tibble-Objekt\n\n# Koeffizienten: Modell mit Trend\ncoefficients_1 &lt;- coef(abrams_mod_es_trends)\nstd_errors_1 &lt;- se(abrams_mod_es_trends)\n\n# Koeffizienten: Modell ohne Trend\ncoefficients_2 &lt;- coef(abrams_mod_es)\nstd_errors_2 &lt;- se(abrams_mod_es)\n\n# Subset von i = -6,...,0,...,6 auslesen\nevents &lt;- -6:6\nevent_names &lt;- names(coefficients_1)[1:13]\n\n# Schätzungen je Modell sammeln\nplot_data_1 &lt;- tibble(\n  Modell = \"Mit Trends\",\n  Event = events,\n  Estimate = coefficients_1[event_names],\n  SE = std_errors_1[event_names]\n)\n\nplot_data_2 &lt;- tibble(\n  Modell = \"Ohne Trends\",\n  Event = events,\n  Estimate = coefficients_2[event_names],\n  SE = std_errors_2[event_names]\n)\n\n# Datenpunkte sammeln\nplot_data &lt;- bind_rows(plot_data_1, plot_data_2) %&gt;%\n  # 1-Standardfehler-Intervall\n  mutate(\n    CI_Lower = Estimate - SE,\n    CI_Upper = Estimate + SE\n  )\n\n\n# Event-Study-Plot\nggplot(\n  data = plot_data, \n  mapping = aes(\n    x = Event, \n    y = Estimate, \n    color = Modell, \n    fill = Modell\n  )\n) +\n  # gesch. Effekte\n  geom_point() +\n  geom_line() +\n  # 1-SE-Intervall\n  geom_ribbon(\n    mapping = aes(\n      ymin = CI_Lower, \n      ymax = CI_Upper\n    ),\n    color =\"white\",\n    alpha = 0.2\n  ) +\n  # Hilfslinien\n  geom_hline(\n    yintercept = c(0), \n    linewidth = .2\n  ) +\n  geom_vline(\n    xintercept = 0, \n    linetype = \"dashed\"\n  ) +\n  # Labels + Legende\n  labs(\n    x = \"Zeitpunkt rel. zur Einf. Add-on-Gesetz\",\n    y = \"Log-Rate: Überfälle mit Schusswaffen\") +\n  scale_y_continuous(limits = c(-.4, .4)) +\n  theme_cowplot() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\nAbbildung 10.2: Event-Study-Regression – Geschätze Rate: Raubüberfälle rel. zur Einführung von Add-On-Gesetzen\n\n\n\n\n\nBeachte, dass lediglich die Änderungen der Koeffizienten in Abbildung 10.2 eine sinnvolle Interpretation haben: Die absoluten Werte auf der Y-Achse sind nicht aussagekräftig, da sie aus Regressionen mit mehreren Regressoren mit von Null verschiedenen Mittelwerten stammen.\nEine Auffälligkeit in Abbildung 10.2 ist, dass die mittlere Kriminalitätsrate bereits eine Periode vor dem Zeitpunkt der Gesetzeseinführung eine Trendumkehr aufzuweisen scheint. David S. Abrams (2012a) weißt darauf hin, dass potenzielle Straftäter durch die laufende öffentliche Debatte und Diskussion über das Gesetz erfahren und ihr Verhaltensweisen in Erwartung der Gesetzesänderung anpassen könnten. Die emprische Studienlage hinsichtlich eines solches Verhalten ist jedoch nicht eindeutig, siehe die Diskussion in David S. Abrams (2012a), Abschnitt IV B.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Event Studies</span>"
    ]
  },
  {
    "objectID": "EventStudies.html#zusammenfassung",
    "href": "EventStudies.html#zusammenfassung",
    "title": "10  Event Studies",
    "section": "10.4 Zusammenfassung",
    "text": "10.4 Zusammenfassung\nMit Event Studies können die Auswirkungen spezifischer Ereignisse oder Interventionen auf eine über die Zeit beobachtete Outcome-Variable untersucht werden. Die zugrunde liegende Annahme für die Identifizierbarkeit des kausalen Effekts ist, dass das untersuchte Event als exogener Schock fungiert, der die Outcome-Variable beeinflusst, jedoch unabhängig von anderen unbeobachtbaren Einflussfaktoren ist, sodass die der Front-Door-Pfad isoliert werden kann.\nDer Effekt wird meist in einem zeitlichen Umfeld nahe des Ereignisses analysiert. Zur Bestimmung eines kontrafaktischen Vergleichswerts für die Outcome-Variable nach dem Event kann die Prognose des Outcomes hilfreich sein. Für die präzise Schätzung des Behandlungseffekts werden häufig Regressionsmodelle herangezogen, die es ermöglichen, zeitliche Veränderungen in der Outcome-Variable zu modellieren und zusätzliche Kontrollvariablen zu berücksichtigen. Dadurch wird die Robustheit und Genauigkeit der Ergebnisse erhöht, was insbesondere bei der Analyse langfristiger Interventionseffekte in komplexen ökonomischen und politischen Kontexten von relevant ist.\n\n\n\n\nAbrams, David S. 2012a. „Estimating the Deterrent Effect of Incarceration Using Sentencing Enhancements“. American Economic Journal: Applied Economics 4 (4): 32–56. https://doi.org/10.1257/app.4.4.32.\n\n\nAbrams, David S. 2012b. „Replication data for: Estimating the Deterrent Effect of Incarceration Using Sentencing Enhancements“. ICPSR - Interuniversity Consortium for Political; Social Research. https://doi.org/10.3886/E113838V1.\n\n\nJacobson, Louis S., Robert J. LaLonde, und Daniel G. Sullivan. 1993. „Earnings Losses of Displaced Workers“. The American Economic Review 83 (4): 685–709. http://www.jstor.org/stable/2117574.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Event Studies</span>"
    ]
  },
  {
    "objectID": "EventStudies.html#footnotes",
    "href": "EventStudies.html#footnotes",
    "title": "10  Event Studies",
    "section": "",
    "text": "Der Ansatz \\(\\eqref{eq:eslinint}\\) wird auch als segmentierte Regression bezeichnet.↩︎\nDie Mittelwerte hier und sämtliche Punktschätzer in den nachfolgenden Regressionen sind bevölkerungsgewichtet, sodass Statistiken von Behörden, die größere Bevölkerungsteile abdecken, einen größeren Einfluss auf die Schätzung haben als Behörden in Regionen mit kleinerer Population.↩︎\nTabelle 10.2 reproduziert Teilergebnisse von Tabelle 1 in David S. Abrams (2012a).↩︎\nFür die Implementierung in R wählen wir \\(\\omega_s = \\beta_s \\cdot D_s\\), wobei \\(\\beta_s\\) der Trend-Koeffizient für Bundesstaat \\(s\\) und \\(D_s\\) ein Indikator für den Staat \\(s\\) ist.↩︎\nVgl. Abbildung 4 in David S. Abrams (2012a).↩︎",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Event Studies</span>"
    ]
  },
  {
    "objectID": "RDD.html",
    "href": "RDD.html",
    "title": "11  Regression Discontiniuty Designs",
    "section": "",
    "text": "11.1 Sharp Regression Discontinuity Design\nModell und funktionale Form\nDie korrekte Spezifikation der funktionalen Form für ein RDD ist wichtig, um eine verzerrte Schätzung des Effekts zu vermeiden. Die einfachste Form eines SRDD kann anhand der linearen Regression \\[\\begin{align}\nY_i = \\beta_0 + \\beta_1 B_i + \\beta_2 X_i + u_i\\label{eq-simpleSRDD}\n\\end{align}\\] geschätzt werden, wobei \\(B_i\\) eine Dummy-Variable für das Überschreiten des Schwellenwertes \\(c\\) ist, d.h. \\[\\begin{align*}\n  B_i=\\begin{cases}\n    0 & X_i &lt; c\\\\\n    1 & X_i \\geq c.\n  \\end{cases}\n\\end{align*}\\] Damit ist \\(B_i\\) eine deterministische Funktion der Laufvariable \\(X_i\\) und zeigt die Zugehörigkeit zur Behandlungs- oder Treatmentgruppe an. Der Koeffizient \\(\\beta_1\\) misst den Behandlungseffekt.\nDas Modell \\(\\eqref{eq-simpleSRDD}\\) unterstellt, dass \\(X\\) links- und rechtsseitig von \\(c\\) denselben Effekt auf \\(Y\\) hat. Diese Annahme ist restriktiv. Eine Alternative ist ein lineares Interaktionsmodell \\[\\begin{align}\nY_i = \\beta_0 + \\beta_1 B_i + \\beta_2 (X_i - c) + \\beta_3(X_i - c)\\times B_i + u_i.\\label{eq:linearSRDD}\n\\end{align}\\] Das Modell \\(\\eqref{eq:linearSRDD}\\) kann unterschiedliche lineare Effekte von \\(X\\) auf \\(Y\\) unterhalb (\\(\\beta_2\\)) und oberhalb (\\(\\beta_2 + \\beta_3\\)) von \\(c\\) abbilden. Beachte, dass \\((X_i - c)\\) die um den Schwellenwert zentrierte Laufvariable ist, sodass \\(\\beta_1\\) wie in \\(\\eqref{eq-simpleSRDD}\\) den Unterschied des Effekts von \\(X\\) auf \\(Y\\) für Beoabachtungen am Schwellenwert erfasst.\nUm unterschiedliche nicht-lineare Zusammenhänge von \\(X\\) und \\(Y\\) unterhalb und oberhalb von \\(c\\) abzubilden, können (interargierte) Polynom-Terme in \\(X\\) verwendet werden. Häufig wird eine quadratische Regressionsfunktion genutzt, \\[\\begin{align}\n  Y_i =&\\, \\beta_0 + \\beta_1 B_i + \\beta_2 (X_i - c) + \\beta_3 (X_i - c)^2\\\\\n       &+\\, \\beta_4(X_i - c)\\times B_i + \\beta_5(X_i - c)\\times B_i + u_i.\\label{eq:quadSRDD}\n\\end{align}\\] Gelman und Imbens (2019) zeigen, dass Polynome höherer Ordnung zu verzerrten Schätzern und hoher Varianz führen können.2 Die Authoren empfehlen stattdessen die Schätzung mit lokaler Regression.\nNicht-parametrische Schätzung und Bandweite\nAktuelle Studien nutzen nicht-parametrische Schätzer, die den Behandlungseffekt als Differenz der geschätzten Regressionsfunktionen am Schwellenwert \\(c\\) berechnen. Um auch nicht-lineare Regressionsfunktionen abzubilden zu können, wird häufig lokale Regression verwendet. Dieses Verfahren liefert eine “lokale” Schätzung der Regressionsfunktionen am Schwellenwert, bei der nur Beobachtungen nahe \\(X = c\\) für die Schätzung berücksichtigt werden. Hinreichende Nähe wird hierbei durch eine sogenannte Bandweite \\(h\\) festgelegt, wobei \\[\\begin{align}\n  \\lvert(X_i-c)\\rvert\\leq h \\label{eq:bwc}\n\\end{align}\\] das Kriterium für eine Berücksichtigung von Beobachtung \\(i\\) bei der Schätzung ist.\nUnter Verwendung einer Bandweite \\(h\\) wird der Regressionsansatz \\(\\eqref{eq:linearSRDD}\\) als lokale lineare Regression mit Uniform-Kernelfunktion bezeichnet. Der Uniform-Kernel gibt allen Beobachtungen, innerhalb der Bandweite \\(h\\) dasselbe Gewicht. Ist \\(h\\) so groß, dass der gesamte Datensatz in die Schätzung einbezogen wird, entspricht der lokale lineare Regressions-Schätzer mit Uniform-Kernel dem (globalen) KQ-Schätzer in einem linearen Interaktionsmodell anhand aller Beobachtungen. Neben dem Uniform-Kernel ist der Triangular-Kernel eine in der Praxis häufig genutzte lineare Kernelfunktion. Der nachstehende Code plottet die Uniform- (grün) sowie die Triangular-Kernelfunktion (blau), siehe Abbildung 11.2.\nCode\nlibrary(ggplot2)\nlibrary(cowplot)\n\n# Kernelfunktionen zeichnen\nggplot() + \n    geom_function(\n      fun = ~ ifelse(\n        test = abs(.) &lt;= 1,\n        yes =  1/2, \n        no = 0\n      ), \n      col = \"green\", \n      n = 1000\n      ) + \n    geom_function(\n      fun = ~ ifelse(\n        test = abs(.) &lt;= 1, \n        yes = 1 - abs(.), \n        no = 0\n      ), \n      col = \"blue\", \n      n = 100\n      ) + \n    scale_x_continuous(\n      name = \"x\", \n      limits = c(-1.5, 1.5), \n      breaks = c(-1, 0, 1)\n    ) +\n    scale_y_continuous(\n      name = \"K(x)\", \n      breaks = c(0, 1), \n      limits = c(0, 1.25)\n    ) +\n    theme_cowplot()\n\n\n\n\n\n\n\n\nAbbildung 11.2: Kernelfunktionen auf [-1, 1]\nIn empirischen Studien wird als Basis-Spezifikation oft eine lokale lineare Regression anhand von \\(\\eqref{eq:linearSRDD}\\) mit einer linearen Kernelfunktionen und geringer bandweite \\(h\\) genutzt. Anschließend wird die Robustheit der Ergebnisse anhand flexiblerer Spezifikationen, die Nicht-Linearitäten in der Regressionsfunktion besser abbilden können, geprüft.\nDie nachstehende Visualisierung zeigt die Schätzung des kausalen Effektes der Behandlung \\(B_i\\) anhand lokaler linearer Regression mit einem Uniform-Kernel für wiefolgt simulierte Daten: \\[\\begin{align*}\n  Y_i =&\\, \\beta_1 X_i + \\beta_2 B + \\beta_3 X_i^2 \\times B_i + u_i,\\\\\n  \\\\\n  u_i \\sim&\\, N(0, 0.5), \\quad X_i \\sim U(0, 10), \\quad B = \\mathbb{I}(X_i \\geq c = 5)\\\\\n  \\beta_1 =&\\, .5, \\quad \\beta_2 = 1.5, \\quad \\beta_3 = -0.15\n\\end{align*}\\]\nDiese Vorschrift ist schnell mit R umgesetzt:\nset.seed(1234)\n# Anz.Beobachtungen\nn &lt;- 750\n\n# Parameter definieren\nc &lt;- 5\nbeta_1 &lt;- .5\nbeta_2 &lt;- 1.5\nbeta_3 &lt;- -.15\n\n# Regressionsfunktion definieren\nf &lt;- function(X) {\n  beta_1 * (X - c) + beta_2 * B + beta_3 * B * (X - c)^2\n}\n\n# Daten erzeugen\nX &lt;- runif(n, 0, 11)\nB &lt;- ifelse(X - c &gt;= 0, 1, 0)\nY &lt;- f(X) + rnorm(n, sd = .5)\n\n# Beoabchtungen sammeln\ndat &lt;- data.frame(\n  Y = Y, X = X - c, B = B\n)\nhtml`\n&lt;style&gt;\n.regression {\n  fill: none;\n  stroke: #000;\n  stroke-width: 1.5px;\n}\n.axis line {\n  stroke: #ddd;\n}\n.axis .baseline line {\n  stroke: #555;\n}\n.axis .domain {\n  display: none;\n} \n&lt;/style&gt;\n&lt;link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css\"&gt;\n`\n\n\n\n\n\n\n\nd3 = require(\"d3-array@3\", \"d3-axis@3\", \"d3-regression@1\", \"d3-scale@4\", \"d3-shape@3\", \"d3-selection@3\", \"d3-format\")\n\nmargin = ({left: 55, right: 8, top: 13, bottom: 24});\nbase = Math.min(width, 500);\ninnerWidth = base - margin.left - margin.right;\ninnerHeight = base-100 - margin.top - margin.bottom;\n\n\nviewof bw_daten_LLRU = Inputs.range([.1, 6], {\n  label: \"Bandweite (h)\",\n  step: .1,\n  value: 1.3\n});\n\nxScaleLLRU = d3.scaleLinear()\n   .domain([-6, 6])\n   .range([0, innerWidth]);\n   \nyScaleLLRU = d3.scaleLinear()\n  .domain([-4, 6])\n  .range([innerHeight, 0]);\n\nlineLLRU = d3.line()\n  .x(d =&gt; xScaleLLRU(d[0]))\n  .y(d =&gt; yScaleLLRU(d[1]));\n  \nxAxisLLRU = d3.axisBottom(xScaleLLRU)\n  .tickSize(innerHeight + 10)\n  .tickValues([-6, -4, -2, 0, 2, 4, 6])\n  .tickFormat(d =&gt; d);\n\nyAxisLLRU = d3.axisLeft(yScaleLLRU)\n  .tickSize(innerWidth + 10)\n  .tickFormat(d =&gt; d);\n\nLLRURegression = d3.regressionLinear()\n  .x(d =&gt; d.X)\n  .y(d =&gt; d.Y);\n{\n  const svg = d3.select(DOM.svg(innerWidth + margin.left + margin.right + 20, innerHeight + margin.top + margin.bottom + 20))\n  \n  const g = svg.append(\"g\")\n      .attr(\"transform\", `translate(${margin.left}, ${margin.top})`);\n\n  g.append(\"g\")\n      .attr(\"class\", \"axis\")\n      .call(xAxisLLRU);\n\n  g.append(\"g\")\n    .attr(\"class\", \"axis\")\n    .attr(\"transform\", `translate(${innerWidth})`)\n    .call(yAxisLLRU);\n\n  // Add X axis label:\n  g.append(\"text\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"font-size\", 13)\n    .attr(\"x\", innerWidth)\n    .attr(\"y\", innerHeight + margin.top + 25)\n    .text(\"X - c\");\n\n  // Y axis label:\n  g.append(\"text\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"transform\", \"rotate(-90)\")\n    .attr(\"font-size\", 13)\n    .attr(\"y\", -margin.left+10)\n    .attr(\"x\", -margin.top+10)\n    .text(\"Y\");\n\n  g.selectAll(\"circle\")\n    .data(transpose(SRDD))\n    .enter().append(\"circle\")\n    .attr(\"r\", 2)\n    .attr(\"cx\", d =&gt; xScaleLLRU(d.X))\n    .attr(\"cy\", d =&gt; yScaleLLRU(d.Y));\n\ng.selectAll(\"circle\")\n .filter( function(d){ return Math.abs(d.X) &lt;= bw_daten_LLRU } )\n .attr(\"fill\", \"orange\")\n .attr(\"stroke\", \"none\");\n \n  &lt;!-- trf --&gt;\nvar  line = d3.line()\n           .x(function(d) { return xScaleLLRU(d.X); }) \n           .y(function(d) { return yScaleLLRU(d.Y_true); }) \n           .curve(d3.curveLinear); \n\n  g.append(\"path\")\n    .datum(transpose(SRDD))\n    .attr(\"d\", line)\n    .attr(\"fill\", \"none\")\n    .attr(\"stroke\", \"red\")\n    .attr(\"stroke-width\", 2);\n\n\nfunction b(d) { return LLRURegression(\n        transpose(SRDD).filter(function(d){ return d.X &lt;= 0 & d.X &gt;= -bw_daten_LLRU })\n    ); }\n\nfunction a(d) { return LLRURegression(\n      transpose(SRDD).filter(function(d){ return d.X &gt; 0 & d.X &lt;= bw_daten_LLRU })\n    ); }\n\n  g.append(\"path\")\n      .attr(\"class\", \"regression\")\n      .datum(b)\n      .attr(\"d\", lineLLRU)\n      .attr(\"stroke-width\", 2)\n      .style(\"stroke\", \"#39FF14\");\n\n  g.append(\"path\")\n      .attr(\"class\", \"regression\")\n      .datum(a)\n      .attr(\"d\", lineLLRU)\n      .attr(\"stroke-width\", 2)\n      .style(\"stroke\", \"#39FF14\");\n  \n  g.append(\"line\")\n  .attr(\"x1\", xScaleLLRU(0))\n  .attr(\"y1\", yScaleLLRU((b().slice(-1))[0][1]))\n  .attr(\"x2\", xScaleLLRU(0))\n  .attr(\"y2\", yScaleLLRU((a().slice(0))[0][1]))\n  .attr(\"stroke\", \"#39FF14\")\n  .attr(\"stroke-width\", 2);\n  \n   g.append(\"text\")\n    .attr(\"x\", d =&gt; xScaleLLRU(-2.75))\n    .attr(\"y\", d =&gt; yScaleLLRU(4.5))\n    .attr(\"dy\", \".35em\")\n    .attr(\"fill\", \"#39FF14\")\n    .text(\n    d3.format(\",.2f\")( (a().slice(0))[0][1] - (b().slice(-1))[0][1] ) \n    );\n  \n  /* dashed line data bw upper */\n  g.append(\"line\")\n  .attr(\"x1\", xScaleLLRU(bw_daten_LLRU))\n  .attr(\"y1\", 0)\n  .attr(\"x2\", xScaleLLRU(bw_daten_LLRU))\n  .attr(\"y2\", innerHeight)\n  .style(\"stroke\", \"blue\")\n  .style(\"stroke-dasharray\", \"4\")\n  .style(\"stroke-width\", \"1\");\n  \n  /* dashed line data bw lower */\n  g.append(\"line\")\n  .attr(\"x1\", xScaleLLRU(-bw_daten_LLRU))\n  .attr(\"y1\", 0)\n  .attr(\"x2\", xScaleLLRU(-bw_daten_LLRU))\n  .attr(\"y2\", innerHeight)\n  .style(\"stroke\", \"blue\")\n  .style(\"stroke-dasharray\", \"4\")\n  .style(\"stroke-width\", \"1\");\n\n  return svg.node();\n}\n\n\n\n\n\n\n\n\nAbbildung 11.3: Nicht-parametrische Regression auf beiden Seiten des Cut-offs\nDer interssierende Effekt am Schwellenwert \\(c=5\\) beträgt \\(\\beta_2 = 1.5\\). Beachte, dass aufgrund des Terms \\(\\beta_3 X_i^2 \\times B_i\\) ein quadratischer Zusammenhang von \\(Y\\) und \\(X\\) oberhalb von \\(X_i = c\\) vorliegt. Es können folgende Eigenschaften der Schätzung in Abhängigkeit von der Bandweite \\(h\\) beobachtet werden:\nDie Wahl der Bandweite ist also eine wichtige Komponenten der RDD-Schätzung: Kleine Bandweiten erlauben eine Schätzung der Regressionsfunktion nahe des Schwellenwertes mit wenig Verzerrung. Allerdings kann diese Schätzung unpräzise sein, wenn nur wenige Beobachtungen \\(\\eqref{eq:bwc}\\) erfüllen. In der Praxis wird \\(h\\) daher mit einem analytischen Schätzer (vgl. G. Imbens und Kalyanaraman 2012) oder anhand von Cross Validation (bspw. G. W. Imbens und Lemieux 2008) bestimmt. Die später in diesem Kapitel betrachteten R-Pakete halten diese Methoden bereit.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Discontiniuty Designs</span>"
    ]
  },
  {
    "objectID": "RDD.html#sharp-regression-discontinuity-design",
    "href": "RDD.html#sharp-regression-discontinuity-design",
    "title": "11  Regression Discontiniuty Designs",
    "section": "",
    "text": "Für die voreingestellte Bandweite \\(h = 1.3\\) liefert die lokale lineare Regression eine gute Approximation des Regressionszusammenhangs auf beiden Seiten des Schwellenwertes und die Schätzung des Behandlungseffekts liegt nahe beim wahren Wert \\(\\beta_2 = 1.5\\).\nFür kleinere Bandweiten verringert sich die Datenbasis der Schätzung. Die Varianz der Schätzung nimmt zu und die Approximation der Regressionsfunktion verschlechtert sich. Wir beobachten eine mit \\(h\\to0\\) zunehmende Verzerrung bei der Schätzung des Behandlungseffekts.\nGrößere Bandweiten \\(h\\) erhöhen die Datenbasis der Schätzung, führen aber zu einer Annäherung der lokalen Schätzung an die globale KQ-Schätzung. Linksseitig des Schwellenwertes erzielen wir damit eine Schätzung mit hoher Güte. Rechsseitig von \\(X_i = c\\) verschlechtert sich die lokale Anpassung am Schwellenwert deutlich, weil die lineare Schätzung den tatsächlichen (nicht-linearen) Zusammenhang nicht adäquat abbilden kann. Die Schätzung des Behandlungseffekts ist hier deutlich verzerrt.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Discontiniuty Designs</span>"
    ]
  },
  {
    "objectID": "RDD.html#manipulation-am-schwellenwert",
    "href": "RDD.html#manipulation-am-schwellenwert",
    "title": "11  Regression Discontiniuty Designs",
    "section": "11.2 Manipulation am Schwellenwert",
    "text": "11.2 Manipulation am Schwellenwert\nEine wichtige Annahmen für die Gültigkeit einer RDD-Schätzung ist, dass keine Manipulation der Gruppenzugehörigkeit am Schwellenwert vorliegt. Wenn sich Subjekte nahe des Schwellenwertes \\(c\\) — d.h. in Abhängigkeit der Laufvariable \\(X\\) — systematisch in den Confoundern \\(Z\\) unterscheiden, können wir den Backdoor-Pfad Oberhalb C → Behandlung B → Y nicht isolieren. Wir erhalten dann eine verzerrte Schätzung des Behandlungseffekts.\nIn empirischen Studien mit Individuen kann Selbstselektion auftreten: Menschen mit \\(X&lt;c\\) aber nahe \\(c\\) (hier Kontrollgruppe) könnten aufgrund unbeobachtbarer Eigenschaften \\(Z\\) die Ausprägung ihrer Laufvariable zu \\(X&gt;c\\) (hier Behandlungsgruppe) manipulieren. Wenn \\(Z\\) die Outcome-Variable beeinflusst, bleibt der Backdoor-Pfad Oberhalb C → Behandlung B → Y so bestehen.\nManipulation resultiert in Häufung von Beobachtungen am Schwellenwert. Dei Verteilung der Laufvariable kann auf diese Unregelmäßigkeit hin untersucht werden. McCrary (2008) schlägt hierfür einen Verfahren vor, das die Kontinuität der Dichtefunktion von \\(X\\) am Schwellenwert testet.\nDer Test von McCrary (2008) ist in rdd::DCdensity() implementiert. Wir zeigen die Anwendung des Tests anhand der oben simulierten Daten. Beachte, dass \\(X_i\\sim U(0, 10)\\), d.h. die Laufvariable ist bei \\(X_i = c\\) kontinuierlich verteilt. Die Nullhypothese (keine Manipulation) gilt für die simulierten Daten\n\n# McCrary-Test durchführen\np_mccrary &lt;- rdd::DCdensity(\n  runvar = X, \n  cutpoint = c, \n  plot = F\n)\n\n# p-Wert\np_mccrary\n\n[1] 0.5013939\n\n\nDer p-Wert 0.5 ist größer als jedes übliche Signifikanzniveau. Damit liegt starke Evidenz für die Nullhypothese (keine Diskontinuität) und gegen Manipulation am Schwellenwert vor.\nCattaneo, Jansson, und Ma (2020) (CMJ) schlagen eine Weiterentwicklung des McCrary-Tests vor, die höhere statistische Macht gegenüber Diskontinuitäten hat am Schwellenwert hat. Der CJM-Test ist im Paket rddensity implementiert.\n\nlibrary(rddensity)\n\n# CJM Schätzer berechnen\nCJM &lt;- rddensity(X, c = 5)\n\nMit der Funktion rddensity::rdplotdensity() erzeugen wir Abbildung 11.4.\n\n# Plot für Dichtefunktion erstellen\nplot &lt;- rdplotdensity(\n  rdd = CJM, \n  X = X, \n  # für Punkte- und Linienplots:\n  type = \"both\" \n)\n\n\n\n\n\n\n\nAbbildung 11.4: CJM-Test – geschätzte Dichtefunktionen der Laufvariable auf beiden Seiten des Schwellenwerts c = 5\n\n\n\n\n\nAbbildung 11.4 zeigt die geschätzten Dichtefunktionen. Erwartungsgemäß finden wir eine große Überlappung der zugehörigen Konfidenzbänder (schattierte Flächen) am Schwellenwert \\(c=5\\).\nMit summary() erhalten wir eine detaillierte Zusammenfassung des Tests.\n\n# Statistische Zusammenfassung des CJM-Tests\nsummary(CJM)\n\n\nManipulation testing using local polynomial density estimation.\n\nNumber of obs =       750\nModel =               unrestricted\nKernel =              triangular\nBW method =           estimated\nVCE method =          jackknife\n\nc = 5                 Left of c           Right of c          \nNumber of obs         329                 421                 \nEff. Number of obs    133                 154                 \nOrder est. (p)        2                   2                   \nOrder bias (q)        3                   3                   \nBW est. (h)           1.918               2.124               \n\nMethod                T                   P &gt; |T|             \nRobust                -0.3338             0.7385              \n\n\nP-values of binomial tests (H0: p=0.5).\n\nWindow Length              &lt;c     &gt;=c    P&gt;|T|\n0.346     + 0.346          20      21    1.0000\n0.521     + 0.544          34      37    0.8126\n0.696     + 0.742          44      57    0.2323\n0.870     + 0.939          54      64    0.4075\n1.045     + 1.137          62      77    0.2349\n1.220     + 1.334          73      98    0.0661\n1.394     + 1.532          86     106    0.1701\n1.569     + 1.729          96     124    0.0685\n1.743     + 1.927         119     140    0.2139\n1.918     + 2.124         133     154    0.2377\n\n\nGemäß des p-Werts (P &gt; |T|) von 0.74 spricht der CJM-Test noch deutlicher gegen eine Diskontinuität als der McCrary-Test.\n\n11.2.1 Case Study: Amtsinhaber-Vorteil (Lee 2008)\nLee (2008) untersucht den Einfluss des Amtsinhaber-Vorteils auf die Wahl von Mitgliedern des US-Repräsentantenhaus. In den meisten Wahlkreisen entfallen große Anteile der Stimmen (oder gar ausschließlich) auf demokratische und republikanische Kanditat*innen, sodass sich die Studie auf diese Parteien beschränkt. Entfällt die Mehrheit der Stimmen auf eine*n Kandiat*in, gewinnt diese*r den Sitz für den Wahlkreis. Durch die Analyse der 6558 Wahlen im Zeitraum 1946-1998 mit einem SRDD kommt die Studie zu dem Ergebnis, dass Amtsinhabende im Durchschnitt einen Vorteil von etwa 8% bis 10% bei der Wahl haben. Dieses Ergebnis kann verschiedene Ursachen haben, bspw. dass die amtierende Partei höhere finanzielle Ressourcen besitzt und von einer besseren Organisation und durch Instrumenalisierung staatlicher Strukturen für die eigenen Zwecke profitiert.\nAnhand der Datensätze house und house_binned illustrieren wir nachfolgend die Schätzung von SRDD-Modellen für den Wahlerfolg der demokratischen Partei, wenn diese Amtsinhaber ist. Wir lesen hierfür zunächst die Datensätze house und house_binned ein und verschaffen uns einen Überblick.\n\nlibrary(tidyverse)\nlibrary(modelsummary)\n\n# Daten einlesen\nhouse &lt;- read_csv(\"datasets/house.csv\")\n# Gruppierter Datensatz\nhouse_binned &lt;- read_csv(\"datasets/house_binned.csv\")\n\n# Überblick verschaffen\nglimpse(house)\n\nRows: 6,558\nColumns: 2\n$ StimmenTm1 &lt;dbl&gt; 0.1049, 0.1393, -0.0736, 0.0868, 0.3994, 0.1681, 0.2516, 0.…\n$ StimmenT   &lt;dbl&gt; 0.5810, 0.4611, 0.5434, 0.5846, 0.5803, 0.6244, 0.4873, 0.5…\n\nglimpse(house_binned)\n\nRows: 100\nColumns: 2\n$ StimmenT   &lt;dbl&gt; 0.5995600, 0.5657000, 0.4272554, 0.5637456, 0.6868627, 0.60…\n$ StimmenTm1 &lt;dbl&gt; 0.104764444, 0.135005263, -0.075690769, 0.084570886, 0.3951…\n\n\nDer Datensatz house enthält die Stimmenanteile demokratischer Kandidat*innen bei der Wahl zum Zeitpunkt \\(T\\) (\\(StimmenT\\)) sowie die Differenz zwischen demokratischen und republikanischen Stimmenanteilen bei der vorherigen Wahl, d.h. zum Zeitpunkt \\(T-1\\) (\\(StimmenTm1\\)). Der Schwellenwert für einen Wahlsieg liegt bei Stimmengleichheit, d.h. \\(StimmenTm1 = 0\\).\nhouse_binned ist eine aggregierte Version von house mit Mittelwerten von jeweils 50 gleichgroßen Intervallen oberhalb und unterhalb der Schwelle von \\(StimmenTm1 = 0\\). Dieser Datensatz eignet sich, um einen ersten Eindruck des funktionalen Zusammenhangs auf beiden Seiten zu erhalten. Wir stellen zunächst diese klassierten Daten mit ggplot2 graphisch dar.\n\n# Klassierte Daten plotten\nhouse_binned %&gt;%\n  ggplot(\n    aes(x = StimmenTm1, y = StimmenT)\n    ) +\n  geom_point() +\n  geom_vline(xintercept = 0, lty = 2)\n\n\n\n\n\n\n\nAbbildung 11.5: Klassierte Daten aus Lee (2008)\n\n\n\n\n\nDie Grafik zeigt eindeutig einen Sprung von \\(StimmenT\\) bei \\(StimmenTm1 = 0\\). Weiterhin erkennen wir, dass der Zusammenhang nahe \\(0\\) vermutlich jeweils gut durch eine lineare Funktion approximiert werden kann. Eine Modell-Spezifikation mit gleicher Steigung auf beiden Seiten des Schwellenwertes scheint hingegen weniger gut geeignet. Wir vergleichen diese Spezifikationen nachfolgend.\nZunächst fügen wir dem Datensatz eine Dummyvariable B hinzu. Diese dient als Indikator für den Wahlgewinn in der letzten Wahl und zeigt die Amtsinhaberschaft (Behandlung) an.\n\n# Behandlungsindikator B hinzufügen\nhouse &lt;- house %&gt;% \n  mutate(B = StimmenTm1 &gt; 0)\n\nglimpse(house)\n\nRows: 6,558\nColumns: 3\n$ StimmenTm1 &lt;dbl&gt; 0.1049, 0.1393, -0.0736, 0.0868, 0.3994, 0.1681, 0.2516, 0.…\n$ StimmenT   &lt;dbl&gt; 0.5810, 0.4611, 0.5434, 0.5846, 0.5803, 0.6244, 0.4873, 0.5…\n$ B          &lt;lgl&gt; TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE…\n\n\nWir überprüfen die Laufvariable mit dem CJM-Test auf Manipulation am Schwellenwert \\(c=0\\).\n\n# CJM-Test durchführen\nCJM_Lee &lt;- rddensity(X = house$StimmenTm1)\n\n# Zusammenfassung anzeigen\nsummary(CJM_Lee)\n\n\nManipulation testing using local polynomial density estimation.\n\nNumber of obs =       6558\nModel =               unrestricted\nKernel =              triangular\nBW method =           estimated\nVCE method =          jackknife\n\nc = 0                 Left of c           Right of c          \nNumber of obs         2740                3818                \nEff. Number of obs    1297                1360                \nOrder est. (p)        2                   2                   \nOrder bias (q)        3                   3                   \nBW est. (h)           0.236               0.243               \n\nMethod                T                   P &gt; |T|             \nRobust                1.4346              0.1514              \n\n\nP-values of binomial tests (H0: p=0.5).\n\nWindow Length / 2          &lt;c     &gt;=c    P&gt;|T|\n0.004                      21      24    0.7660\n0.007                      38      46    0.4452\n0.011                      50      60    0.3909\n0.014                      73      77    0.8066\n0.018                      91     104    0.3902\n0.022                     124     132    0.6618\n0.025                     149     149    1.0000\n0.029                     163     174    0.5860\n0.032                     176     202    0.1984\n0.036                     197     223    0.2225\n\n\n\n# CJM-Plot\nplot &lt;- rdplotdensity(\n  rdd = CJM_Lee,\n  X = house$StimmenTm1, \n  type = \"both\", \n)\n\n\n\n\n\n\n\nAbbildung 11.6: CJM-Test – geschätzte Dichtefunktionen der Laufvariable\n\n\n\n\n\nAbbildung 11.6 und der p-Wert von \\(0.15\\) sind Evidenz gegen eine Manipulation am Schwellenwert.\nUm den Behandlungseffekt anhand eines SRDDs zu ermitteln, schätzen wir das Interaktionsmodell \\[\\begin{align*}\n  \\text{StimmenT}_i =&\\, \\beta_0 + \\beta_1 B_i + \\beta_2 (\\text{StimmenTm1}_i - 50)\\\\\n  +&\\, \\beta_3(\\text{StimmenTm1}_i - 50)\\times B_i + u_i\n\\end{align*}\\] zunächst für eine Bandweite von \\(h = 0.5\\). Aufgrund der Skalierung der Daten (Wahlergebnisse in %) bedeutet dies die Verwendung des gesamten Datensatzes für die Schätzung.\n\n# Interaktionsmodell schätzen\nhouse_llr1 &lt;- lm(\n  formula = StimmenT ~ B * StimmenTm1, \n  data = house\n)\n\n# Zusammenfassung anzeigen  \nmodelsummary(\n  models = house_llr1, \n  vcov = \"HC1\", # robuste Standardfehler\n  stars = T, \n  gof_map = \"nobs\", \n  output = \"gt\"\n) %&gt;% \n  tabopts\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\n(Intercept)\n0.433***\n\n\n\n(0.004)\n\n\nBTRUE\n0.118***\n\n\n\n(0.006)\n\n\nStimmenTm1\n0.297***\n\n\n\n(0.016)\n\n\nBTRUE × StimmenTm1\n0.046*\n\n\n\n(0.018)\n\n\nNum.Obs.\n6558\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\nDer geschätzte Koeffizient von \\(B\\) (BTRUE) beträgt etwa \\(0.12\\) und ist hochsignifikant. Übereinstimmend mit Abbildung 11.5 erhalten wir also eine positive Schätzung des Behandlungseffekts. Die Interpretation ist, dass die amtierenden Demokraten bei der Wahl von einem Amtsinhabervorteil profitieren. Dieser Effekt schlägt sich als Stimmenbonus von geschätzten 12% nieder. Diese Schätzung des Behandlungseffekts könnte jedoch verzerrt sein:\n\nDie (implizite) Wahl von \\(h=0.5\\) in unserer Schätzung macht die Isolation des relevanten Frontdoor-Paths (\\(c=0\\) → Treatment → StimmenT) wenig plausibel. \\(h\\) sollte mit einer datengetriebenen Methode gewählt werden.\nWeiterhin könnte die lineare funktionale Form der Regression inadäquat sein: Die lineare Approximation der wahren Regressionsfunktion nahe des Schwellenwerts \\(0\\) könnte unzureichend sein und in einer verzerrten Schätzung des Effekts resultieren. Zur Überprüfung der Robustheit der Ergebnisse sollte mit Schätzungen anhand nicht-linearer Spezifikationen verglichen werden.\n\nUm diesen Gefahren für die Validität der Studie zu begegnen, schätzen wir nun weitere Spezifikationen. Im Folgenden verwenden wir eine Bandweitenschätzung gemäß G. Imbens und Kalyanaraman (2012).\n\n# Bandweite mit Schätzer von IK (2012) berechnen\n(\nIK_BW &lt;- \n  rdd::IKbandwidth(\n    X = house$StimmenTm1, \n    Y = house$StimmenT\n  )\n)\n\n[1] 0.2685123\n\n\nWir schätzen zunächst erneut das lineare Interaktionsmodell, diesmal jedoch mit der Bandweite IK_BW.\n\n# Lineares Interaktionsmodelle mit IK-Bandweite\nhouse_llin_IK &lt;- lm(\n  formula = StimmenT ~ B * StimmenTm1, \n  data = house %&gt;% \n    filter(\n      abs(StimmenTm1) &lt;= IK_BW\n    )\n)\n\nFür den Vergleich mit einer nicht-linearen Spezifikation schätzen wir auch ein quadratisches Interaktionsmodell.\n\n# Quadratisches Interaktionsmodell mit IK-Bandweite\nhouse_poly_IK &lt;- update(\n  object = house_llin_IK,\n  formula = StimmenT ~ B * poly(StimmenTm1, degree = 2, raw = T)\n)\n\nFür eine Gegenüberstellung der Ergebnisse verwenden wir modelsummary().\n\n# Tabellarischer Modellvergleich\nmodelsummary(\n  models = list(\n    \"Linear int.\" = house_llin_IK, \n    \"Quadratisch int.\" = house_poly_IK\n  ),  \n  vcov = \"HC1\", \n  stars = T,\n  gof_map = \"nobs\", \n  output = \"gt\"\n) %&gt;% \n  tabopts\n\n\n\nTabelle 11.1: Vergleich von SRDD-Interaktionsmodellen für Lee (2008)\n\n\n\n\n\n\n\n\n\n\nLinear int.\nQuadratisch int.\n\n\n\n\n(Intercept)\n0.450***\n0.460***\n\n\n\n(0.005)\n(0.008)\n\n\nBTRUE\n0.085***\n0.068***\n\n\n\n(0.008)\n(0.012)\n\n\nStimmenTm1\n0.360***\n\n\n\n\n(0.036)\n\n\n\nBTRUE × StimmenTm1\n0.055\n\n\n\n\n(0.059)\n\n\n\npoly(StimmenTm1, degree = 2, raw = T)1\n\n0.573***\n\n\n\n\n(0.138)\n\n\npoly(StimmenTm1, degree = 2, raw = T)2\n\n0.798\n\n\n\n\n(0.493)\n\n\nBTRUE × poly(StimmenTm1, degree = 2, raw = T)1\n\n0.036\n\n\n\n\n(0.219)\n\n\nBTRUE × poly(StimmenTm1, degree = 2, raw = T)2\n\n-1.529+\n\n\n\n\n(0.834)\n\n\nNum.Obs.\n2956\n2956\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n\nDie Spalte (1) in Tabelle 11.1 zeigt die lokale Schätzung mit einem linearen Interaktionsmodell. Wir erhalten damit einen Behandlungseffekt von etwa \\(8.5\\%\\). Der Schätzwert fällt also etwas geringer aus als für die globale KQ-Schätzung des linearen Interaktionsmodells. Für das Modell (2) mit quadratischer Spezifikation liegt der Schätzwert mit \\(6.8\\%\\) in der selben Größenordnung. Beide Schätzungen ergeben einen signifikant von \\(0\\) verschieden Effekt. Weiterhin fällt auf, dass in beiden Modellen keine Evidenz für unterschiedliche Formen der Regressionsfunktionen auf beiden Seiten des Schwellenwerts vorliegen: sämtliche Koeffizientenschätzwerte der Interaktionsterme haben hohe Standardfehler und sind nicht signifikant. Im quadratischen Modell hat auch der Term \\(StimmenTm1^2\\) keinen signifikanten Effekt. Diese Ergebnisse deuten darauf hin, dass eine lineare Spezifikation ausreichend ist.\nSRDD-Schätzung mit LOESS\nWir illustrieren nachfolgend die Schätzung des Behandlungseffekts mit einer flexiblen und in der Praxis häufig verwendeten Methode für lokale Regression. Die nachfolgende interaktive Grafik zeigt die klassierten Daten aus Lee (2008) auf dem Intervall \\([-0.5,0.5]\\) gemeinsam mit einer nicht-parametrischen Schätzung des Zusammenhangs von StimmenT und StimmenTm1 mittels LOESS.3 Diese Implementierung von lokaler Regression nutzt einen tricube kernel. Über den Input kann eine Bandweite \\(l\\in(0,1]\\) für den LOESS-Schätzer auf beiden Seiten des Schwellenwerts \\(0\\) gewählt werden. Die Bandweite ist hier der Anteil der Beobachtungen an der gesamten Anzahl an Beobachtungen, die in die Schätzung einbezogen werden sollen.\nFür die Schätzung am Schwellenwert berücksichtigte Daten sind in orange kenntlich gemacht. Die rote linie zeigt die geschätzte Regressionsfunktion über gleichmäßig verteilte Werte von StimmenTm1 auf \\([-0.5,0.5]\\). Die Grafik verdeutlicht, dass die LOESS-Methode flexibel genug ist, um lineare und nicht-lineare Zusammenhänge abbilden zu können. Wie zuvor ist eine adäquate Wahl der Bandweite wichtig:\n\nDer mit LOESS geschätzte Zusammenhang auf beiden Seiten des Schwellenwerts ist etwa linear für den voreingestellten Parameter (\\(l = 0.28\\)).\nFür größere Werte von \\(l\\) nähert sich die Schätzung weiter einem linearen Verlauf an. Die Schätzung des Effekts bleibt vergleichbar mit den Ergebnissen des linearen Interaktionsmodell (s. oben).\nFür kleinere \\(l\\) erhalten wir eine stärkere Anpassung der Schätzung an die Daten. Zu kleine Werte führen zu einer Überanpassung (overfitting). Insbesondere tendiert die geschätzte Funktion zu extremer Steigung nahe des Schwellenwerts → stark verzerrte Schätzung des Effekts!\n\n\nhtml`\n&lt;style&gt;\n.regression {\n  fill: none;\n  stroke: #000;\n  stroke-width: 1.5px;\n}\n.axis line {\n  stroke: #ddd;\n}\n.axis .baseline line {\n  stroke: #555;\n}\n.axis .domain {\n  display: none;\n} \n&lt;/style&gt;\n&lt;link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css\"&gt;\n`\n\n\n\n\n\n\n\nviewof bandwidth = Inputs.range([.01, 1], {\n  label: \"Bandweite LOESS (l)\",\n  step: .01,\n  value: .28\n});\n\nxScaleLoess = d3.scaleLinear()\n   .domain([-.55, .55])\n   .range([0, innerWidth]);\n   \nyScaleLoess = d3.scaleLinear()\n  .domain([.2, .8])\n  .range([innerHeight, 0]);\n\nlineLoess = d3.line()\n  .x(d =&gt; xScaleLoess(d[0]))\n  .y(d =&gt; yScaleLoess(d[1]));\n  \nxAxisLoess = d3.axisBottom(xScaleLoess)\n  .tickSize(innerHeight + 10)\n  .tickValues([-.5, -.25, 0, .25, .5])\n  .tickFormat(d =&gt; d);\n\nyAxisLoess = d3.axisLeft(yScaleLoess)\n  .tickSize(innerWidth + 10)\n  .tickValues([.2, .35, .5, .65, .8])\n  .tickFormat(d =&gt; d);\n\nloessRegression = d3.regressionLoess()\n  .x(d =&gt; d.StimmenTm1)\n  .y(d =&gt; d.StimmenT)\n  .bandwidth(bandwidth);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  const svg = d3.select(DOM.svg(innerWidth + margin.left + margin.right + 20, innerHeight + margin.top + margin.bottom + 20))\n  \n  const g = svg.append(\"g\")\n      .attr(\"transform\", `translate(${margin.left}, ${margin.top})`);\n\n  g.append(\"g\")\n      .attr(\"class\", \"axis\")\n      .call(xAxisLoess);\n\n  g.append(\"g\")\n    .attr(\"class\", \"axis\")\n    .attr(\"transform\", `translate(${innerWidth})`)\n    .call(yAxisLoess);\n\n  // Add X axis label:\n  g.append(\"text\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"font-size\", 13)\n    .attr(\"x\", innerWidth)\n    .attr(\"y\", innerHeight + margin.top + 25)\n    .text(\"Differenz Stimmenanteil Demokraten letzte Wahl zur 50%-Schwelle\");\n\n  // Y axis label:\n  g.append(\"text\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"transform\", \"rotate(-90)\")\n    .attr(\"font-size\", 13)\n    .attr(\"y\", -margin.left+10)\n    .attr(\"x\", -margin.top+10)\n    .text(\"Stimmenanteil Demokraten\");\n\n  g.selectAll(\"circle\")\n    .data(transpose(house_binned))\n    .enter().append(\"circle\")\n    .attr(\"r\", 2)\n    .attr(\"cx\", d =&gt; xScaleLoess(d.StimmenTm1))\n    .attr(\"cy\", d =&gt; yScaleLoess(d.StimmenT));\n\n  g.selectAll(\"circle\")\n   .filter( function(d){ return Math.abs(d.StimmenTm1) &lt;= bandwidth/2 } )\n   .attr(\"fill\", \"orange\")\n   .attr(\"stroke\", \"none\");\n\nfunction b(d) { return loessRegression(\n        transpose(house).filter(function(d){ return d.StimmenTm1 &lt;= 0 & d.StimmenTm1 &gt;= -.5 })\n    ); }\n\nfunction a(d) { return loessRegression(\n      transpose(house).filter(function(d){ return d.StimmenTm1 &gt; 0 & d.StimmenTm1 &lt;= .5  })\n    ); }\n\n  g.append(\"path\")\n      .attr(\"class\", \"regression\")\n      .datum(b)\n      .attr(\"d\", lineLoess)\n      .style(\"stroke\", \"red\");\n\n  g.append(\"path\")\n      .attr(\"class\", \"regression\")\n      .datum(a)\n      .attr(\"d\", lineLoess)\n      .style(\"stroke\", \"red\");\n  \n  g.append(\"text\")\n    .attr(\"x\", d =&gt; xScaleLoess(-.24))\n    .attr(\"y\", d =&gt; yScaleLoess(.55))\n    .attr(\"dy\", \".35em\")\n    .attr(\"fill\", \"#39FF14\")\n    .text(d3.format(\",.2f\")((a().slice(0))[0][1] - (b().slice(-1))[0][1]));\n  \n  g.append(\"line\")\n  .attr(\"x1\", xScaleLoess(0))\n  .attr(\"y1\", yScaleLoess((b().slice(-1))[0][1]))\n  .attr(\"x2\", xScaleLoess(0))\n  .attr(\"y2\", yScaleLoess((a().slice(0))[0][1]))\n  .attr(\"stroke\", \"#39FF14\")\n  .attr(\"stroke-width\", 2);\n  \n  /* dashed line at cutoff */\n  g.append(\"line\")\n  .attr(\"x1\", xScaleLoess(0))\n  .attr(\"y1\", 0)\n  .attr(\"x2\", xScaleLoess(0))\n  .attr(\"y2\", innerHeight)\n  .style(\"stroke\", \"black\")\n  .style(\"stroke-dasharray\", \"1\")\n  .style(\"stroke-width\", \"1\");\n  \n  /* dashed line data bw upper */\n  g.append(\"line\")\n  .attr(\"x1\", xScaleLoess(bandwidth/2))\n  .attr(\"y1\", 0)\n  .attr(\"x2\", xScaleLoess(bandwidth/2))\n  .attr(\"y2\", innerHeight)\n  .style(\"stroke\", \"blue\")\n  .style(\"stroke-dasharray\", \"4\")\n  .style(\"stroke-width\", \"1\");\n  \n  /* dashed line data bw lower */\n  g.append(\"line\")\n  .attr(\"x1\", xScaleLoess(-bandwidth/2))\n  .attr(\"y1\", 0)\n  .attr(\"x2\", xScaleLoess(-bandwidth/2))\n  .attr(\"y2\", innerHeight)\n  .style(\"stroke\", \"blue\")\n  .style(\"stroke-dasharray\", \"4\")\n  .style(\"stroke-width\", \"1\");\n\n  return svg.node();\n}\n\n\n\n\n\n\n\n\nAbbildung 11.7: Nicht-parametrische Regression auf beiden Seiten des Cut-offs.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Discontiniuty Designs</span>"
    ]
  },
  {
    "objectID": "RDD.html#fuzzy-regression-discontinuity-design",
    "href": "RDD.html#fuzzy-regression-discontinuity-design",
    "title": "11  Regression Discontiniuty Designs",
    "section": "11.3 Fuzzy Regression Discontinuity Design",
    "text": "11.3 Fuzzy Regression Discontinuity Design\n\n\n\n\n\n\n\n\n\n\n\nX\nX\n\n\n\nY\nY\n\n\n\nX-&gt;Y\n\n\n\n\n\noberhalb c\noberhalb c\n\n\n\nX-&gt;oberhalb c\n\n\n\n\n\nBehandlung\nBehandlung\n\n\n\nX-&gt;Behandlung\n\n\n\n\n\noberhalb c-&gt;Behandlung\n\n\n\n\n\nZ\nZ\n\n\n\nZ-&gt;X\n\n\n\n\n\nZ-&gt;Y\n\n\n\n\n\nZ-&gt;Behandlung\n\n\n\n\n\nBehandlung-&gt;Y\n\n\n\n\n\n\n\n\nAbbildung 11.8: Kausales Diagram für FRDD\n\n\n\n\n\nEin FRDD liegt vor, wenn die Zuweisung der Behandlung \\(B\\) durch die Laufvariable \\(X\\) (und möglicherweise weitere Variablen \\(Z\\)) beeinflusst wird. Im Vergleich zum SRDD ist die Behandlung dann also nicht ausschließlich durch Überschreiten des Schwellenwerts \\(X = c\\) bestimmt.\nAbbildung 11.8 zeigt den grundsätzlichen Zusammenhang. Hier genügt es weiterhin für \\(X\\) (und ggf. \\(Z\\)) zu kontrollieren, um den Pfad oberhalb \\(C\\) → Behandlung \\(B\\) → \\(Y\\) zu isolieren. Der so für Behandlung \\(B\\) ermittelte Effekt auf \\(Y\\) entspricht jedoch nicht dem “vollständigen” Behandlungseffekt, da bei \\(c\\) die Zuweisung der Behandlung nicht von \\(0\\) auf \\(100\\%\\) springt. Die Schätzung des FRDD berücksichtigt dies und skaliert den geschätzten Effekt entsprechend.\nWir betrachten zunächst den Zusammenhang \\[\\begin{align}\n  Y_i = \\beta_0 + \\beta_1 B_i + \\beta_2 (X_i - c) + u_i.\\label{eq-simpleFRDD}\n\\end{align}\\] In einem FRDD springt die Behandlungswahrscheinlichkeit am Schwellenwert \\(c\\) um \\(\\Delta p&lt;1\\). Wir können \\(B\\) also nicht als deterministische Funktion von \\(X\\), welche die Zuweisung zu Behandlungs- bzw. Kontrollgruppe am Schwellenwert \\(c\\) anzeigt (wie im SRDD), definieren. Stattdessen betrachten wir \\[\\begin{align}\n  P(B_i=1\\vert X_i) =\n  \\begin{cases}\n    g_{X_i&lt;c}(X_i), & X_i &lt; c \\\\\n    g_{X_i\\geq c}(X_i) & X_i \\geq c\n  \\end{cases}\\,. \\label{eq-BFRDD}\n\\end{align}\\] Die Funktionen \\(g_{X_i&lt;c}\\) und \\(g_{X_i\\geq c}\\) können verschieden sein. Es muss jedoch \\[g_{X_i&lt;c}(X_i = c) \\neq g_{X_i\\geq c}(X_i = c)\\] gelten. Die Behandlungsvariable \\(B_i\\) ist im FRDD also eine (binäre) Zufallsvariable, deren bedingte Wahrscheinlichkeitsfunktion \\(P(B_i=1\\vert X_i)\\) am Schwellenwert \\(c\\) eine Diskontinuität aufweist. Abbildung 11.9 zeigt heispielhafte Verläufe nicht-linearer bedingter Wahrscheinlichkeitsfunktion für die Behandlung mit einer Diskontinuität bei \\(X_i = c\\).\n\n\nCode\nlibrary(ggplot2)\nlibrary(cowplot)\n\n# Bedingte Behandlungswahrscheinlichkeit im FRDD illustrieren\nggplot() + \n  geom_function(\n    fun = ~ ifelse(\n      . &lt; 0, \n      -.1 * .^2 + .25, \n      -.1 * (.-1.5)^2 + 1\n    ), \n    n = 1000\n  ) + \n    geom_function(\n    fun = ~ ifelse(\n      . &lt; 0, \n     .35, \n     .65\n    ),\n    n = 1000, \n    lty = 2, \n    col = \"red\"\n  ) + \n  scale_x_continuous(\n    name = \"Laufvariable X\", \n    limits = c(-1.5, 1.5),\n    labels = NULL,\n    breaks = NULL\n  ) +\n  scale_y_continuous(\n    name = \"P(D=1|X)\", \n    breaks = c(0, 1), \n    limits = c(0, 1)\n  ) +\n  theme_cowplot()\n\n\n\n\n\n\n\n\nAbbildung 11.9: Bedingte Behandlungswahrscheinlichkeiten im FRDD\n\n\n\n\n\nDefinition \\(\\eqref{eq-BFRDD}\\) bedeutet, dass eine KQ-Schätzung von \\(\\beta_1\\) anhand \\(\\eqref{eq-simpleFRDD}\\) eine verzerrte Schätzung des Behandlungseffekts ist: Der in \\(\\widehat{\\beta}_1\\) erfasste Effekt auf \\(Y\\) ist auf einen Sprung der Behandlungswahrscheinlichkeit bei \\(X_i = c\\) um weniger als \\(100\\%\\) zurückzuführen. Der wahre Behandlungseffekt wird also unterschätzt. Daher muss \\(\\widehat{\\beta}_1\\) skaliert werden, sodass die Schätzung als Effekt einer Änderung der Behandlungswahrscheinlichkei um \\(100\\%\\) interpretiert werden kann — der erwartete Effekt, wenn ausschließlich Subjekte mit \\(X_i\\geq c\\) behandelt würden. Diese skalierte Schätzung erhalten wir mit IV-Regression (vgl. Kapitel XYZ). Hierfür nutzen wir für \\(B_i\\) die Instrumentvariable \\[\\begin{align*}\n  D_i = \\begin{cases}\n    0, & X_i &lt; c \\\\\n    1, & X_i \\geq c.\n  \\end{cases}\n\\end{align*}\\]\nAngenommen \\(g_{X_i\\geq c}(X_i) = \\alpha_0\\) und \\(g_{X_i&lt;c}(X_i) = \\alpha_0 + \\alpha_1\\) mit \\(\\alpha_0 + \\alpha_1 &lt; 1\\) (vgl. rote Funktion in Abbildung 11.8). Der FRDD-Schätzer des Behandlungseffekts ist dann \\(\\widehat{\\gamma}_\\textup{FRDD}\\) im 2SLS-Verfahren mit den Regressionen \\[\\begin{align}\n  \\begin{split}\n  (\\mathrm{I})\\qquad B_i =&\\, \\alpha_0 + \\alpha_1 D_i + \\alpha_2 (X_i - c) + e_i,\\\\\n  (\\mathrm{II})\\qquad Y_i =&\\, \\gamma_0 + \\gamma_1 \\widehat{B}_i + \\gamma_2 (X_i - c) + \\epsilon_i,\n  \\end{split}\\label{eq:FRDD_simpleIV}\n\\end{align}\\] wobei \\(\\widehat{B}_i\\) die angepassten Werte aus Stufe \\((\\mathrm I)\\) und \\(e_i\\) sowie \\(\\epsilon_i\\) Fehlterterme sind.\nAnalog zum SRDD müssen in empirischen Anwendungen geeignete Spezifikationen für die Regressionsfunktionen \\(\\eqref{eq-simpleFRDD}\\) und \\(\\eqref{eq-BFRDD}\\) gewählt und der 2SLS-Schätzer \\(\\eqref{eq:FRDD_simpleIV}\\) entsprechend angepasst werden. Ein einfaches Interaktionsmodell wäre \\[\\begin{align}\n  \\begin{split}\n  (\\mathrm{I})\\qquad B_i =&\\, \\alpha_0 + \\alpha_1 D_i + \\alpha_2 (X_i - c)\\\\\n  +&\\, \\alpha_3 (X_i - c) \\times D_i + e_i,\\\\\n  \\\\\n  (\\mathrm{II})\\qquad Y_i =&\\, \\gamma_0 + \\gamma_1 \\widehat{B}_i\\\\\n  +&\\, \\gamma_2 (X_i - c) + \\gamma_3 (X_i-c)\\times\\widehat{B}_i, \\epsilon_i\n  \\end{split},\\label{eq:FRDD_lintIV}\n\\end{align}\\] d.h. wir instrumentieren \\(B_i\\) mit \\(D_i\\) und dem Interaktionsterm \\((X_i-c)\\times D_i\\).\nWie im SRDD werden die IV-Ansätze für das FRDD \\(\\eqref{eq:FRDD_simpleIV}\\) und \\(\\eqref{eq:FRDD_lintIV}\\) in empirischen Studien unter Berücksichtigung einer Bandweite (i.d.R. dieselbe Bandweite für beide Stufen) angewendet.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Discontiniuty Designs</span>"
    ]
  },
  {
    "objectID": "RDD.html#case-study-protestantische-arbeitsethik",
    "href": "RDD.html#case-study-protestantische-arbeitsethik",
    "title": "11  Regression Discontiniuty Designs",
    "section": "11.4 Case Study: Protestantische Arbeitsethik",
    "text": "11.4 Case Study: Protestantische Arbeitsethik\nDie Studie Beyond Work Ethic: Religion, Individual, and Political Preferences (Basten und Betz 2013) untersucht den Zusammenhang zwischen Religion, individuellen Merkmalen und politischen Präferenzen. Das Hauptaugenmerk ist die Rolle von Religiosität als Einflussfaktor auf politische Einstellungen. Die Hypothese der Autoren ist, dass Religiosität eines Individuums über den traditionellen Rahmen von Moralvorstellungen und sozialen Normen hinaus auch die politischen Präferenzen beeinflusst. Eine entsprechende Theorie wurde zu Beginn des 20. Jahrhunderts entwickelt und prominent von Max Weber (vgl. Weber 2004) vertreten. Weber argumentiert, dass die protestantische Arbeitsethik einen entscheidenden Einfluss auf die Entwicklung des Kapitalismus hatte. Laut Weber führte der protestantische Glaube an harte Arbeit, ein sparsames Leben und ethisches Verhalten zur einer in den damaligen Gesellschaften weit verbreiteten Geisteshaltung, die wirtschaftliches Wachstum förderte und den Aufstieg des Kapitalismus begünstigte.\nBasten und Betz (2013) nutzen Wahlergebnisse sowie geo- und soziodemographische Datensätze für schweizer Gemeinden, um den Zusammenhang zwischen Religiosität und politischen Präferenzen wie links-rechts-Ausrichtung, Einstellungen zur Umverteilung und Einwanderung zu untersuchen. Hierfür verwenden die Autoren ein FRDD, dass eine historisch bedingte Diskontinuität der geographischen Verteilung von evanglischer bzw. katholischer Religionszugehörigkeit zwischen den Kantonen Freiburg (überwiegend dunkelrote Region, frz. Fribourg) und Waadt (kleinere hellrote Region, frz. Vaud) ausnutzt. Die historische Verteilung der Konfessionen in der betrachteten Region im 16. Jahrhundert durch Abspaltung des Kantons Freiburg ist in Abbildung 11.10 dargestellt.\nAufgrund von Bevölkerungsbewegungen ist die Verteilung der Konfessionen zwar nicht mehr eindeutig durch die Kantonsgrenze bestimmt, jedoch sind die Gemeinden der betrachteten Kantone auch heute noch mehrheitlich protestantisch bzw. katholisch. Es ist plausibel, dass eine Prägung gemäß Webers Theorie vorliegt, sich die Gemeinden nahe der Grenz aber hinsichtlich anderer Charakteristika (insb. der Bevölkerungsstruktur) nicht systematisch unterscheiden. Somit liegt ein quai\n\n\n\n\n\n\n\n\nAbbildung 11.10: Historische Verteilung von Religionszugehörigkeit in Schweizer Gemeinden im 16. Jahrhundert. Quelle: Basten und Betz (2013).\n\n\n\n\n\nDie Ergebnisse der Studie zeigen einen signifikanten Einfluss von Protestantismus auf politische Präferenzen, die über traditionelle Moralvorstellungen hinausgehen: Die Autoren finden Hinweise, dass Einwohner evangelisch geprägter Gemeinden eher konservative soziale und politische Ansichten vertreten. Eine mögliche Erklärung für diesen Effekt ist, dass religiöse Institutionen auch eine soziale und politische Agenda verfolgen, die von den Gläubigen internalisiert wird.\n\n11.4.1 Aufbereitung der Daten\nIn diesem Kapitel zeigen wir, wie die Kernergebnisse der Studie mit R reproduziert werden können. Hierfür werden folgende Pakete benötigt.\n\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(vtable)\nlibrary(rdrobust)\n\nDas Papier sowie der Datensatz BastenBetz.dta sind auf der Übersichtsseite der AEA verfügbar und liegt im STATA-Format .dta vor.4\n\n# Datensatz einlesen\nBastenBetz &lt;- read_dta('BastenBetz.dta')\n\nDer Datensatz BastenBetz enthält Beobachtungen zu 509 schweizer Gemeinden. Eine Vielzahl an Variablen ist lediglich für Robustheits-Checks relevant. Für die Reproduktion der Kernergebnisse erstellen wir zunächst einen reduzierten Datensatz und transformieren einige Variablen.\n\n# Reduzierten Datensatz erstellen\nBastenBetz &lt;- BastenBetz %&gt;%\n  transmute(\n    gini = Ecoplan_gini,\n    prot = prot1980s,\n    bord = borderdis, \n    vaud,\n    pfl, \n    pfr, \n    pfi\n  )\n\nDie Definitionen der Variablen sind in Tabelle 11.2 gegeben. Die Präferenzen pfl, pfr und pfi basieren auf Wahlergebnissen auf Gemeindeebene zu Volksentscheiden.\n\n\n\nTabelle 11.2: BastenBetz – Variablen und Definitionen\n\n\n\n\n\n\n\n\n\nVariable\nDefinition\n\n\n\n\nprot\nAnteil Prothestanten im Jahr 1980 (%)\n\n\ngini\nGini-Koeffizient\n\n\nbord\nLaufdistanz zur Kantonsgrenze (Km)\n\n\nvaud\nDummyvariable: Gemeine im Kanton Waadt\n\n\npfl\nPräferenz für Freizeit (%)\n\n\npfr\nPräferenz für Umverteilung (%)\n\n\npfi\nPräferenz für wirtschaftliche Intervention des Staats (%)\n\n\n\n\n\n\nFür die Berechnung der optimalen Bandweite des FRDD verwenden wir einen MSE-optimalen Schätzer, der in der Funktion rdrobust::rdbwselect() implementiert ist.5\n\n# Bandweite schätzen (Bsp. für Freizeitpräferenz)\nbw_selection &lt;- rdbwselect(\n  y = BastenBetz$pfl,\n  x = BastenBetz$bord,\n  fuzzy = BastenBetz$prot, \n  bwselect = \"mserd\", \n  kernel = \"uniform\"\n) \n\n# Bandweite auslesen und zuweisen\n(OB &lt;- bw_selection$bws[1])\n\n[1] 5.078001\n\n\n\n\n11.4.2 Deskriptive Statistiken\nZur Reproduktion von Tabelle 1 aus Basten und Betz (2013) erzeugen wir eine nach Kantonen gruppierte Zusammenfassung der Daten und berechnen deskriptive Statistiken. Wie im Paper berücksichtigen wir hierbei nur Gemeinden innerhalb der geschätzten optimalen Bandweite OB.\n\n# Datensatz für Reproduktion von Table 1 formatieren\nT1 &lt;- BastenBetz %&gt;%\n  filter(abs(bord) &lt; OB) %&gt;%\n  mutate(\n    vaud = ifelse(\n      test = vaud == 1, \n      yes = \"Waadt\", \n      no = \"Freiburg\"\n    ),\n    prot = prot * 100\n  ) %&gt;%\n  group_by(vaud) %&gt;%\n  summarise(\n    across(\n      everything(), \n      list(\n        Mean = mean, \n        SD = sd, \n        N = length\n      )\n    )\n  ) %&gt;%\n  pivot_longer(\n    cols = -vaud,\n    names_to = c(\"variable\", \"statistic\"), \n    names_sep = \"_\"\n  )\n\nFür die tabellarische Darstellung transformieren wir in ein weites Format, sodass die Tabelle die deskriptive Statistiken spaltenweise für die Kantone zeigt.\n\n# Daten in weites Format überführen\nT1_wider &lt;- T1 %&gt;% \n  pivot_wider(\n    names_from = c(\"vaud\", \"statistic\")\n  )\n\nDie Tabelle erzeugen wir mit gt::gt().\n\n# Tabelle mit gt() erzeugen\nT1_wider %&gt;%\n  gt(rowname_col = \"Variable\") %&gt;% \n  tab_spanner_delim(\n    delim = \"_\",\n  ) %&gt;%\n tabopts\n\n\n\nTabelle 11.3: Datensatz BastenBetz – Zusammenfassende Statistiken\n\n\n\n\n\n\n\n\n\nvariable\nFreiburg\nWaadt\n\n\nMean\nSD\nN\nMean\nSD\nN\n\n\n\n\ngini\n0.302\n0.029\n49\n0.367\n0.052\n84\n\n\nprot\n9.428\n5.695\n49\n83.245\n11.411\n84\n\n\nbord\n−2.327\n1.274\n49\n2.493\n1.201\n84\n\n\npfl\n48.239\n4.774\n49\n39.508\n5.723\n84\n\n\npfr\n43.049\n2.634\n49\n39.19\n5.025\n84\n\n\npfi\n52.642\n2.94\n49\n47.086\n3.368\n84\n\n\n\n\n\n\n\n\n\n\nDie Statistiken in Tabelle 11.3 scheinen konsistent mit der (historischen) Verteilung der Religionszugehörigkeit und politischen Einstellung gemäß der Hypothese: Im überwiegend katholischen Freiburg finden wir eine größere Einkommensungleichkeit und höhere aus Wahlergebnissen abgeleitete Präferenzen für Freizeit, Umverteilung sowie staatliche Interventionen.\n\n\n11.4.3 Modellspezifikation und First-Stage-Ergebnisse\n\nCJM_BB &lt;- rddensity(BastenBetz$bord, c = 0, kernel = \"epanechnikov\")\nsummary(CJM_BB)\n\n\nManipulation testing using local polynomial density estimation.\n\nNumber of obs =       509\nModel =               unrestricted\nKernel =              epanechnikov\nBW method =           estimated\nVCE method =          jackknife\n\nc = 0                 Left of c           Right of c          \nNumber of obs         127                 382                 \nEff. Number of obs    69                  124                 \nOrder est. (p)        2                   2                   \nOrder bias (q)        3                   3                   \nBW est. (h)           8.531               9.57                \n\nMethod                T                   P &gt; |T|             \nRobust                0.7552              0.4501              \n\n\nP-values of binomial tests (H0: p=0.5).\n\nWindow Length              &lt;c     &gt;=c    P&gt;|T|\n1.400     + 1.400          20      20    1.0000\n2.192     + 2.308          27      47    0.0265\n2.985     + 3.215          34      60    0.0095\n3.777     + 4.123          40      72    0.0032\n4.570     + 5.031          44      84    0.0005\n5.362     + 5.939          51      95    0.0003\n6.154     + 6.846          56     100    0.0005\n6.947     + 7.754          60     106    0.0004\n7.739     + 8.662          67     114    0.0006\n8.531     + 9.570          69     124    0.0001\n\n# CJM-Plot\nplot &lt;- rdplotdensity(\n  rdd = CJM_BB,\n  X = BastenBetz$bord, \n  type = \"both\", plotN = 20, \n)\n\n\n\n\n\n\n\n\nDie Kantone Waadt und Freiburg haben bis heute mehrheitlich protestantische bzw. katholische Gemeinden. Die Verteilung von Protestantismus ist also, u.a. aufgrund von Bevölkerungsbewegungen, nicht mehr deterministisch. An der Kantonsgrenze besteht jedoch eine deutliche Diskontinuität im Anteil protestantischer Einwohner, die auf die historische Verteilung der Religionszugehörigkeit zurückzuführen ist. Damit kann ein FRDD implementiert werden, bei dem die Distanz zur Grenze (bord) die zentrierte Laufvariable ist und die Zugehörigkeit zum Kanton Waadt (vaud) ein Instrument für die Behandlungsvariable (prot) ist.\nWir nutzen die Funktion rdrobust::rdplot um diesen Zusammenhang für verschiedene Bandweiten anhand des linearen Interaktionsmodells \\[\\begin{align}\n  \\begin{split}\n  prot_i =&\\, \\alpha_0 + \\alpha_1 vaud_i + \\alpha_2 bord_i \\\\\n  +&\\, \\alpha_3 bord_i \\times vaud_i + u_i\n  \\end{split}\\label{eq:BBFSR}\n\\end{align}\\] grafisch darzustellen. Dies ist die First-Stage-Regression für die 2SLS-Schätzung der Behandlungseffekte.\n\n# Reproduktion von Abbildung 3 in Basten und Betz (2013)\nplots_BB &lt;- list(\n  # gesch. optimale Bandweite\n  p_OB = rdplot(\n    y = BastenBetz$prot, \n    x = BastenBetz$bord, \n    h = c(OB, OB), \n    x.label = \"Distanz zur Grenze (bord)\",\n    y.label = \"Anteil Protestanten (prot)\", \n    title = \"Gesch. Bandweite\",\n    p = 1, \n    nbins = c(6, 14), \n    masspoints = \"off\"\n  ),\n  \n  # Bandweite 10\n  p_BW10 = rdplot(\n    y = BastenBetz$prot, \n    x = BastenBetz$bord, \n    h = c(10, 10), \n    x.label = \"Distanz zur Grenze (bord)\",\n    y.label = \"Anteil Protestanten  (prot)\", \n    title = \"Bandweite = 10\",\n    p = 1, \n    nbins = c(6, 14),\n    masspoints = \"off\"\n  ),\n  \n  # Bandweite 20\n  p_BW20 = rdplot(\n    y = BastenBetz$prot, \n    x = BastenBetz$bord, \n    h = c(20, 20), \n    x.label = \"Distanz zur Grenze (bord)\",\n    y.label = \"Anteil Protestanten  (prot)\", \n    title = \"Bandweite = 20\",\n    p = 1, \n    nbins = c(6, 14),\n    masspoints = \"off\"\n  ),\n  \n  # Gesamter Datensatz\n  p_G = rdplot(\n    y = BastenBetz$prot, \n    x = BastenBetz$bord,\n    x.label = \"Distanz zur Grenze (bord)\",\n    y.label = \"Anteil Protestanten\", \n    title = \"Ges. Datensatz\",\n    p = 1, \n    nbins = c(6, 14),\n    masspoints = \"off\"\n  )\n)\n\nWir sammeln die Ergebnisse in einem Plot-Gitter mit cowplot::plot_grid().\n\n# Reproduktion von Abbildung 3 in Basten und Betz (2013)\nplot_grid(\n  plotlist = map(plots_BB, ~ .$rdplot), ncol = 2\n)\n\n\n\n\n\n\n\nAbbildung 11.11: First-Stage-Regressionen\n\n\n\n\n\nDie Grafiken in Abbildung 11.11 zeigen deutliche Hinweise auf die Diskontinuität in prot nahe der Kantonsgrenze. Die Größe des geschätzten Sprungs scheint nur wenig sensitiv gegenüber der gewählten Bandweite zu sein. Die Signifikanz des Effekts können wir anhand der jeweiligen KQ-Regressionen beurteilen.6\n\n# Reproduktion der First-Stage-Regressionen\n# s. Tabelle 2 in Basten und Betz (2013)\n\n# (1) BW = OB\nFS1 &lt;- lm(\n  formula = prot ~ vaud + bord + vaud * bord, \n  data = BastenBetz %&gt;% \n    filter(\n      abs(bord) &lt;= OB\n    )\n)\n\n# (2) BW = 10\nFS2 &lt;- update(\n  FS1,\n  data = BastenBetz %&gt;% \n    filter(\n      abs(bord) &lt;= 10\n    )\n)\n\n# (3) BW = 20\nFS3 &lt;- update(\n  FS1,\n  data = BastenBetz %&gt;%\n    filter(\n      abs(bord) &lt;= 20\n    )\n)\n\n# (4) Ges. Datensatz\nFS4 &lt;- update(\n  object = FS1,\n  data = BastenBetz\n)\n\n\n# Tabellarische Darstellung\nmodelsummary(\n  list(\n    \"BW = OB\"= FS1, \n    \"BW = 10\" = FS2, \n    \"BW=20\" = FS3, \n    \"Ges. Datensatz\" = FS4\n  ), \n  vcov = \"HC1\", \n  stars = T, \n  gof_map = \"nobs\", \n  output = \"gt\"\n) %&gt;%\n  tabopts()\n\n\n\nTabelle 11.4: First-Stage-Regressionen\n\n\n\n\n\n\n\n\n\n\nBW = OB\nBW = 10\nBW=20\nGes. Datensatz\n\n\n\n\n(Intercept)\n0.134***\n0.100***\n0.103***\n0.109***\n\n\n\n(0.017)\n(0.013)\n(0.010)\n(0.009)\n\n\nvaud\n0.671***\n0.726***\n0.756***\n0.710***\n\n\n\n(0.034)\n(0.022)\n(0.018)\n(0.014)\n\n\nbord\n0.017**\n0.001\n0.001\n0.002*\n\n\n\n(0.006)\n(0.003)\n(0.001)\n(0.001)\n\n\nvaud × bord\n-0.006\n-0.001\n-0.009***\n-0.004***\n\n\n\n(0.012)\n(0.005)\n(0.003)\n(0.001)\n\n\nNum.Obs.\n133\n207\n312\n509\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n\nFür die geschätze Bandweite schätzen wir einen hochsignifikanten Sprung in prot von etwa 67% an der Kantonsgrenze. Auch für größere Bandweiten von 10km und 20km sowie für den gesamten Datensatz finden wir vergleichbare signifikante Effekte, was eine bei zunehmender Distanz zur Grenze persistente Diskrepanz der Religionszugehörigkeit bestätigt.\n\n\n11.4.4 Second-Stage-Ergebnisse\nWir schätzen nun den LATE von Protestantismus für die Outcome-Variablen gini, pfl, pfi und pfr, vgl. Tabelle 11.2. Die Spezifikation für die Second-Stage-Regression der FRDD-Schätzung ist \\[\\begin{align}\n  \\begin{split}\n    Y_i = \\gamma_0 + \\gamma_1 \\widehat{prot}_i +  \\gamma_2 bord_i + \\gamma_3 bord_i  \\times vaud_i + e_i\n  \\end{split},\n\\end{align}\\] wobei \\(\\widehat{prot}_i\\) angepasste Werte aus der KQ-Schätzung von \\(\\eqref{eq:BBFSR}\\) mit Bandweite OB sind. Dazu erzeugen wir zunächst eine angepasste Version des Objekts BastenBetz, welche nur Gemeinden innerhalb der Bandweite enthält.\n\n# Gemeinden innerhalb der Bandweite filtern\nBastenBetz_OB &lt;- BastenBetz %&gt;% \n  filter(\n    abs(bord) &lt;= OB\n  )\n\nZur Illustration schätzen wir nun die Second-Stage-Regression für \\(Y = pfl\\).\n\n# Second-Stage-Regression für `pfl`\nBastenBetz_OB %&gt;% \n  mutate(\n    prot_fitted = fitted(FS1)\n    ) %&gt;%\n\nlm(\n  pfl ~ prot_fitted + bord + vaud:bord, \n  data = .\n) %&gt;% \n  summary()\n\n\nCall:\nlm(formula = pfl ~ prot_fitted + bord + vaud:bord, data = .)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.8870  -3.8621  -0.0423   3.4993  12.1636 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  50.5275     1.9721  25.621  &lt; 2e-16 ***\nprot_fitted -13.4600     3.1749  -4.240 4.24e-05 ***\nbord          0.4380     0.6528   0.671    0.503    \nbord:vaud    -0.3636     0.7939  -0.458    0.648    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.433 on 129 degrees of freedom\nMultiple R-squared:  0.383, Adjusted R-squared:  0.3686 \nF-statistic: 26.69 on 3 and 129 DF,  p-value: 1.704e-13\n\n\nDer Koeffizient prot_fitted ist der gesuchte Behandlungseffekt. Beachte, dass die von summary() berechneten Standardfehler ungültig sind, weil diese die zusätzliche Unsicherheit durch die Berechnung von \\(\\widehat{prot}\\) über die First-Stage-Regression nicht berücksichtigen. Nachfolgend nutzen wir AER::ivreg(), um komfortabel gültige (heteroskedastie-robuste) Inferenz betreiben zu können.7\n\n# Schätzung mit 2SlS\n# s. Tabelle 4 in Basten und Betz (2013)\n#\n# Wir instrumentieren Treatment (`prot1980s`) mit dem Schwellenindikator (`vaud`)\n# ivreg: exogene Variablen instrumentieren sich selbst, daher\n# ' | vaud * borderdis '\nlibrary(AER)\n# (1) Präferenz für Freizeit\nSS_pfl &lt;- ivreg(\n  formula = pfl ~ prot + bord:vaud + bord | vaud * bord,\n  data = BastenBetz_OB\n)\n\n# (2) Präferenz für Umverteilung\nSS_pfr &lt;- update(\n  object = SS_pfl,\n  formula = pfr ~ prot + bord:vaud + bord | vaud * bord,\n)\n\n# (3) Präferenz für Intervention\nSS_pfi &lt;- update(\n  object = SS_pfl,\n  formula = pfi ~ prot + bord:vaud + bord | vaud * bord,\n)\n\n# (4) Einkommensungleichheit\nSS_gini &lt;- update(\n  object = SS_pfl,\n  formula = pfi ~ prot + bord:vaud + bord | vaud * bord,\n)\n\n\n# Tabellarische Darstellung\nmodelsummary(\n  list(\n    \"(1) Freizeit\"= SS_pfl, \n    \"(2) Umverteilung\" = SS_pfr, \n    \"(3) Intervention\" = SS_pfi, \n    \"(4) Ungleichheit\" = SS_gini\n  ), \n  vcov = \"HC1\", \n  stars = T, \n  gof_map = \"nobs\", \n  output = \"gt\"\n) %&gt;%\n  tabopts()\n\n\n\nTabelle 11.5: Ergebnisse der Second-Stage-Regressionen\n\n\n\n\n\n\n\n\n\n\n(1) Freizeit\n(2) Umverteilung\n(3) Intervention\n(4) Ungleichheit\n\n\n\n\n(Intercept)\n50.528***\n44.560***\n52.871***\n52.871***\n\n\n\n(1.918)\n(0.950)\n(1.063)\n(1.063)\n\n\nprot\n-13.460***\n-5.061*\n-6.487***\n-6.487***\n\n\n\n(3.161)\n(2.161)\n(1.738)\n(1.738)\n\n\nbord\n0.438\n0.444\n-0.165\n-0.165\n\n\n\n(0.639)\n(0.357)\n(0.332)\n(0.332)\n\n\nbord × vaud\n-0.364\n-0.909\n0.011\n0.011\n\n\n\n(0.811)\n(0.561)\n(0.432)\n(0.432)\n\n\nNum.Obs.\n133\n133\n133\n133\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n\nDie Koeffizienten von prot in Tabelle 11.5 sind die mit 2SLS ermittelten erwarteten Behandlungseffekte einer 100%-Reformation (d.h. von 100% katholisch zu 100% protestantisch) für eine durchschnittliche Gemeine nahe der Kantonsgrnze. Es handelt sich jeweils um einen lokalen durchschnittlichen Behandlungseffekt (LATE). Gem. der Definition der abhängigen Variablen, interpretieren wir die Koeffizienten von prot in de Regressionen (1), (2) und (3) als erwartete Prozentänderung durch Reformation. Der Koeffizient in Regression (4) gibt die erwartete Änderung des Gini-Index an. Sämtliche geschätzte Effekte sind signifikant und haben ein mit der Hypothese der Autoren konsistentes negatives Vorzeichen.\nDie Ergebnisse sind Evidenz, dass Protestantismus zu verringerter Präferenz für Freizeit, Umverteilung sowie wirtschaftspolitische Intervention seitens des Staats führt. Auch die ökonomische Ungleichheit ist signifikant geringer, als in einer durchschnittlichen vollständig katholischen Gemeinde.\n\n\n11.4.5 Addendum: FRDD-Schätzung mit rdrobust()\nDie Funktion rdrobust::rdrobust() erlaubt die Schätzung von SRDD und FRDD mit einer Vielzahl von Optionen, s. ?rdrobust. Dies erleichtert die Schätzung mehrerer Modellspezifikationenen und Bandweiten. Mit dem nachstehenden Befehl schätzen wir den LATE von Reformation auf die Präferenz für Umverteilung anhand lokaler quadratischer Regression. Der Output gibt einen Überblick der Bandweitenschätzung sowie der 2 Stufen des 2SLS-Schätzers, inkl. robuster Inferenzstatistiken.\n\npfr_rdr &lt;- rdrobust(\n  y = BastenBetz$pfr,\n  x = BastenBetz$bord,\n  fuzzy = BastenBetz$prot, \n  p = 2,\n  kernel = \"uniform\",\n  vce = \"HC1\"\n) \n\npfr_rdr %&gt;% \n  summary()\n\nFuzzy RD estimates using local polynomial regression.\n\nNumber of Obs.                  509\nBW type                       mserd\nKernel                      Uniform\nVCE method                      HC1\n\nNumber of Obs.                  127          382\nEff. Number of Obs.              85          131\nOrder est. (p)                    2            2\nOrder bias  (q)                   3            3\nBW est. (h)                  10.796       10.796\nBW bias (b)                  22.271       22.271\nrho (h/b)                     0.485        0.485\nUnique Obs.                      97          261\n\nFirst-stage estimates.\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     0.701     0.039    17.782     0.000     [0.624 , 0.778]     \n        Robust         -         -    15.837     0.000     [0.599 , 0.768]     \n=============================================================================\n\nTreatment effect estimates.\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional    -5.047     2.254    -2.239     0.025    [-9.464 , -0.629]    \n        Robust         -         -    -2.210     0.027   [-10.114 , -0.607]    \n=============================================================================\n\n\nAuch für die quadratische Spezifikation erhalten wir mit -5.047 ein vergleichbares signifikantes Ergebnis für den LATE von Protestantismus auf Umverteilung, vgl. Spalte (2) in Tabelle 11.5.\nMit der Option bwselect = \"msetwo\" kann die Bandweite jeweils für die lokale Regression links- und rechtssetig des Schwellenwerts geschätzt werden.\n\npfr_rdr %&gt;% \n  update(bwselect = \"msetwo\") %&gt;%\n  summary()\n\nFuzzy RD estimates using local polynomial regression.\n\nNumber of Obs.                  509\nBW type                      msetwo\nKernel                      Uniform\nVCE method                      HC1\n\nNumber of Obs.                  127          382\nEff. Number of Obs.              51          134\nOrder est. (p)                    2            2\nOrder bias  (q)                   3            3\nBW est. (h)                   5.340       11.387\nBW bias (b)                  13.917       22.330\nrho (h/b)                     0.384        0.510\nUnique Obs.                      97          261\n\nFirst-stage estimates.\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     0.649     0.046    14.216     0.000     [0.560 , 0.739]     \n        Robust         -         -    11.970     0.000     [0.534 , 0.743]     \n=============================================================================\n\nTreatment effect estimates.\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional    -7.487     3.378    -2.216     0.027   [-14.109 , -0.866]    \n        Robust         -         -    -2.156     0.031   [-14.750 , -0.704]    \n=============================================================================\n\n\nTrotz Diskrepanz der geschätzten Bandweiten erhalten wir eine größere aber vergleichbare Schätzung für einen negativen Effekt.\n\n\n\n\nBasten, Christoph, und Frank Betz. 2013. „Beyond work ethic: Religion, individual, and political preferences“. American Economic Journal: Economic Policy 5 (3): 67–91.\n\n\nCattaneo, Matias D, Michael Jansson, und Xinwei Ma. 2020. „Simple local polynomial density estimators“. Journal of the American Statistical Association 115 (531): 1449–55.\n\n\nGelman, Andrew, und Guido Imbens. 2019. „Why high-order polynomials should not be used in regression discontinuity designs“. Journal of Business & Economic Statistics 37 (3): 447–56.\n\n\nImbens, G. W., und Thomas Lemieux. 2008. „Regression discontinuity designs: A guide to practice“. Journal of econometrics 142 (2): 615–35.\n\n\nImbens, Guido, und Karthik Kalyanaraman. 2012. „Optimal bandwidth choice for the regression discontinuity estimator“. The Review of economic studies 79 (3): 933–59.\n\n\nLee, David S. 2008. „Randomized experiments from non-random selection in US House elections“. Journal of Econometrics 142 (2): 675–97.\n\n\nMcCrary, Justin. 2008. „Manipulation of the running variable in the regression discontinuity design: A density test“. Journal of Econometrics 142 (2): 698–714.\n\n\nWeber, Max. 2004. Die protestantische Ethik und der Geist des Kapitalismus. Bd. 1614. CH Beck.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Discontiniuty Designs</span>"
    ]
  },
  {
    "objectID": "RDD.html#footnotes",
    "href": "RDD.html#footnotes",
    "title": "11  Regression Discontiniuty Designs",
    "section": "",
    "text": "Engl. fuzzy.↩︎\nUrsachen sind Überanpassung an die Daten sowie instabiles Verhalten der Schätzung nahe des Schwellenwertes.↩︎\nLOESS ist eine Variante von lokaler Polynom-Regression.↩︎\nSiehe alternativ das working paper, falls kein Abbonement für AEA-Journals vorliegt.↩︎\nBasten und Betz (2013) setzen BW = 5.01, den Durchschnitt von IK-Schätzungen über Modelle sämtlicher betrachteter Outcome-Variablen. Diese Bandweite liegt nahe des Ergebnisses von rdbwselect. Wir verwenden nachfolgend die Schätzung OB.↩︎\nWir nutzen update() um die Regression mit weniger Code für verschiedene Bandweiten zu schätzen.↩︎\nDie Autoren geben an, robuste SEs zu nutzen. Das scheint nicht der Fall zu sein, denn vcov = \"HC0\" liefert die Ergebinsse im Paper. Die von Stata berechneten HC1-SEs weichen ab. Dies ändert allerdings nichts an der Signifikanz der Koeffizienten. Wir nutzen vcov = \"HC1\".↩︎",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Discontiniuty Designs</span>"
    ]
  },
  {
    "objectID": "SyntheticControl.html",
    "href": "SyntheticControl.html",
    "title": "12  Synthetic Control",
    "section": "",
    "text": "12.1 Schätzung von Interventionseffekten mit SCM\nÄhnlich wie bei manchen Matching-Methoden wird bei SCM die Ähnlichkeit der synthetischen Einheit mit der untersuchten Einheit durch eine gewichtete Kombination von Kontrolleinheiten basierend auf ihren Prä-Interventionsmerkmalen erreicht. Seien \\(i = 1, 2, \\ldots, N\\) die Einheiten in der Stichprobe, wobei \\(i = 1\\) die behandelte Einheit und \\(i = 2, \\ldots, N\\) potenziellen Kontrolleinheiten (auch Donor pool genannt) sind. Die Daten liegen für die Perioden \\(t = 1, 2, \\ldots, T\\) vor, mit \\(T_0\\) dem Zeitpunkt direkt vor der Intervention und \\(T_1, \\ldots, T\\) den Perioden nach der Intervention.\nFür SCM bestimmen wir einen Vektor von Gewichten \\(\\mathbf{w}^* := (w_2^*, \\ldots, w_k^*)^T\\), der die Summe der quadrierten Differenzen zwischen den Ausprägungen von \\(k\\) Charakteristika der behandelten Einheit vor der Intervention, \\(X_{1,\\,m}^{\\text{Pre}}\\), \\(m=1,\\dots,k\\), und der gewichteten Summe dieser Charakteristika für die Kontrolleinheiten, \\(X_{i,\\,m}^{\\text{Pre}}\\), minimiert:\nunter der Nebenbedingung, dass \\(\\sum_{i=2}^{N} w_i = 1\\) und \\(w_i \\geq 0\\) für alle \\(i\\). Die \\(v_m\\) sind weitere Gewichte, welche die Relevanz der Variablen für die Vorhersage der Outcome-Variable der interessierenden Einheit, \\(Y_{1,\\,t}\\), beinflussen. Diese Gewichte werden meist in einem weiteren Optimierungsverfahren (bspw. mit Cross-Validation) bestimmt (vgl. A. Abadie, Diamond, und Hainmueller 2014). Als Verlustfunktion hierbei wird meist der mittlere quadratische Fehler bei der Vorhersage von \\(Y_{1,\\,t}\\) (MSPE)1 vor der Behandlung anhand der synthetischen Einheit verwendet,\n\\[\\begin{align}\n  \\sum_{t=1}^{T_0} \\left( Y_{1,\\,t} - \\sum_{i=2}^N w_i(\\mathbf{v}) Y_{i,\\,t} \\right)^2, \\label{eq:scopt2}\n\\end{align}\\] mit \\(\\mathbf{v} := (v_1,\\dots,v_k)'\\).\nDurch die Lösung des Optimierungsproblems \\(\\eqref{eq:scopt}\\) unter Berücksichtigung von \\(\\eqref{eq:scopt2}\\) erhalten wir die geschätzten Gewichte \\(\\widehat{w}_i\\), welche den Einfluss der Kontrolleinheit \\(i=2,\\dots,N\\)-ten bei der Zusammensetzung der Kontrollgruppe festlegen. Anhand der \\(\\widehat{w}_i\\) wird die Outcome-Variable der synthetischen Kontrolleinheit konstruiert, welche als Referenz für die Schätzung des kausalen Effekts der Intervention dient. Die Outcome-Variable der synthetischen Kontrollgruppe für die Nach-Interventionsperiode kann formal ausgedrückt werden als\nwobei \\(Y_{1,t}^{\\text{Synth}}\\) der Wert der Outcome-Variable \\(Y\\) für die synthetische Kontrollgruppe zum Zeitpunkt \\(t\\) und \\(Y_{i,t}\\) der entsprechende Wert des Outcomes für die \\(i\\)-te Kontrolleinheit ist. Bei SCM schätzen wir den kausalen Effekt \\(\\tau_t\\) der Intervention zum Zeitpunkt \\(t\\) als die Differenz der Post-Interventionswerte von \\(Y\\) zwischen der behandelten Einheit und dem synthetischen Doppelgänger,\n\\[\n\\widehat{\\tau}_t = Y_{1,\\,t} - Y_{1,\\,t}^{\\text{synth}},\\quad t &gt; T_0.\n\\]\nDer mit SCM geschätzte Effekt ermittelt also für \\(t &gt; T_0\\), wie sich die Intervention auf die behandelte Einheit ausgewirkt hat durch einen Vergleich mit der Situation, die eingetreten wäre, wenn die Einheit nicht behandelt worden wäre, repräsentiert durch die synthetische Kontrollgruppe.\nDer SCM-Schätzer von A. D. Abadie Alberto und Hainmueller (2010) ist im R-Paket Synth (Hainmueller, Diamond, und Abadie 2011) implementiert. Wir illustrieren die Methode nachfolgend mit einer empirischen Anwendung zu den Konsequenzen des Brexit auf die nachfolgende Entwicklung der britischen Volkswirtschaft.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Synthetic Control</span>"
    ]
  },
  {
    "objectID": "SyntheticControl.html#sec-siscm",
    "href": "SyntheticControl.html#sec-siscm",
    "title": "12  Synthetic Control",
    "section": "",
    "text": "\\[\\begin{align}\n  \\mathbf{w}^* := \\arg\\min_{\\mathbf{w}} \\sum_{m=1}^{k} v_m \\left( X_{1,\\,m}^{\\text{Pre}} - \\sum_{i=2}^{N} w_i X_{i,m}^{\\text{Pre}} \\right)^2,\\label{eq:scopt}\n\\end{align}\\]\n\n\n\n\\[\\begin{align}\n  Y_{1,\\,t}^{\\text{Synth}} = \\sum_{i=2}^{N} \\widehat{w}_i Y_{i,\\,t},\\quad t &gt; T_0,\\label{eq:dgkonst}\n\\end{align}\\]",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Synthetic Control</span>"
    ]
  },
  {
    "objectID": "SyntheticControl.html#case-study-ökonomische-kosten-des-brexit",
    "href": "SyntheticControl.html#case-study-ökonomische-kosten-des-brexit",
    "title": "12  Synthetic Control",
    "section": "12.2 Case Study: Ökonomische Kosten des Brexit",
    "text": "12.2 Case Study: Ökonomische Kosten des Brexit\nBorn u. a. (2019) untersuchen die ökonomischen Kosten des Brexits mit einem kausalanalytischen Forschungsansatz. Der Kern der empirischen Analyse ist eine Kombination von quasi-experimenteller Identifikation und struktureller Zeitreihenanalyse. Hiermit können nicht nur die aggregierten Kosten des EU-Ausstiegs für Großbrittanien zu quantifiziert, sondern auch die Kanäle indentifiziert werden, durch die die erwartete wirtschaftliche Desintegration die britische Makroökonomie beeinflusst hat. Hierbei identifizieren Born u. a. (2019) einen Anstieg der wirtschaftspolitischen Unsicherheit und eine Abwärtskorrektur der Wachstumserwartungen als Haupttreiber für den Rückgang der Wirtschaftsleistung.\nDer quasi-experimentelle Ansatz betrachtet das Brexit-Referendum als ein natürliches makroökonomisches Experiment und untersucht die Konsequenzn der wirtschaftlichen Desintegration für das Bruttoinlandsprodukt (BIP) im Nachfolgezeitraum mit SCM. Hierzu wird gemäß der in Kapitel 12.1 erläuterten Vorgehensweise ein syntetischer Doppelgänger für die britische Wirtschaft aus einem Donor Pool von 23 Volkswirtschaften konstruiert, und der Effekt des Referendums als Unterschied zwischen der tatsächlichen und synthetischen Trajektorien des BIP für Folgeperioden ermittelt. Die Analyse zeigt, dass das Brexit-Votum bis Ende 2018 zu einem BIP-Rückgang von etwa 1.7% bis 2.5% geführt hat.\nWie reproduzieren nun die wesentlichen Ergebnisse des SCM-Ansatzes der Studie mit R. Hierfür lesen zunächst den Datensatz brexit.csv (hier verfügbar) in R ein. Dieser enthält vierteljährliche Beobachtungen makroökonomischer Variablen für 24 Länder für den Zeitraum 1995-Q1–2021-Q4.\n\nlibrary(readr)\nlibrary(dplyr)\n\n# Datensatz 'brexit.csv' einlesen\nbrexit &lt;- read_csv(\"datasets/brexit.csv\") %&gt;%\n  as.data.frame()\n\nbrexit ist ein Datensatz mit einer Panel-Struktur. Die Zeit- und Entitätsvariablen sind Year/quarter und Country/ID. Beachte, dass die Variable Time zusätzlich das Jahr und das Quartal als numerische Variable angibt.\n\n# Überblick über 'brexit'\nglimpse(brexit)\n\nRows: 2,496\nColumns: 21\n$ Time          &lt;dbl&gt; 1995.00, 1995.00, 1995.00, 1995.00, 1995.00, 1995.00, 19…\n$ Year          &lt;dbl&gt; 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 19…\n$ quarter       &lt;chr&gt; \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q…\n$ Country       &lt;chr&gt; \"Australia\", \"Austria\", \"Belgium\", \"Canada\", \"Finland\", …\n$ real_con_raw  &lt;dbl&gt; 4.660970e+11, 1.214713e+11, 1.608240e+11, 5.558142e+11, …\n$ real_inv_raw  &lt;dbl&gt; 1.683258e+11, 5.537994e+10, 6.118800e+10, 1.894910e+11, …\n$ real_exp_raw  &lt;dbl&gt; 1.246639e+11, 6.634091e+10, 1.501160e+11, 3.353030e+11, …\n$ real_imp_raw  &lt;dbl&gt; 9.781032e+10, 7.439282e+10, 1.468880e+11, 2.572610e+11, …\n$ real_gdp_raw  &lt;dbl&gt; 8.495864e+11, 2.165699e+11, 2.910360e+11, 1.084659e+12, …\n$ real_gdp_2016 &lt;dbl&gt; 0.5080841, 0.6832146, 0.6877292, 0.6057397, 0.6370480, 0…\n$ tot_emp_raw   &lt;dbl&gt; 8077377.2, 3737003.3, 3920400.0, 13274100.0, 2050262.7, …\n$ pop_quarterly &lt;dbl&gt; 13144039.8, 6043266.6, 7666495.5, 21714093.3, 3827395.7,…\n$ lab_prod      &lt;dbl&gt; 0.9988637, 0.9863141, 0.9942753, 0.9997992, 0.9885239, 1…\n$ ConGDP        &lt;dbl&gt; 0.5486164, 0.5608871, 0.5525914, 0.5124322, 0.5244422, 0…\n$ InvGDP        &lt;dbl&gt; 0.1981267, 0.2557140, 0.2102420, 0.1747010, 0.2085606, 0…\n$ ExpGDP        &lt;dbl&gt; 0.14673485, 0.30632565, 0.51579873, 0.30913218, 0.268451…\n$ ImpGDP        &lt;dbl&gt; 0.1151270, 0.3435049, 0.5047073, 0.2371815, 0.2485870, 0…\n$ LPG           &lt;dbl&gt; -0.0078972729, -0.0093478618, 0.0033636783, 0.0054461911…\n$ EmpSha        &lt;dbl&gt; 0.6145277, 0.6183747, 0.5113679, 0.6113127, 0.5356809, 0…\n$ gdp           &lt;dbl&gt; -49.19159, -31.67854, -31.22708, -39.42603, -36.29520, -…\n$ ID            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n\n# 'Time' zeigt Jahr + Quartal\nbrexit %&gt;% \n  filter(Country == \"United Kingdom\") %&gt;% \n  select(Time) %&gt;%\n  slice_head(n = 5)\n\n     Time\n1 1995.00\n2 1995.25\n3 1995.50\n4 1995.75\n5 1996.00\n\n\nFür die Schätzung der Gewichte \\(w_i\\) für die Konstruktion des UK-Doppelgängers werden die in gelisteten Charakteristika der Volkswirtschaften verwendet.\n\n\n\nTabelle 12.1: brexit – Variablen und Definitionen\n\n\n\n\n\nVariable\nDefinition\n\n\n\n\ngdp\nVeränderung des BIP relativ zu 2016\n\n\nConGDP\nAnteil: Konsum/BIP (%)\n\n\nInvGDP\nAnteil: Investitionen/BIP (%)\n\n\nExpGDP\nAnteil: Exporte/BIP (%)\n\n\nImpGDP\nAnteil: Importe/BIP (%)\n\n\nEmpSha\nAnteil: Beschäftigte/Erwerbsbevölkerung (%)\n\n\nLPG\nWachstum der Arbeitsproduktivität (%)\n\n\n\n\n\n\nZur Berechnung von SCM mit dem R-Paket Synth müssen die Daten zunächst mit der Funktion Synth::dataprep() aufbereitet werden, s. ?Synth::dataprep() für weitere Details. Neben dem Datensatz (foo) unter expliziter Nennung der Prädiktoren (predictors) und der Outcome-Variable (dependent) übergeben wir Variablen für die Indentifikation von Einheiten (ID) und Zeitpunkten (Time), sowie Donor Pool (controls.identifier) und behandelter Einheit (treatment.identifier). Weiterhin werden die Vorbehandlungsperiode (time.predictors.prior) sowie der Zeitraum über den die Regressor-Gewichte \\(v_m\\) bestimmt werden sollen (time.optimize.ssr), festgelegt. Für letztere übergeben wir einen numerischen Vektor für sämtliche Zeitpunkte von 1995-Q1 bis zum Brexit-Referendum in 2016-Q2.\nUm einen ersten Überblick über die Entwicklung der BIP im Datensatz zu gewinnen, vergleichen wir die Zeitreihen für Donor-Pool-Länder (grau) und Großbritannien (blau) mit ggplot.\n\nlibrary(cowplot)\n\nbrexit %&gt;%\n  mutate(\n    group = ifelse(\n      Country == \"United Kingdom\", \n      yes = \"UK\", \n      no =\"else\"\n    )\n  ) %&gt;%\n  \n  ggplot(\n    mapping = aes(\n      x = Time, \n      y = gdp, \n      color = group, \n      group = Country, \n      lwd = group\n    )\n  ) +\n  scale_color_manual(\n    values = c(\n      \"UK\" = \"#00BFC4\", \"else\" = alpha(\"gray\", .75)\n    )\n  ) +\n  scale_linewidth_manual(\n    values = c(\"UK\" = 1, \"else\" = .5)\n  ) +\n  geom_line() +\n  # Brexit-Referendum\n  geom_vline(\n    xintercept = 2016.25, \n    lty = \"dotted\"\n  ) +\n  theme_cowplot() +\n  guides(\n    lwd = \"none\", \n    color = guide_legend(position = \"inside\")\n  ) +\n  theme(legend.position.inside = c(.1, .9))\n\n\n\n\n\n\n\nAbbildung 12.1: BIP relativ zu 2016\n\n\n\n\n\nAbbildung 12.1 zeigt, dass das BIP von Großbritannien zwar auch nach dem Brexit-Referendum (gepunktete Linie) gewachsen ist, jedoch vergleichsweise schwach. Eine Analyse mit SCM kann statistische Evidenz für den mutmaßlich negativen Effekt des Referendums auf das Wachstum in den Folgeperioden liefern.\nWir laden nun das Paket Synth und bereiten die Daten für die Analyse vor.\n\n# R-Paket 'Synth' laden\nlibrary(Synth)\n\n# Daten für die Optimierung vorbereiten\ndataprep_out &lt;- dataprep(\n  foo = brexit, \n  predictors = c(\n    \"ConGDP\", \"InvGDP\", \n    \"ExpGDP\", \"ImpGDP\", \n    \"LPG\", \"EmpSha\"\n  ), \n  dependent = \"gdp\", \n  unit.variable = \"ID\",\n  time.variable = \"Time\", \n  treatment.identifier = 23, \n  controls.identifier = (brexit$ID %&gt;% unique())[-23], \n  time.predictors.prior = seq(1995, 2016.25, .25),\n  time.optimize.ssr = seq(1995, 2016.25, .25),\n  unit.names.variable = \"Country\"\n)\n\nAnhand der vorbereiteten Daten dataprep_out wird nun die Bestimmung der Gewichte mit Synth::synth() durchgeführt.\n\n# Gewichte per Optimierung bestimmen\nsynth_out &lt;- synth(dataprep_out)\n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 0.6083746 \n\nsolution.v:\n 0.1488472 0.08840361 0.1480946 0.153318 0.1815462 0.2797904 \n\nsolution.w:\n 1.42199e-05 4.00616e-05 8.47284e-05 0.00014488 4.45754e-05 4.84009e-05 0.001608051 4.77577e-05 0.06654494 2.07094e-05 0.1446237 1.188e-05 2.377e-06 0.04837474 1.33542e-05 0.0001405933 4.61625e-05 0.0001592545 1.49993e-05 4.14211e-05 3.78112e-05 0.0002273924 0.737708 \n\n\nSynth::synth() gibt Infos über den Optimierungsprozess und dessen Ergebnisse automatisch in der Konsole aus. Wir können diese mit Synth::synth.tab() leicht tabellarisch zusammenfassen und mit gt::gt() darstellen.\n\n# Zusammenfassung der Ergebnisse\n(\n  tb &lt;- synth.tab(\n    synth.res = synth_out, \n    dataprep.res = dataprep_out\n  )  \n)\n\n$tab.pred\n       Treated Synthetic Sample Mean\nConGDP   0.655     0.635       0.534\nInvGDP   0.168     0.202       0.226\nExpGDP   0.254     0.219       0.454\nImpGDP   0.256     0.232       0.423\nLPG      0.003     0.003       0.003\nEmpSha   0.634     0.625       0.611\n\n$tab.v\n       v.weights\nConGDP 0.149    \nInvGDP 0.088    \nExpGDP 0.148    \nImpGDP 0.153    \nLPG    0.182    \nEmpSha 0.28     \n\n$tab.w\n   w.weights      unit.names unit.numbers\n1      0.000       Australia            1\n2      0.000         Austria            2\n3      0.000         Belgium            3\n4      0.000          Canada            4\n5      0.000         Finland            5\n6      0.000          France            6\n7      0.002         Germany            7\n8      0.000         Hungary            8\n9      0.067         Iceland            9\n10     0.000         Ireland           10\n11     0.145           Italy           11\n12     0.000           Japan           12\n13     0.000           Korea           13\n14     0.048      Luxembourg           14\n15     0.000     Netherlands           15\n16     0.000     New Zealand           16\n17     0.000          Norway           17\n18     0.000        Portugal           18\n19     0.000 Slovak Republic           19\n20     0.000           Spain           20\n21     0.000          Sweden           21\n22     0.000     Switzerland           22\n24     0.738   United States           24\n\n$tab.loss\n       Loss W    Loss V\n[1,] 0.135733 0.6083746\n\n\nFür die tabellarische Darstellung mit gt::gt() berücksichtigen wir lediglich Volkswirtschaften mit Gewicht &gt; .0001.\n\n# Darstellung mit gt()\ntb$tab.w %&gt;% \n  # Berücksichtige nur Länder mit relevanten Gewichten\n  filter(w.weights &gt; .0001) %&gt;% \n  arrange(desc(w.weights)) %&gt;% \n  gt::gt() %&gt;%\n  tabopts\n\n\n\nTabelle 12.2: Gewichte für den synthetischen UK-Doppelgänger\n\n\n\n\n\n\n\n\n\nw.weights\nunit.names\nunit.numbers\n\n\n\n\n0.738\nUnited States\n24\n\n\n0.145\nItaly\n11\n\n\n0.067\nIceland\n9\n\n\n0.048\nLuxembourg\n14\n\n\n0.002\nGermany\n7\n\n\n\n\n\n\n\n\n\n\nDer synthetische UK-Doppelgänger kann nun gemäß der Vorschrift \\(\\eqref{eq:dgkonst}\\) konstruiert werden. Wir erzeugen hierzu ein tibble-Objekt mit den entsprechenden ID-Variablen.\n\n# Doppelgänger konstruieren\ndoppelganger &lt;- left_join(\n  x = brexit, \n  y = tb$tab.w, \n  by = c(\"Country\" = \"unit.names\")\n) %&gt;% \n  select(Time, Year, Country, gdp, w.weights) %&gt;%\n  group_by(Time, Year) %&gt;%\n  summarise(\n    gdp = sum(gdp * w.weights, na.rm = T)\n  ) %&gt;%\n  mutate(type = \"Doppelgaenger\") %&gt;%\n  ungroup()\n\nglimpse(doppelganger)\n\nRows: 104\nColumns: 4\n$ Time &lt;dbl&gt; 1995.00, 1995.25, 1995.50, 1995.75, 1996.00, 1996.25, 1996.50, 19…\n$ Year &lt;dbl&gt; 1995, 1995, 1995, 1995, 1996, 1996, 1996, 1996, 1997, 1997, 1997,…\n$ gdp  &lt;dbl&gt; -36.87991, -36.70512, -36.32948, -35.72637, -35.34392, -34.57688,…\n$ type &lt;chr&gt; \"Doppelgaenger\", \"Doppelgaenger\", \"Doppelgaenger\", \"Doppelgaenger…\n\n\nFür die nachfolgenden Schritte der Analyse führen wir das beobachtete GDP für Großbritannien mit dem syntethischen GDP des Doppelgängers zusammen.\n\n# tibble mit UK-GDP erstellen\nUK &lt;- brexit %&gt;% \n  filter(Country == \"United Kingdom\") %&gt;% \n  select(Time, Year, gdp) %&gt;%\n  mutate(type = \"UK\")\n\n# UK und Doppelgänger zusammenführen\nthe_gdps &lt;- bind_rows(\n  doppelganger, UK\n)\n\nFür einen Vergleich von UK- und Doppelgänger-BIP folgen wir Born u. a. (2019) und berechnen die Differenz der BIP über den gesamten Zeitraum, die so genannte Doppelgänger-Gap.\n\n# UK-Doppelgänger-Gap berechnen\ngdp_gap &lt;- the_gdps %&gt;% \n  pivot_wider(\n    values_from = gdp, \n    names_from = \"type\"\n  ) %&gt;%\n  mutate(gdp_gap = UK - Doppelgaenger)\n\nAls ein Maß für die Unsicherheit bei der Schätzung des GDPs für den Doppelgänger berechnen Born u. a. (2019) die Standardabweichung der Doppelgänger-Gap für den Zeitraum vor dem Brexit-Referendum.\n\n# Standardabweichung der Gap vor dem Brexit-Vote\nsd_gap &lt;- gdp_gap %&gt;%\n  filter(Time &lt; 2016.25) %&gt;% \n  summarise(\n    sd = sd(gdp_gap)\n  ) %&gt;% \n  pull(sd)\n\nWir nutzen nun ggplot2::ggplot(), um den syntetischen Doppelgänger und das BIP für Großbritannien über den gesamten Zeitraum darzustellen. Für die Darstellung von Unsicherheit bei der Konstruktion des Doppelgängers unterlegen wir die Doppelgänger-Zeitreihe mit einer Schattierung in der Breite der geschätzten Standardabweichung von 0.78 für die Periode vor dem Referendum.\n\n(\n  p_gdp &lt;- ggplot() +\n    # 1-SD-Band um das Doppelgänger-GDP\n    geom_ribbon(\n      data = the_gdps %&gt;% \n        filter(type == \"Doppelgaenger\"), \n      mapping = aes(\n        x = Time, \n        ymin = gdp - sd_gap, \n        ymax = gdp + sd_gap\n      ), \n      fill = alpha(\"red\", alpha = .2), \n      color = \"white\"\n    ) +\n    # UK- und Doppelgänger-GDP\n    geom_line(\n      data = the_gdps, \n      mapping = aes(\n        x = Time, \n        y = gdp, \n        col = type\n      ),\n      lwd = 1\n    ) +\n    # Brexit-Referendum\n    geom_vline(\n      xintercept = 2016.25, \n      lty = \"dotted\"\n    ) +\n    scale_color_discrete(name = \"\") +\n    # Legende hinzufügen\n    cowplot::theme_cowplot() +\n    theme(legend.position = c(.025, .9))  \n)\n\n\n\n\n\n\n\nAbbildung 12.2: UK-BIP und synthetischer Doppelgänger\n\n\n\n\n\nAbbildung 12.2 zeigt, dass der synthetische Doppelgänger über weite Teile der Vorperiode eine gute Anpassung an das beobachtete BIP von Großbritannien aufweist, insbesondere für den Zeitraum unmittelbar vor dem Brexit-Referendum. Nach dem Referendum zeigt sich bereits nach wenigen Quartalen eine deutliche Abweichung zwischen der geschätzten und der beobachteten Trajektorie. Eine Beschränkung der in p_gdp verwendeten Datenpunkte auf einen Bereich nahe des Referendums bestärkt diese Schlussfolgerung.\n\n# Close-up im Bereich des Referendums\np_gdp +\n  scale_x_continuous(\n    limits = c(2015, 2021), \n    expand = c(0, .1)\n    ) +\n  scale_y_continuous(limits = c(-4, 12))\n\n\n\n\n\n\n\nAbbildung 12.3: UK-BIP und synthetischer Doppelgänger – Close-Up\n\n\n\n\n\nIn Abbildung 12.2 ist eine ab Mitte 2017 außerhalb des Standardabweichungsbereichs verlaufende Divergenz der Zeitreihen zu erkennen. Diese stellen wir nachfolgend anhand der Doppelgänger-Gap mit ggplot2::ggplot() dar.\n\n# BIP-Doppelgänger-Gap\nggplot(data = gdp_gap) +\n  geom_hline(yintercept = 0) +\n  geom_line(\n    mapping = aes(x = Time, y = gdp_gap),\n    lwd = 1\n  ) + \n  geom_ribbon(\n    mapping = aes(\n      x = Time, \n      ymin = gdp_gap - sd_gap, \n      ymax = gdp_gap + sd_gap\n    ), \n    fill = alpha(\"darkgray\", alpha = .2), \n    color = \"white\"\n  ) +\n  # Referendum\n  geom_vline(\n    xintercept = 2016.25,\n    lty = \"dotted\"\n  ) +\n  scale_x_continuous(\n    expand = c(0, .1), \n    limits = c(2015, 2021)\n  ) +\n  scale_y_continuous(limits = c(-6, 1.5)) +\n  cowplot::theme_cowplot()\n\n\n\n\n\n\n\nAbbildung 12.4: UK-BIP und synthetischer Doppelgänger – Doppelgänger-Gap\n\n\n\n\n\nDie in Abbildung 12.4 gezeigte Doppelgänger-Gap stimmt gut mit dem von Born u. a. (2019) geschätzten verlorenen Wachstums des BIP relativ zu 2016 um bis zu 2.5% bis Ende des Jahres 2018 überein.\nAls weiteres Maß für den Effekt des Referendums im Folgezeitraum können wir die mittlere Doppelgänger-Gap für sämtliche Beobachtungsperioden nach dem Brexit-Referendum schnell bestimmen.\n\n# Mittlerer Unterschied nach dem Brexit-Referendum\ngdp_gap %&gt;% \n  filter(Time &gt; 2016.25) %&gt;% \n  pull(gdp_gap) %&gt;% \n  mean()\n\n[1] -2.343273\n\n\n\n12.2.1 Placebo-Tests: Grafische Inferenz\nAuch für SCM sind Placebo-Tests ein hilfreiches Instrument zur Überprüfung der Gültigkeit von Studienergebnissen. Eine gründliche Placebo-Analyse kann festzustellen, ob der beobachtete Effekt tatsächlich auf die Intervention zurückzuführen ist und nicht auf unberücksichtigte (möglicherweise unbeobachtbare) Faktoren.\nEin Ansatz ist hierfür ist es, den synthetische-Doppelgänger für fiktive Interventionszeitpunkte vor dem tatsächlichen Behandlungszeitpunkt zu konstruieren, und die entsprechenden Trajektorien mit dem ursprünglichen Doppelgänger zu vergleichen. So kann die Validität der ursprünglichen Doppelgänger-Trajektorie im Hinblick auf mögliche anderweitige Ereignisse vor der Intervention geprüft werden: Doppelgänger-Trajektorien für fiktive, frühere Interventionen sollten sich nicht systematisch von der andhand von Daten bis zur tatsächlichen Intervention berechneten Trajektorie unterscheiden.\nWir definieren hierzu eine Funktion placebo(), die einen syntethischen Doppelgänger des BIP Großbritanniens mit Gewichten auf Basis eines vorgegebenen Interventionszeitpunktes (treat) zurückgibt. Abgesehen vom früheren Interventionszeitpunkt (und der damit einhergehenden verkleinerten Stichprobe) erfolgt die Berechnung der Gewichte mit derselben Spezifikation wie zuvor.\n\n# Funktion für Placebo-Doppelgänger:\n# Fiktive frühere Intervention\nplacebo &lt;- function(treat) {\n  \n  # Datenvorbereitung für fiktives Datum 'treat'\n  dataprep_out &lt;- dataprep(\n    foo = brexit, \n    predictors = c(\n      \"ConGDP\", \"InvGDP\",\n      \"ExpGDP\", \"ImpGDP\",\n      \"LPG\", \"EmpSha\"\n    ), \n    dependent = \"gdp\", \n    unit.variable = \"ID\",\n    time.variable = \"Time\", \n    treatment.identifier = 23, \n    controls.identifier = (brexit$ID %&gt;% unique())[-23], \n    time.predictors.prior = seq(1995, treat, .25),\n    time.optimize.ssr = seq(1995, treat, .25),\n    unit.names.variable = \"Country\"\n    )\n  \n  # Doppelgänger bestimmen\n  synth_out &lt;- quietly(synth)(dataprep_out)$result\n  \n  # Ergebnisse auslesen\n  tb &lt;- synth.tab(\n    synth.res = synth_out, \n    dataprep.res = dataprep_out\n    )\n  \n  return(\n    \n    # Doppelgänger konstruieren \n    left_join(\n      x = brexit, \n      y = tb$tab.w, \n      by = c(\"Country\" = \"unit.names\")\n    ) %&gt;% \n      select(Time, Country, gdp, w.weights) %&gt;%\n      group_by(Time) %&gt;%\n      summarise(\n        gdp = sum(gdp * w.weights, na.rm = T)\n      ) %&gt;%\n      mutate(type = paste0(\"Placebo\", treat))  \n    )\n  \n}\n\nWie in Born u. a. (2019) berechnen wir nun 12 Placebo-Doppelgänger des BIP von Großbritannien für fiktive Zeitpunkte eines Referendums über sämtliche Quartale im Zeitraum 2010-Q1 bis 2016-Q1. Dies ist komfortabel durch Iteration von placebo() über diese Zeitpunkte mit purrr::map_dfr() umsetzbar.\n\n# Iteration über fiktive frühere Referenden\nplacebos_tbl &lt;- map_dfr(\n  .x = seq(2010, 2016, .25), \n  .f =  \\(x) placebo(x) \n)\n\nplacebos_tbl ist ein tibble-Objekt im tidy-Format. Wir können die Placebo-Doppelgänger sowie den ursprünglich berechneten Doppelgänger und das tatsächliche BIP also ähnlich wie in Abbildung 12.2 mit ggplot2::ggplot() darstellen.\n\n# Vergleich mit Placebo-Doppelgänger\n(\n  p_UKDG &lt;- ggplot(\n    data = placebos_tbl,\n    mapping = aes(\n      x = Time, \n      y = gdp, \n      group = type\n    )\n  ) +\n    # Placebos (mit jitter)\n    geom_line(\n      lwd = .25, \n      col = \"gray80\",\n      position = position_jitter(height = .25)\n    ) +\n    # Ursprünglicher Doppelgänger\n    geom_line(\n      data = the_gdps %&gt;% \n        filter(type == \"Doppelgaenger\"), \n      mapping = aes(col = type), \n      lwd = 1\n    ) +\n    # Beobachtetes BIP\n    geom_line(\n      data = the_gdps %&gt;% \n        filter(type == \"UK\"), \n      mapping = aes(col = type), \n      lwd = 1\n    ) +\n    # Intikator für Referendum\n    geom_vline(xintercept = 2016.25, lty = \"dotted\") +\n    # Formatierung\n    cowplot::theme_cowplot() +\n    theme(legend.position = c(.05, .9))\n)\n\n\n\n\n\n\n\nAbbildung 12.5: Placebo-Doppelgänger\n\n\n\n\n\n\n# Close-up bei Referendum\np_UKDG +\n      scale_x_continuous(\n      limits = c(2015, 2021), expand = c(0, .05)\n    ) +\n      scale_y_continuous(\n      limits = c(-3, 13),  expand = c(0, 0)\n    )\n\n\n\n\n\n\n\nAbbildung 12.6: Placebo-Doppelgänger – Close-Up\n\n\n\n\n\nBeachte, dass position = position_jitter(height = .25) eine zufällige, kleine Verschiebung (jitter) der Trajektorien der Placebo-Doppelgänger für eine bessere Unterscheidbarkeit bewirkt. Abbildung 12.5 und Abbildung 12.6 zeigen, dass sich die Placebo-Pfade für fiktive frühere Referenden (grau) nicht systematisch vom ursprünglich berechneten synthetischen Doppelgänger (rot) unterscheiden. Insbesondere finden wir keinen Rückgang der synthetischen BIP relativ zum beobachteten BIP für Großbritannien vor dem Referendum. Deutliche Abweichungen vom tatsächlichen BIP ergeben sich erst jenseits der tatsächlichen Referendums. Diese Placebo-Analyse bekräftigt also die Validität der Konstruktion des “Benchmark-Doppelgängers” für die Periode bis 2016-Q2 und die Schätzung des kausalen Effekts des Referendums anhand der entsprechenden Doppelgänger-Gap.\nEin weiterer Placebo-Test in Born u. a. (2019) ist ein Vergleich der Doppelgänger-Gap Großbritanniens mit Doppelgänger-Gaps für fiktive Referenden in 2016-Q2 in Ländern mit wesentlichem Einfluss bei der Konstruktion des synthetischen Doppelgängers für Großbritannien: Die Schätzung des kausalen Effekts des Referendums auf das BIP in Großbritannien ist glaubwürdig, wenn lediglich die Doppelgänger-Gap für Großbritannien durch das Referendum beeinflusst wird, nicht aber die Doppelgänger-Gaps für Länder in der Kontrollgruppe.\nFür diese grafische Placebo-Analyse modifizieren wir die Funktion placebo() entsprechend. placebo_gap() berechnet die Doppelgänger-Gap für das mit treat identifizierte Land. Das if-Statement zu Beginn stellt sicher, dass Großbritannien nicht als Kontroll-Einheit für die Placebo-Gaps verwendet wird.\n\n# Funktion für Placebo-Gaps\nplacebo_gap &lt;- function(treat) {\n  \n  # Kontrollgruppe definieren\n  if(treat != 23) {\n    controls &lt;- (1:24)[-c(23, treat)]\n  } else {\n    controls &lt;- (1:24)[-23]\n  }\n  \n  # Daten vorbereiten\n  dataprep_out &lt;- dataprep(\n    foo = brexit, \n    predictors = c(\n      \"ConGDP\", \"InvGDP\",\n      \"ExpGDP\", \"ImpGDP\",\n      \"LPG\", \"EmpSha\"\n    ), \n    dependent = \"gdp\", \n    unit.variable = \"ID\",\n    time.variable = \"Time\", \n    treatment.identifier = treat, \n    controls.identifier = controls, \n    time.predictors.prior = seq(1995, 2016.25, .25),\n    time.optimize.ssr = seq(1995, 2016.25, .25),\n    unit.names.variable = \"Country\"\n  )\n  \n  # Gewichte bestimmen\n  synth_out &lt;- quietly(synth)(dataprep_out)$result\n  \n  # Ergebnisse zusammenfassen\n  tb &lt;- synth.tab(\n    synth.res = synth_out, \n    dataprep.res = dataprep_out\n  )\n  \n  # Doppelgänger bestimmen\n  doppel &lt;- left_join(\n    x = brexit, \n    y = tb$tab.w, \n    by = c(\"Country\" = \"unit.names\")\n  ) %&gt;% \n    select(Time, gdp, Country, w.weights) %&gt;%\n    group_by(Time) %&gt;%\n    summarise(\n      gdp_synth = sum(gdp * w.weights, na.rm = T), \n    )\n  \n  # Beobachtetes BIP auslesen\n  gdp &lt;- brexit %&gt;% filter(ID == treat) %&gt;% pull(gdp)\n  \n  return(\n    \n    # Doppelgänger-Gap berechnen\n    doppel %&gt;% \n      mutate(\n        ID = treat,\n        gdp = gdp,\n        gdp_gap = gdp - gdp_synth\n      )\n    \n  )\n  \n}\n\nFür die Berechnung der Placebo-Gaps iterieren wir über die Indizes der in Tabelle 12.2 gelisteten Volkswirtschaften der Kontrollgruppe für Großbritannien.\n\n# Indizes für \"Donor Countries\" und UK\ndonors_and_UK &lt;- brexit %&gt;% \n  select(ID, Country) %&gt;% \n  distinct() %&gt;%\n  filter(\n    Country %in% \n      c(\n        \"United States\", \"Italy\", \"Iceland\", \n        \"Luxembourg\", \"Germany\", \"United Kingdom\"\n      )\n  ) %&gt;%\n  pull(ID)\n\n\n# Placebo-Doppelgänger-Gaps berechnen\nplacebo_gaps_tbl &lt;- map_dfr(\n  .x = donors_and_UK, \n  .f =  \\(x) placebo_gap(x) \n)\n\nFür die grafische Darstellung ergänzen wir die Variable Country zur Unterscheidung der Doppelgänger-Gaps für Großbritannien und die Kontroll-Länder.\n\n# ID-Variable für UK und Kontroll-Länder\nplacebo_gaps_tbl &lt;- placebo_gaps_tbl %&gt;%\n  mutate(\n    Country = ifelse(ID == 23, \"UK\", \"else\")\n  )\n\nUm die Vergleichbarkeit der Doppelgänger-Gaps zu gewährleisten, standardisieren Born u. a. (2019) die Schätzungen der Gaps anhand der jeweiligen Mittelwerte für das Jahr 2015 und der Standardabweichungen im Zeitraum vor dem Brexit-Referendum. Wir berechnen diese Statistiken zunächst.\n\n# Mittelwerte für 2015\nmeans &lt;- placebo_gaps_tbl %&gt;% \n  group_by(ID) %&gt;% \n  filter(between(Time, 2015, 2015.75)) %&gt;% \n  summarise(\n    mean2015 = mean(gdp_gap)\n  )\n\n# Standardabweichungen vor Referendum\nsds &lt;- placebo_gaps_tbl %&gt;% \n  group_by(ID) %&gt;% \n  filter(Time &lt; 2016.25) %&gt;% \n  summarise(\n    thesd = sd(gdp_gap)\n  )\n\nMit dplyr::left_join() führen wir diese Statistiken mit placebo_gaps_tbl zusammen und berechnen die standardisierten Doppelgänger-Gaps.\n\n# Join + Standardisierung\nplacebo_gaps_std &lt;- \n  left_join(placebo_gaps_tbl, means) %&gt;% \n  left_join(sds) %&gt;%\n  mutate(gdp_gap_std = (gdp_gap - mean2015)/thesd)\n\nAnalog zum Code für Abbildung 12.4 plotten wir die Placebo-Gap-Zeitreihen mit ggplot2::ggplot().\n\n# Placebo-Gaps mit UK-Gap vergleichen\nggplot(\n  data = placebo_gaps_std,\n  mapping = aes(\n    x = Time, \n    y = gdp_gap_std,\n    group = ID,\n    lwd = Country,\n    color = Country\n  )\n) +\n  # Hilfslinie bei Differenz = 0\n  geom_hline(yintercept = 0) +\n  # Gaps\n  geom_line() +\n  # Referendum\n  geom_vline(xintercept = 2016.25, lty = \"dotted\") +\n  # Formatierung\n  scale_color_manual(\n    values = c(\"UK\" = \"steelblue\", \"else\" = alpha(\"darkgray\", .5))\n  ) +\n  scale_linewidth_manual(\n    values = c(\"UK\" = 1, \"else\" = .5)\n  ) +\n  scale_x_continuous(\n    limits = c(2015, 2021), expand = c(0, .05)\n  ) +\n  theme_cowplot() +\n  theme(legend.position = c(.05, .9))\n\n\n\n\n\n\n\nAbbildung 12.7: Placebo- und UK-Doppelgänger-Gaps\n\n\n\n\n\nAbbildung 12.7 zeigt die standardisierten Placebo-Doppelgänger-Gaps für ein fiktives Referendum zum Zeitpunkt 2016-Q2 in den 5 Kontroll-Volkswirtschaften, die für Konstruktion des BIP-Doppelgängers von Großbrittannien relevant sind (grau). Der Vergleich mit der standardisierten Doppelgänger-Gap für Großbritannien (blau). Der Verlauf der Placebo-Gaps zeigt an, dass keine Abweichungen mit negativem Trend von der Referenzlinie bei 0 (kein Unterschied zwischen beobachtetem und syntetischem BIP) nach dem Referendum vorliegen. Damit liefert die Grafik keine Hinweise auf einen Effekt fiktiver Interventionen in den Kontroll-Ländern. Für Großbritannien jedoch ist, ähnlich wie in Abbildung 12.4, ein negativer Trend nach dem Referendum deutlich erkennbar.\n\n\n12.2.2 Statistische Inferenz\nDie bisherigen Placebo-Tests liefern lediglich grafische Evidenz für die Signifikanz des negativen Effekts des Brexit-Referendums auf die Britische Volkswirtschaft. Methoden für statistische Inferenz für SCM sind Gegenstand aktueller Forschung. Born u. a. (2019) verwenden den End-Of-Sample Instability Test (\\(S\\)) von Andrews (2003). Dieses Verfahren kann für einen Test auf einen Strukturbruch gegen Ende einer Zeitreihe verwendet werden. In der vorliegende Studie wird der Test angewendet, um zu überprüfen, ob die Verteilung der Doppelgänger-Gap Großbritanniens für die letzen \\(m\\) Perioden jenseits des Referendums signifikant verschieden ist von Verteilung vorheriger Perioden.\nWir zeigen nachfolgend, wie diese Analyse in R mit der Funktion CPAT::Andrews.test() aus dem Paket CPAT durchgeführt werden kann. Wir testen zunächst auf eine signifikante Diskrepanz der Doppelgänger-Gap in Form eines Sturkturbruchs ab 2017 und fassen die Ergebnisse tabellarisch mit broom::tidy() und gt::gt() zusammen.\n\nlibrary(CPAT)\n\n# Andrews' (2003) Test für 2017 durchführen\nAndrews.test(\n  x = gdp_gap$gdp_gap, \n  M = which(gdp_gap$Time == 2017)\n) %&gt;% \n  broom::tidy() %&gt;% \n  gt::gt() %&gt;%\n  tabopts\n\n\n\nTabelle 12.3: Andrews’ (1993) End-of-Sample Instability Test\n\n\n\n\n\n\n\n\n\nstatistic\np.value\nmethod\n\n\n\n\n14.196\n0.693\nAndrews' Test for Structural Change\n\n\n\n\n\n\n\n\n\n\nGem. des großen \\(p\\)-Werts kann die Nullhypothese (keine strukturelle Veränderung ab 2017) nicht abgelehnt werden. Wir führen den Test nun für sämtliche Zeitpunkte ab 2017 durch und plotten die \\(p\\)-Werte nebst gepunkteten roten Hilfslinien für die gängigen Signifikanzniveaus (10%, 5%, 1%).\n\n# Andrews' (1993) test für \n# Post-Referendumsperioden\npvals_andrews &lt;- map(seq(2017, 2020.5, .25), \\(time) {\n  tibble(\n    Time = time,\n    gap = gdp_gap %&gt;% filter(Time == time) %&gt;% pull(gdp_gap),\n    pvalue = CPAT::Andrews.test(\n      x = gdp_gap$gdp_gap, \n      M = which(gdp_gap$Time == time)\n    )$p.value\n  )\n}) %&gt;% \n  bind_rows()\n\n\n# p-Werte für Post-Interventionsperioden\npvals_andrews %&gt;%\n  ggplot(mapping = aes(x = Time, y = pvalue)) + \n  geom_hline(\n    yintercept = c(.1,.05, .01), \n    lty = \"dotted\", \n    col = \"red\"\n  ) +\n  geom_line() +\n  scale_x_continuous(expand = c(0, 0)) +\n  cowplot::theme_cowplot()\n\n\n\n\n\n\n\nAbbildung 12.8: P-Werte für Andrews’ (2003) Test\n\n\n\n\n\nDer Verlauf der \\(p\\)-Werte zeigt deutlich, dass es für Zeitpunkte jenseits von 2018-Q3 Evidenz für eine strukturelle Veränderung der Doppelgänger-Gap für Großbrittannien gibt. Diese Ergebnisse untermauern die Signifikanz der in Born u. a. (2019) mit SCM gefundenen negativen Effekte des Brexit-Votums auf die Britische Volkswirtschaft weiter.\n\n\n\n\nAbadie, Alberto, Alexis Diamond, und Jens Hainmueller. 2014. „Comparative Politics and the Synthetic Control Method: COMPARATIVE POLITICS AND THE SYNTHETIC CONTROL METHOD“. American Journal of Political Science 59 (2): 495–510. https://doi.org/10.1111/ajps.12116.\n\n\nAbadie, Alexis Diamond, Alberto, und Jens Hainmueller. 2010. „Synthetic Control Methods for Comparative Case Studies: Estimating the Effect of California’s Tobacco Control Program.“ Journal of the American Statistical Association 105 (490): 493–505. https://doi.org/10.1198/jasa.2009.ap08746.\n\n\nAndrews, D. W. K. 2003. „End-of-Sample Instability Tests“. Econometrica 71 (6): 1661–94. https://doi.org/10.1111/1468-0262.00466.\n\n\nBorn, Benjamin, Gernot J Müller, Moritz Schularick, und Petr Sedláček. 2019. „The Costs of Economic Nationalism: Evidence from the Brexit Experiment*“. The Economic Journal 129 (623): 2722–44. https://doi.org/10.1093/ej/uez020.\n\n\nHainmueller, Jens, Alexis Diamond, und Alberto Abadie. 2011. „Synth: An R Package for Synthetic Control Methods in Comparative Case Studies“. Journal of Statistical Software 42 (13): 1–17. https://www.jstatsoft.org/v42/i13/.",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Synthetic Control</span>"
    ]
  },
  {
    "objectID": "SyntheticControl.html#footnotes",
    "href": "SyntheticControl.html#footnotes",
    "title": "12  Synthetic Control",
    "section": "",
    "text": "Engl. für Mean squared prediction error↩︎",
    "crumbs": [
      "Kausale Inferenz",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Synthetic Control</span>"
    ]
  },
  {
    "objectID": "RegReg.html",
    "href": "RegReg.html",
    "title": "13  Regularisierte Regression",
    "section": "",
    "text": "13.1 Ridge Regression\nRidge Regression wurde von Hoerl und Kennard (1970) als Alternative zur KQ-Schätzung bei hoch-korrelierten Regressoren eingeführt. Die Verlustfunktion lautet \\[\\begin{align}\n  \\mathrm{RSS}(\\boldsymbol{\\beta},p=2,\\lambda) = \\mathrm{RSS}(\\boldsymbol{\\beta}) + \\lambda \\lVert\\boldsymbol{\\beta}\\rVert_2,\\label{eq:ridgeloss}\n\\end{align}\\] d.h. der Parameter \\(\\lambda\\) reguliert den Einfluss eines \\(\\ell_2\\)-Strafterms \\[\\begin{align*}\n  \\lVert\\boldsymbol{\\beta}\\rVert_2 = \\sqrt{\\sum_{j=1}^k\\beta_j^2}\n\\end{align*}\\] auf die Verlustfunktion \\(\\mathrm{RSS}(\\boldsymbol{\\beta},p=2,\\lambda)\\). Der Ridge-Schätzer ergibt sich als \\[\\begin{align}\n  \\widehat{\\boldsymbol{\\beta}}^{\\mathrm{R}}_\\lambda := \\arg\\min_{\\boldsymbol{\\beta}}\\mathrm{RSS}(\\boldsymbol{\\beta}) + \\lambda \\lVert\\boldsymbol{\\beta}\\rVert_2.\\label{eq:ridgereg}\n\\end{align}\\]\nFür Das Optimierungsproblem \\(\\eqref{eq:ridgereg}\\) kann wir aus den Bedingungen 1. Ordnung \\[\\begin{align}\n  -2\\boldsymbol{X}'(\\boldsymbol{Y} - \\boldsymbol{X}\\boldsymbol{\\beta}) + 2\\lambda\\boldsymbol{\\beta} = \\boldsymbol{0}\n\\end{align}\\] die analytische Lösung \\[\\begin{align}\n  \\widehat{\\boldsymbol{\\beta}}^{\\mathrm{R}}_\\lambda = (\\boldsymbol{X}'\\boldsymbol{X} + \\lambda\\boldsymbol{I}_p)^{-1}\\boldsymbol{X}'\\boldsymbol{Y},\\label{eq:ridgecf}\n\\end{align}\\] bestimmt werden, wobei \\(\\boldsymbol{I}_k\\) die \\(k\\times k\\) Einheitsmatrix ist. Aus Gleichung \\(\\eqref{eq:ridgecf}\\) kann die Wirkungsweise des Strafterms \\(\\lambda \\lVert\\boldsymbol{\\beta}\\rVert_2\\) abgeleitet werden: Ridge Regression modifiziert die Diagonale der zu invertierenden Matrix \\(\\boldsymbol{X}'\\boldsymbol{X}\\) durch Addition von \\(\\lambda&gt;0\\). Dies ist hilfreich, wenn\nFür eine grafische Betrachtung des Optimierungskalküls \\(\\eqref{eq:ridgereg}\\) betrachten wir die äquivalente Darstellung als Lagrange-Problem \\[\\begin{align}\n  \\widehat{\\boldsymbol{\\beta}}^{\\mathrm{R}}_\\lambda := \\arg\\min_{\\lVert\\boldsymbol{\\beta}\\rVert&lt;t}\\mathrm{RSS}(\\boldsymbol{\\beta}).\\label{eq:ridgeLg}\n\\end{align}\\] In der folgenden interaktiven Grafik illustrieren wir das Optimierungsproblem \\(\\eqref{eq:ridgeLg}\\) sowie den resultierenden Schätzer der Koeffizienten \\((\\beta_1, \\beta_2)\\) in einem multiplen Regressionsmodell mit den Regressoren \\(X_1\\) und \\(X_2\\).",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regularisierte Regression</span>"
    ]
  },
  {
    "objectID": "RegReg.html#ridge-regression",
    "href": "RegReg.html#ridge-regression",
    "title": "13  Regularisierte Regression",
    "section": "",
    "text": "\\(k\\geq n\\) und damit \\(\\boldsymbol{X}'\\boldsymbol{X}\\) nicht invertiertbar (singulär) ist. Dann kann der KQ-Schätzer nicht berechnet werden.3 Die Inverse \\((\\boldsymbol{X}'\\boldsymbol{X} + \\lambda\\boldsymbol{I}_p)^{-1}\\) hingegen existiert unter milden Bedingungen.\nhohe Kollinearität vorliegt, sodass \\((\\boldsymbol{X}'\\boldsymbol{X})^{-1}\\) zwar existiert, aber zu einer instablilen KQ-Schätzung mit hoher Varianz führt.\n\n\n\nDie blaue Ellipse ist die Menge aller Schätzwerte \\(\\left(\\widehat\\beta_{1},\\, \\widehat\\beta_{2}\\right)\\) für den angegebenen Wert von \\(\\mathrm{RSS}\\). Im Zentrum der Ellipse liegt der KQ-Schätzer, welcher \\(\\mathrm{RSS}\\) minimiert.\nDer blaue Kreis ist die Menge aller Koeffizienten-Paare \\((\\beta_1, \\beta_2)\\), welche die Restriktion \\(\\beta_1^2 + \\beta_2^2\\leq t\\) erfüllen. Beachte, dass die Größe des Kreises nur durch den Parameter \\(t\\) bestimmt wird, welcher für einen vorgegebenen Wertebereich variiert werden kann.\nDer blaue Punkt ist der Ridge-Schätzer \\((\\widehat\\beta^R_{1,t},\\, \\widehat\\beta^R_{2,t})\\). Dieser ergibt sich als Schnittpunkt zwischen der blauen \\(\\mathrm{RSS}\\)-Ellipse und der Restriktionsregion und variiert mit \\(t\\). Die gestrichelte rote Kurve zeigt den Ridge-Lösungspfad.\nFür kleine Werte \\(t\\) drückt die Shrinkage die geschätzten Koeffizienten Richtung 0, wobei der Lösungspfad i.d.R. nicht-linear verläuft, d.h. die Shrinkage auf den Koeffizienten ist grundsätzlich unterschiedlich. Die Lösung \\((\\widehat\\beta^R_{1,t},\\, \\widehat\\beta^R_{2,t}) = (0,0)\\) existiert nur als Grenzwert für \\(t\\to0\\).\nBeachte, dass der Effekt von \\(t\\) auf die Schätzung umgekehrt für \\(\\lambda\\) verläuft: Größere \\(\\lambda\\) führen zu stärkerer Regularisierung.\n\n\n\n\n13.1.1 Eigenschaften des Schätzers\nDer Ridge-Schätzer \\(\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{R}}_\\lambda\\) ist nicht invariant gegenüber der Skalierung der Regressoren. Für empirische Daten sollte daher vorab eine Standardisierung der erklärenden Variablen durchgeführt werden.4 Um die Eigenschaften des Ridge-Schätzers besser zu verstehen, betrachten wir hier den Fall orthonormaler Regressoren \\(\\boldsymbol{X}_j\\).5 Dann ist \\[\\begin{align}\n  \\widehat{\\beta}^{\\mathrm{R}}_{\\lambda,\\,j} = (1+\\lambda)^{-1} \\cdot\\widehat{\\beta}_j,\\quad j = 1,\\dots,k,\\label{eq:ridgeortho}\n\\end{align}\\] d.h. der Ridge-Schätzer skaliert die KQ-Lösung mit einem von \\(\\lambda\\) abhängigen Faktor.6\nWir illustrieren dies, indem wir den Zusammenhang zwischen KQ- und Ridge-Schätzer im orthonormalen Fall als R-Funktion ridge_ortho() implementieren und für die Parameterwerte \\(\\lambda\\in\\{0,0.5,2\\}\\) plotten.\n\nlibrary(tidyverse)\n\n# Funktion für Rige Regression bei orthonormalen Regressoren\nridge_ortho &lt;- function(KQ, lambda) {\n  1/(1 + lambda) * KQ\n}\n\n\n# KQ-Schätzer gegen Ridge-Schätzer plotten\ndat &lt;- tibble(KQ = seq(-1, 1, .01))\n\nggplot(dat) +\n  geom_function(fun = ridge_ortho, \n                args = list(lambda =  0), \n                lty = 2) + \n  geom_function(fun = ridge_ortho, \n                args = list(lambda = .5), \n                col = \"red\") + \n  geom_function(fun = ridge_ortho, \n                args = list(lambda = 2), \n                col = \"blue\") + \n  xlim(-.4, .4) +\n  xlab(\"KQ-Schätzer von beta_1\") +\n  ylab(\"Ridge-Schätzer von beta_1\")\n\n\n\n\n\n\n\nAbbildung 13.1: Shrinkage des OLS-Schätzers bei Ridge Regression\n\n\n\n\n\nAbbildung 13.1 zeigt, dass der Ridge-Schätzer eine lineare Transformation des KQ-Schätzers (gestrichelte Linie) ist. Größere Werte des Regularisierungsparameters \\(\\lambda\\) führen zu stärkerer Shrinkage des Koeffizientenschätzers in Richtung 0. Die \\(\\ell_2\\)-Norm führt zu proportional zum Absolutwert des KQ-Schätzers verlaufender Shrinkage: Größere Koeffizienten werden stärker bestraft als kleine Koeffizienten.\nDie Eigenschaft \\[\\mathrm{E}\\left(\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{R}}_{\\lambda,\\,j}\\right) = (1+\\lambda)^{-1} \\cdot \\beta_j\\] zeigt, dass \\(\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{R}}_{\\lambda,\\,j}\\) (für fixes \\(\\lambda&gt;0\\)) nicht erwartungstreu für \\(\\beta_j\\) ist. Weiterhin ist \\[\\begin{align*}\n  \\mathrm{Var}\\left(\\widehat{\\beta}^{\\mathrm{R}}_{\\lambda,\\,j}\\right) =&\\,\n  \\mathrm{Var}\\left(\\widehat{\\beta}_j\\right) \\cdot \\left(\\frac{\\lambda}{1+\\lambda^2}\\right)\\\\\n    =&\\, \\sigma^2\\cdot \\left(\\frac{\\lambda}{1+\\lambda^2}\\right),\n\\end{align*}\\] wobei \\(\\sigma^2\\) die Varianz des Regressionsfehlers \\(u\\) ist. Wegen \\(\\lambda&lt;(1+\\lambda)^2\\) für \\(\\lambda&gt;0\\) gilt \\[\\mathrm{Var}\\left(\\widehat{\\beta}^{\\mathrm{R}}_{\\lambda,\\,j}\\right)&lt;\\mathrm{Var}\\left(\\widehat{\\beta}_j\\right).\\] Der Ridge-Schätzer hat also eine kleinere Varianz als der KQ-Schätzer. Diese Eigenschaften können auch für korrelierte Regressoren gezeigt werden.\n\n\n13.1.2 Ridge Regression mit glmnet\nWir zeigen nun anhand simulierter Daten, wie der Ridge-Lösungspfad mit dem R-Paket glmnet berechnet werden kann. Wir erzeugen zunächst Daten gemäß der Vorschrift \\[\\begin{align}\n  \\begin{split}\n  Y_i =&\\, \\boldsymbol{X}_i' \\boldsymbol{\\beta} + u_i,\\\\\n  \\\\\n  \\beta_j =&\\,  \\frac{5}{j^2}, \\qquad\\qquad\\ j=1,\\dots,5,\\\\\n  \\beta_j =&\\, -\\frac{5}{(j-5)^2}, \\quad j=6,\\dots,10,\\\\\n  \\\\\n  \\boldsymbol{X}_i \\sim&\\, N(\\boldsymbol{0}, \\boldsymbol{\\Sigma}), \\quad u_i \\overset{u.i.v.}{\\sim} N(0, 1), \\quad i = 1,\\dots,25.\n  \\end{split} \\label{eq:ridgedgp1}\n\\end{align}\\] Hierbei wird \\(\\boldsymbol{\\Sigma}\\) so definiert, dass jeder Regressor \\(N(0,1)\\)-verteilt ist und eine Korrelation von \\(0.8\\) mit allen anderen Regressoren aufweist. Mit der Vorschrift für die \\(\\beta_j\\) stellen wir sicher, dass es wenige Variablen gibt, die \\(Y\\) stark beeinflussen, da der Absolutbetrag der Koeffizienten in \\(j\\) abnimmt.7\n\nlibrary(gendata)\nset.seed(1234)\n\n# Parameter definieren\nN &lt;- 80\nk &lt;- 10\n\ncoefs &lt;- 5/(1:(k/2))^2\nbeta &lt;- c(coefs, -coefs)\n\n# Beobachtungen simulieren\nX &lt;- as.matrix(\n  genmvnorm(\n    k = k, \n    cor = rep(.8, (k^2-k)/2), \n    n = N)\n  )\nY &lt;- X %*% beta + rnorm(N)\n\nWir schätzen nun ein Modell mit allen 10 Regressoren mit glmnet. Beachte, dass für den Ridge-Strafterm alpha = 0 gesetzt werden muss.8\n\nlibrary(glmnet)\n\n# Ridge-Regression anpassen\nridge_fit &lt;- glmnet(\n  x = X, \n  y = Y, \n  alpha = 0 # für Ridge-Strafterm\n)\n\nDer Lösungspfad der Ridge-Schätzung kann nach Transformation der geschätzen Koeffizienten und der zugehörigen \\(\\lambda\\)-Werte in ein langes Format überführt und komfortabel mit ggplot2 dargestellt werden.\n\n# Lambda-Sequenz auslesen\nlambdas &lt;- ridge_fit$lambda\n\n# Ridge-Schätzung für Lambdas im langen Format \nas.matrix(ridge_fit$beta) %&gt;% \n  as_tibble() %&gt;% \n  rownames_to_column(\"Variable\") %&gt;%\n  pivot_longer(-Variable) %&gt;% \n  group_by(Variable) %&gt;% \n  mutate(lambda = lambdas) %&gt;%\n  \n  # Grafik mit ggplot erzeugen\n  ggplot(\n    mapping = aes(\n      x = lambda, \n      y = value, \n      col = Variable\n    )\n  ) + \n  geom_line() +\n  ylab(\"gesch. Koeffizienten\") +\n  scale_x_log10(\"log_10(lambda)\")\n\n\n\n\n\n\n\nAbbildung 13.2: Lösungspfad für Ridge-Schätzung\n\n\n\n\n\nAbbildung 13.2 zeigt den nicht-linearen Verlauf der Shrinkage auf den geschätzten Modellkoeffizienten. Die Koeffizienten werden mit zunehmendem \\(\\lambda\\) von der KQ-Lösung ausgehend (linkes Ende der Skala) in Richtung 0 gezwungen.\nÜber die Funktion cv.glmnet() kann ein optimales \\(\\lambda\\) mit Cross Validation (CV) ermittelt werden. Ähnlich wie bei glmnet() wird für die Validierung automatisch eine \\(\\lambda\\)-Sequenz erzeugt. Wir nutzen autoplot() aus dem R-Paket ggfortify für die Visualisierung der Ergebnisse mit ggplot2.\n\nlibrary(ggfortify)\n\n# Cross-validierte Bestimmung von lambda\nridge_cvfit &lt;- cv.glmnet(\n  y = Y, \n  x = X, \n  intercept = F,\n  alpha = 0\n) \n\n# Ergebnisse plotten\nridge_cvfit %&gt;% \n  autoplot(label.n = 0)\n\n\n\n\n\n\n\nAbbildung 13.3: Lösungspfad für Ridge-Schätzung\n\n\n\n\n\nAbbildung 13.3 zeigt ridge_cvfit$lambda.min, das optimale \\(\\lambda\\) mit dem geringsten CV Mean-Squarred-Error (linke gestrichelte Linie) und ridge_cvfit$lambda.1se, das größte \\(\\lambda\\), welches innerhalb einer Standardabweichung entfernt ist (rechte gestrichelte Linie).9 Wir berechnen die Schätzung für lambda.min.\n\n(\n  ridge_coefs &lt;- coef(\n    object = ridge_cvfit, \n    s = ridge_cvfit$lambda.min\n  )\n)\n\n11 x 1 sparse Matrix of class \"dgCMatrix\"\n                    s1\n(Intercept)  .        \nX1           4.1302194\nX2           1.0245661\nX3           0.3139297\nX4           0.5697498\nX5           0.2928664\nX6          -4.1693524\nX7          -0.7509305\nX8          -0.3844761\nX9          -0.3841997\nX10         -0.4078514\n\n\nWir schätzen das Modell nun mit KQ und vergleichen die Koeffizienten mit der Ridge-Schätzung.\n\n# KQ-Schätzung durchführen\nKQ_fit &lt;- lm(Y ~ X - 1)\n\n# Koeffizienten auslesen und transformieren:\ntibble(\n  Ridge = as.matrix(ridge_coefs)[2:11, ],\n  KQ = KQ_fit$coefficients\n) %&gt;% \n  mutate(j = factor(1:10)) %&gt;%\n  pivot_longer(\n    cols = Ridge:KQ, \n    names_to = \"Methode\", \n    values_to = \"Koeffizient\"\n  ) %&gt;%\n\n# Bar-Plot für Koeffizientenvergleich erzeugen  \n  ggplot(\n    mapping = aes(\n      x = j, \n      y = Koeffizient, \n      fill = Methode\n    )\n  ) +\n  geom_bar(\n    position = \"dodge\", \n    stat = \"identity\", \n    width = .5\n  )\n\n\n\n\n\n\n\nAbbildung 13.4: Koeffizientenvergleich: Ridge vs. KQ\n\n\n\n\n\nDer Vergleich anhand von Abbildung 13.4 zeigt deutlich, dass Ridge Regression im Vergleich mit KQ zu absolut kleineren Koeffizientenschätzungen tendiert. Inwiefern dies Konsequenzen für die Prognosegüte der Schätzung hat, können wir Anhand eines Testdatensatzes bestimmen. Hierzu vergleichen wir die mittleren Fehler (MSE) bei der Prognose von \\(Y\\) für die Beobachtungen im Testdatensatz. Für die Simulation des Testdatensatzes nutzen wir erneut die Vorschrift \\(\\eqref{eq:ridgedgp1}\\) um 80 neue Beobachtungen zu erzeugen.\n\n# Test-Datensatz erstellen\nset.seed(4321)\n# Regressoren\nnew_X &lt;- as.matrix(\n  genmvnorm(\n    k = k, \n    cor = rep(.85, (k^2-k)/2), \n    n = N\n  )\n)\n# Abh. Variable\nnew_Y &lt;- new_X %*% beta + rnorm(N)\n\nFür beide Methoden können wir predict() für die Prognosen von \\(Y\\) für den Testdatensatz (new_Y) nutzen.\n\n# Ridge: Vorhersage von new_Y für Test-Datensatz\nY_predict_ridge &lt;- predict(\n  object = ridge_cvfit, \n  newx = new_X, \n  s = ridge_cvfit$lambda.min\n)\n\n# Ridge: MSE für Test-Datensatz berechnen\nmean((Y_predict_ridge - new_Y)^2)\n\n[1] 1.288457\n\n\nDie Vorhersage für lm() benötigt dieselben Variablennamen wie im angepassten Modell, s. KQ_fit$coefficients.\n\n# Test-Datensatz für predict.lm() formatieren\nnew_X &lt;- as.data.frame(new_X)\ncolnames(new_X) &lt;- paste0(\"X\", 1:k)\n\n# KQ: Vorhersage von new_Y für Test-Datensatz\nY_predict_KQ &lt;- predict(\n  object = KQ_fit, \n  newdata = new_X\n)\n\n# KQ: MSE für Test-Datensatz berechnen\nmean((Y_predict_KQ - new_Y)^2)\n\n[1] 29.33797\n\n\nDie Ergebnisse zeigen, dass der Ridge-Schätzer trotz seiner Verzerrung einen deutlich geringeren mittleren Vorhersagefehler für die Testdaten erzielt als der KQ-Schätzer. Diese Eigenschaft der Koeffizientenschätzung kann die Prognosegüte von Ridge Regression gegenüber der KQ-Regression verbessern.\n\n\n13.1.3 Beispiel: Vorhersage von Abschlussnoten in Mathe\nZur Illustration von Ridge Regression nutzen wir den Datensatz SP aus Cortez und Silva (2008).10 SP enhält Beobachtungen zu Leistungen von insgesamt 100 Schülerinnen und Schülern im Fach Mathematik in der Sekundarstufe an zwei portugiesischen Schulen. Neben der Abschlussnote in Mathe (G3, Skala von 0 bis 20) beinhaltet SP diverse demografische, soziale und schulbezogene Merkmale, die mithilfe von Schulberichten und Fragebögen erhoben wurden. Ziel ist es, ein Modell für die Prognose von G3 anzupassen.\nWir lesen zunächst die Daten (im .csv-Format) ein.\n\n# Daten einlesen\nSP &lt;- read_csv(file = \"datasets/SP.csv\")\n\nEin Überblick zeigt, dass der Großteil der Regressoren aus kategorialen Variablen mit sozio-ökonomischen Informationen besteht.\n\n# Überblick\nglimpse(SP)\n\nRows: 100\nColumns: 31\n$ school     &lt;chr&gt; \"GP\", \"GP\", \"GP\", \"MS\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\",…\n$ sex        &lt;chr&gt; \"M\", \"M\", \"F\", \"F\", \"M\", \"F\", \"F\", \"F\", \"F\", \"F\", \"M\", \"M\",…\n$ age        &lt;dbl&gt; 17, 18, 19, 17, 16, 16, 19, 16, 16, 16, 18, 16, 15, 17, 17,…\n$ address    &lt;chr&gt; \"R\", \"R\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"R\", \"U\", \"U\",…\n$ famsize    &lt;chr&gt; \"GT3\", \"GT3\", \"LE3\", \"GT3\", \"LE3\", \"GT3\", \"GT3\", \"GT3\", \"GT…\n$ Pstatus    &lt;chr&gt; \"T\", \"T\", \"T\", \"T\", \"A\", \"T\", \"T\", \"T\", \"A\", \"T\", \"T\", \"T\",…\n$ Medu       &lt;dbl&gt; 1, 4, 3, 2, 3, 2, 0, 2, 3, 4, 4, 2, 1, 2, 2, 3, 3, 4, 4, 2,…\n$ Fedu       &lt;dbl&gt; 2, 3, 2, 2, 4, 3, 1, 1, 1, 4, 4, 2, 2, 3, 2, 3, 1, 3, 4, 2,…\n$ Mjob       &lt;chr&gt; \"at_home\", \"teacher\", \"services\", \"other\", \"services\", \"oth…\n$ Fjob       &lt;chr&gt; \"other\", \"services\", \"other\", \"at_home\", \"other\", \"other\", …\n$ reason     &lt;chr&gt; \"home\", \"course\", \"reputation\", \"home\", \"home\", \"reputation…\n$ guardian   &lt;chr&gt; \"mother\", \"mother\", \"other\", \"mother\", \"mother\", \"mother\", …\n$ traveltime &lt;dbl&gt; 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1,…\n$ studytime  &lt;dbl&gt; 2, 3, 2, 3, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 3, 1, 2,…\n$ failures   &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ schoolsup  &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"yes\", \"yes\", \"no\", \"no\", \"no\", \"no…\n$ famsup     &lt;chr&gt; \"no\", \"no\", \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"yes\", …\n$ paid       &lt;chr&gt; \"no\", \"no\", \"yes\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"yes\", \"n…\n$ activities &lt;chr&gt; \"no\", \"no\", \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"no\", \"y…\n$ nursery    &lt;chr&gt; \"yes\", \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"yes\", \"yes\"…\n$ higher     &lt;chr&gt; \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"no\", \"yes\", \"yes…\n$ internet   &lt;chr&gt; \"no\", \"yes\", \"yes\", \"no\", \"yes\", \"no\", \"no\", \"yes\", \"yes\", …\n$ romantic   &lt;chr&gt; \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"…\n$ famrel     &lt;dbl&gt; 3, 5, 4, 3, 5, 4, 3, 4, 2, 2, 1, 5, 4, 5, 3, 5, 4, 4, 5, 5,…\n$ freetime   &lt;dbl&gt; 1, 3, 2, 4, 3, 4, 4, 5, 3, 4, 4, 4, 3, 3, 4, 4, 5, 2, 3, 4,…\n$ goout      &lt;dbl&gt; 3, 2, 2, 3, 3, 3, 2, 2, 3, 4, 2, 4, 2, 3, 4, 2, 4, 2, 3, 4,…\n$ Dalc       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1,…\n$ Walc       &lt;dbl&gt; 5, 2, 2, 1, 1, 3, 1, 1, 2, 3, 2, 4, 1, 3, 3, 1, 3, 2, 1, 1,…\n$ health     &lt;dbl&gt; 3, 4, 1, 3, 5, 4, 5, 5, 4, 4, 1, 5, 5, 3, 5, 5, 1, 3, 5, 5,…\n$ absences   &lt;dbl&gt; 4, 9, 22, 8, 4, 6, 2, 20, 5, 6, 5, 0, 2, 2, 12, 0, 17, 0, 4…\n$ G3         &lt;dbl&gt; 10, 16, 11, 11, 11, 10, 9, 12, 7, 11, 16, 12, 9, 12, 12, 13…\n\n\nUm die Prognosegüte des Modells beurteilen zu können, partitionieren wir SP zufällig in einen Test- sowie einen Trainingsdatensatz (mit 30 und 70 Beobachtungen), jeweils für die Regressoren und die abhängige Variable.\n\n# ID für Beobachtungen im Testdatensatz zufällig erzeugen\nset.seed(1234)\nID &lt;- sample(1:nrow(SP), size = 30)\n\n# Regressoren aufteilen\nSP_test &lt;- SP[ID,]\nSP_train &lt;- SP[-ID,]\n\n# Abh. Variable aufteilen\nY_test &lt;- SP_test$G3\nY_train &lt;- SP_train$G3\n\nAls nächstes passen wir ein Ridge-Regressionsmodell für alle Regressoren in SP_train an und ermitteln ein optimales \\(\\lambda\\) mit Cross Validation. Beachte, dass cv.glmnet nicht für Regressoren im data.frame/tibble-Format ausgelegt ist, sondern ein matrix-Format erwartet. Wir transformieren SP_train daher mit data.matrix().\n\n# Ridge-Regression und CV für Trainingsdaten\nSP_fit_cv &lt;- cv.glmnet(\n  x = data.matrix(SP_train %&gt;% select(-G3)), \n  y = Y_train, \n  alpha = 0\n)\n\n# CV-Ergebnisse für lambda visualisieren\nSP_fit_cv %&gt;% \n  autoplot(label.n = 0)\n\n\n\n\n\n\n\n\nWie für das Beispiel mit simulierten Daten erhalten wir mit predict() Vorhersagen für die erzielte Punktzahl. Beachte, dass wir den MSE nicht für die Trainingsdaten SP_train, sondern für die Testdaten SP_test berechnen.\n\n# Prognose von G3 anhand des Ridge-Modells\nY_predict_ridge &lt;- predict(\n  object = SP_fit_cv, \n  newx = data.matrix(\n    SP_test %&gt;% \n      select(-G3)\n    ), \n  s = SP_fit_cv$lambda.min\n)\n\n# MSE für Testdaten berechnen\nmean((Y_predict_ridge - Y_test)^2)\n\n[1] 21.13249\n\n\nAuch in diesem empirischen Beispiel zeigt ein Vergleich der MSEs, dass Ridge Regression dem KQ-Schätzer hinsichtlich der Vorhersagegüte überlegen ist.\n\n# Modell mit KQ schätzen\nSP_fit_KQ &lt;- lm(G3 ~ ., SP_train)\n\n# Prognose\nY_predict_KQ &lt;- predict(\n  object = SP_fit_KQ, \n  newdata = SP_test %&gt;% \n    select(-G3)\n)\n\n# Testset-MSE berechnen\nmean((Y_predict_KQ - Y_test)^2)\n\n[1] 29.76893\n\n\nDer MSE für Ridge ist mit \\(21.13\\) deutlich kleiner als \\(29.77\\), der MSE für KQ.\nFür die Interpretation der Ridge-Schätzung erweitern den Code für die ggplot2-Grafik der Koeffizienten-Pfade um eine vertikale Linie des mit CV ermittelten \\(\\lambda\\) und fügen mit dem Paket ggrepel Labels für die Pfade der größten Koeffizienten hinzu.\n\nlibrary(ggrepel)\n\n# Lambda-Sequenz auslesen\nlambdas &lt;- SP_fit_cv$lambda\n\n# Ridge-Schätzung für Lambdas im langen Format \ndf &lt;- as.matrix(SP_fit_cv$glmnet.fit$beta) %&gt;% \n  as_tibble() %&gt;% \n  mutate(\n    Variable = rownames(SP_fit_cv$glmnet.fit$beta)\n  ) %&gt;%\n  pivot_longer(-Variable) %&gt;% \n  group_by(Variable) %&gt;% \n  mutate(lambda = lambdas) \n\n# Grafik mit ggplot erzeugen\ndf %&gt;%\n  ggplot(\n    mapping = aes(\n      x = lambda, \n      y = value, \n      col = Variable\n    )\n  ) + \n  geom_line() +\n  geom_label_repel(\n    data = df %&gt;% \n      filter(lambda == min(lambdas)),\n    mapping = aes(label = Variable), \n    seed = 1234,\n    size = 5, \n    max.overlaps = 8, \n    nudge_x = -.5) +\n  ylab(\"gesch. Koeffizienten\") +\n  scale_x_log10(\"log_10(lambda)\") +\n  geom_vline(\n    xintercept = SP_fit_cv$lambda.min, \n    col = \"red\", \n    lty = 2\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nAbbildung 13.5: Lösungspfad für Ridge-Schätzung\n\n\n\n\n\nAbbildung 13.5 gibt Hinweise darauf, dass neben der Schulzugehörigkeit und Indikatoren für schulische Leistung (bspw. failures) sozio-ökonomische Prädiktoren wie internet (Internetzugang zuhause), Pstatus (Zusammenleben der Eltern) und address/traveltime (sozialer Status) relevante Variablen zu sein scheinen.\nDas optimale \\(\\lambda_\\mathrm{cv} \\approx 0.21\\) (gestrichelte rote Linie in Abbildung 13.5) führt zu deutlicher Shrinkage, was eine mögliche Erklärung für den besseren Testset-MSE von Ridge Regression ist: Die Koeffizienten von Variablen mit wenig Erklärungskraft werden durch die Regularisierung in Richtung 0 gezwungen und reduzieren so die Varianz der Vorhersage gegenüber der (idealerweise) unverzerrten KQ-Schätzung.\n\n\n\n\n\n\nKey Facts zu Ridge Regression\n\n\n\n\nRidge-Regression regularisiert den KQ-Schätzer mit der \\(\\ell_2\\)-Norm der Koeffizienten. Diese Form von Regularisierung ist eine Alternative für KQ in Anwendungen mit mehr Regressoren als Beobachtugen (\\(k\\geq n\\)) und/oder wenn KQ aufgrund starker Kollinearität eine hohe Varianz aufweist.\nDer Ridge-Schätzer \\(\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{R}}_\\lambda\\) ist nicht erwartungstreu. Die geschätzten Koeffizienten sind auch für \\(n\\to\\infty\\) verzerrt.\nAufgrund der verzerrten Schätzung ist statistische Inferenz für Koeffizienten mit \\(\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{R}}_\\lambda\\) problematisch. Anstatt für strukturelle Modelle oder die Schätzung kausaler Effekte wird Ridge Regression in der Praxis daher überwiegend für Prognosen verwendet.\nDie Wahl von \\(\\lambda\\) impliziert einen Tradeoff zwischen Verzerrung und Varianz: Große \\(\\lambda\\) schrumpfen die Koeffizientenschätzer Richtung 0 (mehr Verzerrung), führen aber zu einer kleineren Varianz der Schätzung. Entsprechend können Vorhersagen mit mehr Verzerrung aber weniger Varianz als mit KQ getroffen werden.\nRidge Regression kann in R mit dem Paket glmnet berechnet werden.",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regularisierte Regression</span>"
    ]
  },
  {
    "objectID": "RegReg.html#lasso-regression",
    "href": "RegReg.html#lasso-regression",
    "title": "13  Regularisierte Regression",
    "section": "13.2 Lasso Regression",
    "text": "13.2 Lasso Regression\nLeast Absolute Shrinkage and Selection Operator (Lasso) ist ein von Tibshirani (1996) vorgeschlagener Schätzer, der die Verlustfunktion des KQ-Schätzers um einen Strafterm für die Summe der (absoluten) Größe der Koeffizienten \\(\\boldsymbol\\beta = (\\beta_1, \\dots,\\beta_k)'\\) erweitert. Die Verlustfunktion des Lasso-Schätzers von \\(\\boldsymbol{\\beta}\\) lautet \\[\\begin{align}\n\\mathrm{RSS}(\\boldsymbol{\\beta},p=1,\\lambda) = \\mathrm{RSS}(\\boldsymbol{\\beta}) + \\lambda \\lVert\\boldsymbol{\\beta}\\rVert_1.\\label{eq:lassoloss}\n\\end{align}\\] Für den Strafterm wird also die \\(\\ell_1\\)-norm \\[\n\\lVert\\boldsymbol{\\beta}\\rVert_1 = \\sum_{j=1}^k \\lvert\\beta_j \\rvert\n\\] verwendet. Der Lasso-Schätzer \\(\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{L}}_\\lambda\\) für \\(\\boldsymbol{\\beta}\\) minimiert \\(\\eqref{eq:lassoloss}\\), \\[\\begin{align}\n\\boldsymbol{\\beta}^{\\mathrm{L}}_\\lambda = \\arg\\min_{\\boldsymbol{\\beta}} \\ \\mathrm{RSS}(\\boldsymbol{\\beta},p=1,\\lambda).\n\\end{align}\\] Entsprechend erhalten wir in Abhängigkeit von \\(\\lambda\\) ein Kontinuum an Lösungen \\[\\begin{align}\n  \\left\\{\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{L}}_\\lambda\\right\\}_{\\lambda=0}^{\\lambda=\\infty},\\label{eq:LassoPath}\n\\end{align}\\] der sogenannte Lasso-Pfad.\nDas Optimierungsproblem \\(\\eqref{eq:lassoloss}\\) hat die äquivalente Darstellung \\[\\begin{align}\n  \\begin{split}\n    \\widehat{\\boldsymbol{\\beta}}^{\\mathrm{L}}_\\lambda =&\\, \\arg\\min_{\\boldsymbol{\\beta}} \\mathrm{RSS}(\\boldsymbol{\\beta}) + \\lambda\\left(\\lVert\\boldsymbol{\\beta}\\rVert_1 - t\\right)\\\\\n    =&\\, \\arg\\min_{\\lVert\\boldsymbol{\\beta}\\rVert_1\\leq t} \\mathrm{RSS}(\\boldsymbol{\\beta}),\n  \\end{split}\\label{eq:lassolagrange}\n\\end{align}\\] welche über den Lagrange-Ansatz unter der Nebenbedingung \\(\\lVert\\boldsymbol{\\beta}\\rVert_1 \\leq t\\) gelöst werden kann.\nÄhnlich wie der KQ-Schätzer ist der Lasso-Schätzer \\(\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{L}}_\\lambda\\) durch Bedingungen 1. Ordnung bestimmt. Diese Bedingungen lassen sich komfortabel in Matrix-Schreibweise darstellen als \\[\\begin{align}\n  -2\\boldsymbol{X}_j'(\\boldsymbol{Y} - \\boldsymbol{X}\\boldsymbol{\\beta}) + \\lambda\\cdot\\mathrm{sgn}(\\beta_j) = 0, \\quad j = 1,\\dots,k.\\label{eq:LassoFOC}\n\\end{align}\\] Aus Gleichung \\(\\eqref{eq:LassoFOC}\\) folgt, dass der Lasso-Schätzer aufgrund des Strafterms im Allgemeinen nicht algebraisch bestimmt werden kann.11\nIn Abhängigkeit von \\(\\lambda\\) zwingt der Lasso-Schätzer die KQ-Schätzung von \\(\\beta_j\\) zu einem (absolut) kleineren Wert: Ähnlich wie bei Ridge Regression bewirkt der \\(\\ell_1\\)-Strafterm eine mit \\(\\lambda\\) zunehmende Schrumpfung der geschätzen Koeffizienten in Richtung 0. Charakteristisch für die Lösung des Lasso-Schätzers ist, dass \\(\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{L}}_j = 0\\), wenn die Bedingung \\[\\begin{align}\n  \\left\\lvert\\boldsymbol{X}_j'(\\boldsymbol{Y} - \\boldsymbol{X}\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{L}}_\\lambda)\\right\\rvert - \\lambda/2 \\leq 0 \\label{eq:lassoselection}\n\\end{align}\\] erfüllt ist. In Abhängigkeit von \\(\\lambda\\) kann der Lasso-Schätzer folglich geschätzte Regressionskoeffizienten nicht nur in Richtung \\(0\\), sondern diese auch exakt mit \\(0\\) schätzen und damit Variablenselektion betreiben. Aufgrund der mit \\(\\lambda\\) zunehmenden Shrinkage bis die Bedingung \\(\\eqref{eq:lassoselection}\\) erfüllt und der Koeffizient gleich \\(0\\) gesetzt wird, bezeichnet man Lasso auch als einen Soft Thresholding Operator. Im nächsten Abschnitt betrachten wir die Eigenschaften von Lasso-Regularisierung unter vereinfachten Annahmen bzgl. der Regressoren.\n\n13.2.1 Lasso ist Soft Thresholding\nWir betrachten nun eine mathematische Darstellung von Selektions- und Shrinkage-Eigenschaft des Lasso-Schätzers in einem vereinfachten Modell. Wenn die Regressoren \\(\\boldsymbol{X}\\) orthonormal zueinander sind, existiert eine analytische Lösung des Lasso-Schätzers, \\[\\begin{align}\n  \\widehat{\\boldsymbol{\\beta}}^{\\mathrm{L}}_\\lambda =\n  \\begin{cases}\n    \\widehat{\\boldsymbol{\\beta}}_j - \\lambda/2 &, \\ \\ \\widehat{\\boldsymbol{\\beta}}_j &gt; \\lambda/2\\\\\n    0 &, \\ \\ \\lvert\\widehat{\\boldsymbol{\\beta}}_j\\rvert\\leq\\lambda/2\\\\\n    \\widehat{\\boldsymbol{\\beta}}_j + \\lambda/2 &, \\ \\ \\widehat{\\boldsymbol{\\beta}}_j &lt; \\lambda/2\n  \\end{cases},\\label{eq:lassoST}\n\\end{align}\\] wobei \\(\\widehat{\\boldsymbol{\\beta}}_j\\) der KQ-Schätzer von \\(\\beta_j\\) ist. Anhand von \\(\\eqref{eq:lassoST}\\) können wir die Selektionseigenschaft sowie die Schrumpfung der KQ-Koeffizientenschätzung in Abhängigkeit der durch \\(\\lambda\\) regulierten \\(\\ell_1\\)-Strafe erkennen. Für eine Visualisierung implementieren wir \\(\\eqref{eq:lassoST}\\) als R-Funktion lasso_st() und zeichnen die resultierenden Koeffizientenschätzungen für die Parameterwerte \\(\\lambda\\in\\{0, 0.2, 0.4\\}\\).\nWir definieren zunächst die Funktion lasso_st().\n\nlibrary(tidyverse)\n\n# Funktion für Lasso soft-thresholding definieren\nlasso_st &lt;- function(KQ, lambda) {\n  case_when(\n    KQ &gt; lambda/2         ~ KQ - lambda/2,\n    abs(KQ) &lt;= lambda/2   ~ 0,\n    KQ &lt; -lambda/2        ~ KQ + lambda/2,\n  )\n}\n\nIm nächsten Schritt zeichnen wir lasso_st() für eine Sequenz von KQ-Schätzwerten gegeben \\(\\lambda\\).\n\n# Sequenz von KQ-Schätzwerten für Illustration definieren\ndat &lt;- tibble(\n  KQ = seq(-1, 1, .01)\n)\n\n# Lasso-Schätzer als Funktion des KQ-Schätzers plotten\nggplot(dat) +\n  geom_function(\n    fun = lasso_st, \n    args = list(lambda = 0), \n    lty = 2\n  ) + \n  geom_function(\n    fun = lasso_st, \n    args = list(lambda = .2),\n    col = \"red\"\n  ) + \n  geom_function(\n    fun = lasso_st, \n    args = list(lambda = .4), \n    col = \"blue\"\n  ) + \n  xlim(-.4, .4) +\n  xlab(\"KQ-Schätzer von beta_1\") +\n  ylab(\"Lasso-Schätzer von beta_1\")\n\n\n\n\n\n\n\nAbbildung 13.6: Shrinkage und Selektion von OLS-Koeffizienten mit Lasso\n\n\n\n\n\nAbbildung 13.6 zeigt, dass der \\(\\ell_1\\)-Strafterm des Lasso-Schätzers zu einem linearen Verlauf der auf den KQ-Schätzer (gezeichnet für \\(\\lambda = 0\\), gestrichelte Linie) applizierten Shrinkage führt: Der Lasso-Schätzer ist eine abschnittsweise-lineare Funktion des KQ-Schätzers in \\(\\lambda\\): Je größer der Parameter \\(\\lambda\\), desto größer ist das Intervall von KQ-Schätzwerten \\([-\\lambda/2,\\lambda/2]\\), wo der Lasso-Schätzer zu Variablenselektion führt, d.h. hier den Koeffizienten \\(\\beta_j\\) als \\(0\\) schätzt (rote bzw. blaue Linie).\nAnhand von Abbildung 13.6 kann abgeleitet werden, dass der Lasso-Schätzer nicht invariant gegenüber der Skalierung der Regressoren ist: Die Stärke der Regularisierung durch \\(\\lambda\\) ist hängt von der Magnitude des KQ-Schätzers ab. Daher müssen die Regressoren vor Berechnung der Schätzung standardsiert werden. Üblich ist hierbei eine Normierung auf einen Mittelwert von \\(0\\) und eine Varianz von \\(1\\).\nDie nachstehende interaktive Grafik illustriert das Lasso-Optimierungsproblem \\(\\eqref{eq:lassolagrange}\\) sowie den resultierenden Schätzer der Koeffizienten \\((\\beta_1, \\beta_2)\\) in einem multiplen Regressionsmodell mit korrelierten Regressoren \\(X_1\\) und \\(X_2\\).\n\nDie blaue Ellipse ist die Menge aller Schätzwerte \\(\\left(\\widehat\\beta_{1},\\, \\widehat\\beta_{2}\\right)\\) für den angegebenen Wert von \\(\\mathrm{RSS}\\). Im Zentrum der Ellipse liegt der KQ-Schätzer, welcher \\(\\mathrm{RSS}\\) minimiert.\nDas graue Quadrat ist die Menge aller Koeffizienten-Paare \\((\\beta_1, \\beta_2)\\), welche die Restriktion \\(\\lvert\\beta_1\\rvert+\\lvert\\beta_2\\rvert\\leq t\\) erfüllen. Beachte, dass die Größe dieser Region nur durch den Parameter \\(t\\) bestimmt wird.\nDer blaue Punkt ist der Lasso-Schätzer \\((\\widehat{\\boldsymbol{\\beta}}^L_{1,t},\\, \\widehat{\\boldsymbol{\\beta}}^L_{2,t})\\). Dieser ergibt sich als Schnittpunkt zwischen der blauen \\(\\mathrm{RSS}\\)-Ellipse und der Restriktionsregion und variiert mit \\(t\\). Die gestrichelte rote Linie zeigt den Lasso-Lösungspfad.\nFür kleine Werte, erhalten wir starke Shrinkage auf \\(\\widehat\\beta_{1,t}\\) bis zum Wertebereich \\(t\\leq50\\), wo \\(\\widehat{\\boldsymbol{\\beta}}^L_{1,t}=0\\). Hier erfolgt Variablenselektion: Die Regularisierung führt zu einem geschätzten Modell, das lediglich \\(X_2\\) als erklärende Variable enthält. In diesem Bereich von \\(t\\) bewirkt die Shrinkage, dass \\(\\widehat{\\boldsymbol{\\beta}}^L_{2,t}\\to0\\) für \\(t\\to0\\).\n\n\n\nBeachte, dass der rote Lasso-Pfad (die Menge aller Lasso-Lösungen) äquivalent als Funktion von \\(\\lambda\\) im Optimierungsproblem \\(\\eqref{eq:lassoloss}\\) dargestellt werden kann. Implementierungen mit statistischer Software berechnen die Lasso-Lösung häufig in Abhängigkeit von \\(\\lambda\\). Ein Algorithmus hierfür ist LARS.\n\n\n13.2.2 Berechnung der Lasso-Lösung mit dem LARS-Algorithmus\nFür die Berechnung des Lasso-Lösungspfads kann der LARS-Algorithmus von Efron u. a. (2004) im Lasso-Modus genutzt werden.12 Der Lasso-Lösungspfad beinhaltet geschätzte Koeffizienten über ein Intervall für \\(\\lambda\\), welches sämtliche Modellkomplexitäten zwischen der (trivialen) Lösung mit maximaler Shrinkage auf allen Koeffizienten (\\(\\lambda\\) groß, alle gesch. Koeffizienten sind \\(0\\)) und der unregularisierten Lösung (\\(\\lambda = 0\\), KQ-Schätzung) abbildet. Der LARS-Algorithmus erzeugt den Lösungspfad sequentiell, sodass die Schätzung als Funktion von \\(\\lambda\\) veranschaulicht werden kann, ähnlich wie bei Ridge Regression.\nWir zeigen nun anhand simulierter Daten, wie Lasso-Lösungen mit dem R-Paket lars berechnet werden können. Hierfür erzeugen wir Daten gemäß der Vorschrift \\[\\begin{align}\n  \\begin{split}\n  Y_i =&\\, \\boldsymbol{X}_i' \\boldsymbol{\\beta}_v + u_i\\\\\n  \\\\\n  \\boldsymbol{\\beta}_v =&\\, (-1.25, -.75, 0, 0, 0, 0, 0, .75, 1.25)'\\\\\n  \\\\\n  \\boldsymbol{X}_i \\sim&\\, N(\\boldsymbol{0}, \\boldsymbol{I}_{9\\times9}), \\quad u_i \\overset{u.i.v.}{\\sim} N(0, 1), \\quad i = 1,\\dots,25.\n  \\end{split}\\label{eq:larsdgp}\n\\end{align}\\]\n\nlibrary(lars)\nset.seed(1234)\n\n# Parameter definieren\nN &lt;- 25\nbeta_v &lt;- c(-1.25, -.75, 0, 0, 0, 0, 0, .75, 1.25)\n\n# Beobachtungen simulieren\nX &lt;- matrix(rnorm(N * 9), ncol = 9)\nY &lt;- X %*% beta_v + rnorm(N)\n\nEntsprechend des DGP passen wir ein Modell ohne Konstante an. Damit lars::lars() den Lösungspfad des Lasso-Schätzers berechnet, muss type = \"lasso\" gewählt werden.13\n\n# Lösungen des Lasso-Schätzers mit LARS berechnen\n(\n  fit_lars &lt;- lars(\n    x = X, \n    y = Y, \n    intercept = F,\n    type = \"lasso\" # Wichtig: Lasso-Modus\n  )\n)\n\n\nCall:\nlars(x = X, y = Y, type = \"lasso\", intercept = F)\nR-squared: 0.858 \nSequence of LASSO moves:\n                      \nVar  9 2 8 1 3 5 4 7 6\nStep 1 2 3 4 5 6 7 8 9\n\n\nDie Zusammenfassung zeigt, dass der LARS-Algorithmus als erstes die (relevante) Variable \\(X_9\\) aktiviert.14 Mit abnehmender Regularisierung (kleinere \\(\\lambda\\)) werden in den nächsten 3 Schritten die übrigen relevanten Variablen \\(X_2\\), \\(X_8\\) und \\(X_1\\) aktiviert. Über die weiteren Schritte nähert der Algorithmus die Lösung an die saturierte Schätzung (das Modell mit allen neun Regressoren) an und aktiviert schrittweise die übrigen, irrelevanten Variablen.\nWir visualisieren die geschätzen Koeffizienten an jedem Schritt des Lösungspfads als Funktion von \\(\\lambda\\). In der Praxis wird der Regularisierungsparameter häufig auf der natürlichen log-Skala dargestellt.\n\n# Transformation in ein weites Format\nfit_lars$beta %&gt;% \n  as_tibble() %&gt;% \n  mutate(\n    lambda = c(fit_lars$lambda, 1e-2)\n  ) %&gt;% \n  pivot_longer(\n    cols = 1:9, \n    names_to = \"Variable\", \n    values_to = \"gesch. Koeffizient\"\n  ) %&gt;% \n  \n# Visualisierung mit ggplot  \n  ggplot(\n    mapping = aes(\n      x = log(lambda), \n      y = `gesch. Koeffizient`, \n      color = Variable\n    )\n  ) + \n  geom_line() \n\n\n\n\n\n\n\nAbbildung 13.7: LARS-Lösungspfad für Lasso-Schätzung\n\n\n\n\n\nAbbildung 13.7 zeigt, dass die Shrinkage der geschätzten Koeffizienten nach der Aktivierung rasch abnimmt und sich für kleine Werte von \\(\\lambda\\) der KQ-Lösung annähert. Wir sehen auch, dass es einen Bereich von \\(\\lambda\\)-Werten gibt, für die das wahre Modell mit den Variablen \\(X_1\\), \\(X_2\\), \\(X_8\\) und \\(X_9\\) selektiert werden kann. Je nach Ziel der Analyse kann es sinnvoll sein, ein \\(\\lambda\\) in diesem Intervall zu schätzen.\n\n\n13.2.3 Wahl des Regularisierungsparameters \\(\\lambda\\) für den Lasso-Schätzer\nWie zuvor bei Ridge Regression muss in empirischen Anwendungen ein Wert für den Tuning-Parameter \\(\\lambda\\) gewählt werden. Hierbei besteht die Herausforderung darin, einen geeigneten Wert zu finden, der zu wünschenswerten Eigenschaften des resultierenden Modells führt. So ist für gute Vorhersagen wichtig, dass das Modell nicht zu sehr an die Daten angepasst ist (Overfitting), um eine gute Generalisierung auf neue Daten zu ermöglichen. Gleichzeitig muss das Modell flexibel genug sein, um wesentliche Eigenschaften des datenerzeugenden Prozesses hinreichend gut zu erfassen. In der Regel wird hierbei eine sparsame Modellierung angestrebt, die nur eine Teilmenge der Prädiktoren nutzt.\nIn der Praxis werden verschiedene Verfahren verwendet, um den Wert für den Tuning-Parameter \\(\\lambda\\) zu bestimmen. Gängige Methoden sind Cross Validation (CV) und Informationskriterien. In Abhängigkeit der Methode und der Daten ergeben sich ober- oder unterparameterisierte Modelle. Aufgrund der Implementierung im R-Paket lars betrachten wir CV.15 Wir zeigen nachfolgend anhand der simulierten Daten aus dem letzten Abschnitt, wie für die LARS-Schätzung ein optimales \\(\\lambda\\) mit leave-one-out CV (LOO-CV) bestimmt werden kann. Hierzu nutzen wir lars::cv.lars() unter Verwendung derselben Argumente wie zuvor im Aufruf von lars().\n\n# LARS-Lösungen mit CV evaluieren\nfit_lars_cv &lt;- cv.lars(\n  x = X, \n  y = Y, \n  intercept = F,\n  normalize = T,\n  type = \"lasso\", \n  plot.it = F, \n  K = N # für LOO-CV\n) \n\nDas Objekt fit_lars_cv ist eine Liste mit den CV-Ergebnissen. Wir können diese einfach mit ggplot visualisieren. index ist hierbei das Verhältnis der \\(\\ell_1\\)-Norm des Lasso-Schätzers für einen spezifischen Wert von \\(\\lambda\\) und der \\(\\ell_1\\)-Norm des KQ-Schätzers. Das optimale \\(\\lambda\\) wird so implizit geschätzt. cv.error ist der mit CV geschätzte MSE.\n\n# CV-MSE\nfit_lars_cv %&gt;% \n  as_tibble() %&gt;%\n\n  ggplot(\n    mapping = aes(\n      x = index, \n      y = cv.error\n    )\n  ) + \n  geom_line() +\n  xlab(\"|beta_lambda| / |beta|\") +\n  ylab(\"CV-MSE\")\n\n\n\n\n\n\n\nAbbildung 13.8: CV-MSE und relative Position von \\(\\lambda\\) auf dem Lassopfad\n\n\n\n\n\nIn der Grafik erkennen wir ein Minimum des CV-MSEs bei etwa 0.73.\n\n# CV-MSE-minimierendes Lambda bestimmen\nID &lt;- which.min(fit_lars_cv$cv.error) # Index\n\n(\n  fraction_opt &lt;- fit_lars_cv$index[ID]\n)\n\n[1] 0.7272727\n\n\nDie geschätzten Koeffizienten für die optimale Regularisierung können mit coef() ausgelesen werden.\n\n# LARS-Lasso-Fit für optimales lambda bestimmen\ncoef(\n  object = fit_lars, \n  s = fraction_opt, \n  mode = \"fraction\"\n)\n\n[1] -0.6513191 -0.6060906 -0.1946089  0.0000000  0.0000000  0.0000000  0.0000000\n[8]  0.4977908  1.3122407\n\n\nDas Ergebnis veranschaulicht die Selektionseigenschaft von Lasso: Gemäß DGP \\(\\eqref{eq:larsdgp}\\) sind die Variablen \\(X_3\\) bis \\(X_7\\) irrelevante Prädiktoren für \\(Y\\); ihre wahren Koeffizienten sind \\(0\\). In der kreuzvalidierten Lasso-Schätzung erreicht die Regularisierung, dass die Koeffizienten der Variablen \\(X_4\\) bis \\(X_7\\) tatsächlich mit 0 geschätzt werden. Wir schätzen für das mit CV bestimmte \\(\\lambda\\) also ein leicht überspezifiziertes Modell mit den Regressoren \\(X_1\\), \\(X_2\\), \\(X_3\\), \\(X_8\\) und \\(X_9\\). Beachte, dass die Lasso-Schätzung einen Kompromiss impliziert: Die Varianz der Schätzung ist geringer als die des KQ-Schätzers im Modell mit allen Variablen.16 Aufgrund der Regularisierung sind die mit Lasso geschätzten Koeffizienten der relevanten Variablen jedoch in Richtung \\(0\\) verzerrt.\nEinen positiven Effekt dieses Kompromisses beobachten wir anhand des mittleren Vorhersagefehlers für Daten, die nicht zur Berechnung des Schätzers verwendet wurden. Wir vergleichen den Vorhersagefehler nachfolgend anhand eines solchen simulierten Test-Datensatzes mit 25 neuen Beobachtungen. Den Vorhersagefehler bestimmen wir als MSE zwischen den vorhergesagten und den tatsächlichen Ausprägungen für \\(Y\\).\n\n# Test-Datensatz erstellen\nset.seed(4321)\nnew_X &lt;- matrix(rnorm(N * 9), ncol = 9)\nnew_Y &lt;- new_X %*% beta_v + rnorm(N)\n\n# Lasso: Vorhersage von new_Y für Test-Datensatz\nY_predict_lars &lt;- predict(\n  object = fit_lars, \n  s = fraction_opt, \n  type = \"fit\", \n  mode = \"fraction\", \n  newx = new_X\n)$fit\n\n# Lasso: MSE für Test-Datensatz berechnen\nmean((Y_predict_lars - new_Y)^2)\n\n[1] 1.419817\n\n\nWir schätzen nun das große Modell mit allen 9 Variablen mit KQ und berechnen ebenfalls den MSE der Prognosen für den Test-Datensatz.\n\n# KQ-Schätzung des großen Modells durchführen\nKQ_fit &lt;- lm(Y ~ X - 1)\n\n# Test-Datensatz für predict.lm() formatieren\nnew_X &lt;- as.data.frame(new_X)\ncolnames(new_X) &lt;- paste0(\"X\", 1:9)\n\n# KQ: Vorhersage von new_Y für Test-Datensatz\nY_predict_KQ &lt;- predict(\n  object = KQ_fit, \n  newdata = new_X\n)\n\n# KQ: MSE für Test-Datensatz berechnen\nmean((Y_predict_KQ - new_Y)^2)\n\n[1] 9.851932\n\n\nOffenbar führt die Lasso-Schätzung zu einem deutlich geringeren MSE der Vorhersage von Y für den Test-Datensatz als die KQ-Schätzung und damit zu einer höheren Vorhersagegüte. Das “sparsame” mit Lasso-Regression geschätzte Modell ist dem “großen” mit KQ geschätztem Modell in dieser Hinsicht also überlegen.\n\n\n\n\n\n\nKey Facts zu Lasso-Regression\n\n\n\n\nLasso-Regression bestraft die Verlustfunktion des KQ-Schätzers mit der \\(\\ell_1\\)-Norm der Koeffizienten.\nNeben Koeffizientenschätzung mit Shrinkage in Richtung \\(0\\) kann der Lasso-Schätzer Variablenselektion durchführen: Regressionskoeffizienten können exakt mit \\(0\\) geschätzt und so ein “sparsames”, leichter zu interpretierendes Modell gewählt werden.\nWie bei Ridge Regression impliziert die Wahl von \\(\\lambda\\) einen Bias-Variance-Tradeoff, der für Vorhersagen nützlich ist: Für größere \\(\\lambda\\) wird mehr Verzerrung induziert und möglicherweise relevante Variablen mit kleinen Koeffizienten aus dem Modell entfernt. Ein solches sparsames Modell kann eine höhere Prognosegüte haben als ein komplexes, unregularisiertes Modell.\nDer Lasso-Schätzer \\(\\widehat{\\boldsymbol{\\beta}}_\\lambda^L\\) ist nicht erwartungstreu.\nLasso Regression kann bspw. mit dem LARS-Algorithmus (Paket lars) oder mit glmnet berechnet werden.",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regularisierte Regression</span>"
    ]
  },
  {
    "objectID": "RegReg.html#vergleich-von-lasso--und-ridge-regression-mit-simulation",
    "href": "RegReg.html#vergleich-von-lasso--und-ridge-regression-mit-simulation",
    "title": "13  Regularisierte Regression",
    "section": "13.3 Vergleich von Lasso- und Ridge-Regression mit Simulation",
    "text": "13.3 Vergleich von Lasso- und Ridge-Regression mit Simulation\nIn diesem Kapitel illustrieren wir Vor- und Nachteile von Lasso- und Ridge-Regression in Prognose-Anwendungen anhand von Monte-Carlo-Simulationen. Wir betrachten hierbei datenerzeugende Prozesse, die sich hinsichtlich der Anzahl relevanter Variablen sowie der Korrelation dieser Variablen unterscheiden.\nDie grundlegende Vorschrift für die Simulationen ist \\[\\begin{align*}\n  Y_i = \\sum_{j=1}^{k=40} \\beta_j X_{i,j} + u_i, \\quad u_i \\overset{u.i.v.}{\\sim} N(0,1), \\quad i=1,\\dots,100,\n\\end{align*}\\] wobei die Regressoren \\(X_j\\) eine Varianz von \\(1\\) haben und aus einer multivariaten Normalverteilung mit Korrelation \\[\\rho\\in(0,0.5,0.8)\\] gezogen werden.\nFür die Koeffizienten \\(\\boldsymbol{\\beta}\\) unterscheiden wir zwei Szenarien. In Szenario A ist \\[\\boldsymbol{\\beta} = (1,\\dots,1)',\\] d.h. alle Variablen sind relevant und haben denselben Einfluss auf \\(Y\\). In Szenario B erzeugen wir \\(\\boldsymbol{\\beta}\\) einmalig vorab so, dass \\[\\beta_j = \\begin{cases}1,\\quad \\text{mit Wsk.  }p\\\\ 0,\\quad \\text{mit Wsk.  }1-p, \\end{cases}\\] d.h. nur eine Teilmenge der Variablen beeinflusst \\(Y\\) jeweils mit demselben Effekt \\(\\beta_j = 1\\). Die übrigen Variablen sind irrelevant.\nWir schätzen und validieren die Modelle mit glmnet().\n\n13.3.1 Prognosegüte in diversen Szenarien\n\n# Simulationsparameter definieren\nrho &lt;- c(0, 0.5, 0.8)   # Korrelation\nk &lt;- 40                 # Anz. Regressoren\nN &lt;- 100                # Anz. Beobachtungen\nn_sim &lt;- 100            # Anz. Simulationen\n\nDamit der Code für die Simulation möglichst wenig repetitiv ist, definieren wir eine Funktion cv.glmnet_MSE(), die unter Angabe der Daten X und Y, des Trainingssets train sowie des Parameters alpha den gewünschten regularisierten Schätzer under Verwendung von Cross Validation anpasst und den Testset-MSE zurückgibt.\n\n# allg. Funktion für Testset-MSE nach CV\ncv.glmnet_MSE &lt;- function(X, Y, train, alpha) {\n  \n  # Modell mit glmnet schätzen; lambda per CV bestimmen\n  fit_cv &lt;- cv.glmnet(\n    x = X[train,],\n    y =Y[train],\n    alpha = alpha\n  )\n  \n  # Vorhersagen treffen\n  Y_pred &lt;- predict(\n    object = fit_cv, \n    s = fit_cv$lambda.min, \n    newx = X[-train,])\n  \n  return(\n    # Testset-MSE berechnen\n    mean(\n      (Y[-train] - Y_pred)^2\n      )\n  )\n}\n\nWir initialisieren zunächst Matrizen, in welche die MSEs aus den 100 Simulationsdurchläufen reihenweise geschrieben werden. lasso_mse und ridge_mse haben je eine Spalte für jede Korrelation in rho\n\n# Matrizen für simulierte MSEs initialisieren...\nlasso_mse &lt;- matrix(\n  data = NA, \n  nrow = n_sim, \n  ncol = length(rho)\n) \nridge_mse &lt;- lasso_mse\n\n# ... und benennen\ncolnames(lasso_mse) &lt;- paste0(\"Kor=\", rho)\ncolnames(ridge_mse) &lt;- colnames(lasso_mse)\n\nFür die Simulation iterieren wir mit purrr::walk über den Vektor rho sowie über die Laufvariable 1:n_sim. Beide Schleifen nutzen den Syntax für anonyme Funktionen:\n\n# Die anonyme Funktion\nfunction(x) return(x)\n# ist äquivalent definiert als\n\\(x) return(x)\n\nIn jeden Simulationsdurchlauf erzeugen wir den Datensatz entsprechend der obigen Vorschrift, teilen die Daten auf und berechnen MSEs für Lasso- und Ridge-Regression mit cv.glmnet_MSE().\nSzenario A\n\n# Koeffizienten-Vektor definieren\nbeta &lt;- rep(1, k) \n\n\nlibrary(mvtnorm)\nlibrary(tidyverse)\n\nset.seed(1234)\n\n# Simulation durchführen\nwalk(1:length(rho), \\(j) {\n  \n  # Korrelationsmatrix definieren\n  Sigma &lt;- matrix(\n    data = rho[j], \n    nrow = k, \n    ncol = k\n  )\n  diag(Sigma) &lt;- 1\n  \n  walk(1:n_sim, \\(i) {\n    \n  # Daten simulieren\n  X &lt;- rmvnorm(\n    n = N, \n    mean = rep(0, k), \n    sigma = Sigma\n  )\n  Y &lt;- X %*% beta + rnorm(N)\n    \n  # Trainingsdaten definieren\n  ID_train &lt;- sample(\n    x = c(1:N), \n    size = N/2\n  )\n    \n  # Modelle mit CV schätzen und MSEs berechnen\n  # Ridge-Regression\n  ridge_mse[i, j] &lt;&lt;- cv.glmnet_MSE(\n    X = X, \n    Y = Y, \n    train = ID_train, \n    alpha = 0\n  )\n  \n  # Lasso-Regression\n  lasso_mse[i, j] &lt;&lt;- cv.glmnet_MSE(\n    X = X, \n    Y = Y, \n    train = ID_train, \n    alpha = 1\n  )\n  \n  })\n  \n})\n\nBeachte, dass hier der Super-Assignment-Operator &lt;&lt;- genutzt wird, damit walk die Matrizen ridge_mse und lasso_mse in der globalen Umgebung überschreibt.17\nWir berechnen jeweils den mittleren MSEs, sammeln die Ergebnisse in einer tibble() und nutzen gt() für die tabellarische Darstellung.\n\nlibrary(gt)\n\n# Ergebnisse tabellarisch darstellen\ntibble(\n  Methode = c(\n    \"Lasso-Regression\", \n    \"Ridge-Regression\"\n  ),\n) %&gt;%\n  bind_cols(\n    bind_rows(\n      colMeans(lasso_mse),\n      colMeans(ridge_mse)  \n    )    \n  ) %&gt;%\n  gt() %&gt;%\n  tabopts\n\n\n\nTabelle 13.1: Durchschnittliche Testset-MSEs für Setting A\n\n\n\n\n\n\n\n\n\nMethode\nKor=0\nKor=0.5\nKor=0.8\n\n\n\n\nLasso-Regression\n7.17\n10.398\n7.581\n\n\nRidge-Regression\n4.841\n1.615\n1.517\n\n\n\n\n\n\n\n\n\n\nTabelle 13.1 zeigt, dass Ridge-Regression gegenüber Lasso-Regression für jede der drei betrachteten Korrelationen überlegen ist. Insbesondere bei stärker korrelierten Regressoren ist Ridge vorteilhaft.\nFür Szenario B überschreiben wir beta nach Multiplikation mit einem zufälligen binären Vektor, sodass einige der Koeffizienten \\(0\\) und die zugehörigen Variablen irrelevant für \\(Y\\) sind.\nSzenario B\n\n# Wsk. für Relevanz einer Variable\np &lt;- .3\n\n# Koeffizienten-Vektor definieren\nset.seed(123)\nbeta &lt;- beta * sample(\n  x = 0:1, \n  size = k, \n  replace = T, \n  prob = c(1-p, p)\n)\n\n# Koeffizienten prüfen\nhead(beta, n = 10)\n\n [1] 0 1 0 1 1 0 0 1 0 0\n\n\nEine wiederholung der Simulation für die modifizierten Koeffizienten beta und liefert folgende tabellarische Auswertung.\n\n\n\n\nTabelle 13.2: Durchschnittliche Testset-MSEs für Szenario B\n\n\n\n\n\n\n\n\n\nMethode\nKor=0\nKor=0.5\nKor=0.8\n\n\n\n\nLasso\n2.51\n2.143\n1.923\n\n\nRidge\n3.331\n2.562\n2.014\n\n\n\n\n\n\n\n\n\n\nDie Ergebnisse in Tabelle 13.2 zeigen, dass Ridge-Regression in Szenario B bis auf den Fall unkorrelierter Regressoren etwas schlechter abschneidet als in Szenario A. Die hohe Anzahl irrelevanter Variablen verbessert die Leistung von Lasso deutlich: Hier ist es plausibel, dass Lasso aufgrund der Thresholding-Eigenschaft die Koeffizienten einiger irrelevanten Variablen häufig exakt \\(0\\) setzt und damit ein sparsameres Modell schätzt als Ridge. Entsprechend erzielt Lasso in diesem Szenario insbesondere für \\(\\rho = 0\\) genauere Vorhersagen als Ridge Regression.\n\n\n13.3.2 Visualisierung des Bias-Variance-Tradeoffs bei Prognosen\nFür ein besseres Verständnis, wie sich der Regularisierungsparameter \\(\\lambda\\) auf den Bias-Variance-Tradeoff bei Prognosen mit Ridge- und Lasso-Regression auswirkt, vergleichen wir für beide Methoden nachfolgend die Abhängigkeit des MSEs der Prognose \\(\\widehat{Y}_0\\) für den Wert \\(Y_0\\) der abhängigen Variable eines Datenpunkts anhand seiner Regressoren \\(\\boldsymbol{X}_0'\\), wobei \\[\\begin{align}\n  \\text{MSE}(\\widehat{Y}_0) = \\text{Bias}(\\widehat{Y}_0)^2 + \\text{Var}(\\widehat{Y}_0) + \\text{Var}(Y_0) \\label{eq:pbvdecomp}\n\\end{align}\\] Beachte, dass \\(\\text{Var}(Y_0)\\) die durch den datenerzeugenden Prozess (und damit unvermeidbare) Varianz von \\(Y_0\\) ist, wohingegen \\(\\text{Bias}(\\widehat{Y}_0)^2\\) und \\(\\text{Var}(\\widehat{Y}_0)\\) von dem verwendeten Schätzer für \\(\\widehat{Y}_0\\) abhängt.\nFür die Simulation betrachten wir erneut Szenario A aus Kapitel 13.3.1 mit \\(50\\) Beobachtungen für ein Modell mit \\(40\\) unkorrelierten Regressoren. Wir legen zunächst die Simulationsparameter fest und erzeugen den vorherzusagenden Datenpunkt (X_0, Y_0).\n\n# Parameter festlegen\nset.seed(1234)\nn &lt;- 200 # Anz. Iterationen\nN &lt;- 50  # Anz. Beobachtungen\nk &lt;- 40  # Anz. Variablen\n\n# Korrelationsmatrix definieren\nSigma &lt;- diag(k) # Diagonalmatrix\nbeta &lt;- rep(x = 1, k)\n\n# Prognose-Ziel vorab zufällig generieren:\n\n# Regressoren\nX_0 &lt;- rmvnorm(\n  n = 1, \n  mean = rep(x = 0, k)\n)\n\n# Abh. Variable\nY_0 &lt;- X_0 %*% beta + rnorm(n = 1) %&gt;% \n  as.vector()\n\nAnhand der Simulationsergebnisse wollen wir die von der verwendeten Schätzfunktion abhängigen Komponenten von \\(\\eqref{eq:pbvdecomp}\\) untersuchen. Wir initialisieren hierzu die Listen ridge_fits und lasso_fits, in die unsere Simulationsergebnisse geschrieben werden.\n\n# Listen für Simulationsergebnisse initialisieren\nridge_fits &lt;- list()\nlasso_fits &lt;- list()\n\nWeiterhin definieren wir separate \\(\\lambda\\)-Sequenzen für Lasso- und Ridge-Schätzer.18\n\n# Lambda-Sequenzen festlegen\nlambdas_r &lt;- seq(.25, 2.5, length.out = 100)\nlambdas_l &lt;- seq(.05, 0.5, length.out = 100)\n\nFür die Simulation iterieren wir mit walk() über simulierte Datensätze und schreiben jeweils den vollständigen Output von glmnet() in die zuvor definierten Listen ridge_fits und lasso_fits.\n\n# Simulation\nwalk(1:n, \\(i) {\n  \n  # Daten simulieren\n  X &lt;- rmvnorm(\n    n = N, \n    mean = rep(0, k), \n    sigma = Sigma\n  )\n  Y &lt;- X %*% beta + rnorm(n = N, sd = 5)\n  \n  # Modelle mit glmnet schätzen\n  # Ridge-Regression\n  ridge_fits[[i]] &lt;&lt;- glmnet(\n    x = X, \n    y = Y, \n    alpha = 0, \n    intercept = F\n  )\n  # Lasso-Regression\n  lasso_fits[[i]] &lt;&lt;- glmnet(\n    x = X, \n    y = Y, \n    alpha = 1, \n    intercept = F\n  )\n  \n})\n\nWir nutzen Funktionen aus purrr und dplyr, um über die in den Simulationsdurchläufen angepassten Modelle zu iterieren. Mit predict() erhalten wir Punktvorhersagen für Y_0 für jedes \\(\\lambda\\) der zuvor definierten \\(\\lambda\\)-Sequenzen. Beachte, dass map() jeweils eine Liste mit 200 Punktvorhersagen für jedes der 100 zurückgibt. Mit list_rbind() können wir die Ergebnisse komfortabel jeweils in einer tibble sammeln.\n\n# Prognosen für Ridge-Regression\npred_r &lt;- map(\n  .x = ridge_fits, \n  .f = ~ as_tibble(\n    predict(\n      object = ., \n      s = lambdas_r, \n      newx = X_0\n    )\n  ) \n) %&gt;%\n  list_rbind() \n\n# Prognosen für Lasso-Regression\npred_l &lt;- map(\n  .x = lasso_fits, \n  .f = ~ as_tibble(\n    predict(\n      object = ., \n      s = lambdas_l, \n      newx = X_0)\n    ) \n) %&gt;%\n  list_rbind() \n\nFür die statistische Auswertung berechnen wir jeweils \\(\\text{MSE}(\\widehat{Y}_0)\\), \\(\\text{Bias}(\\widehat{Y}_0)^2\\) und \\(\\text{Var}(\\widehat{Y}_0)\\) und führen die Ergebnisse mit pivot_longer() in ein langes Format sim_data_r über. Wir berechnen weiterhin mit MSE_min_r das \\(\\lambda\\), für das wir über die Simulationsdurchläufe durchschnittlich den geringsten \\(\\text{MSE}\\) beobachten.\nRidge-Regression\n\n# Ergebnisse für Ridge-Regression zusammenfassen\nsim_data_r &lt;- tibble(\n  \n  lambda = lambdas_r,\n  \n  \"MSE\" = map_dbl(\n    .x = pred_r,  \n    .f = ~ mean((.x - Y_0)^2)\n  ),\n  \n  \"Bias^2\" = map_dbl(\n    .x = pred_r, \n    .f = ~ (mean(.x) - Y_0)^2\n  ),\n  \n  \"Varianz\" = map_dbl(\n    .x = pred_r, \n    .f = ~ var(.x)\n  )\n) %&gt;%\n  pivot_longer(\n    cols = -lambda, \n    values_to = \"Wert\",\n    names_to = \"Statistik\"\n  )\n\n# Lambda bei MSE-Minimum bestimmen\nMSE_min_r &lt;- sim_data_r %&gt;% \n  filter(\n    Statistik == \"MSE\",\n    Wert == min(Wert)\n  ) \n\nLasso-Regression\n\n# Ergebnisse zusammenfassen\nsim_data_l &lt;- tibble(\n  \n  lambda = lambdas_l,\n  \n  \"MSE\" = map_dbl(\n    .x = pred_l,  \n    .f = ~ mean((. - Y_0)^2)\n  ),\n  \n  \"Bias^2\" = map_dbl(\n    .x = pred_l, \n    .f = ~ (mean(.) - Y_0)^2\n  ),\n  \n  \"Varianz\" = map_dbl(\n    .x = pred_l, \n    .f = ~ var(.)\n  )\n) %&gt;%\n  pivot_longer(\n    cols = -lambda, \n    values_to = \"Wert\", \n    names_to = \"Statistik\"\n  )\n\n# Lambda bei MSE-Minimum bestimmen\nMSE_min_l &lt;- sim_data_l %&gt;% \n  filter(\n    Statistik == \"MSE\",\n    Wert == min(Wert)\n  ) \n\nDie Datensätze im langen Format, sim_data_r und sim_data_l, werden nun für die Visualisierung der Ergebnisse mit ggplo2 genutzt.\n# MSE, Bias^2 und Varianz gegen Lambda plotten\n\n# Ridge-Regression\nsim_data_r %&gt;%\n  ggplot(\n    mapping = aes(\n      x = lambda, \n      y = Wert, \n      color = Statistik\n    )\n  ) +\n  geom_line() +\n  geom_point(data = MSE_min_r)\n\n# Lasso-Regression\nsim_data_l %&gt;%\n  ggplot(\n    mapping = aes(\n      x = lambda, \n      y = Wert, \n      color = Statistik\n    )\n  ) +\n  geom_line() +\n  geom_point(data = MSE_min_l)\n\n\n\n\n\n\n\n\n\n\n\n(a) Ridge Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Lasso Regression\n\n\n\n\n\n\n\nAbbildung 13.9: Simulierte MSE-Komponenten in Abhängigkeit von Lambda\n\n\n\nAnhand von Abbildung 13.9 lässt sich der Bias-Variance-Tradeoff bei der Vorhersage von \\(Y_0\\) gut erkennen: Bereits für kleine \\(\\lambda\\) erzielen beide Methode eine deutliche Reduktion des MSE. Dies wir durch etwas zusätzlichen Bias, aber eine überproportionale Verringerung der Varianz erreicht. Der erkennbare funktionale Zusammenhang zeigt, dass der MSE eine konvexe Funktion von \\(\\lambda\\) ist. Damit existieren optimale \\(\\lambda\\) mit minimalem MSE (grüne Punkte), die wir mit Cross Validation schätzen können.",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regularisierte Regression</span>"
    ]
  },
  {
    "objectID": "RegReg.html#inferenz-für-treatment-effekt-schätzung-mit-vielen-variablen",
    "href": "RegReg.html#inferenz-für-treatment-effekt-schätzung-mit-vielen-variablen",
    "title": "13  Regularisierte Regression",
    "section": "13.4 Inferenz für Treatment-Effekt-Schätzung mit vielen Variablen",
    "text": "13.4 Inferenz für Treatment-Effekt-Schätzung mit vielen Variablen\nIn empirischen Studien des Effekts einer Behandlungsvariable \\(B\\) auf eine Outcome-Variable \\(Y\\) steht häufig eine Vielzahl potentieller Kontrollvariablen zur Verfügung. Häufig ist unklar, welche Variablen in das Modell aufgenommen werden sollten, um das Risiko einer verzerrten Schätzung durch ausgelassene Variablen zu vermindern und gleichzeitig eine Schätzung mit geringer Varianz zu gewährleisten. Ist der Beobachtungsumfang \\(N\\) relativ zur Variablenanzahl \\(k\\) groß, so kann die KQ-Schätzung einer langen Regression (ein Modell mit allen \\(k\\) Kontrollvariablen) gute Ergebnisse liefern. In der Praxis liegt diese wünschenswerte Situation jedoch oft nicht vor und es ist \\(k\\lesssim N\\) oder sogar \\(k&gt;N\\). Dann ist eine KQ-Schätzung des Behandlungseffekts anhand aller \\(k\\) Variablen mit hoher Varianz behaftet bzw. gar nicht möglich.19 Ein weiteres Szenario ist \\(k(N)&gt;N\\), d.h. die Anzahl der Regressoren kann mit dem Beobachtungsumfang wachsen.20 Lasso-Verfahren können dann hilfreich sein, um Determinanten von \\(Y\\) und \\(B\\) zu identifizieren und damit eine Menge an Kontrollvariablen zu selektieren, für die eine erwartungstreue und konsistente Schätzung des interessierenden Effekts wahrscheinlich ist.\nBetrachte zunächst das Modell mit allen Kontrollvariablen \\(X_j\\), \\[\\begin{align}\n  Y_i = \\beta_0 + \\alpha_0 B_i + \\sum_{j=1}^k \\beta_{j} X_{i,j} + u_i, \\label{eq:lassotmt}\n\\end{align}\\] wobei einige \\(\\beta_{j}=0\\) sind und wir annehmen, dass \\(B\\) lediglich mit ein paar der \\(X_j\\) korrelliert. Die Shrinkage der geschätzten Koeffizienten aus einer naiven Lasso-Regression von \\(\\eqref{eq:lassotmt}\\) führt grundsätzlich zu einer verzerrten Schätzung des Behandlungseffekts \\(\\alpha_0\\) und damit zu ungültiger Inferenz.21\nDie Verzerrung von geschätzten Koeffizienten kann vermieden werden, indem Lasso lediglich zur Selektion von Kontrollvariablen verwendet wird. Dabei wird mit einer Lasso-Regression von \\(Y\\) auf die \\(X_j\\) eine Teilmenge von Regressoren \\(\\mathcal{S}\\) selektiert und der Treatment-Effekt anschließend mit der KQ-Schätzung von \\[\\begin{align}\n  Y_i = \\beta_0 + \\alpha_0 B_i + \\sum_{j\\in\\mathcal{S}} \\beta_{j} X_{i,j} + e_i,\n\\end{align}\\] basierend auf der Selektion \\(\\mathcal{S}\\) berechnet wird.22 Ein solcher Post-Lasso-Selection-Schätzer (Belloni und Chernozhukov 2013) ist jedoch im Allgemeinen und insbesondere in hoch-dimensionalen Settings nicht konsistent für \\(\\alpha_0\\) und nicht asymptotisch normalverteilt, da weiterhin die Gefahr einer verzerrten Schätzung durch in \\(\\mathcal{S}\\) ausgelassene Variablen besteht, die mit \\(B\\) korrelieren: Lasso selektiert Variablen \\(X_j\\), die “gut” \\(Y\\) erklären. Dabei kann nicht ausgeschlossen werden, das ein Modell gewählt wird, dass relevante Determinanten von \\(B\\) auslässt. Selbst wenn wir ein mit Lasso gewähltes Modell mit KQ (d.h. ohne Shrinkage) schätzen, würde \\(\\alpha_0\\) verzerrt geschätzt!\nBelloni, Chernozhukov, und Hansen (2014) schlagen ein alternatives Verfahren vor, dass auf Selektion der Determinanten \\(X_j\\) von \\(Y\\) und \\(B\\) basiert. Dieses Verfahren wird als Post-Double Selection bezeichnet und kann wiefolgt implementiert werden:\nPost-Double-Selection-Schätzer\n\nBestimme die Determinanten \\(X_j\\) von \\(Y\\) mit Lasso-Regression und bezeichne die Menge der selektierten Variablen als \\(\\mathcal{S}_Y\\).\nBestimme die Determinanten \\(X_j\\) von \\(B\\) mit Lasso-Regression und bezeichne die Menge der selektierten Variablen als \\(\\mathcal{S}_B\\).\nBestimme die Schnittmenge \\(\\mathcal{S}_{YB} = \\mathcal{S}_Y \\cap \\mathcal{S}_B\\). Schätze den Treatment-Effekt als \\(\\widehat{\\alpha}_0\\) in der KQ-Regression \\[\\begin{align}\n  Y_i = \\beta_0 + \\alpha_0 B_i + \\sum_{j\\in\\mathcal{S}_{YB}} \\beta_{j} X_{i,j} + v_i.\n\\end{align}\\]\n\nBelloni, Chernozhukov, und Hansen (2014) zeigen, dass \\(\\widehat{\\alpha}_0\\) aus diesem Verfahren ein asymptotisch normalverteiler Schätzer für \\(\\alpha_0\\) ist und herkömmliche t-Tests und Konfidenzintervalle gültige Inferenz erlauben.\nWir illustrieren die in diesem Abschnitt betrachteten Schätzer nun anhand simulierter Daten mit R. Die fiktive Problemstellung ist die Schätzung eines wahren Treatment-Effekts \\(\\alpha_0 = 2\\), wenn so viele potenzielle Kontrollvariablen vorliegen, dass der KQ-Schätzer gerade noch berechnet werden kann, aber aufgrund hoher Varianz unzuverlässig ist. Hierzu erzeugen wir \\(Y\\) gemäß der Vorschrift \\[\\begin{align*}\n  Y_i =&\\, \\alpha_0 B_i + \\sum_{j=1}^{k_Y} \\beta_{j}^Y X_{i,j}^Y + \\sum_{l=1}^{k_{YB}} \\beta_{l}^{YB} X_{i,l}^{YB} + u_i,\\\\\n  \\\\\n  \\beta_j^{YB} \\overset{u.i.v}{\\sim}&\\,N(10,1), \\quad \\beta_j^{Y} \\overset{u.i.v}{\\sim}U(0,1), \\quad u_i \\overset{u.i.v}{\\sim}N(0,1).\\\\\n  \\\\\n  i=&\\,1,\\dots,550\n\\end{align*}\\]\nDie Behandlungsvariable \\(B_i\\) entspricht der Vorschrift \\[\\begin{align*}\n  B_i =&\\, \\sum_{l=1}^{k_{YB}} \\beta_{l}^{YB} X_{i,l}^{YB} + e_i,\\\\\n  \\\\\n  \\beta_j^{YB} \\overset{u.i.v}{\\sim}&\\,N(2,0.2), \\quad e_i \\overset{u.i.v}{\\sim}N(0,1).\n\\end{align*}\\] Wir wählen \\(k_{YB} = k_{Y} = 25\\). Zusätzlich zu \\(B\\), den Determinanten von \\(Y\\) und \\(B\\) (\\(X^{YB}\\)) sowie den Variablen, die ausschließlich \\(Y\\) beeinflussen (\\(X^{Y}\\)) gibt es \\(k_U = 499\\) Variablen \\(X^U\\), die weder \\(Y\\) noch \\(B\\) beeinflussen und damit irrelevant für die Schätzung des Behandlungseffekts sind. Wir haben also \\(N=550\\) Beobachtungen und insgesamt \\(k = 1+k_{Y} + k_{YB} + k_{U} = 550\\) potenzielle Kontrollvariablen von denen \\(k_{YB} = 25\\) für eine unverzerrte Schätzung von \\(\\alpha_0\\) relevant sind.\nDer nachstehende Code generiert die Daten gemäß der Vorschrift.\n\nlibrary(mvtnorm)\nlibrary(tidyverse)\nset.seed(4321)\n\nn &lt;- 550      # Beobachtungen\np_Y &lt;- 25     # Determinanten Y\np_B &lt;- 25     # Determinanten B *und* Y\np_U &lt;- 499    # irrelevante Variablen \n\n# Variablen generieren\nXB &lt;- rmvnorm(n = n, sigma = diag(p_B))\nXU &lt;- rmvnorm(n = n, sigma = diag(p_U))\nXY &lt;- rmvnorm(n = n, sigma = diag(p_Y))\n\n# Stetige Behandlungsvariable erzeugen\nB &lt;- XB %*% rnorm(p_B, 2, sd = .2) + rnorm(n)\n\n# Abh. Variable erzeugen, Behandlungseffekt (ATE) ist 2\nY &lt;- 2 * B + \n  XB %*% rnorm(p_B, mean = 10) + \n  XY %*% runif(p_Y) + \n  rnorm(n)\n\n# Variablen in tibble sammeln\nX &lt;- cbind(B, XB, XU, XY) %&gt;% \n  as_tibble()\n\n# Namen zuweisen\ncolnames(X) &lt;- c(\n  \"B\", \n  paste0(\"XB\", 1:p_B), \n  paste0(\"XU\", 1:p_U),\n  paste0(\"XY\", 1:p_Y) \n)\n\nWünschenswert wäre die KQ-Schätzung des wahren Modells. Diese ergibt eine Schätzung nahe des wahren Treatment-Effekts \\(\\alpha_0 = 2\\). Unter realen Bedingungen wäre diese Regression jedoch nicht implementierbar, weil die relevanten Kovariablen XB unbekannt sind.\n\n# KQ: Wahres Modell schätzen\nlm(Y ~ B + XB - 1)$coefficients[\"B\"]\n\n       B \n1.937031 \n\n\nWir schätzen daher zunächst die “lange” Regression mit allen \\(k\\) verfügbaren Variablen mit KQ. Beachte, dass der KQ-Schätzer für \\(\\alpha_0\\) zwar implementierbar und erwartungstreu ist, jedoch eine hohe Varianz aufweist. Wegen \\(k=N=550\\) erhalten wir eine perfekte Anpassung an die Daten und können mangels Freiheitsgraden keine Hypothesentests durchführen.\n\n# KQ: Lange Regression schätzen\nlm(Y ~ . - 1, data = X)$coefficients[\"B\"]\n\n       B \n3.079497 \n\n\nDie KQ-Schätzung von \\(\\alpha_0\\) anhand der langen Regression weicht deutlich vom wahren Wert \\(\\alpha_0 = 2\\) ab.\nEine “kurze” KQ-Regression nur mit der Behandlungsvariable \\(B\\) führt wegen Korrelation mit den ausgelassenen Determinanten in XB zu einer deutlich verzerrten Schätzung.\n\n# KQ: Kurze Regression\nlm(Y ~ B - 1)$coefficients[\"B\"]\n\n       B \n6.716837 \n\n\nDie Methoden von Belloni und Chernozhukov (2013) und Belloni, Chernozhukov, und Hansen (2014) sind im R-Paket hdm implementiert. Mit den Funktionen hrm::rlasso() und hdm::rlassoEffect kann Lasso-Regression sowie Post- und Double-Post-Selection durchgeführt werden.23\nWir berechnen zunächst den naiven Lasso-Schätzer in einem Modell mit allen Variablen.\n\nlibrary(hdm)\n\n# Naiver Post-Lasso-Schätzer\nlasso &lt;- rlasso(\n  x = X, \n  y = Y, \n  intercept = F, \n  post = F\n)\n\n# Koeffizientenschätzer auslesen\nlasso$coefficients[\"B\"] \n\n       B \n6.368456 \n\n\nAuch dieser Schätzer ist deutlich verzerrt. Problematisch ist hier nicht nur die Shrinkage auf \\(\\widehat{\\alpha}_0\\), sondern die Selektion der Variablen in XB:\n\n# Welche Variablen in XB selektiert Lasso *nicht*?\nnselektiert &lt;- which(lasso$coef[1:26] == 0)   # ID\n\n# Namen auslesen\nnames(lasso$coef[1:26])[nselektiert]\n\n[1] \"XB8\"  \"XB10\" \"XB16\" \"XB18\" \"XB20\"\n\n\nDurch das Auslassen dieser Determinanten von \\(Y\\) und \\(B\\) leidet der Lasso-Schätzer unter OVB.\nAls nächstes berechnen wir den Post-Lasso-Selection-Schätzer.\n\n# Post-Lasso-Selection-Schätzer berechnen\np_lasso &lt;- rlasso(\n  x = X,\n  y = Y, \n  intercept = F, \n  post = T\n)\n\n# Schätzung für alpha_0\np_lasso$coef[\"B\"]\n\n       B \n6.362409 \n\n\nDie Ähnlichkeit der Post-Lasso-Schätzung von \\(\\alpha_0\\) zur Lasso-Schätzung zeigt deutlich, dass die Verzerrung des Lasso-Schätzers überwiegend durch ausgelassene Variablen anstatt durch Shrinkage verursacht wird.\nMit rlassoEffect() können wir den Post-Double-Selection-Schätzer berechnen.\n\n# Post-Double-Selection-Schätzer\npds_lasso &lt;- rlassoEffect(\n  x = X %&gt;% \n    dplyr::select(-B) %&gt;% \n    as.matrix(),\n  y = Y, \n  d = B, \n  method = \"double selection\"\n)\n\n# Schnittmenge der selektierten Determinanten \n# von Y und B\n(\n  S_BY &lt;- names(\n    which(pds_lasso$selection.index)\n  )\n)\n\n [1] \"XB1\"   \"XB2\"   \"XB3\"   \"XB4\"   \"XB5\"   \"XB6\"   \"XB7\"   \"XB8\"   \"XB9\"  \n[10] \"XB10\"  \"XB11\"  \"XB12\"  \"XB13\"  \"XB14\"  \"XB15\"  \"XB16\"  \"XB17\"  \"XB18\" \n[19] \"XB19\"  \"XB20\"  \"XB21\"  \"XB22\"  \"XB23\"  \"XB24\"  \"XB25\"  \"XU209\" \"XU241\"\n[28] \"XU295\" \"XY3\"   \"XY7\"   \"XY8\"   \"XY12\"  \"XY13\"  \"XY15\"  \"XY16\"  \"XY19\" \n[37] \"XY23\" \n\n\nDouble Selection führt ebenfalls zu einem Post-Lasso-KQ-Schätzer mit allen 25 relevaten Variablen in XB. Wir selektieren allerdings deutlich weniger irrelevante Variablen aus XU als mit Single Selection und dennoch einige Determinanten von \\(Y\\) aus XY. Double Selection führt also zu einer unverzerrten Schätzen mit geringerer Varianz. Mit summary() erhalten wir gültige Inferenz bzgl. des Treatment-Effekts.\n\nsummary(pds_lasso)\n\n[1] \"Estimates and significance testing of the effect of target variables\"\n   Estimate. Std. Error t value Pr(&gt;|t|)    \nd1   1.94977    0.07127   27.36   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDer Post-Double-Selection-Schätzer liefert unter den betrachteten Verfahren die beste Schätzung von \\(\\alpha_0\\) und erlaubt gülstige statistische Inferenz. Der geschätzte Effekt ist hoch-signifikant.\n\n\n\n\n\n\nKey Facts zum Post-Double-Selection-Schätzer\n\n\n\n\nDurch die sorgfältige Auswahl von Variablen, die mit Behandlung- und Outcome-Variable zusammenhängen, ermöglicht die Double-Selection eine bessere Kontrolle über das Risiko ausgelassender Variablen in Beobachtungsstudien und ermöglicht gültige (asymptotisch normale) Inferenz.\nDer Post-Double-Selection-Schätzer besteht aus drei Regressionen:\n\nEs werden Variablen mit Lasso selektiert, welche die Behandlungs-Variable erklären.\nEs werden Variablen mit Lasso selektiert, welche die Outcome-Variable erklären.\nDer Post-Double-Selection-Schätzer ist der KQ-Schätzer in einer Regression, die für die Schnittmenge der ausgewählten Variablen kontrolliert.\n\nDank der Selektion mit Lasso kann der Schätzer auch bei hoch-dimensionalen Daten (\\(k&gt;n\\)) angewendet werden.\nPost-Double-Selection-Schätzer für Behandlungseffekte sind im R-Paket hdm implementiert.\n\n\n\n\n13.4.1 Case Study: Makroökonomisches Wachstum\nZur Illustration des Post-Double-Selection Schätzers betrachten wir eine empirische Anwendung bzgl. der Validierung von makroökonomischer Wachstumtheorie. Aus neo-klassischen Ansätzen wie dem Solow-Swan-Modell kann die Hypothese, dass Volkswirtschaften zu einem gemeinsamen Wachstumspfad hin konvergieren, abgeleitet werden. Diese Konvergenzhypothese impliziert die Existenz von Aufholeffekten: Ärmere Volkswirtschaften müssen im mittel schneller Wachsen als die Wirschaft wohlhabender Länder. Die grundlegende Spezifikation eines entsprechenden Regressionsmodells lautet \\[\\begin{align}\n  \\text{WR}_{i} = \\alpha_0 \\text{BIP0}_i + u_i, \\label{eq:growthmodel1}\n\\end{align}\\] wobei \\(\\text{WR}_{i}\\) die Wachstumsrate des Pro-Kopf-BIP in Land \\(i\\) über einen Zeitraum (typischerweise berechnet als Log-Differenz zwischen zwei Perioden) und \\(\\text{BIP0}_i\\) das (logarithmierte) Pro-Kopf-BIP zu beginn der Referenzperiode ist. Gemäß der Konvergenzhypothese muss \\(\\alpha_0&lt;0\\) sein: Je wohlhabender eine Volkswirtschaft ist, desto geringer ist das Wirtschaftswachstum.\nUm Verzerrung durch ausgelassene Kovariablen zu vermeiden, sollte das Modell \\(\\eqref{eq:growthmodel1}\\) um länder-spezifische Regressoren \\(x_{i,j}\\), die sowohl das Ausgagnsniveau \\(\\text{BIP0}\\) sowie die Wachtumsrate beinflussen, erweitert werden. Zu der großen Menge potentieller Kovariablen gehören makro- und sozio-ökonomische Maße wie bspw. die Investitionstätigkeit des Staates, Offenheit der Volkswirtschaft, das politische Umfeld, das Bildungsniveau, die Demographie usw. Eine bevorzugte Spezifikation ist daher \\[\\begin{align}\n  \\text{WR}_{i} = \\alpha_0 \\text{BIP0}_i + \\sum_{j=1}^k \\beta_j x_{i,j} + u_i,\\label{eq:growthmodel2}\n\\end{align}\\] wobei \\(\\alpha_0\\) als Behandlungseffekt interpretiert werden kann. Beachte, dass \\(\\eqref{eq:growthmodel2}\\) eine Regression in der Form von \\(\\eqref{eq:lassotmt}\\) ist.\nWir illustrieren die Schätzung von und Inferenz bzgl. \\(\\alpha_0\\) in \\(\\eqref{eq:growthmodel2}\\) mit Post-Double-Selektion für einen 90 Länder umfassenden Auszug aus dem Datensatz von Barro und Lee (2013), der als Objekt GrowthData im R-Paket hdm verfügbar ist.24\n\n# Datensatz in Arbeitsumgebung verfügbar machen\nlibrary(hdm)\ndata(GrowthData)\n\n# Anzahl Beobachtungen und Variablen\ndim(GrowthData)\n\n[1] 90 63\n\n\nDie Spalte Outcome ist die jeweilige Wachstumsrate des BIP zwischen den Perioden 1965-1975 und 1975-1985 und gdpsh465 ist das reale Pro-Kopf-BIP im Jahr 1965 zu Preisen von 1980.\nWir führen zunächst eine graphische Analyse hinsichtlich des Modells einfachen Modells \\(\\eqref{eq:growthmodel1}\\) durch, indem wir gdpsh465 gegen Outcome plotten und die geschätzte Regressionsgerade einzeichnen.\n\n# Einfache grafische Analyse mit ggplot2\nGrowthData %&gt;%\n  ggplot(\n    mapping = aes(\n      x = gdpsh465, \n      y = Outcome\n    )\n  ) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\nAbbildung 13.10: BIP-Wachstum: Einfache Regression\n\n\n\n\n\nAbbildung 13.10 zeigt einen geringen positiven geschätzten Effekt \\(\\widehat{\\alpha}_0\\). Eine Auswertung mit lm() ergibt, dass der Effekt \\(\\alpha_0\\) nicht signifikant von \\(0\\) verschieden ist.\n\n# Einfache Regression durchführen, \n# Inferenz für gdpsh465 erhalten\nlm(Outcome ~ gdpsh465, data = GrowthData) %&gt;%\n  summary() %&gt;%\n  coefficients() %&gt;% \n  .[2, ]\n\n   Estimate  Std. Error     t value    Pr(&gt;|t|) \n0.001316713 0.006102200 0.215776701 0.829661165 \n\n\nDer positive Effekt aus der einfachen Schätzung widerspricht der Konvergenzhypothese. Dieses Ergebnis könnte allerdings durch Auslassen relevanter Kovariablen ungültig sein. Beispielsweise ist es plausibel, dass das Bildungsniveau einer Volkswirtschaft sowohl mit dem BIP korreliert ist als auch die Wachstumsrate beeinflusst. Dann wäre das Bildungsniveau eine relevante Kovariable, deren Auslassen zu einer verzerrten Schätzung von \\(\\alpha_0\\) führt.\nEine “lange” Regression mit allen Kovariablen ist zwar möglich, aber problematisch: Das Verhältnis von Beobachtungen (90) zu Regressoren (62) bedeutet eine hohe Unsicherheit der Schätzung.\n\n# Inferenz für alpha_0 in langer Regression\nsummary(\n  lm(Outcome ~ . - 1 , data = GrowthData)\n  ) %&gt;% \n  coefficients() %&gt;% \n  .[2, ]\n\n    Estimate   Std. Error      t value     Pr(&gt;|t|) \n-0.009377989  0.029887726 -0.313773911  0.756018518 \n\n\nDer geschätzte Koeffizient \\(\\widehat{\\alpha}_0\\) ist nun zwar negativ, liefert jedoch weiterhin keine Evidenz, dass \\(\\alpha_0\\) von 0 verschieden ist. Ein Vergleich der Standardfehler zeigt aber, dass die KQ-Schätzung aufgrund Berücksichtigung aller potentiellen Kovariablen mit deutlich größerer Varianz behaftet ist als in der einfachen KQ-Regression \\(\\eqref{eq:growthmodel1}\\)\nPost-Double-Selection erlaubt gültige Inferenz bzgl. \\(\\alpha_0\\) nach Schätzung der Menge relevanter Kovariablen. Wir weisen die entsprechenden Variablen R-Objekten zu und berechnen den Schätzer.\n\n# Variablen für Post-Double-Selection vorbereiten\n\n# abh. Variable\ny &lt;- GrowthData %&gt;% \n  pull(Outcome)\n\n# \"Treatment\"\nd &lt;- GrowthData %&gt;% \n  pull(gdpsh465)\n\n# potentielle Regressoren\nX &lt;- GrowthData %&gt;% \n  dplyr::select(\n    -Outcome, -intercept, -gdpsh465\n  )\n\n\n# Post-Double-Selection-Schätzer berechnen\nGrowth_DS &lt;- \n  rlassoEffect(\n    x = X %&gt;% \n      as.matrix(), \n    y = y, \n    d = d, \n    method = \"double selection\"\n)\n\nPost-Double-Selection wählt aus der Menge potentieller Kovariablen lediglich sieben Regressoren aus.\n\n# Selektierte Variablen einsehen\n# ID\nSelektion &lt;- Growth_DS$selection.index\n\n# Namen auslesen\nnames(\n  which(Selektion == T)\n)\n\n[1] \"bmp1l\"    \"freetar\"  \"hm65\"     \"sf65\"     \"lifee065\" \"humanf65\" \"pop6565\" \n\n\nTabelle 13.3 zeigt die Definitionen der ausgewählten Variablen.\n\n\n\n\nTabelle 13.3: Mit PDS selektierte Variablen aus GrowthData. Referenzjahr 1965.\n\n\n\n\n\n\n\n\n\nVariable\nBeschreibung\n\n\n\n\nbmp1l\nSchwarzmarktprämie d. Währung\n\n\nfreetar\nMaß für Zollbeschränkungen\n\n\nhm65\nEinschreibungsquote Uni (Männer)\n\n\nsf65\nBeschulungsquote Sekundarstufe (Frauen)\n\n\nlifee065\nLebenserwartung bei Geburt\n\n\nhumanf65\nDurschn. Bildung im Alter 25 (Frauen)\n\n\npop6565\nAnteil Bevölkerung ü. 65 Jahre\n\n\n\n\n\n\n\n\n\n\n\n# Gültige Inferenz mit dem Post-Double-Selection-Schätzer\nsummary(Growth_DS)\n\n[1] \"Estimates and significance testing of the effect of target variables\"\n   Estimate. Std. Error t value Pr(&gt;|t|)   \nd1  -0.05001    0.01579  -3.167  0.00154 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDas Ergebnis der Post-Double-Selection-Schätzung unterstützt die (bedingte) Konvergenzhypothese mit einer signifikanten negativen Schätzung \\(\\widehat{\\alpha}_0\\approx-0.05\\).\n\n\n\n\nBarro, Robert J., und Jong Wha Lee. 2013. „A new data set of educational attainment in the world, 1950–2010“. Journal of Development Economics 104: 184–98. https://doi.org/https://doi.org/10.1016/j.jdeveco.2012.10.001.\n\n\nBelloni, Alexandre, Daniel Chen, Victor Chernozhukov, und Christian Hansen. 2012. „Sparse models and methods for optimal instruments with an application to eminent domain“. Econometrica 80 (6): 2369–429.\n\n\nBelloni, Alexandre, und Victor Chernozhukov. 2013. „Least squares after model selection in high-dimensional sparse models“. Bernoulli, 521–47.\n\n\nBelloni, Alexandre, Victor Chernozhukov, und Christian Hansen. 2014. „High-dimensional methods and inference on structural and treatment effects“. Journal of Economic Perspectives 28 (2): 29–50.\n\n\nCortez, Paulo, und Alice Maria Gonçalves Silva. 2008. „Using data mining to predict secondary school student performance“.\n\n\nEfron, Bradley, Trevor Hastie, Iain Johnstone, und Robert Tibshirani. 2004. „Least angle regression“.\n\n\nHahn, P Richard, Carlos M Carvalho, David Puelz, und Jingyu He. 2018. „Regularization and confounding in linear regression for treatment effect estimation“.\n\n\nHoerl, Arthur E, und Robert W Kennard. 1970. „Ridge regression: Biased estimation for nonorthogonal problems“. Technometrics 12 (1): 55–67.\n\n\nTibshirani, Robert. 1996. „Regression shrinkage and selection via the lasso“. Journal of the Royal Statistical Society Series B: Statistical Methodology 58 (1): 267–88.",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regularisierte Regression</span>"
    ]
  },
  {
    "objectID": "RegReg.html#footnotes",
    "href": "RegReg.html#footnotes",
    "title": "13  Regularisierte Regression",
    "section": "",
    "text": "Beachte, dass für \\(\\lambda=0\\) die Verlustfunktion des KQ-Schätzers folgt.↩︎\nD.h. wir wählen \\(p\\), um einen Schätzer mit für die konkrete Anwendung hilfreichen Eigenschaften zu erhalten.↩︎\nBeispiel: X &lt;- matrix(rnorm(100), ncol = 10). Vergleiche solve(t(X) %*% X) und solve(t(X) %*% X + diag(.01, nrow = 10))↩︎\nBspw. mit der Funktion scale().↩︎\nOrthonormalität heißt \\(\\boldsymbol{X}_i'\\boldsymbol{X}_j = 1\\) für \\(i=j\\) und \\(0\\) sonst. Dann ist \\(\\boldsymbol{X}\\)’\\(\\boldsymbol{X} = \\boldsymbol{I}_k\\).↩︎\n\\((1+\\lambda)^{-1}\\) wird auch als Shrinkage-Faktor bezeichnet.↩︎\nFür bessere Interpretierbarkeit der Grafischen Auswertung, wählen wir positive und negative Koeffizienten mit gleichem Bertag.↩︎\nalpha ist ein Mischparameter im Algorithmus für elastic net, siehe ?glmnet.↩︎\nDie Wahl von lambda.1se ist eine Heuristik, welche die Schätzunsicherheit berücksichtigt und zu einem “sparsameren” Modell tendiert.↩︎\nWir verwenden eine Auszug aus dem Orignaldatensatz, der nebst ausführlicher Variablenbeschreibung hier verfügbar ist.↩︎\nZur Bestimmung des Schätzers werden Algorithmen der nicht-linearen Optimierung genutzt.↩︎\nLARS steht für Least Angle Regression.↩︎\nlars() standardisiert die Regressoren standardmäßig (aufgrund des DGPs hier nicht nötig).↩︎\nAktivierung meint die Aufnahme einer Variable in der Modell gegeben eines hinreichend kleinen \\(\\lambda\\).↩︎\nChetverikov, Liao, and Chernozhukov (2020) zeigen, dass CV zu konsistenter Modellselektion führen kann.↩︎\nWegen \\(N=25\\) verbleiben bei der KQ-Schätzung mit 9 Regressoren nur 16 Freiheitsgrade.↩︎\nDies folgt aus der Definition von walk. &lt;- bewirkt hier lediglich Assignment in der Funktionsumgebung.↩︎\nDie Sequenzen haben wir in Abhängigkeit des DGP so gewählt, dass die Abhängigkeit der Prognosegüte von \\(\\lambda\\) gut visualisiert werden kann.↩︎\nBeachte, dass der KQ-Schätzer bei \\(k&gt;N\\) nicht lösbar ist.↩︎\nDieses Szenario wird unter Bedingungen bzgl. der Wachstumsrate und der Größe der Koeffizienten betrachet, s. (Belloni und Chernozhukov 2013).↩︎\nHahn u. a. (2018) geben eine ausführliche Erläuterung dieser Problematik.↩︎\nSolche Verfahren werden Post-Selection-Schätzer gennant.↩︎\nDiese Funktionen ermitteln ein optimales \\(\\lambda\\) mit dem in Belloni u. a. (2012) vorgeschlagenen Algorithmus.↩︎\nEine ausführliche Beschreibung der Variablen ist hier einsehbar.↩︎",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regularisierte Regression</span>"
    ]
  },
  {
    "objectID": "Machine Learning.html",
    "href": "Machine Learning.html",
    "title": "14  Machine Learning",
    "section": "",
    "text": "Das Gradientenabstiegsverfahren (Gradient Descent) ist ein iteratives Optimierungsverfahren zur Minimierung einer differenzierbaren Zielfunktion \\(f(x)\\). Es wird häufig eingesetzt, um die Verlustfunktionen in maschinellen Lernmodellen zu minimieren. Der Algorithmus aktualisiert die Variablen schrittweise in die entgegengesetzte Richtung des Gradienten der Funktion an der aktuellen Position. Der Gradient gibt dabei die Richtung des steilsten Anstiegs an, wodurch die entgegengesetzte Richtung zum schnellsten Abstieg (Descent) führt.\nDer folgende Pseudocode zeigt die grundlegende Vorgehensweise des Gradientenabstiegsverfahrens unter Einbeziehung eines Momentum-Terms, der dazu dient, das Konvergenzverhalten zu verbessern und lokale Minima effektiver zu überwinden.\n\\[\\begin{align*}\n& \\textbf{Algorithmus: Gradientenabstiegsverfahren mit Momentum} \\\\\n& \\textup{Initialisiere: }\\\\\n& \\quad x_0 \\text{ (Startpunkt) }\\\\\n& \\quad \\eta \\text{ (Lernrate) }\\\\\n& \\quad \\alpha \\text{ (Momentum-Faktor) }\\\\\n& \\quad v_0 = 0 \\text{ (Anfangsmomentum) } \\\\[1em]\n& \\text{Für } t = 0, 1, 2, \\dots \\text{ bis Konvergenz} \\\\\n& \\quad \\text{1. Berechne den Gradienten: } \\nabla f(x_t) \\\\\n& \\quad \\text{2. Aktualisiere den Momentum-Term: } v_{t+1} = \\alpha v_t - \\eta \\nabla f(x_t) \\\\\n& \\quad \\text{3. Aktualisiere die Position: } x_{t+1} = x_t + v_{t+1} \\\\\n& \\quad \\text{4. Überprüfe das Abbruchkriterium (z.B. } \\| \\nabla f(x_t) \\| &lt; \\epsilon\\text{)} \\\\\n\\end{align*}\\]",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Machine Learning</span>"
    ]
  },
  {
    "objectID": "Literatur.html",
    "href": "Literatur.html",
    "title": "Literatur",
    "section": "",
    "text": "Abadie, Alberto, Alexis Diamond, and Jens Hainmueller. 2014.\n“Comparative Politics and the Synthetic Control Method:\nCOMPARATIVE POLITICS AND THE SYNTHETIC CONTROL METHOD.”\nAmerican Journal of Political Science 59 (2): 495–510. https://doi.org/10.1111/ajps.12116.\n\n\nAbadie, Alberto, and Guido W. Imbens. 2008. “On the Failure of the\nBootstrap for Matching Estimators.” Econometrica. Journal of\nthe Econometric Society 76 (6): 1537–57. https://doi.org/10.3982/ECTA6474.\n\n\nAbadie, Alberto, and Jann Spiess. 2022. “Robust Post-Matching\nInference.” Journal of the American Statistical\nAssociation 117 (538): 983–95. https://doi.org/10.1080/01621459.2020.1840383.\n\n\nAbadie, Alexis Diamond, Alberto, and Jens Hainmueller. 2010.\n“Synthetic Control Methods for Comparative Case Studies:\nEstimating the Effect of California’s Tobacco Control Program.”\nJournal of the American Statistical Association 105 (490):\n493–505. https://doi.org/10.1198/jasa.2009.ap08746.\n\n\nAbrams, David S. 2012a. “Estimating the Deterrent Effect of\nIncarceration Using Sentencing Enhancements.” American\nEconomic Journal: Applied Economics 4 (4): 32–56. https://doi.org/10.1257/app.4.4.32.\n\n\nAbrams, David S. 2012b. “Replication Data for: Estimating the\nDeterrent Effect of Incarceration Using Sentencing Enhancements.”\nICPSR - Interuniversity Consortium for Political; Social Research. https://doi.org/10.3886/E113838V1.\n\n\nAcemoglu, Daron, Giuseppe De Feo, and Giacomo Davide De Luca. 2020.\n“Weak States: Causes and Consequences of the Sicilian\nMafia.” The Review of Economic Studies. https://doi.org/10.1093/restud/rdz009.\n\n\nAcemoglu, Daron, Simon Johnson, James A. Robinson, and Pierre Yared.\n2008a. “Income and Democracy.” American Economic\nReview 98 (3): 808–42. https://doi.org/10.1257/aer.98.3.808.\n\n\n———. 2008b. “Replication Data for: Income and Democracy.”\nICPSR - Interuniversity Consortium for Political; Social Research. https://doi.org/10.3886/E113251V1.\n\n\nAdireksombat, Kampon. 2010. “The Effects of the 1993 Earned Income\nTax Credit Expansion on the Labor Supply of Unmarried Women.”\nPublic Finance Review 38 (1): 11–40. https://doi.org/https://doi.org/10.1177/1091142109358626.\n\n\nAndrews, D. W. K. 2003. “End-of-Sample Instability Tests.”\nEconometrica 71 (6): 1661–94. https://doi.org/10.1111/1468-0262.00466.\n\n\nArellano, Manuel, and Stephen Bond. 1991. “Some Tests of\nSpecification for Panel Data: Monte Carlo Evidence and an Application to\nEmployment Equations.” The Review of Economic Studies 58\n(2): 277. https://doi.org/10.2307/2297968.\n\n\nAustin, P. 2011. “An Introduction to Propensity Score Methods for\nReducing the Effects of Confounding in Observational Studies.”\nMultivariate Behavioral Research 46 (3): 399–424. https://doi.org/10.1080/00273171.2011.568786.\n\n\nAustin, Peter C., and Dylan S. Small. 2014. “The Use of\nBootstrapping When Using Propensity-Score Matching Without Replacement:\nA Simulation Study.” Statistics in Medicine 33 (24):\n4306–19. https://doi.org/10.1002/sim.6276.\n\n\nAustin, Peter C., and Elizabeth A. Stuart. 2017. “Estimating the\nEffect of Treatment on Binary Outcomes Using Full Matching on the\nPropensity Score.” Statistical Methods in Medical\nResearch 26 (6): 2505–25. https://doi.org/10.1177/0962280215601134.\n\n\nBarro, Robert J., and Jong Wha Lee. 2013. “A New Data Set of\nEducational Attainment in the World, 1950–2010.” Journal of\nDevelopment Economics 104: 184–98. https://doi.org/https://doi.org/10.1016/j.jdeveco.2012.10.001.\n\n\nBasten, Christoph, and Frank Betz. 2013. “Beyond Work Ethic:\nReligion, Individual, and Political Preferences.” American\nEconomic Journal: Economic Policy 5 (3): 67–91.\n\n\nBelloni, Alexandre, Daniel Chen, Victor Chernozhukov, and Christian\nHansen. 2012. “Sparse Models and Methods for Optimal Instruments\nwith an Application to Eminent Domain.” Econometrica 80\n(6): 2369–429.\n\n\nBelloni, Alexandre, and Victor Chernozhukov. 2013. “Least Squares\nAfter Model Selection in High-Dimensional Sparse Models.”\nBernoulli, 521–47.\n\n\nBelloni, Alexandre, Victor Chernozhukov, and Christian Hansen. 2014.\n“High-Dimensional Methods and Inference on Structural and\nTreatment Effects.” Journal of Economic Perspectives 28\n(2): 29–50.\n\n\nBodory, Hugo, Lorenzo Camponovo, Martin Huber, and Michael Lechner.\n2020. “The Finite Sample Performance of Inference Methods for\nPropensity Score Matching and Weighting Estimators.” Journal\nof Business & Economic Statistics. https://doi.org/10.2139/ssrn.2731969.\n\n\nBorn, Benjamin, Gernot J Müller, Moritz Schularick, and Petr Sedláček.\n2019. “The Costs of Economic Nationalism: Evidence from the Brexit\nExperiment*.” The Economic Journal 129 (623): 2722–44.\nhttps://doi.org/10.1093/ej/uez020.\n\n\nCallaway, Brantly, and Pedro H. C. Sant’Anna. 2021.\n“Difference-in-Differences with Multiple Time Periods.”\nJournal of Econometrics 225 (2): 200–230. https://doi.org/10.1016/j.jeconom.2020.12.001.\n\n\nCameron, A. Colin, Jonah B. Gelbach, and Douglas L. Miller. 2008.\n“Bootstrap-Based Improvements for Inference with Clustered\nErrors.” Review of Economics and Statistics 90 (3):\n414–27. https://doi.org/10.1162/rest.90.3.414.\n\n\n———. 2011. “Robust Inference with Multiway Clustering.”\nJournal of Business &Amp; Economic Statistics 29 (2):\n238–49. https://doi.org/10.1198/jbes.2010.07136.\n\n\nCattaneo, Matias D, Michael Jansson, and Xinwei Ma. 2020. “Simple\nLocal Polynomial Density Estimators.” Journal of the American\nStatistical Association 115 (531): 1449–55.\n\n\nCortez, Paulo, and Alice Maria Gonçalves Silva. 2008. “Using Data\nMining to Predict Secondary School Student Performance.”\n\n\nCutrera, Antonino. 1900. La Mafia E I Mafiosi.\n(Palermo, IT: Reber).\n\n\nDahl, Robert Alan. 1971. Polyarchy: Participation and Opposition:\nParticipation and Opposition. New Haven: Yale Univ. Press.\n\n\nDi Tella, Rafael, and Ernesto Schargrodsky. 2004. “Do Police\nReduce Crime? Estimates Using the Allocation of Police Forces After a\nTerrorist Attack.” American Economic Review 94 (1):\n115–33. https://doi.org/10.1257/000282804322970733.\n\n\nEfron, B. 1979. “Bootstrap Methods: Another Look at the\nJackknife.” The Annals of Statistics 7 (1). https://doi.org/10.1214/aos/1176344552.\n\n\nEfron, Bradley, Trevor Hastie, Iain Johnstone, and Robert Tibshirani.\n2004. “Least Angle Regression.”\n\n\nEissa, N., and J. B. Liebman. 1996. “Labor Supply Response to the\nEarned Income Tax Credit.” The Quarterly Journal of\nEconomics 111 (2): 605–37. https://doi.org/10.2307/2946689.\n\n\nFearon, James D., and David D. Laitin. 2003. “Ethnicity,\nInsurgency, and Civil War.” American Political Science\nReview 97 (01): 75–90. https://doi.org/10.1017/s0003055403000534.\n\n\nGelman, Andrew, and Guido Imbens. 2019. “Why High-Order\nPolynomials Should Not Be Used in Regression Discontinuity\nDesigns.” Journal of Business & Economic Statistics\n37 (3): 447–56.\n\n\nGoodman-Bacon, Andrew. 2021. “Difference-in-Differences with\nVariation in Treatment Timing.” Journal of Econometrics\n225 (2): 254–77. https://doi.org/10.1016/j.jeconom.2021.03.014.\n\n\nHahn, P Richard, Carlos M Carvalho, David Puelz, and Jingyu He. 2018.\n“Regularization and Confounding in Linear Regression for Treatment\nEffect Estimation.”\n\n\nHainmueller, Jens. 2012. “Entropy Balancing for Causal Effects: A\nMultivariate Reweighting Method to Produce Balanced Samples in\nObservational Studies.” Political Analysis 20 (1):\n25–46. https://doi.org/10.1093/pan/mpr025.\n\n\nHainmueller, Jens, Alexis Diamond, and Alberto Abadie. 2011.\n“Synth: An r Package for Synthetic Control Methods in Comparative\nCase Studies.” Journal of Statistical Software 42 (13):\n1–17. https://www.jstatsoft.org/v42/i13/.\n\n\nHájek, J. 1971. “Comment on ‘an Essay on the Logical\nFoundations of Survey Sampling’ by Basu, d.”\nFoundations of Statistical Inference 236.\n\n\nHansen, Lars Peter. 1982. “Large Sample Properties of Generalized\nMethod of Moments Estimators.” Econometrica 50 (4):\n1029. https://doi.org/10.2307/1912775.\n\n\nHill, Jennifer, and Jerome P. Reiter. 2006. “Interval Estimation\nfor Treatment Effects Using Propensity Score Matching. Statistics in\nMedicine.” Statistics in Medicine 25 (13): 2230–56. https://doi.org/10.1002/sim.2277.\n\n\nHirano, Keisuke, Guido Imbens, and Geert Ridder. 2003. “Efficient\nEstimation of Average Treatment Effects Using the Estimated Propensity\nScore.” Econometrica 71 (4): 1161–89. https://doi.org/10.1111/1468-0262.00442.\n\n\nHoerl, Arthur E, and Robert W Kennard. 1970. “Ridge regression: Biased estimation for nonorthogonal\nproblems.” Technometrics 12 (1): 55–67.\n\n\nHuntington, Samuel P. 1991. The Third Wave: Democratization in the\nLate Twentieth Century: Democratization in the Late Twentieth\nCentury. Norman, OK: Univ. of Oklahoma Press.\n\n\nHuntington-Klein, Nick. 2021. The Effect: An Introduction to\nResearch Design and Causality. Chapman; Hall/CRC. https://doi.org/10.1201/9781003226055.\n\n\nImbens. 2016. “Matching on the Estimated Propensity Score.”\nEconometrica 84 (2): 781–807. https://doi.org/10.3982/ecta11293.\n\n\nImbens, G. W., and Thomas Lemieux. 2008. “Regression Discontinuity\nDesigns: A Guide to Practice.” Journal of Econometrics\n142 (2): 615–35.\n\n\nImbens, Guido, and Karthik Kalyanaraman. 2012. “Optimal Bandwidth\nChoice for the Regression Discontinuity Estimator.” The\nReview of Economic Studies 79 (3): 933–59.\n\n\nJacobson, Louis S., Robert J. LaLonde, and Daniel G. Sullivan. 1993.\n“Earnings Losses of Displaced Workers.” The American\nEconomic Review 83 (4): 685–709. http://www.jstor.org/stable/2117574.\n\n\nLee, David S. 2008. “Randomized Experiments from Non-Random\nSelection in US House Elections.” Journal of\nEconometrics 142 (2): 675–97.\n\n\nLiu, Regina Y. 1988. “Bootstrap Procedures Under Some Non-i.i.d.\nModels.” The Annals of Statistics 16 (4): 1696–1708. https://doi.org/10.1214/aos/1176351062.\n\n\nLove, Thomas. 2004. “Graphical Display of Covariate\nBalance.” Presentation.\n\n\nMcCrary, Justin. 2008. “Manipulation of the Running Variable in\nthe Regression Discontinuity Design: A Density Test.” Journal\nof Econometrics 142 (2): 698–714.\n\n\nMiguel, Edward, Shanker Satyanath, and Ernest Sergenti. 2004.\n“Economic Shocks and Civil Conflict: An Instrumental Variables\nApproach.” Journal of Political Economy 112 (4): 725–53.\nhttps://doi.org/10.1086/421174.\n\n\nNickell, Stephen. 1981. “Biases in Dynamic Models with Fixed\nEffects.” Econometrica 49 (6): 1417. https://doi.org/10.2307/1911408.\n\n\nRosenbaum, Paul R., and Donald R. Rubin. 1983. “The Central Role\nof the Propensity Score in Observational Studies for Causal\nEffects.” Biometrika 70 (1): 170–84. https://doi.org/10.1017/cbo9780511810725.016.\n\n\nRueschemeyer, Dietrich, Evelyne H. Stephens, and John D. Stephens. 1992.\nCapitalist Development and Democracy. Cambridge: Polity Pr.\n\n\nSargan, J. D. 1958. “The Estimation of Economic Relationships\nUsing Instrumental Variables.” Econometrica 26 (3): 393.\nhttps://doi.org/10.2307/1907619.\n\n\nTibshirani, Robert. 1996. “Regression Shrinkage and Selection via\nthe Lasso.” Journal of the Royal Statistical Society Series\nB: Statistical Methodology 58 (1): 267–88.\n\n\nWeber, Max. 2004. Die Protestantische Ethik Und Der Geist Des\nKapitalismus. Vol. 1614. CH Beck.\n\n\nWooldridge, Jeffrey. 2010. Econometric Analysis of Cross Section and\nPanel Data. Second edition. Cambridge, Massachusetts: MIT.",
    "crumbs": [
      "Literatur"
    ]
  }
]