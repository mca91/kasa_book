[
  {
    "objectID": "FixedEffects.html",
    "href": "FixedEffects.html",
    "title": "\n5  Panel-Daten\n",
    "section": "",
    "text": "5.1 Pooled Regression und unbeobachtbare Heterogenität\nEin Panel-Datensatz enthält Beobachtungen von \\(n\\) Einheiten für (bis zu) \\(T\\) Zeitpunkte, wobei \\(t=1,\\dots,T\\). Betrachte das Panel-Modell\n\\[\\begin{align}\n  Y_{it} = \\beta_0 + \\beta_1 B_{it} + \\beta_2 X_i + \\beta_3 U_i + \\epsilon_{it},\\label{eq:unobshetmodel}\n\\end{align}\\]\nwobei \\(U_i\\) unbeobachtete und \\(X_i\\) beobachtete, zeitlich-invariante Heterogenitäten zwischen den Beobachtungseinheiten \\(i=1,\\dots,n\\) sind. Wie zuvor ist \\(B_{it}\\) die Behandlungsvariable und \\(\\beta_1\\) der interessierende kausale Effekt einer Veränderung von \\(B_{it}\\) auf \\(Y_{it}\\).\nAngenommen wir beobachten \\(Y_{it}\\) und \\(B_{it}\\) für \\(T=1\\), also für eine Periode. Bei Korrelation zwischen den unbeobachtbaren zeit-invarianten Effekten \\(U_i\\) und der Behandlungsvariable \\(B_{it}\\) kann der kausale Effekt \\(\\beta_1\\) nicht identifiziert werden. Diese Situation ist in Abbildung 5.1 dargestellt.\nFE_dag_single_period\nU\nUiX\nXiU-&gt;X\nB\nBt=1U-&gt;B\nY\nYt=1U-&gt;Y\nX-&gt;B\nX-&gt;Y\nB-&gt;Y\n\n\n\n\nAbbildung 5.1: Backdoors durch beobachtete und unbeobachtete Variablen\nAbbildung 5.1 zeigt Backdoors durch die \\(U_i\\), die wir mit einer “naiven” KQ-Schätzung der fehlspezifizierten Regression \\[\\begin{align}\n  Y_{it} = \\beta_0 + \\beta_1 B_{it} + \\beta_2 X_i + \\varepsilon_{it},\\quad t=1,\\label{eq:femodelfail}\n\\end{align}\\] mit \\(\\varepsilon_{it} = U_i + \\epsilon_{it}\\) nicht schließen können.1\nWir betrachten nun eine Generalisierung von Abbildung 5.1 für \\(T=2\\) Perioden, dargestellt in Abbildung 5.2.\nFE_dag2\nU\nUiX\nXiU-&gt;X\nB1\nBt=1U-&gt;B1\nY1\nYt=1U-&gt;Y1\nB2\nBt=2U-&gt;B2\nY2\nYt=2U-&gt;Y2\nX-&gt;B1\nX-&gt;Y1\nX-&gt;B2\nX-&gt;Y2\nB1-&gt;Y1\nB1-&gt;B2\nB2-&gt;Y2\n\n\n\n\nAbbildung 5.2: Panel-Design mit Backdoors durch beobachtete und unbeobachtete zeit-invariante Variablen\nDer in Abbildung 5.2 gezeigte Zusammenhang führt (idealerweise) zwar zu einer Verdoppelung des Beobachtungsumfangs, jedoch besteht weiterhin das in Abbildung 5.1 gezeigte Endogenitätsproblem, falls die Regression \\(\\eqref{eq:femodelfail}\\) nun anhand einer Zusammenlegung (Pooling) der Beobachtungen für \\(t\\in\\{1,2\\}\\) geschätzt wird:2 Die unbeobachteten zeit-invarianten Einflüsse \\(U_i\\) verursachen auch für Periode \\(t=2\\) Backdoor-Pfade.\nIn diesem Kapitel betrachten wir Panel-Verfahren, welche den kausalen Effekt in Abbildung 5.2 und Verallgemeinerungen hiervon schätzen können. Bevor wir diese Methoden betrachten, veranschaulichen wir die verzerrte Schätzung eines Behandlungseffekts mit Pooled Regression in Modell \\(\\eqref{eq:femodelfail}\\) bei unbeobachtbaren Heterogenitäten für einen simulierten Datensatz paneldata.csv. Der Datensatz enthält Beobachtungen von \\(n=12\\) Einheiten zu \\(T=8\\) Perioden. Alle Einheiten weisen unbeobachtbare zeit-invariante Heterogenitäten auf, die mit \\(B_{it}\\) korellieren. Der wahre Behandlungseffekt beträgt \\(\\beta_1 = -1\\).3\nWir lesen zunächst den Datensatz ein und selektieren die benötigten Variablen.\n# Datensatz 'paneldata.csv' einlesen\npaneldata &lt;- read_csv(\"datasets/paneldata.csv\") %&gt;% \n  select(X, Y, ID, time, col)\n# Panel-Dimensionen bestimmen\npaneldata %&gt;%\n  summarise(\n    N = unique(ID) %&gt;% length(),\n    T = unique(time) %&gt;% length()\n  )\n\n# A tibble: 1 × 2\n      N     T\n  &lt;int&gt; &lt;int&gt;\n1    12     8\nMit der Funktion plm::is.pbalanced() überprüfen wir, ob im Panel-Datensatz für alle beobachteten Einheiten die gleiche Anzahl an Beobachtungsperioden vorliegt (balanced panel).4\nlibrary(plm)\n\n# Datensatz balanced?\nis.pbalanced(\n  x = paneldata, \n  index = c(\"ID\", \"time\")\n)\n\n[1] TRUE\nZunächst schätzen wir eine Pooled Regression für die ersten beiden Zeitperioden, basierend auf einem entsprechend gefilterten Datensatz.5\n# Subsetting der Daten für 2 Perioden (t = {1, 2})\npaneldata_T2 &lt;- paneldata %&gt;% \n  filter(\n    dplyr::between(time, 1, 2)\n  )\nFür die Schätzung von \\(\\eqref{eq:femodelfail}\\) nutzen wir fixest::feols().\nlibrary(fixest)\n\n# Naive KQ-Schätzung für t = {1, 2}\npanel_KQ &lt;- feols(\n  fml = Y ~ X, \n  data = paneldata_T2\n)\n\nsummary(panel_KQ)\n\nOLS estimation, Dep. Var.: Y\nObservations: 24\nStandard-errors: IID \n            Estimate Std. Error  t value   Pr(&gt;|t|)    \n(Intercept) -2.50547   1.481150 -1.69157 1.0485e-01    \nX            3.80692   0.194202 19.60295 2.0252e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 3.28785   Adj. R2: 0.943388\nDie Schätzung von \\(\\beta_1\\) ist \\(3.81\\) und weist auf eine deutliche Verzerrung hin. Wir illustrieren die Problematik in Abbildung 5.3, in dem wir die für die Regression verwendeten Daten (Kreise) sowie die Beobachtungen späterer Perioden (Kreuze) nach Gruppenzugehörigkeit einfärben und die Schätzung der Pooled Regression abtragen.\nlibrary(cowplot)\n\n# Plot: Naiver KQ-Schätzer für t = 1, 2\nggplot(\n  mapping = aes(x = X, y = Y)\n) +\n  geom_point(\n    data = paneldata %&gt;% \n      filter(time &gt; 2),\n    mapping = aes(color = col),\n    pch = 3,\n    show.legend = F\n  ) +\n  geom_point(\n    data = paneldata %&gt;% \n      filter(time %in% 1:2),\n    mapping = aes(color = col),\n    show.legend = F\n  ) +\n  # Naive KQ-Schätzung für t = 1, 2\n  geom_smooth(\n    data = paneldata %&gt;% \n      filter(time %in% 1),\n    method = \"lm\", \n    se = F,\n    col = \"black\"\n  ) +\n  scale_color_identity() +\n  theme_cowplot()\n\n\n\n\n\n\nAbbildung 5.3: paneldaten.csv – Pooled Regression für t = 1, 2\nAbbildung 5.3 zeigt einen negativen Verlauf des Zusammenhangs zwischen X und Y anhand der Variation der Beobachtungen innerhalb der farblich gekennzeichneten Gruppen. Dieser negative Zusammenhang kann aufgrund der Endogenität von \\(X\\) nicht erfasst werden.\nEine Erweiturung der Regression auf sämtliche Perioden (Pooling aller \\(n\\times T = 12 \\times 8 = 96\\) Beobachtungen) erhöht lediglich die Präzision der Schätzung (geringerer Standardfehler von \\(\\widehat{\\beta}_1\\)), nicht aber die Endogenität, vgl. Abbildung 5.4.\n# Naive KQ-Schätzung für t = 1,...,8\npanel_KQ &lt;- feols(\n  fml = Y ~ X, \n  data = paneldata \n)\n\nsummary(panel_KQ)\n\nOLS estimation, Dep. Var.: Y\nObservations: 96\nStandard-errors: IID \n            Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept) -1.45318   1.008859 -1.44042   0.15307    \nX            3.76470   0.134364 28.01868 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 4.63461   Adj. R2: 0.891928\n# Plot: Naiver KQ-Schätzer für t = 1,...,8\nggplot(\n  data = paneldata,\n  mapping = aes(x = X, y = Y)\n) +\n  geom_point(\n    mapping = aes(color = col),\n    show.legend = F\n  ) +\n  # Pooled Schätzung\n  geom_smooth(\n    data = paneldata,\n    method = \"lm\", \n    se = F,\n    col = \"black\"\n  ) +\n  scale_color_identity() +\n  theme_cowplot()\n\n\n\n\n\n\nAbbildung 5.4: paneldaten.csv – Pooled Regression für t = 1, …, 8",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html#sec-panel-uh",
    "href": "FixedEffects.html#sec-panel-uh",
    "title": "\n5  Panel-Daten\n",
    "section": "",
    "text": "1 Wegen \\(E(\\varepsilon_{it}\\vert B_{it})\\neq 0\\) ist der KQ-Schätzer von \\(\\beta_1\\) nicht erwartungstreu und inkonsistent.\n\n\n2 Pooled Regression kann auch berechnet werden, wenn nicht für alle \\(n\\) Einheiten jeweils \\(T\\) Beobachtungen vorliegen (unbalanced Panel).3 Der (R code für den) DGP ist diesem StackExchange-Post entnommen.\n\n\n\n\n4 Fehlende Beobachtungen sind typischerweise mit einem NA-Wert gekennzeichnet. Der Differenz-Schätzer kann auch berechnet werden, wenn der Datensatz nicht ausgeglichen (unbalanced) ist.\n\n5 Wir verweisen nachfolgend explizit auf Funktionen aus dplyr, falls Funktionen aus plm identische Namen haben.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html#regression-in-differenzen",
    "href": "FixedEffects.html#regression-in-differenzen",
    "title": "\n5  Panel-Daten\n",
    "section": "\n5.2 Regression in Differenzen",
    "text": "5.2 Regression in Differenzen\nWir betrachten erneut den in Abbildung 5.2 dargestellten DGP für \\(T=2\\) Zeitperioden. In dieser Situation können Backdoors durch die \\(U_i\\) anhand einer simplen Transformation von Modell \\(\\eqref{eq:femodel}\\) geschlossen werden: Regression der Zeit-Differenzen zwischen den Perioden \\(t=2\\) und \\(t=1\\), \\[\\begin{align}\n  \\Delta Y_{it} = \\beta_1 \\Delta B_{it} + e_{it}, \\qquad i=1,\\dots,n,\\qquad t=1,2 \\label{eq:femodeldiff},\n\\end{align}\\] wobei \\(\\Delta Y_{it} := Y_{i2} - Y_{i1}\\) und \\(\\Delta e_{it} := \\epsilon_{i2} - \\epsilon_{i1}\\) für \\(t=2\\). Beachte, dass \\(\\Delta U_i=\\Delta X_i=0\\). Differenzieren der Komponenten führt zu einem Modell, in dem weder für (beobachtbare) \\(X_i\\) noch für (unbeobachtbare) \\(U_i\\) kontrolliert werden muss, damit \\(\\beta_1\\) identifiziert werden kann.6 Der Behandlungseffekt \\(\\beta_1\\) kann mit KQ geschätzt werden.7\n6 Ein Nachteil der Differenzbildung ist also, dass wir die Koeffizienten der beobachtbaren, zeitlich konstanten Regressoren nicht schätzen können.7 Der Differenzen-Schätzer ist erwartungstreu und konsistent, wenn \\(E(\\epsilon_{is}\\vert B_{it})=0\\) für \\(s\\geq t\\).Zur Transformation der Regressoren in fixest::feols() verwenden wir den Operator d(). Dieser benötigt die im Argument panel.id als Formel spezifizierten Identifikationsvariablen für Einheiten (ID) und Zeitpunkte (time).\n\n# Panel-Schätzer: KQ-Regression in Differenzen\npanel_diff &lt;- feols(\n  fml = d(Y) ~ d(X) - 1, \n  data = paneldata %&gt;% \n      filter(\n        dplyr::between(time, 1, 2)\n      ),\n  panel.id = ~ ID + time\n)\n\nsummary(panel_diff)\n\nOLS estimation, Dep. Var.: d(Y, 1)\nObservations: 12\nStandard-errors: Clustered (ID) \n        Estimate Std. Error  t value  Pr(&gt;|t|)    \nd(X, 1) -1.03205   0.326838 -3.15767 0.0091166 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.907432   Adj. R2: 0.509923\n\n\nDie Schätzung anhand der Regression in Differenzen liegt nahe beim wahren Behandlungseffekt \\(\\beta_1 = -1\\). Abbildung Abbildung 5.5 zeigt die ersten Differenzen der Daten und den mit KQ geschätzten Zusammenhang.\n\n# Transformation zu Differenzen\npaneldata_diff &lt;- paneldata %&gt;% \n  mutate(\n    DeltaX = X - dplyr::lag(X),\n    DeltaY = Y - dplyr::lag(Y)\n  ) %&gt;%\n  drop_na()\n\n# Plot: KQ-Schätzer für Differenzen  \n  ggplot(\n    mapping = aes(x = DeltaX, y = DeltaY)\n  ) + \n    geom_point(\n      data = paneldata_diff %&gt;% \n        filter(time &gt; 2),\n      mapping = aes(color = col),\n      pch = 3,\n      show.legend = F\n    ) +\n    geom_point(\n      data = paneldata_diff %&gt;% \n        filter(time == 2),\n      mapping = aes(color = col),\n      show.legend = F\n    ) +\n  geom_smooth(\n    data = paneldata_diff %&gt;% \n      filter(time == 2),\n    method = \"lm\", \n    se = F,\n    color = \"black\"\n  ) + \n  scale_color_identity() +\n  theme_cowplot()\n\n\n\n\n\n\nAbbildung 5.5: paneldaten.csv – Regression in Differenzen für t = 2\n\n\n\n\nWie bei Pooling können wir den Differenzen-Schätzer für den gesamten Datensatz berechnen.\n\n# Panel-Schätzer: KQ-Regression in Differenzen\npanel_diff &lt;- feols(\n  fml = d(Y) ~ d(X) - 1, \n  data = paneldata,\n  panel.id = ~ ID + time\n)\n\nsummary(panel_diff)\n\nOLS estimation, Dep. Var.: d(Y, 1)\nObservations: 84\nStandard-errors: Clustered (ID) \n         Estimate Std. Error  t value   Pr(&gt;|t|)    \nd(X, 1) -0.982042   0.135217 -7.26269 1.6178e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 1.12641   Adj. R2: 0.571235\n\n\nBeachte, dass der Standardfehler der Schätzers etwas größer ist als für den KQ-Schätzer in der Pooled Regression. Grund hierfür ist der Verlust von \\(12\\) Beobachtungen bei der Bildung der \\(T-1 = 7\\) Differenzen.\n\n# Plot: KQ-Schätzer in Differenzen (alle t)\nggplot(\n  data = paneldata_diff,\n  mapping = aes(x = DeltaX, y = DeltaY)\n) + \n  geom_point(\n    color = \"gray\",\n    show.legend = F\n  ) +\n  geom_point(\n    mapping = aes(color = col),\n    show.legend = F\n  ) +\n  geom_smooth(\n    method = \"lm\", \n    se = F,\n    color = \"black\"\n  ) + \n  scale_color_identity() +\n  theme_cowplot()\n\n\n\n\n\n\nAbbildung 5.6: paneldaten.csv – Regression in Differenzen für t = 2, …, 8",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html#fixed-effects-regression",
    "href": "FixedEffects.html#fixed-effects-regression",
    "title": "\n5  Panel-Daten\n",
    "section": "\n5.3 Fixed-Effects-Regression",
    "text": "5.3 Fixed-Effects-Regression\nDie KQ-Schätzung der Regression in Differenzen hat den Nachteil, dass die Koeffizienten von einheiten-spezifischen Variablen nicht geschätzt werden können. Weiterhin impliziert die Differenzbildung einen Verlust des Beobachtungsumfangs bei der Schätzung des kausalen Effekts.8 Für den Datensatz paneldata.csv verlieren wir \\(1/8\\) der Stichprobe. Abhängig von der empirischen Fragestellung und der Datenverfügbarkeit (Verhältnis von \\(T\\) und \\(n\\)) kann Fixed-Effects-Regression eine nützliche Alternative zu Regression in Differenzen sein.\n8 Eine Reduktion des Beobachtungsumfangs erhöht die Varianz der Schätzung. Für \\(T=2\\) ist der Differenzen-Schätzer äquivalent zu den Schätzern im Fixed-Effects-Modell, ist jedoch ineffizient für \\(T&gt;2\\).9 Beachte, dass eine bessere Anpassung an die Daten bei der Modellierung von paneldata.csv mit einheiten-spezifischen Achsenabschnitten anhand von Abbildung 5.4 plausibel scheint.Wir betrachten erneut Modell \\(\\eqref{eq:unobshetmodel}\\) und definieren \\[\\begin{align*}\n  \\alpha_i = \\beta_0 + \\beta_3 U_i.\n\\end{align*}\\] Nach einsetzen in \\(\\eqref{eq:unobshetmodel}\\) erhalten wir das Modell \\[\\begin{align}\n  Y_{it} = \\alpha_i + \\beta_1 B_{it} + \\beta_2 X_i + \\epsilon_{it} \\label{eq:femodel},\n\\end{align}\\] mit einheiten-spezifischen Konstanten (“feste Effekte”) \\(\\alpha_i\\) für \\(i=1,\\dots,n\\), die als individuelle Achsenabschnitte nterpretieren werden können. Das Modell \\(\\eqref{eq:femodel}\\) wird daher auch als Fixed-Effects-Modell bezeichnet.9\n\n5.3.1 Within- und LSDV-Schätzer\nFür die Vermeidung von Backdoors durch die \\(\\alpha_i\\) subtrahieren wir die einheiten-spezifischen Mittelwerte von den Komponenten (Within-Transformation)10, \\[\\begin{align}\n  Y_{it} - \\overline{Y}_i =&\\, (\\alpha_i - \\overline{\\alpha}_i) + \\beta_1 (B_{it} - \\overline{B}_i) + \\beta_2 (X_i - \\overline{X}_i) + (\\epsilon_{it} - \\overline{\\epsilon}_i)\\notag\\\\\n  \\tilde Y_{it} =&\\, \\beta_1 \\tilde B_{it} + \\tilde\\epsilon_{it}.\\label{eq:fewithin}\n\\end{align}\\] Der Within-Schätzer von \\(\\beta_1\\) ist der KQ-Schätzer in \\(\\eqref{eq:fewithin}\\). Dieser Schätzer nutzt die Variabilität innerhalb der Beobachtungseinheiten über die Zeit, um die Koeffizienten der unabhängigen Variablen zu schätzen. Ähnlich wie für den Differenzen-Schätzer eliminieren die Mittelwert-Differenzen \\(\\alpha_i - \\overline{\\alpha}_i=0\\) und \\(X_i - \\overline{X}_i=0\\) den Einfluss zeit-invarianter Variablen.\n10 Die Durchschnitte werden hierbei also über die Zeitperioden berechnet.11 Für \\(n-1\\) Einheiten ist der individuelle Achsenabschnitt damit \\(\\beta_0 + \\gamma_i\\) und für eine Einheit \\(\\beta_0\\). Diese Einheit (hier \\(i=1\\)) wird auch als Referenzkategorie bezeichnet. Alternativ kann das Modell mit \\(n\\) Dummies und ohne die Konstante \\(\\beta_0\\) geschrieben werden.12 KQ ist hier erwartungstreu und konsistent, sofern \\(E(\\epsilon_{is}\\vert B_{it})=0\\) für alle \\(s\\) und \\(t\\).Das Modell \\(\\eqref{eq:femodel}\\) kann weiterhin als eine Regression mit \\(n-1\\) Dummy-Variablen und einer Konstante geschrieben werden, \\[\\begin{align}\n  Y_{it} = \\beta_0 + \\beta_2 B_{it} + \\beta_2 X_i  + \\gamma_2 D^{(2)}_i + \\gamma_3 D^{(3)}_i + \\cdots + \\gamma_n D^{(n)}_i + \\epsilon_{it} \\label{eq:drmodel}.\n\\end{align}\\] Die Darstellung \\(\\eqref{eq:drmodel}\\) hat \\(n\\) verschiedene Achsenabschnitte – einen für jede Beobachtungseinheit – und kann ebenfalls mit KQ geschätzt werden.11 Der KQ-Schätzer ergibt für die Modelle \\(\\eqref{eq:femodel}\\) und \\(\\eqref{eq:drmodel}\\) numerisch äquivalente Schätzungen von \\(\\beta_1\\), wenn \\(X_i\\) in der Dummy-Regression ausgelassen wird.12 Die Schätzung von \\(\\eqref{eq:drmodel}\\) mit KQ wird in der Literatur auch als Least Squares Dummy Variables (LSDV) Regression bezeichnet.\nBeachte, dass die Schätzung der Koeffizienten beobachtbarer zeitlich konstanter Regressoren wie \\(X_{i}\\) lediglich in Modell \\(\\eqref{eq:drmodel}\\) möglich ist.\nFixed-Effects-Regressionen können mit fixest::feols() geschätzt werden.13 Je nach Spezifikation des Formula-Arguments (fml) wird ein effizienter Algorithmus für die entsprechende Transformation von \\(\\eqref{eq:femodel}\\) angwandt. Für paneldata.csv erhalten wir mit fml = Y ~ X | ID per Referenz des Indikators ID eine Variante des Within-Schätzers.\n13 Eine Alternative ist plm::plm() mit dem Argument method = \"within\".\n# Fixed-Effects-Schätzung\npanel_FE &lt;- feols(\n  fml = Y ~ X | ID,  \n  data = paneldata\n)\n\nsummary(panel_FE)\n\nOLS estimation, Dep. Var.: Y\nObservations: 96\nFixed-effects: ID: 12\nStandard-errors: Clustered (ID) \n  Estimate Std. Error  t value   Pr(&gt;|t|)    \nX -1.04507    0.10473 -9.97865 7.5526e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.746006     Adj. R2: 0.996829\n                 Within R2: 0.602694\n\n\nDie Zusammenfassung der Schätzung zeigt einen signifikanten Koeffizienten, der mit einer Schätzung von \\(-1.05\\) nahe beim wahren Wert von \\(\\beta_1 = -1\\) liegt. Die geschätzten einheiten-spezifischen Effekte können mit fixest::fixef() ausgelesen werden.\n\n# Geschätzte Fixed Effects (Einheiten) auslesen\nfixest::fixef(panel_FE)\n\n$ID\n        1         2         3         4         5         6         7         8 \n 3.814550  7.149097 12.716507 15.319130 23.458442 28.239634 33.659734 35.729516 \n        9        10        11        12 \n41.701817 47.911623 55.044052 59.445967 \n\nattr(,\"class\")\n[1] \"fixest.fixef\" \"list\"        \nattr(,\"exponential\")\n[1] FALSE\n\n\nMit fml = Y ~ X + factor(ID) erfolgt eine Schätzung der Dummy-Regression \\(\\eqref{eq:drmodel}\\) mit \\(n-1=11\\) Dummies. Der Referenzeinheit ist ID == 1. Wir sehen, dass der geschätzte Koeffizient von \\(X\\) mit dem Ergebnis des Within-Schätzers übereinstimmt.\n\n# LSDV-Schätzung\npanel_FE &lt;- feols(\n  fml = Y ~ X + factor(ID),  \n  data = paneldata\n)\n\nsummary(panel_FE)\n\nOLS estimation, Dep. Var.: Y\nObservations: 96\nStandard-errors: IID \n             Estimate Std. Error   t value   Pr(&gt;|t|)    \n(Intercept)   3.81455   0.298907  12.76164  &lt; 2.2e-16 ***\nX            -1.04507   0.093136 -11.22082  &lt; 2.2e-16 ***\nfactor(ID)2   3.33455   0.427925   7.79236 1.6832e-11 ***\nfactor(ID)3   8.90196   0.446770  19.92516  &lt; 2.2e-16 ***\nfactor(ID)4  11.50458   0.487840  23.58267  &lt; 2.2e-16 ***\nfactor(ID)5  19.64389   0.552272  35.56923  &lt; 2.2e-16 ***\nfactor(ID)6  24.42508   0.601629  40.59826  &lt; 2.2e-16 ***\nfactor(ID)7  29.84518   0.719118  41.50248  &lt; 2.2e-16 ***\nfactor(ID)8  31.91497   0.753382  42.36225  &lt; 2.2e-16 ***\nfactor(ID)9  37.88727   0.833968  45.43012  &lt; 2.2e-16 ***\nfactor(ID)10 44.09707   0.910884  48.41127  &lt; 2.2e-16 ***\nfactor(ID)11 51.22950   1.049050  48.83416  &lt; 2.2e-16 ***\nfactor(ID)12 55.63142   1.128472  49.29801  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.746006   Adj. R2: 0.996829\n\n\n\n5.3.2 Zeit-Fixed-Effects\nNeben zeit-invarianten Heterogenitäten zwischen den Beobachtungseinheiten können beobachtbare und unbeobachtbare Einflüsse vorliegen, die nicht zwischen den Einheiten, jedoch über die Zeit variieren. Ein DGP mit solchen zeitabhängigen Heterogenitäten ist in Abbildung 5.7 für \\(T=2\\) dargestellt.14\n14 Zur Vereinfachung der Interpretierbarkeit vernachlässigt das DAG in Abbildung 5.7 zeitlich konstante Variablen.\n\n\n\n\nFE_dag3\nU1\nUt=1U2\nUt=2U1-&gt;U2\nX1\nXt=1U1-&gt;X1\nB1\nBt=1U1-&gt;B1\nY1\nYt=1U1-&gt;Y1\nX2\nXt=2U2-&gt;X2\nB2\nBt=2U2-&gt;B2\nY2\nYt=2U2-&gt;Y2\nX1-&gt;X2\nX1-&gt;B1\nX1-&gt;Y1\nX2-&gt;B2\nX2-&gt;Y2\nB1-&gt;Y1\nB1-&gt;B2\nB2-&gt;Y2\n\n\n\n\nAbbildung 5.7: Panel-Design mit Backdoors durch beobachtete und unbeobachtete zeitabhängige Variablen\n\n\n\n\nFür beobachtbare zeitabhängige Backdoor-Variablen \\(X_t\\) kann durch Aufnahme dieser in die Regression \\(\\eqref{eq:femodel}\\) kontrolliert werden. Analog zum Fixed-Effects-Ansatz mit einheiten-spezifischen Konstanten können Backdoors durch unbeobachtbare zeitabhängige Einflüsse \\(U_t\\) durch Kontrolle für perioden-spezifische Dummies \\(D_t^{(t)}\\) (Time Fixed Effects) vermieden werden. Das Modell lautet dann\n\\[\\begin{align*}\n  Y_{it} = \\beta_0 + \\beta_1 B_{it} + \\beta_2 X_t + \\lambda_2 D_t^{(2)} + \\cdots + \\lambda_T D_t^{(T)} + \\epsilon_{it}.\n\\end{align*}\\]\nIn empirischen Anwendung ist es häufig plausibel, für zeit- und einheiten-spezifische Effekte zu kontrollieren. Der entsprechende Regressionsansatz wird als Two Way Fixed Effects (TWFE) bezeichnet.\nEin TWFE-Modell für paneldata.csv kann mit feols() leicht unter Angabe der Identifikationsvariable für die Zeitperioden (time) innerhalb des fml-Arguments geschätzt werden.\n\n# TWFE-Schätzung\npanel_TWFE &lt;- feols(\n  fml = Y ~ X | ID + time,  \n  data = paneldata\n)\n\nsummary(panel_TWFE)\n\nOLS estimation, Dep. Var.: Y\nObservations: 96\nFixed-effects: ID: 12,  time: 8\nStandard-errors: Clustered (ID) \n  Estimate Std. Error  t value   Pr(&gt;|t|)    \nX -1.01411   0.096129 -10.5495 4.3209e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.655695     Adj. R2: 0.997325\n                 Within R2: 0.636218\n\n\n\n# Geschätzte Fixed Effects (Einheiten + Zeit) auslesen\nfixest::fixef(panel_TWFE)\n\n$ID\n        1         2         3         4         5         6         7         8 \n 3.608414  6.893444 12.445006 15.020731 23.126151 27.884480 33.255238 35.311437 \n        9        10        11        12 \n41.252680 47.433690 54.515757 58.889276 \n\n$time\n          1           2           3           4           5           6 \n 0.00000000 -0.16836639  0.84624725  0.09109152  0.45843997 -0.38103581 \n          7           8 \n 0.24023573  0.31186366 \n\nattr(,\"class\")\n[1] \"fixest.fixef\" \"list\"        \nattr(,\"references\")\n  ID time \n   0    1 \nattr(,\"exponential\")\n[1] FALSE\n\n\n\n\n\n\n\n\nKey Facts zu Fixed-Effects-Regression\n\n\n\n\nEin Fixed-Effects-Designs betrachten unbeobachtete, mit den erklärenden Variablen korrelierte Heterogenitäten als konstante parameter. Korrigieren für diese Heterogenitäten ist Voraussetzung für eine verzerrungsfreie Schätzung kausaler Effekte.\n\nFixed-Effects-Schätzer schließen Backdoors aufgrund von Heterogenitäten zwischen Beobachtungseinheiten die über die Zeit konstant sind (einheiten-spezifische Effekte) und/oder für Heterogenitäten, die identisch für die Beobachtungseinheiten sind, jedoch über die Zeit variieren (Zeit-Effekte):\n\nKQ nach der Within-Transformation (Within-Schätzer) ist erwartungstreu und konsistent, solange die erklärenden Variablen zeitlich unkorreliert mit den Fehlertermen sind.\nLSDV-Regression ist eine Variante die Backdoors durch unbeobachtbare Heterogenitäten mit Dummy-Variablen schließt. In einer LSDV-Regression können die Koeffizienten zeitlich konstanter Variablen geschätzt werden.\n\n\nStatistische Inferenz für Fixed-Effects-Schätzer erfolgt anhand einer Approximation der asymptotischen Normalverteilung. Da die Fehlerterme heteroskedastisch und/oder über die Zeit korreliert sein können, sollten (cluster-)robuste Standardfehler verwendet werden.\nFixed-Effects-Modelle können in R mit dem Paketen fixest oder plm berechnet werden.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html#random-effects",
    "href": "FixedEffects.html#random-effects",
    "title": "\n5  Panel-Daten\n",
    "section": "\n5.4 Random Effects",
    "text": "5.4 Random Effects\nDer Fixed-Effects-Ansatz behandelt die einheiten-spezifischen Effekte \\(\\alpha_i\\) in Modell \\(\\eqref{eq:femodel}\\) als konstante Parameter, für die korrigiert oder kontrolliert werden muss. Der Random-Effects-Ansatz betrachtet die \\(\\alpha_i\\) als Zufallsvariablen mit einer identischen Verteilung, unter der Annahme, dass die \\(\\alpha_i\\) nicht mit den erklärenden Variablen korellieren.15 Falls diese Annahmen erfüllt sind, ist der Random-Random-Effects-Schätzer effizienter als der Fixed-Effects-Schätzer: Der mittlere quadratische Fehler der Schätzung ist geringer.16\n15 Erwartungstreue und Konsistenz und Effizienz erfordern \\(E(\\alpha_i\\vert B_{it})=0\\) und \\(E(\\epsilon_{it}\\vert\\alpha_i,B_{it})=0\\).16 Die Schätzung erfolgt meist mit der Generalized Least Squares (GLS) oder mit Maximum-Likelihood (ML).Das einfache Random-Effects-Modell notieren wir als \\[\\begin{align*}\n  Y_{it} =&\\, \\beta_0 + \\beta_1 B_{it} + \\varepsilon_{it},\n\\end{align*}\\] wobei sich der Fehlerterm \\(\\varepsilon_{it}\\) aus dem zufälligen individuellen Effekt \\(\\alpha_i\\) und dem unabhängigen Fehler \\(\\epsilon_{it}\\) zusammensetzt, \\[\\begin{align*}\n  \\varepsilon_{it} = \\alpha_i + \\epsilon_{it}.\n\\end{align*}\\]\nFür ein Beispiel simulieren wir Daten gemäß der Vorschrift \\[\\begin{align}\n  Y_{it} = \\alpha_i + \\beta B_{it} + \\epsilon_{it}\\label{eq:resim}\n\\end{align}\\] und wählen \\[\\begin{align*}\n  & \\alpha_i \\overset{u.i.v}{\\sim} N(0,2.5^2), \\\\\n  & \\beta_1 = -1,\\\\\n  & B_{it} \\sim N(0,1),\\\\\n  & \\epsilon_{it} \\overset{u.i.v}{\\sim} N(0,0.75^2).\n\\end{align*}\\] Wie in paneldata.csv erzeugen wir Daten für \\(n=12\\) Individuen, die zu \\(T=8\\) Zeitperioden beobachtet werden. Mit diesen Komponenten wird die Outcome-Variable \\(Y_{it}\\) wie in \\(\\eqref{eq:resim}\\) generiert. Der nachstehende Code erzeugt die Daten als Matrizen B und Y, die anschließend in ein langes Datenformat (tibble) umgewandelt werden.\n\nlibrary(plm)\n\nset.seed(1234)\n\n# Parameter\nn &lt;- 12  # Individuen\nm &lt;- 8   # Perioden\nbeta &lt;- -1 # Behandlungseffekt\nsigma_alpha &lt;- 2.5 # SD für RE\nsigma_epsilon &lt;- 0.75 # SD für Fehler\n\n# Random Effects\nalpha &lt;- rnorm(n, mean = 0, sd = sigma_alpha)\n\n# Matrizen\nB &lt;- matrix(NA, nrow = m, ncol = n)\nY &lt;- matrix(NA, nrow = m, ncol = n)\n\n# Simulation\nfor (i in 1:n) {\n  for (t in 1:m) {\n    B[t, i] &lt;- rnorm(1, mean = 0, sd = 1)\n    epsilon_it &lt;- rnorm(1, mean = 0, sd = sigma_epsilon)\n    Y[t, i] &lt;- alpha[i] + beta * B[t, i] + epsilon_it\n  }\n}\n\n# tibble erzeugen\nRE_paneldata &lt;- tibble(\n  id = factor(rep(1:n, each = m)),\n  time = rep(1:m, times = n),\n  B = as.vector(B),\n  Y = as.vector(Y)\n)\n\nFür die Anpassung des Random-Effect-Schätzers an den simulierten Datensatz RE_paneldata nutzen wir plm::plm() mit model = \"random\". Mit effect = \"individual\" legen wir einheiten-spezifische Random Effects fest.17\n17 Analog zu Fixed-Effects-Modellen können mit effect = \"twoway\" einheiten- und zeit-spezifische zufällige Effekte modelliert werden.\n# Random-Effects-Modell anpassen\npanel_RE &lt;- plm(\n  formula = Y ~ B, \n  data = RE_paneldata, \n  index = c(\"id\", \"time\"),\n  effect = \"individual\",\n  model = \"random\"\n)\n\nsummary(panel_RE)\n\nOneway (individual) effect Random Effect Model \n   (Swamy-Arora's transformation)\n\nCall:\nplm(formula = Y ~ B, data = RE_paneldata, effect = \"individual\", \n    model = \"random\", index = c(\"id\", \"time\"))\n\nBalanced Panel: n = 12, T = 8, N = 96\n\nEffects:\n                 var std.dev share\nidiosyncratic 0.5221  0.7226  0.13\nindividual    3.4801  1.8655  0.87\ntheta: 0.8643\n\nResiduals:\n     Min.   1st Qu.    Median   3rd Qu.      Max. \n-2.019439 -0.351116  0.017785  0.420719  2.109010 \n\nCoefficients:\n             Estimate Std. Error  z-value Pr(&gt;|z|)    \n(Intercept) -1.156573   0.552747  -2.0924   0.0364 *  \nB           -0.996175   0.075859 -13.1320   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    143.86\nResidual Sum of Squares: 50.753\nR-Squared:      0.64721\nAdj. R-Squared: 0.64346\nChisq: 172.45 on 1 DF, p-value: &lt; 2.22e-16\n\n\nDie Schätzung zeigt eine gute Anpassung an die Daten und der geschätzte Behandlungseffekt liegt mit \\(-0.996\\) nahe am wahren Koeffizienten \\(\\beta_1 = -1\\).\nMit plm::ranef() erhalten wir Differenzen der geschätzten einheiten-spezifischen Effekte vom geschätzten Erwartungswert (Intercept).\n\n# Gesch. Random Effects auslesen:\n# Differenzen zur Konstante (Intercept)\nranef(panel_RE)\n\n          1           2           3           4           5           6 \n-1.92217199  1.24364147  3.27470045 -4.12524574  2.00235610  2.71903482 \n          7           8           9          10          11          12 \n-0.17492965 -0.50237866  0.01435925 -1.03252985  0.16092971 -1.65776590 \n\n\nFür die grafische Darstellung der Schätzung berechnen wir zunächst mit fitted() die angepassten Werte. Für ein mit plm() geschätztes Random-Effects-Modell werden die individuellen Effekte von fitted() nicht berücksichtigt und müssen daher manuell hinzugefügt werden. Hierfür lesen wir zunächst den geschätzten Erwartungswert der gemeinsamen Verteilung \\(\\widehat{\\beta}_0\\) aus und addieren anschließend die von ranef() ausgegebenen Differenzen der individuellen Effekte gruppenweise.\n\n# Intercept\nhat_beta_0 &lt;- panel_RE$coefficients[1]\n\n# Gesch. Random Effects jeweils berücksichtigen\nRE_paneldata &lt;- RE_paneldata %&gt;%\n  mutate(\n    fitted_RE = \n      fitted(panel_RE) \n    + hat_beta_0 \n    + rep(ranef(panel_RE), each = m)\n  )\n\n\n# Daten und geschätztes RE-Modell plotten\nggplot(\n  data = RE_paneldata, \n  mapping = \n    aes(\n      x = B, \n      y = Y, \n      col = id\n    )\n) + \n  geom_point(show.legend = F) +\n  geom_line(\n    mapping = aes(y = fitted_RE, group = id), \n    show.legend = F\n  ) +\n  theme_cowplot()\n\n\n\n\n\n\nAbbildung 5.8: RE_paneldata – Random-Effects-Schätzung für simulierte Daten\n\n\n\n\n\n5.4.1 Verzerrung bei Endogenität\nDie Random-Effects-Methode findet bei kausalen Analyse in empirischen Anwendungen selten Anwendung, weil die Annahme von Unkorreliertheit mit den erklärenden Regressoren oft unplausibel ist. Falls diese Annahme (wie in den DAGs Abbildung 5.1 und Abbildung 5.2) verletzt ist, kann Random Effects die ensprechenden Backdoors nicht schließen: Der Random-Effects-Schätzer ist dann verzerrt und inkonsistent, ähnlich wie der naive KQ-Schätzer in einer Pooled Regression. Im nächsten Abschnitt untersuchen wir Konsequenzen dieser Eigenschaft anhand simulierter Daten.\nZur Illustration der Verzerrung des Random-Effects-Schätzers bei Endogenität von erklärenden Variablen verwenden wir erneut den anhand eines Fixed-Effects-DGPs simulierten Datensatz paneldata.csv.\n\n# Random-Effects-Schätzung für `paneldata`\npanel_RE &lt;- plm(\n  formula = Y ~ X, \n  effect = \"individual\",\n  model = \"random\",\n  index = c(\"ID\", \"time\"),  \n  data = paneldata\n)\n\nsummary(panel_RE)\n\nOneway (individual) effect Random Effect Model \n   (Swamy-Arora's transformation)\n\nCall:\nplm(formula = Y ~ X, data = paneldata, effect = \"individual\", \n    model = \"random\", index = c(\"ID\", \"time\"))\n\nBalanced Panel: n = 12, T = 8, N = 96\n\nEffects:\n                 var std.dev share\nidiosyncratic 0.6437  0.8023 0.229\nindividual    2.1732  1.4742 0.771\ntheta: 0.811\n\nResiduals:\n   Min. 1st Qu.  Median 3rd Qu.    Max. \n-6.0355 -1.9888 -0.1651  1.9196  6.4374 \n\nCoefficients:\n            Estimate Std. Error z-value  Pr(&gt;|z|)    \n(Intercept) 18.34586    2.31566  7.9225 2.328e-15 ***\nX            0.77031    0.26346  2.9238  0.003458 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    818.14\nResidual Sum of Squares: 749.94\nR-Squared:      0.083362\nAdj. R-Squared: 0.07361\nChisq: 8.54862 on 1 DF, p-value: 0.0034579\n\n\nOffenbar weicht der Random-Effects-Schätzer des Effects von \\(X\\) auf \\(Y\\) deutlich vom wahren Parameter \\(\\beta_1 = -1\\) ab. Diese Abweichung ist auf die Endogenität von \\(X\\) zurückzuführen.\nDie nächste Grafik vergleicht die Schätzungen des Behandlungseffekts für den Datensatz paneldata.csv mit Pooling (schwarze Linie), Fixed Effects (farbige Linien) und Random Effects (gestrichelte schwarze Linie). Vorab erweitern wir paneldata um die angepassten Werte für die Fixed- und die Random-Effects-Schätzung in panel_FE und panel_RE.18\n18 Für bessere Lesbarkeit erzeugen wir hier mit predict() eine Regressionsgerade, deren Achsenabschnitt dem geschätzten Erwartungswert der Random-Effects-Verteilung entspricht.\npaneldata &lt;- paneldata %&gt;% \n  mutate(\n    # Vorhergesagte Werte für FE-Schätzung\n    yhat_FE = fitted(panel_FE),\n    # Vorhergesagte Werte für RE-Schätzung\n    yhat_RE = predict(panel_RE)\n  )\n\n\nggplot(\n  data = paneldata,\n  mapping = aes(x = X, y = Y)\n) +\n  # Beoachtungen\n  geom_point(\n    mapping = aes(color = col), \n    show.legend = F\n  ) +\n  # Pooling\n  geom_smooth(\n    method = \"lm\", \n    se = F,\n    col = \"black\"\n  ) +\n  # Fixed Effects\n  geom_line(\n    mapping = aes(\n      y = yhat_FE,\n      group = ID,\n      col = col\n    ), \n    show.legend = F\n  ) +\n  # Random Effects\n  geom_line(\n    mapping = aes(y = yhat_RE), \n    lty = \"dashed\", \n    show.legend = F\n  ) +\n  theme_cowplot()\n\n\n\n\n\n\nAbbildung 5.9: paneldaten.csv – Vergleich von Schätzern bei Einheiten mit endogeneen Effekten\n\n\n\n\n\n\n\n\n\n\nKey Facts zu Random-Effects-Regression\n\n\n\n\nRandom-Effects-Ansätze basieren auf der Annahme, dass (unbeobachtbare) Heterogenitäten zufällig sind. Wir nehmen an, dass die unbeobachteten Heterogenitäten nicht mit den erklärenden Variablen korreliert sind. Letzteres führt zu inkonsistenten Schätzern!\nIteratives GLS oder MLE ermöglichen eine effizientere Schätzung des Random-Effects-Modells als Pooling oder Fixed-Effects-Schätzer, da sowohl die Variation innerhalb als auch zwischen den Beoabchtungseinheiten Einheiten genutzt wird.\nIn Random-Effects-Modellen können die Effekte zeitlich konstanter Variablen geschätzt werden, da die einheiten-spezifischen Effekte als zufällig betrachtet werden.\nUnter den skizzierten Annahmen sind Random-Effects-Schätzer asymptotisch normalverteilt. Für statische Inferenz sollten cluster-robuste Standardfehler verwendet werden.\nRandom-Effects-Modelle können in R mit den Paketen plm und lme4 geschätzt werden.\n\n\n\n\nInteraktive Illustration von Panel-Schätzern\nDie nachfolgende interaktive Illustration erlaubt einen Vergleich der in Abbildung 5.9 geplotteten geschätzten Regressionsfunktionen für paneldata.csv mit dem wahren DGP (Show truth) unter Reproduktion der in Abbildung 5.9 gezeigten Komponenten.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html#dynamische-modelle-und-cluster-robuste-standardfehler",
    "href": "FixedEffects.html#dynamische-modelle-und-cluster-robuste-standardfehler",
    "title": "\n5  Panel-Daten\n",
    "section": "\n5.5 Dynamische Modelle und Cluster-robuste Standardfehler",
    "text": "5.5 Dynamische Modelle und Cluster-robuste Standardfehler\nViele ökonomische und soziale Prozesse sind autoregressiv: Der Zustand einer Variable in der Vergangenheit beeinflusst ihren aktuellen Zustand. Bei der Modellierung von Outcome-Variablen in Panel-Designs kann es notwendig sein, diese Abhängigkeit zu berücksichtigen, um die Identifizierbarkeit kausaler Effekte zu gewährleisten. Dynamische Panelmodelle verwenden hierzu vergangene Werte (lags) der Outcome-Variable, \\(Y_{it-j}\\) mit \\(j&gt;0\\) als (zusätzliche) Regressoren. Ein einfaches dynamisches Panelmodell ist \\[\\begin{align}\n  Y_{it} = \\rho Y_{it-1} + \\beta_1 B_{it} + \\epsilon_{it}, \\label{eq:dynpanel}\n\\end{align}\\] wobei \\(Y_{it-1}\\) der Wert von \\(Y_{it}\\) in der Periode \\(t-1\\) ist, \\(0\\neq\\lvert\\rho\\rvert&lt;1\\), und \\(\\epsilon_{i,t}\\) ein u.i.v. Fehlerterm ist. In diesem Modell ist \\(Y_{it-1}\\) kausal für \\(Y_{it}\\).\nDie Verwendung dynamischer Modelle hat folgende Motivationen:\n\n\n(a) Präzisere Schätzung: Berücksichtigen von gelaggten abhängigen Variablen ermöglicht die Modellierung einer zeitabhängigen Dynamik von \\(Y_{it}\\). Die Autokorellation und damit die Varianz der Fehlerterme kann reduziert werden, da ein Teil dieser zeitlichen Abhängigkeiten direkt modelliert wird. Dies kann die Präzision der Schätzung des kausalen Effekts \\(\\beta_1\\) verbessern.\n\n\n\n\n\n\nLDVOK2\nBt\nBtYt\nYtBt-&gt;Yt\nYtm1\nYt-1Ytm1-&gt;Yt\n\n\n\n\nAbbildung 5.10: Kontrolle für vergangenen Wert verbessert Präzision\n\n\n\n\n\n\n(b) Vermeidung von Endogenität: Nichtberücksichtigen von relevanten gelaggten abhängigen Variablen führt zu verzerrten und inkonsistenten Schätzern.\n\n\n\n\n\n\nLDVOK1\nBt\nBtYt\nYtBt-&gt;Yt\nV\nVV-&gt;Bt\nYtm1\nYt-1V-&gt;Ytm1\nYtm1-&gt;Yt\n\n\n\n\nAbbildung 5.11: Kontrolle für vergangenen Wert schließt Backdoor.\n\n\n\n\n\n5.5.1 Verzerrung in dynamischen Panels\nEin zentrales Problem bei der Schätzung dynamischer Panelmodelle ist der sogenannte Nickell-Bias. Dieser tritt auf, wenn die Within-Transformation in Anwesenheit von gelagten abhängigen Variablen verwendet wird. Die Mittelwert-Differenzen eliminieren zwar die zeit-invarianten Effekte, führt aber zu Korrelation zwischen den gelagten abhängigen Variablen und den transformierten Fehlertermen: Der Nickell-Bias entsteht bei der Within-Transformation, weil der Regressor (\\(Y_{i,t-1} - \\overline{Y}_{i,-1}\\))19 mit dem transformierten Fehlerterm (\\(\\epsilon_{it} - \\overline{\\epsilon}_i\\)) korreliert ist, was zu einer verzerrten Schätzung führt.\n19 Hier ist \\(\\overline{Y}_{i,-1} = \\frac{1}{T-1}\\sum_{t=2}^T y_{it-1}\\).20 Dies ist problematisch für Mikro-Studien: Die Querschnittsdimension des Panels kann oft “hinreichend” groß gewählt werden. Die Zeit-Dimension ist aus natürlichen Gegebenheiten jedoch oft klein.Nickell (1981) zeigt, dass diese Verzerrung für den Within-Schätzer \\(\\widehat{\\rho}^\\textup{Within}\\) nicht verschwindet, wenn die Anzahl der Beobachtungseinheiten (\\(n\\)) divergiert, solange die Zeitdimension (\\(T\\)) endlich ist.20 Der Nickell-Bias ist besonders bei kurzen Panelen (kleines \\(T\\)) problematisch. Es ist \\[\\begin{align*}\n  \\widehat{\\rho}^\\textup{Within} \\approx \\rho - \\frac{1 + \\rho}{T-1},\n\\end{align*}\\] d.h. die Verzerrung beträgt ungefähr \\(-\\frac{1+\\rho}{T-1}\\).\nHinzufügen von \\(Y_{it-1}\\) als Regressor in Fixed- und Random-Effects-Modellen ist jenseits der verzerrten Schätzung von \\(\\rho\\) problematisch, wenn \\(Y_{it-1}\\) mit \\(B_{it}\\) korreliert ist. Kontrollieren für \\(Y_{it-1}\\) öffnet dann Backdoor-Pfade, die wir mit FE- oder RE-Ansätzen schließen wollen. In sämtlichen dynamischen Varianten der Fixed- und Random-Effects-Modelle sind die in diesem Kapitel behandelten Schätzer eines kausalen Effekts \\(\\beta_1 \\neq 0\\) von \\(B_{it}\\) auf \\(Y_{it}\\) daher verzerrt.\nDer Arellano-Bond-Schätzer (Arellano und Bond 1991) ist eine Methode, die für Endogenität in dynamischen Panel-Modellen korrigiert. Das Verfahren betrachtet die Regression in Differenzen zur Korrektur für Heterogenitäten zwischen den Einheiten und schätzt die Koeffizienten anhand der generalisierten Momentenmethode (GMM). Hierbei werden vergangene Werte von \\(Y_{it}\\) als Instrumente für endogene Differenzen von \\(Y_{it}\\) genutzt. Siehe Wooldridge (2010) für Beispiele.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html#beispiel-einkommen-und-demokratie",
    "href": "FixedEffects.html#beispiel-einkommen-und-demokratie",
    "title": "\n5  Panel-Daten\n",
    "section": "\n5.6 Beispiel: Einkommen und Demokratie",
    "text": "5.6 Beispiel: Einkommen und Demokratie\nEine Vielzahl polit-ökonomischer Standardwerke und Studien (bspw. Dahl 1971; Huntington 1991; Rueschemeyer, Stephens, und Stephens 1992) liefert vermeindliche Belege für einen zentralen Grundsatz der Modernisierungstheorie: Ein höheres Pro-Kopf-Einkommen erhöht die Nachfrage der Bevölkerung nach politischer Freiheit und demokratischen Insitutionen. Acemoglu u. a. (2008a) argumentieren, dass der in derartigen länderübergreifenden Analysen mit Pooling häufig als positiv geschätzte Zusammenhang zwischen Einkommen und Demokratisierung nicht kausal interpetiert werden sollte. Ein Grund hierfür ist, dass (unbeobachtbare) ausgelassene länderspezifische Faktoren, die sowohl die ökonomische Entwicklung als auch die Stärke demokratischer Institutionen beeinflussen, wahrscheinlich sind. Um diese mögliche Ursache für Endogenität des Einkommens im Modell \\[\\begin{align}\n  \\text{Demokratisierung}_{it} = \\beta_0 + \\beta_1\\,\\text{PK-Einkommen}_{it-1} + \\epsilon_{it}\n\\end{align}\\] zu adressieren, nutzen Acemoglu u. a. (2008a) Panel-Modelle und Schätzer, die insbesondere für länderspezifische zeit-invariante Einflüsse kontrollieren.\nDas Kernergebnis von Acemoglu u. a. (2008a) ist, dass es keinen kausalen Zusammenhang zwischen dem Einkommen (Wirtschaftswachstum) und der Demokratisierung gibt. Die Autoren zeigen, dass historische und geografische Faktoren, die sowohl das Einkommen als auch die politischen Institutionen beeinflussen, den vermeintlichen Zusammenhang erklären können.\nFür die nachfolgenden Code-Beispiele nutzen wir einen Auszug des Datensatzes aus dem Replikationspaket zu Acemoglu u. a. (2008a), siehe Acemoglu u. a. (2008b).\nWir lesen zunächst den Datensatz acemogluetal2008.csv ein.\n\ndeminc &lt;- read_csv(\"datasets/acemogluetal2008.csv\")\nglimpse(deminc)\n\nRows: 2,321\nColumns: 8\n$ fhpolrigaug  &lt;dbl&gt; NA, NA, NA, NA, 0.50, NA, NA, NA, NA, 1.00, 1.00, 0.12, 0…\n$ lrgdpch      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ country      &lt;chr&gt; \"Andorra\", \"Andorra\", \"Andorra\", \"Andorra\", \"Andorra\", \"A…\n$ year         &lt;dbl&gt; 1950, 1955, 1960, 1965, 1970, 1975, 1980, 1985, 1990, 199…\n$ year_numeric &lt;dbl&gt; 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 31, 32, 33, 3…\n$ sample       &lt;dbl&gt; 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, …\n$ code         &lt;chr&gt; \"ADO\", \"ADO\", \"ADO\", \"ADO\", \"ADO\", \"ADO\", \"ADO\", \"ADO\", \"…\n$ polity4      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0.00, 0.00, 0…\n\n\nTabelle 5.1 enthält Beschreibungen der in deminc verfügbaren Variablen.\n\n\n\n\n\n\n\n\nVariable\nBeschreibung\n\n\n\ncountry\nLand\n\n\ncode\nLänder-Code\n\n\nfhpolrigaug\nFreedom House Political Rights Index (FHPRI)\n\n\nlrgdpch\nLog(Reales-Pro-Kopf-Einkommen)\n\n\npolity4\nPolity Composite Democracy Index\n\n\nsample\nZugehörigkeit zur verwendeten Stichprobe (Indikator)\n\n\nyear\nJahr\n\n\nyear_numeric\nID-Variable f. Jahr\n\n\n\n\n\nTabelle 5.1: deminc: Demokratisierung und Einkommen (Acemoglu u. a. 2008a)\n\n\nWir vernachlässigen zunächst die Panel-Struktur der Daten und regressieren FHPRI auf das Pro-Kopf-Einkommen für die in Acemoglu u. a. (2008a) verwendete Stichprobe mit Beobachtungen in 5-Jahresschritten von 1955 bis 2000 (Beobachtungen mit sample == 1).\n\n# Pooled Regression\ndeminc_pooling1 &lt;- feols(\n  fml = fhpolrigaug ~ lrgdpch,\n  data = deminc %&gt;% \n    filter(sample == 1), \n)\n\nsummary(deminc_pooling1)\n\nOLS estimation, Dep. Var.: fhpolrigaug\nObservations: 960\nStandard-errors: IID \n             Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept) -1.339442   0.068767 -19.4780 &lt; 2.2e-16 ***\nlrgdpch      0.231010   0.008271  27.9287 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.268295   Adj. R2: 0.448221\n\n\nDieser naive Ansatz ingoriert konstante Heterogenitäten zwischen den Ländern und einen (plausiblen) zeitlich verzögerten Einfluss ökonomisch günstiger Bedingung auf die Demokratisierung. Der geschätzte Koeffizient von lrgdpch ist \\(0.23\\) (d.h. ein geschätzer positiver Zusammenhang) und signifikant.\nDie Regression von FHPRI auf das Einkommen in \\(t-1\\) (l(lrgdpch)) führt zu ähnlichen Schätzungen der Koeffizienten. Dies ist plausibel unter der Hypothese, dass es ausgelassende Faktoren gibt, welche die Demokratisierung und das Pro-Kopf-Einkommen in sämtlichen Perioden beeinflussion.\n\n# Pooling mit Einkommem_{t-1}\ndeminc_pooling_lag &lt;- feols(\n  fml = fhpolrigaug ~ l(lrgdpch),\n  panel.id = ~ country + year,\n  data = deminc %&gt;% \n    filter(sample == 1), \n)\n\nsummary(deminc_pooling_lag)\n\nOLS estimation, Dep. Var.: fhpolrigaug\nObservations: 831\nStandard-errors: Clustered (country) \n               Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept)   -1.412158   0.108044 -13.0702 &lt; 2.2e-16 ***\nl(lrgdpch, 1)  0.240773   0.012568  19.1582 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.270376   Adj. R2: 0.456289\n\n\nEin simpler Ansatz zur Kontrolle für fixe länderspezifische Effekte ist die KQ-Schätzung des Regressionsmodell in ersten Differenzen. Analog zu Abbildung 2 in Acemoglu u. a. (2008a) schätzen wir hierfür zunächst ein Modell der Differenzen zwischen den Perioden 1995 und 1970. Zur Schätzung und anschließenden Reproduktion der Grafik (siehe Abbildung 5.12) berechnen wir die Differenzen anhand eines gruppierten Datensatzes.\n\n# Zeit-Differenzen länderweise berechnen\ndeminc_f &lt;- deminc %&gt;%\n  filter(\n    year %in% c(1970, 1995)\n  ) %&gt;%\n  group_by(code) %&gt;%\n  summarise(\n    dlrgdpch = diff(lrgdpch),\n    dfhpolrigaug = diff(fhpolrigaug)\n    ) %&gt;%\n  drop_na()\n\n# KQ-Schätzung für Differenzen 1995 - 1970\nfeols(\n  fml = dfhpolrigaug ~ dlrgdpch,\n  data = deminc_f\n) %&gt;% \n  summary()\n\nOLS estimation, Dep. Var.: dfhpolrigaug\nObservations: 103\nStandard-errors: IID \n            Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept) 0.126292   0.040080 3.150983 0.0021415 ** \ndlrgdpch    0.032981   0.063541 0.519045 0.6048649    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.338838   Adj. R2: -0.007214\n\n\n\nggplot(\n  data = deminc_f,\n  mapping = aes(\n    x = dlrgdpch,\n    y = dfhpolrigaug\n  ) \n  ) +\n  # Referenz-Linie (kein Effelt)\n  geom_hline(yintercept = 0, lty = 2) +\n  # Datenpunkte\n  geom_text(\n    mapping = aes(label = code),\n    position = position_jitter(\n      height = .05, \n      seed = 1234\n      )\n    ) +\n  # gesch. lineares Modell einzeichnen\n  geom_smooth(\n    method = \"lm\", \n    se = F) +\n  labs(\n    x = \"Diff. Log(Pro-Kopf-BIP) (1970 - 1995)\",\n    y = \"Diff. Demokratie-Index (1970 - 1995)\"\n  ) +\n  theme_cowplot()\n\n\n\n\n\n\nAbbildung 5.12: deminc – Regression der Zeit-Differenzen zwischen 1995 und 1970\n\n\n\n\n\n# Panel-Schätzer: KQ-Regression in Differenzen\n# (Alle Perioden)\ndeminc_diff &lt;- feols(\n  fml = d(fhpolrigaug) ~ d(lrgdpch), \n  data = deminc,\n  panel.id = ~ country + year\n)\n\nsummary(deminc_diff)\n\nOLS estimation, Dep. Var.: d(fhpolrigaug, 1)\nObservations: 968\nStandard-errors: Clustered (country) \n               Estimate Std. Error   t value Pr(&gt;|t|) \n(Intercept)    0.005878   0.006013  0.977540  0.32992 \nd(lrgdpch, 1) -0.021539   0.040164 -0.536278  0.59258 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.213629   Adj. R2: -7.634e-4\n\n\n\n# time + country fixed effects\n# (2)\nfeols(\n  fml = fhpolrigaug ~ \n    l(fhpolrigaug) \n  + l(lrgdpch) \n  | year + country,\n  panel.id = ~ country + year,\n  cluster = ~ country,\n  data = deminc, \n)\n\nOLS estimation, Dep. Var.: fhpolrigaug\nObservations: 988\nFixed-effects: year: 10,  country: 150\nStandard-errors: Clustered (country) \n                  Estimate Std. Error  t value   Pr(&gt;|t|)    \nl(fhpolrigaug, 1) 0.388762   0.048986 7.936204 4.6184e-13 ***\nl(lrgdpch, 1)     0.001137   0.031503 0.036088 9.7126e-01    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.165328     Adj. R2: 0.751359\n                 Within R2: 0.146859\n\n\n\n# Arellano-Bond-Schätzer\n# (3)\ndeminc_filtered &lt;- deminc %&gt;%\n    filter(sample == 1) %&gt;%\n    drop_na()\n\n# Define the panel data structure\npdata &lt;- pdata.frame(deminc_filtered, index = c(\"country\", \"year_numeric\"))\npgmm(\n  formula = \n    fhpolrigaug ~ \n    lag(fhpolrigaug, 1) \n  + lag(lrgdpch, 1) \n  \n  | lag(fhpolrigaug, 2:3)\n  + lag(lrgdpch, 2:3),\n    effect = \"twoways\", \n    model = \"twosteps\",\n    data = pdata\n) %&gt;% \n  summary()\n\nTwoways effects Two-steps model Difference GMM \n\nCall:\npgmm(formula = fhpolrigaug ~ lag(fhpolrigaug, 1) + lag(lrgdpch, \n    1) | lag(fhpolrigaug, 2:3) + lag(lrgdpch, 2:3), data = pdata, \n    effect = \"twoways\", model = \"twosteps\")\n\nUnbalanced Panel: n = 138, T = 1-9, N = 881\n\nNumber of Observations Used: 598\nResiduals:\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-1.280670 -0.031088  0.000000  0.002335  0.009490  0.993065 \n\nCoefficients:\n                    Estimate Std. Error z-value  Pr(&gt;|z|)    \nlag(fhpolrigaug, 1)  0.50943    0.11696  4.3555 1.327e-05 ***\nlag(lrgdpch, 1)     -0.17873    0.12092 -1.4781    0.1394    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSargan test: chisq(24) = 29.03412 (p-value = 0.21885)\nAutocorrelation test (1): normal = -3.828848 (p-value = 0.00012874)\nAutocorrelation test (2): normal = 0.474211 (p-value = 0.63535)\nWald test for coefficients: chisq(2) = 21.49026 (p-value = 2.155e-05)\nWald test for time dummies: chisq(7) = 18.08866 (p-value = 0.011576)\n\n\nAnalog zu Querschnittsdaten können die hier betrachteten Panel-Schätzer Endogenitäten aufgrund simultaner Kausalität oder nicht beheben. In solchen Szenarien können Panel-Methoden in Kombination mit einer Schätzstrategie basierend auf Instrument-Variablen hilfreich sein. Wir betrachten solche Schätzer in den empirischen Beispielen in Kapitel Kapitel 6.\n\n\n\n\n\n\nAcemoglu, Daron, Simon Johnson, James A. Robinson, und Pierre Yared. 2008a. „Income and Democracy“. American Economic Review 98 (3): 808–42. https://doi.org/10.1257/aer.98.3.808.\n\n\n———. 2008b. „Replication data for: Income and Democracy“. ICPSR - Interuniversity Consortium for Political; Social Research. https://doi.org/10.3886/E113251V1.\n\n\nArellano, Manuel, und Stephen Bond. 1991. „Some Tests of Specification for Panel Data: Monte Carlo Evidence and an Application to Employment Equations“. The Review of Economic Studies 58 (2): 277. https://doi.org/10.2307/2297968.\n\n\nDahl, Robert Alan. 1971. Polyarchy: Participation and Opposition: Participation and opposition. New Haven: Yale Univ. Press.\n\n\nHuntington, Samuel P. 1991. The Third Wave: Democratization in the Late Twentieth Century: Democratization in the late twentieth century. Norman, OK: Univ. of Oklahoma Press.\n\n\nNickell, Stephen. 1981. „Biases in Dynamic Models with Fixed Effects“. Econometrica 49 (6): 1417. https://doi.org/10.2307/1911408.\n\n\nRueschemeyer, Dietrich, Evelyne H. Stephens, und John D. Stephens. 1992. Capitalist development and democracy. Cambridge: Polity Pr.\n\n\nWooldridge, Jeffrey. 2010. Econometric Analysis of Cross Section and Panel Data. Second edition. Cambridge, Massachusetts: MIT.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "IV.html",
    "href": "IV.html",
    "title": "6  IV-Regression",
    "section": "",
    "text": "6.1 Der einfache lineare IV-Schätzer\nIm folgenden nehmen wir an, dass sämtliche Zusammenhänge linear sind. Zunächst betrachten wir das einfache Regressionsmodell\n\\[\\begin{align}\n  Y_i = \\beta_0 + \\beta_1 B_i + u_i \\ \\ , \\ \\ i=1,\\dots,n, \\label{eq:simpleiv}\n\\end{align}\\]\nwobei der Fehlerterm \\(u_i\\) mit dem Regressor \\(B_i\\) korreliert ist (d.h. \\(B\\) ist ein endogener Regressor), sodass der KQ-Schätzer für den kausalen Effekt \\(\\beta_1\\) inkonsistent ist.\nDamit \\(Z\\) ein gültiges Instrument für \\(B\\) in dem in Abbildung 6.1 gezeigten Forschungsdesign ist, müssen die folgenden Bedingungen erfüllt sein:\nSei \\(\\text{Cov}(A,B)\\) die Kovarianz zwischen den Variablen \\(A\\) und \\(B\\). \\(Z\\) muss zwei Bedingungen erfüllen, um ein gültiges Instrument zu sein:\nUnter diesen Annahmen erlaubt das Forschungsdesign die Anwendung des einfachsten IV-Ansatzes, wobei eine endogene Variable \\(B\\) durch eine Instrumentvariable \\(Z\\) instrumentiert wird. Die folgende Umformung zeigt, warum der kausale Effekt von B auf Y anhand der (Ko)Variation in diesen Variablen identifiziert werden kann:\n\\[\\begin{alignat*}{2}\n  \\textup{Cov}(Z,Y) &= \\textup{Cov}(Z,\\beta_0 + \\beta_1 B + u) &\\quad& \\text{(Gl. \\eqref{eq:simpleiv})} \\\\\n  \\\\\n  \\textup{Cov}(Z,Y) &= \\textup{Cov}(Z, \\beta_1 B + u) &\\quad& \\text{($\\beta_0$ konstant)} \\\\\n  \\\\\n  \\textup{Cov}(Z,Y) &= \\beta_1\\textup{Cov}(Z,B) &\\quad& \\text{($\\beta_1$ konstant, $Z$ exogen)} \\\\\n  \\\\\n  \\beta_1 &= \\frac{\\textup{Cov}(Z,Y) }{\\textup{Cov}(Z,B)} &\\quad& \\text{($Z$ relevant)}\n\\end{alignat*}\\]\nEine naheliegende Implementierung gemäß dieses Identifikationsprinzips ist der einfache IV-Schätzer\n\\[\\begin{align}\n  \\widehat{\\beta}_{\\textup{IV}} = \\frac{\\widehat{\\textup{Cov}}(Z,Y) }{\\widehat{\\textup{Cov}}(Z,B)}, \\label{eq:simpleivest}\n\\end{align}\\]\nwobei lediglich die Kovarianzfunktion \\(\\textup{Cov}(\\cdot,\\cdot)\\) durch ihr Stichprobenäquivalent \\(\\widehat{\\textup{Cov}}(\\cdot,\\cdot)\\) ersetzt wird.\nErwartungswert und Konsistenz\nEine hilfreiche Darstellung von \\(\\eqref{eq:simpleivest}\\) ist\n\\[\\begin{align*}\n  \\widehat{\\beta}_\\textup{IV} = \\beta_1 + \\frac{\\sum_{i=1}^n (Z_i-\\overline Z) u_i}{\\sum_{i=1}^n (Z_i - \\overline{Z})B_i}.\n\\end{align*}\\]\nAnhand dieser Form kann der Erwartungswert sowie das Verhalten für große Stichproben untersucht werden. Eine wichtige Eigenschaft ist\n\\[\\begin{align}\n  \\textup{E}\\big(\\widehat{\\beta}_\\textup{IV}\\big) = \\beta_1 + \\underbrace{\\textup{E}\\bigg(\\frac{\\sum_{i=1}^n (Z_i-\\overline Z) u_i}{\\sum_{i=1}^n (Z_i - \\overline{Z})B_i}\\bigg)}_{\\neq0},\\label{eq:ivbiasterm}\n\\end{align}\\]\nsodass \\(\\widehat{\\beta}_\\textup{IV}\\) bei Endogenität von \\(X\\) ein verzerrter Schätzer von \\(\\beta_1\\) ist.1 Glücklicherweise kann man zeigen, dass\n\\[\\begin{align*}\n  \\frac{\\sum_{i=1}^n (Z_i-\\overline Z) u_i}{\\sum_{i=1}^n (Z_i - \\overline{Z})B_i}\\to 0 \\quad \\text{für} \\quad n\\to\\infty\n\\end{align*}\\]\nbei Gültigkeit der IV-Annahmen \\(\\eqref{eq:ivassum1}\\) und \\(\\eqref{eq:ivassum2}\\), d.h. \\(\\widehat{\\beta}_\\textup{IV}\\) ist ein konsistener Schätzer für \\(\\beta_1\\),\n\\[\\begin{align*}\n  \\widehat{\\beta}_\\textup{IV} \\to \\beta_1 \\quad \\text{für} \\quad n\\to\\infty.\n\\end{align*}\\]\nSchwache Instrumente\nBeachte, dass die Annahme der Relevanz des Instruments für die Herleitung des Identifikationsprinzips und des Schätzers \\(\\eqref{eq:simpleivest}\\) von entscheidender Bedeutung ist: Sind \\(Z\\) und \\(B\\) unkorreliert, so ist \\(\\text{Cov}(B,Z) = 0\\) und \\(\\beta_1\\) damit nicht identifizierbar. Weiterhin würde \\(\\widehat{\\text{Cov}}(B,Z)\\to0\\) wenn \\(n\\to\\infty\\), sodass \\(\\widehat{\\beta}_{\\textup{IV}}\\to\\infty\\)!\nIn empirischen Anwendungen ist \\(\\text{Cov}(B,Z) = 0\\) unwahrscheinlich. Die Kovarianz von \\(B\\) und \\(Z\\) kann jedoch gering sein. In diesem Fall bezeichnet man \\(Z\\) als ein schwaches Instrument. Anhand von Gleichung \\(\\eqref{eq:simpleivest}\\) können wir die Konsequenzen der Verwendung eines schachen Instruments ableiten: Ein sehr schwacher linearer Zusammenhang von \\(B\\) und \\(Z\\) — und damit tendenziell \\(\\widehat{\\text{Cov}}(B,Z) \\approx 0\\) — kann trotz Relevanz von \\(Z\\) zu einem Schätzer mit großer Varianz führen.\nDie Relevanz eines Instruments kann mit einem Hypothesentests geprüft werden. Wie die “Stärke” eines Instruments beurteilt werden sollte, ist eine nicht-triviale Frage. Wir betrachten diesen Aspekt näher in Kapitel 6.2.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>IV-Regression</span>"
    ]
  },
  {
    "objectID": "IV.html#der-einfache-lineare-iv-schätzer",
    "href": "IV.html#der-einfache-lineare-iv-schätzer",
    "title": "6  IV-Regression",
    "section": "",
    "text": "1. Relevanz des Instruments für die endogene Variable\n\\(B\\) und \\(Z\\) müssen korreliert sein (Pfeil von Z nach B in Abbildung 6.1): \\[\\begin{align}\n    \\text{Cov}(B,Z) \\neq 0 \\label{eq:ivassum1}\n  \\end{align}\\]\n\n\n2. Exogenität des Instruments hinsichtlich der Outcome-Variable\nDas Instrument \\(Z\\) darf nicht mit dem Fehlerterm \\(u\\) in der Modellgleichung \\(\\eqref{eq:simpleiv}\\) korreliert sein (keine Pfade von Z nach Y außer durch B in Abbildung 6.1): \\[\\begin{align}\n    \\text{Cov}(Z,u) = 0 \\label{eq:ivassum2}\n  \\end{align}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n1 Beachte, dass der endogene Regressor \\(B_i\\) mit \\(u_i\\) korreliert, sodass der Erwartungswert des Bruchs in \\(\\eqref{eq:ivbiasterm}\\) ungleich \\(0\\) ist.\n\n\n\n\n\n\n\n6.1.1 Identifizierbarer Behandlungseffekt\nRegression ermöglicht in der Regel die Schätzung eines durchschnittlichen Behandlungseffekts (ATE) für eine betrachtete Population mit heterogenen Behandlungseffekten (in Modell \\(\\eqref{eq:simpleiv}\\) unterstellen wir den empirisch unwahrscheinlichen Fall eines einheitlichen kausalen Effekts \\(\\beta_1\\)). Das Adjustieren für Endogenität mit IV-Regression hat hier einen Preis: Beachte, dass im IV-Design ein Teil der beobachteten Variation der Behandlungsvariable \\(B\\) (wie in \\(\\eqref{eq:simpleiv}\\) angenommen) endogen ist und wir den Effekt von \\(B\\) auf \\(Y\\) anhand der exogenen Variation eines validen Instruments \\(Z\\) schätzen. Daher können wir grundsätzlich nur einen lokalen durchschnittlichen Behandlungseffekt (LATE) identifizieren: Der LATE ist eine gewichtete Variante des ATE, wobei Beobachtungen, deren Behandlung gut durch \\(Z\\) erklärt wird den größten Einfluss haben.2\n2 Siehe Kapitel 10 und 19 in Huntington-Klein (2021) für nicht-technische Erläuterungen und Beispiel zu LATE.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>IV-Regression</span>"
    ]
  },
  {
    "objectID": "IV.html#sec-2SLS",
    "href": "IV.html#sec-2SLS",
    "title": "6  IV-Regression",
    "section": "\n6.2 2SLS-Verfahren",
    "text": "6.2 2SLS-Verfahren\nDer einfache IV-Schätzer \\(\\eqref{eq:simpleivest}\\) ist ein Spezialfall eines allgemeineren Regressionsverfahrens, das in zwei Schritten Durchgeführt wird. Im fall von Modell \\(\\eqref{eq:simpleiv}\\) erfolgt die Schätzung anhand der folgenden einfachen Regressionen:\n\n\n1. Stufe: Regression von \\(B\\) auf \\(Z\\)\nRegressiere die endogene Variable \\(B\\) auf das Instrument \\(Z\\): \\[\\begin{align}\n    B_i = \\alpha_0 + \\alpha_1 Z_i + u_i, \\quad 1,\\dots,n.\n  \\end{align}\\] Berechne die geschätzten Werte \\[\\begin{align}\n    \\widehat{B}_i = \\widehat{\\alpha}_0 + \\widehat{\\alpha}_1 Z_i.\n  \\end{align}\\]\nDie \\(\\widehat{B}_i\\) aus dieser Regression sind “bereinigt”: Die Variation in den \\(\\widehat{B}_i\\) wird lediglich durch die exogene Variation in \\(Z\\) verursacht.\n\n\n2. Stufe: Regression von \\(Y\\) auf \\(\\widehat{B}\\)\nRegressiere die Beobachtungen der abhängigen Variable \\(Y_i\\) auf die geschätzten Werte \\(\\widehat{B}_i\\) aus der 1. Stufe: \\[\\begin{align}\n    Y_i = \\gamma_0 + \\gamma_1 \\widehat{B}_i + e_i.\n  \\end{align}\\] Der geschätzte Koeffizient \\(\\widehat{\\gamma}_1\\) aus dieser Regression ist der Two-Stage-Least-Squares-Schätzer (2SLS-Schätzer) von \\(\\beta_1\\).\n\n\n\n6.2.1 Äquivalenz von 2SLS und einfacher IV-Schätzer\nDer KQ-Schätzer von \\(\\gamma_1\\) in der 2. Stufe ist \\[\\begin{align}\n  \\widehat{\\gamma}_1 = \\frac{\\sum (\\widehat{B}_i - \\overline{\\widehat{B}})(Y_i - \\bar{Y})}{\\sum (\\widehat{B}_i - \\bar{\\widehat{B}})^2} = \\frac{\\widehat{\\text{Cov}}(\\widehat{B}, Y)}{\\widehat{\\textup{Var}}(\\widehat{B}_i)}.\n\\end{align}\\] Da \\(\\widehat{B}_i = \\widehat{\\alpha}_0 + \\widehat{\\alpha}_1 Z_i\\), die angepassten Werte aus der 1. Stufe, eine lineare Funktion von \\(Z_i\\) sind, können wir \\(\\widehat{\\text{Cov}}(\\widehat{B}, Y)\\) wie folgt schreiben: \\[\\begin{align}\n  \\widehat{\\text{Cov}}(\\widehat{B}, Y) = \\widehat{\\alpha}_1 \\widehat{\\text{Cov}}(Z, Y)\n\\end{align}\\] Eine ähnliche Umformung zeigt, dass \\[\\begin{align}\n  \\widehat{\\text{Var}}(\\widehat{B}) = \\widehat{\\alpha}_1^2 \\widehat{\\text{Var}}(Z).\n\\end{align}\\]\nKombinieren wir diese Ergebnisse, erhalten wir folgende Darstellung für den KQ-Schätzer von \\(\\gamma_1\\) in der 2. Stufe: \\[\\begin{align}\n  \\widehat{\\gamma}_1 = \\frac{\\widehat{\\text{Cov}}(\\widehat{B}, Y)}{\\widehat{\\text{Var}}(\\widehat{B})} = \\frac{\\widehat{\\alpha}_1 \\widehat{\\text{Cov}}(Z, Y)}{\\widehat{\\alpha}_1^2 \\widehat{\\text{Var}}(Z)} = \\frac{\\widehat{\\text{Cov}}(Z, Y)}{\\widehat{\\alpha}_1 \\widehat{\\text{Var}}(Z)}\n\\end{align}\\]\nDer KQ-Schätzer von \\(\\widehat{\\alpha}_1\\) in der 1. Stufe ist definiert als \\(\\widehat{\\alpha}_1 = \\frac{\\widehat{\\text{Cov}}(Z, B)}{\\widehat{\\text{Var}}(Z)}\\). Somit gilt \\[\\begin{align}\n  \\widehat{\\gamma}_1 = \\frac{\\widehat{\\text{Cov}}(Z, Y)}{\\frac{\\widehat{\\text{Cov}}(Z, B)}{\\widehat{\\text{Var}}(Z)} \\widehat{\\text{Var}}(Z)} = \\frac{\\widehat{\\text{Cov}}(Z, Y)}{\\widehat{\\text{Cov}}(Z, B)} = \\widehat{\\beta}_{\\textup{IV}}.\\label{eq:equiviv}\n\\end{align}\\]\n\n6.2.2 Wozu 2SLS?\n\n\n\n\n\nIV_DAG\nX\nXB\nBX-&gt;B\nY\nYX-&gt;Y\nZ\nZX-&gt;Z\nU\nUU-&gt;B\nU-&gt;Y\nB-&gt;Y\nZ-&gt;B\n\n\n\n\nAbbildung 6.2: IV-Design mit beobachtbaren Confoundern\n\n\n\n\nIn der Praxis werden IV-Schätzungen mit statistischer Software häufig anhand einer Implementierung des 2SLS-Verfahren durchgeführt. Gründe hierfür sind:\n\n\nBedingte Exogenität. Für den in Abbildung 6.1 dargestellten DGP ist die Exogenität von Z gegeben. In empirischen Anwendungen kann es jedoch schwierig sein, ein Instrument Z zu finden, dass plausibel nur mit dem endogenen Regressor korreliert. Eine schwächere Bedingung als Exogenität ist Exogenität nach Kontrolle für beobachtbare gemeinsame Determinanten (X) von Z und Y.3\nDiese Situation ist in Abbildung 6.2 dargestellt: Aufgrund der Pfeile von X zu Z und Y ist die Bedingung \\(\\eqref{eq:ivassum2}\\) verletzt. Durch Kontrolle für X in beiden Regressionen des 2SLS-Verfahrens können die Pfade durch X geschlossen werden.\n\nMehrere endogene Variablen / Instrumente. Der 2SLS-Ansatz kann leicht für mehrere endogene Variablen (und mehrere Instrumentvariablen) erweitert werden. Für jede der endogenen Variablen erfolgt hierbei eine separate Regression in der ersten Stufe des 2SLS-Verfahrens, wobei jeweils mehrere Instrumente verwendet werden und zusätzlich für beobachtbare Kovariablen X kontrolliert werden kann.\n\nStatistische Inferenz. Die Berechnung von \\(\\widehat{\\beta}_\\textup{IV}\\) erfordert Sorgfalt bei der Konstruktion von Inferenzstatistiken. Die in Kapitel 6.2.1 gezeigte Äquivalenz impliziert, dass wir bei der Schätzung der Variabilität von \\(\\widehat{\\beta}_\\textup{IV}\\) die Unsicherheit aus den beiden KQ-Schätzungen des 2SLS-Verfahrens berücksichtigen müssen. Korrigierte Standardfehlerformeln können vergleichsweise einfach anhand der Regressionsdarstellung hergeleitet werden und sind statistischer Software implementiert (bspw. ivreg in R).\nWeiterhin ermöglicht das Regressions-Framework diagnostische Tests. So kann die Relevanz von Instrumenten anhand von F-Tests für die Koeffizienten in den Regressionen der ersten Stufe des 2SLS-Verfahrens überprüft werden. Sofern mehr Instrumente als endogene Variablen vorliegen, kann die Exogenität der Instrumente getestet werden.\n\n\n3 Formal: \\(\\textup{Cov}(Z,u\\vert X) = 0\\).\nInteraktive Illustrationen des 2SLS-Verfahren\nDer DGP im nachfolgenden interaktiven Beispiel ist\n\\[\\begin{align}\n  \\begin{split}\n    X_i =&\\, \\gamma \\cdot Z_i + v_i,\\\\\n    Y_i =&\\, \\beta_1 \\cdot X_i + u_i,\n  \\end{split}\n  \\label{eq:OJSIVDGP}\n\\end{align}\\] wobei \\(Z_i \\sim N(0, .25^2)\\). Die Fehlerterme \\(v_i\\) und \\(u_i\\) sind \\(N(0,1)\\)-verteilt und folgen einer gemeinsam Normalverteilung mit Korrelationsparameter \\(\\rho\\), \\[\\begin{align}\n\\begin{pmatrix}\nv_i \\\\ u_i\n\\end{pmatrix}\n\\sim N\n\\bigg[\n\\begin{pmatrix}\n0 \\\\ 0\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & \\rho \\\\\n\\rho & 1\n\\end{pmatrix}\n\\bigg].\n\\end{align}\\]\nWir sind daran interessiert, den Parameter \\(\\beta_1\\) zu schätzen, um den Effekt von \\(X\\) auf \\(Y\\) zu bestimmen, wobei wir \\(n=1000\\) Beobachtungen von \\((X_i, Y_i, Z_i)\\) verwenden.\nBeachte, dass \\(X_i\\) eine Funktion der (exogenen) Variable \\(Z_i\\) und des Fehlerterms \\(v_i\\) ist. Wenn die Fehlerterme \\((v_i, u_i)’\\) im DGP \\(\\eqref{eq:OJSIVDGP}\\) korreliert sind (\\(\\rho\\neq0\\)), dann besteht Korrelation zwischen \\(X_i\\) und \\(u_i\\). Dies impliziert, dass \\(X\\) ein endogener Regressor im “naiven” Regressionsmodell \\[\\begin{align}\nY_i = \\beta_0 + \\beta_1 X_i + e_i, \\quad i = 1,\\dots,N.\n\\end{align}\\] Der KQ-Schätzer von \\(\\beta_1\\) ist dann verzerrt und inkonsistent.\nWenn \\(Z\\) Erklärungskraft für \\(X\\) hat, d.h. \\(\\gamma\\neq0\\) mit \\(|\\gamma|\\) nicht zu klein gewählt ist (\\(Z\\) ist relevant), und \\(Z\\) nur über \\(X\\) auf \\(Y\\) wirkt (\\(Z\\) ist exogen in der Gleichung von \\(Y_i\\)), dann kann der kausale Effekt von \\(X\\) auf \\(Y\\) anhand einer Instrumentvariablen-Regression mit \\(Z\\) konsistent geschätzt werden.\nDie folgende Interaktive Grafik berechnet den 2SLS-Schätzer Analog zu der in Kapitel 6.2 erläuterten Vorgehensweise:\n\n\nSchätze das Regressionsmodell\n\\[\\begin{align}\nX_i = \\alpha_0 + \\alpha_1 \\cdot Z_i + \\epsilon_i\n\\end{align}\\] und berechnen Sie die angepassten Werte \\(\\widehat{X}_i\\). Dieser Schritt isoliert die exogene Variation in \\(X_i\\), die auf \\(Z_i\\) zurückzuführen ist.\n\n\nSchätze den Effekt von \\(X\\) auf \\(Y\\) unter Verwendung von \\(\\widehat{X}_i\\), dem exogenen Teil von \\(X_i\\) aus 1., in der Regression\n\\[\\begin{align}\nY_i = \\delta_0 + \\delta_1 \\cdot \\widehat{X}_i  + \\varepsilon_i.\n\\end{align}\\] Der KQ-Schätzer \\(\\widehat{\\delta}_1\\) von \\(\\delta_1\\) ist der 2SLS-Schätzer von \\(\\beta_1\\).\n\n\nDie Grafik illustriert das Verhalten des IV-Schätzers (lila Grade) im Vergleich zum KQ-Schätzer (gestrichelte Grade) und zum wahren Zusammenhang (grüne Grade) für eine simulierte Stichprobe (gegeben der gewählten Parameter) anhand der geschätzten Regressionslinien. Die voreingestellten Parameter-Kombinationen zeigen\n\ndie Verzerrung von 2SLS, wenn \\(Z\\) ein schwaches Instrument für \\(X\\) ist,\neine Situation in der \\(X\\) exogen ist (KQ ist unverzerrt), was zu vergleichbaren Schätzungen führt (sofern \\(Z\\) kein Schwaches Instrument ist)\neine starke Verzerrung von KQ, wenn \\(X\\) endogen und irrelevant (\\(\\beta_1 = 0\\)) ist.\n\n\n\nAnhand der obigen interaktiven Grafik lässt sich zwar die Verzerrung der Schätzer einschätzen, jedoch nicht die Unsicherheit der Schätzung. Um die gesamte Verteilung der Schätzer in endlichen Stichproben zu illustrieren, zeigt die nachstehende Grafik Kerndichteschätzungen basierend auf \\(N\\) simulierte Stichproben der Größe \\(n\\) für den gewählten DGP.4 Die Applikation gibt weiterhin den R-Code für eine Simulation der Daten gemäß der gewählten Parameter aus.\n4 Beachte, dass die Simulation insbesondere für große \\(N\\) und \\(n\\) einige Sekunden dauern kann (grauer Balken am linken Rand zeigt laufende Berechnung an).Die voreingestellten Parameter-Kombinationen zeigen:\n\nWenn \\(Z\\) ein schwaches Instrument ist, kann der IV-Schätzer verzerrt sein und eine deutlich größere Varianz als der KQ-Schätzer haben.\nWenn \\(X\\) exogen ist, hat der IV-Schätzer eine größere Varianz als der KQ-Schätzer.\nWenn die Endogenität von \\(X\\) “stark” ist (hohe Korrelation von \\(u\\) und \\(v\\)), kann der IV-Schätzer auch in kleinen Stichproben hilfreich sein: IV hat eine deutlich geringere Verzerrung als KQ, aber eine größere Varianz.\n\n\n\n\n\nlibrary(faux) # install.packages(\"faux\")\n\nset.seed(1234)\n\nn &lt;- 1000\n\nerrors &lt;- rnorm_multi(\n    n, mu = c(0, 0), sd = c(1, 1),\n    r = -0.8, varnames = c(\"u\", \"v\"), \n)\n\nZ &lt;- rnorm(n, sd = .25)\nX &lt;- 2 * Z + errors$v\nY &lt;- 0 * X + errors$u\n\nthe_data &lt;- data.frame(X, Y)\n\n\nlibrary(cowplot)\n\nthe_data %&gt;%\n  mutate(Xhat = lm(X ~ Z)$fitted) %&gt;%\n  \n  ggplot(aes(x = X, y = Y)) + \n  geom_point() +\n  geom_smooth(\n    method = \"lm\", \n    se  = FALSE, \n    col = \"red\"\n  ) +\n  geom_hline(\n    yintercept = 0, \n    col = \"darkgreen\"\n    ) +\n  geom_smooth(\n    mapping = aes(x = Xhat, y = Y), \n    method = \"lm\", \n    se  = FALSE,\n    col = \"steelblue\"\n    ) +\n  theme_cowplot()\n\n\n\n\n\n\n\n\nlibrary(AER)\n\nKQ_mod_sim &lt;- lm(\n  formula = Y ~ X,\n  data = the_data\n)\n\nsummary(KQ_mod_sim)\n\n\nCall:\nlm(formula = Y ~ X, data = the_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.10480 -0.48829  0.00025  0.49527  2.42887 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.01074    0.02254   0.476    0.634    \nX           -0.64579    0.02025 -31.889   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7128 on 998 degrees of freedom\nMultiple R-squared:  0.5047,    Adjusted R-squared:  0.5042 \nF-statistic:  1017 on 1 and 998 DF,  p-value: &lt; 2.2e-16\n\n\n\nlibrary(ivreg)\n\niv_mod_sim &lt;- ivreg(\n  formula = Y ~ X | Z,\n  data = the_data\n)\n\nsummary(iv_mod_sim)\n\n\nCall:\nivreg(formula = Y ~ X | Z, data = the_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3.24501 -0.67660  0.01894  0.69021  3.52318 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  0.020535   0.031863   0.644    0.519\nX           -0.007139   0.059949  -0.119    0.905\n\nDiagnostic tests:\n                 df1 df2 statistic p-value    \nWeak instruments   1 998     294.5  &lt;2e-16 ***\nWu-Hausman         1 997     415.3  &lt;2e-16 ***\nSargan             0  NA        NA      NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.007 on 998 degrees of freedom\nMultiple R-Squared: 0.0111, Adjusted R-squared: 0.01011 \nWald test: 0.01418 on 1 and 998 DF,  p-value: 0.9052",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>IV-Regression</span>"
    ]
  },
  {
    "objectID": "IV.html#beispiel-der-schwache-staat-die-bauern-und-die-mafia",
    "href": "IV.html#beispiel-der-schwache-staat-die-bauern-und-die-mafia",
    "title": "6  IV-Regression",
    "section": "\n6.3 Beispiel: Der schwache Staat, die Bauern und die Mafia",
    "text": "6.3 Beispiel: Der schwache Staat, die Bauern und die Mafia\nAcemoglu, De Feo, und De Luca (2020) untersuchen den Aufstieg und die Auswirkungen der sizilianischen Mafia gegen Ende des 19. Jahrhunderts. Die Studie argumentiert, dass das Wachstum der Mafia teilweise auf das Aufkommen sozialistischer Bauern-Organisationen (Fasci siciliani) zurückzuführen ist, die in einem Umfeld schwacher staatlicher Präsenz die Rechte der Bauern verteidigten. Grundbesitzer, Verwalter und lokale Politiker wandten sich also an die Mafia, um diese sozialistische “Bedrohung” zu bekämpfen und die Kontrolle über die landwirtschaftlich arbeitende Bevölkerung zu behalten. Die Studie identifiziert einen signifikanten (positiven) kausalen Zusammenhang zwischen dem Aufstieg der Fasci und der Ausbreitung der Mafia in Sizilien.\n\n6.3.1 Identifikationsstrategie\nDie Beziehung zwischen dem Aufkommen der Fasci und der Mafia-Aktivität im einfachen Regressionsmodell \\[\\begin{align}\n  \\textup{Mafia-Aktivität} = \\beta_0 + \\beta_1 \\textup{Fasci siciliani} + \\varepsilon \\label{eq:fascimafiamod1}\n\\end{align}\\] ist aufgrund mehrerer Faktoren endogen:\n\nExterne Faktoren, die sowohl die Entstehung der Fasci siciliani als auch der Mafia beeinflussen sind wahrscheinlich. Beispielsweise könnten wirtschaftliche Notlagen oder politische Instabilität sowohl die Organisation der Bauern als auch die Etablierung der Mafia begünstigen.\nSimultante Kasalität: Die Präsenz der Fasci könnte die Mafia-Aktivitäten beeinflussen und umgekehrt: Intensive Mafia-Aktivitäten könnten die Notwendigkeit für Bauernorganisationen erhöhen, was wiederum die Mafia stärkt. Außerdem erschwert die zeitliche Nähe zwischen der Entstehung der Fasci und der Verbreitung der Mafia die Identifizierung der Kausalrichtung.\n\nWir können das Modell \\(\\eqref{eq:fascimafiamod1}\\) um (messbare) unter 1. fallende Regressoren erweitern, um einer verzerrten Schätzung aufgrund relevanter ausgelassener Variablen vorzubeugen. Eine Verzerrung aufgrund der in 2. beschriebenen simultanen Kausalität kann jedoch nicht durch multiple Regression vermieden werden.\nAcemoglu, De Feo, und De Luca (2020) nutzen die folgende Identifikationsstrategie: Eine extreme Dürre im Jahr 1893 (insbesondere Regenausfall im Frühlung) hatte einen erheblichen negativen Einfluss auf die landwirtschaftliche Produktion in Sizilien und verursachte große Not unter den Bauern, was die Entstehung der Fasci beförderte. Die Dürre kann als natürliches Experiment betrachtet werden, wobei durch die Variation in der Niederschlagsmenge (das Instrument) die Variation im Aufkommen von Fasci-Organisationen in verschiedenen Gemeinden isoliert werden kann, die unabhängig von der späteren Mafia-Aktivität ist. Anhand dieser exogenen Variation im Organisationsgrad der Bauern kann der Effekt auf die Entwicklung der Mafia identifiziert werden.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>IV-Regression</span>"
    ]
  },
  {
    "objectID": "IV.html#case-study-ökonomische-schocks-und-bürgerkriege",
    "href": "IV.html#case-study-ökonomische-schocks-und-bürgerkriege",
    "title": "6  IV-Regression",
    "section": "\n6.4 Case Study: Ökonomische Schocks und Bürgerkriege",
    "text": "6.4 Case Study: Ökonomische Schocks und Bürgerkriege\nEin Kernproblem bei der Schätzung der kausalen Beziehung zwischen wirtschaftlichen Schocks und dem Auftreten von kriegerischen Auseinandersetzungen ist die Endogenität von Variablen, die wirtschaftliche Stabilität messen (vgl. Fearon und Laitin 2003). Beispielsweise kann eine Verschlechterung der wirtschaftlichen Bedingungen eines Landes die Wahrscheinlichkeit eines Konflikts im Inland erhöhen. Gleichermaßen beeinflussen kriegerische Handlung im Inland die wirtschaftliche Situation einer Volkswirtschaft negativ.\n\n\n\n\n\nIV_DAG\nC\nCBIP\nBIPC-&gt;BIP\nKonflikt\nKonfliktC-&gt;Konflikt\nBIP-&gt;Konflikt\nKonflikt-&gt;BIP\n\n\n\n\nAbbildung 6.3: Simultane Kausalität zw. Kriegsrisiko und Wirtschaftslage\n\n\n\n\nIn der “Konfliktgleichung”\n\\[\\begin{align}\n  \\text{Konflikt-Wsk.} = \\beta_0 + \\beta_1\\, \\Delta\\text{BIP} + \\text{Kontrollv.} + \\epsilon\\label{eq:rainconf1}\n\\end{align}\\]\nliegt dann Endogenität des Regressors für “wirtschaftliche Stabilität”, hier \\(\\Delta\\text{BIP}\\), aufgrund von simultanter Kausalität vor. Die multiple Regression \\(\\eqref{eq:rainconf1}\\) liefert dann eine verzerrte Schätzungen des interessierenden Effekts \\(\\beta_1\\).\nMiguel, Satyanath, und Sergenti (2004) untersuchen die kausale Beziehung zwischen wirtschaftlichen Schocks und dem Auftreten von Bürgerkriegen in 41 afrikanischen Sub-Sahara-Ländern für den Zeitraum von 1981 bis 1999.5 Hierbei adressieren die Autoren das Endogenitätsproblem in einem IV-Ansatz mit Instrumenten, die mit wirtschaftlichen Schocks korreliert sind, aber nicht unmittelbar mit der Wahrscheinlichkeit eines Bürgerkriegs zusammenhängen.\n5 Siehe rainconflict$country %&gt;% unique().Die Identifikationsstrategie basiert auf metereologischen Faktoren: In den betrachteten Agrarökonomien sind Schocks in den Niederschlägen entscheidend für die Entwicklung des Bruttoinlandsprodukts. Ungünstige Wetterbedingungen, die landwirtschaftliche Erträge negativ beeinflussen, haben einen direkten (negativen) Effekt auf die wirtschaftliche Situation. Variation in der Regenmenge ist jedoch keine unmittelbare Determinante der Konfliktwahrscheinlichkeit und folglich exogen in Modellgleichung \\(\\eqref{eq:rainconf1}\\). Maße für die Veränderungen in der Niederschlagsmenge sind somit plausible Instrumente für endogene Variablen, die Veränderungen im Bruttoinlandsprodukt messen.\n\n\n\n\n\nIV_DAG\nC\nCBIP\nBIPC-&gt;BIP\nKonflikt\nKonfliktC-&gt;Konflikt\nNiederschlag\nNiederschlagNiederschlag-&gt;BIP\nBIP-&gt;Konflikt\nKonflikt-&gt;BIP\n\n\n\n\nAbbildung 6.4: IV-Design bei simultaner Kausalität zw. Kriegsrisiko und Wirtschaftslage\n\n\n\n\nAnhand von Länder-Paneldaten mit Informationen über wirtschaftliche Indikatoren, Konfliktereignisse und Niederschläge, isolieren Miguel, Satyanath, und Sergenti (2004) in einem IV-Ansatz die exogene Variation der wirtschaftlichen Entwicklung, d.h. Variation in \\(\\Delta\\text{BIP}\\) die nicht mit dem Fehlerterm in der Konfliktgleichung korreliert ist. Die Ergebnisse ihrer 2SLS-Schätzungen zeigen, dass negative ökonomische Schocks die Wahrscheinlichkeit eines Bürgerkriegs signifikant erhöhen. Miguel, Satyanath, und Sergenti (2004) zeigen weiterhin, dass ihre Ergebnisse robust gegenüber verschiedenen Modell-Spezifikationen unter Berücksichtigung diverser Kontrollvariablen sind.\nWir reproduzieren nachfolgend die zentralen Ergebnisse von Miguel, Satyanath, und Sergenti (2004) anhand eines Auszugs (rainconflict.csv) aus dem der Studie zugrundeliegenden Datensatz. Der vollständige Datensatz ist, nach Registrierung, hier verfügbar.\n\nlibrary(readr)\n\n# Datensatz 'rainconflict' einlesen\nrainconflict &lt;- read_csv2(\n  file = \"datasets/rainconflict.csv\"\n)\n\n\n# Überblick verschaffen\nglimpse(rainconflict)\n\nRows: 743\nColumns: 19\n$ any_prio   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,…\n$ war_prio   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,…\n$ ccode      &lt;dbl&gt; 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404,…\n$ country    &lt;chr&gt; \"Guinea-Bissau\", \"Guinea-Bissau\", \"Guinea-Bissau\", \"Guinea-…\n$ gdp_g      &lt;dbl&gt; 0.216560572, 0.104712047, -0.042654045, 0.034653414, 0.0366…\n$ gdp_g_l    &lt;dbl&gt; -0.152877718, 0.216560572, 0.104712047, -0.042654045, 0.034…\n$ GPCP_g     &lt;dbl&gt; 0.170644149, 0.023161817, -0.215036541, 0.098459557, 0.0185…\n$ GPCP_g_l   &lt;dbl&gt; -0.048803251, 0.170644149, 0.023161817, -0.215036541, 0.098…\n$ GPCP_g_fl  &lt;dbl&gt; 0.023161817, -0.215036541, 0.098459557, 0.018551834, 0.0545…\n$ gdp_1979   &lt;dbl&gt; 0.556, 0.556, 0.556, 0.556, 0.556, 0.556, 0.556, 0.556, 0.5…\n$ polity2l   &lt;dbl&gt; -7, -7, -7, -7, -8, -8, -8, -8, -8, -8, -6, -6, -6, -6, 5, …\n$ polity2_IV &lt;dbl&gt; -7, -7, -7, -8, -8, -8, -8, -8, -8, -6, -6, -6, -6, 5, 5, 5…\n$ ethfrac    &lt;dbl&gt; 0.8037570, 0.8037570, 0.8037570, 0.8037570, 0.8037570, 0.80…\n$ relfrac    &lt;dbl&gt; 0.5450, 0.5450, 0.5450, 0.5450, 0.5450, 0.5450, 0.5450, 0.5…\n$ oil        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ lmtnest    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ lpopl1     &lt;dbl&gt; 6.695799, 6.714170, 6.732211, 6.749931, 6.768493, 6.786717,…\n$ tot_100_g  &lt;dbl&gt; 0.3326812088, -0.0604966730, 0.0235692672, 0.6656700373, -0…\n$ year       &lt;dbl&gt; 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990,…\n\n\n\n\n\n\n\n\n\n\n\nVariable\nBeschreibung\n\n\n\nany_prior\nDummyvariable: Konflikt mit mind. 25 Toten im Jahr t\n\n\nwar_prio\nDummyvariable: Konflikt mit mind. 1000 Toten im Jahr t\n\n\nccode\nLänderkennung (numerisch)\n\n\ncountry\nName des Landes\n\n\ngdp_g\n(BIP_t - BIP_t-1) / BIP_t-1\n\n\ngdp_g_l\n(BIP_t-1 - BIP_t-2) / BIP_t-2\n\n\nGPCP_g\n(Niederschlag_t - Niederschlag_t-1) / Niederschlag_t-1\n\n\nGPCP_g_l\nGPCP_g in t-1\n\n\nGPCP_g_fl\nGPCP_g in t+1\n\n\ngdp_1979\nLog Pro-Kopf-BIP in 1979\n\n\npolity2_IV\nDiff. zw. Demokratie- und Autokrarie-Score im Jahr t (Skala v. -10 bis 10)\n\n\npolity2l\npolity2_IV im Jahr t-1 (Skala v. -10 bis 10)\n\n\nethfrac\nEthno-linguistische Fragmentierung (Anteil)\n\n\nrelfrac\nReligiöse Fragmentierung (Anteil)\n\n\noil\nDummy für Öl-exportierendes Land\n\n\nlmtnest\nLog Anteil Gebirgsregionen an Landesfläche\n\n\nlpopl1\nLog Bevölkerung im Jahr t-1\n\n\ntot_100_g\nHandelsbedingungen (Index, 1995 = 100)\n\n\nyear\nJahr der Beobachtung\n\n\n\n\n\n\n\n\nTabelle 6.1: rainconflict – Polit-ökonomische Charakteristika afrikanischer Länder v. 1981 bis 1999\n\n\n\n\n# ccode zu Typ 'factor' transformieren\nrainconflict &lt;- rainconflict %&gt;% \n  mutate(\n    ccode = as.factor(ccode)\n  )\n\n\nlibrary(modelsummary)\n\n# Statistische Zusammenfassung\ndatasummary(\n  formula = All( rainconflict %&gt;% select(-ccode, -year) )   \n    ~ (mean + sd) * Arguments(na.rm = TRUE) \n    + N, \n  fmt = 4,\n  data = rainconflict \n) \n\n\n\n \n\n  \n    \n\ntinytable_hlwyde6ilskgvx0ljsa0\n\n\n      \n\n \n                mean\n                sd\n                N\n              \n\n\nany_prio  \n                  0.2678 \n                  0.4431\n                  743\n                \n\nwar_prio  \n                  0.1669 \n                  0.3731\n                  743\n                \n\ngdp_g     \n                  -0.0048\n                  0.0707\n                  743\n                \n\ngdp_g_l   \n                  -0.0056\n                  0.0724\n                  743\n                \n\nGPCP_g    \n                  0.0182 \n                  0.2094\n                  743\n                \n\nGPCP_g_l  \n                  0.0113 \n                  0.2067\n                  743\n                \n\nGPCP_g_fl \n                  0.0150 \n                  0.2107\n                  743\n                \n\ngdp_1979  \n                  1.1639 \n                  0.9009\n                  743\n                \n\npolity2l  \n                  -3.6083\n                  5.5543\n                  743\n                \n\npolity2_IV\n                  -3.4035\n                  5.5766\n                  736\n                \n\nethfrac   \n                  0.6546 \n                  0.2374\n                  743\n                \n\nrelfrac   \n                  0.4868 \n                  0.1857\n                  743\n                \n\noil       \n                  0.1184 \n                  0.3233\n                  743\n                \n\nlmtnest   \n                  1.5783 \n                  1.4334\n                  743\n                \n\nlpopl1    \n                  8.7497 \n                  1.2068\n                  743\n                \n\ntot_100_g \n                  -0.0068\n                  0.1552\n                  661\n                \n\n\n\n\n    \n\n\n\nTabelle 6.2: rainconflict – Statistische Zusammenfassung\n\n\n\n\nlibrary(fixest)\n\n# (1)\n(\n  rncnf_mod1 &lt;- feols(\n    fml = gdp_g ~ GPCP_g + GPCP_g_l,\n    data = rainconflict,\n    vcov = ~ ccode\n  )\n)\n\nOLS estimation, Dep. Var.: gdp_g\nObservations: 743\nStandard-errors: Clustered (ccode) \n             Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept) -0.006147   0.002460 -2.49856 0.0166787 *  \nGPCP_g       0.055430   0.016301  3.40029 0.0015378 ** \nGPCP_g_l     0.034058   0.013213  2.57761 0.0137398 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.069815   Adj. R2: 0.02088\n\n\n\n# (2)\nrncnf_mod2 &lt;- feols(\n  fml = gdp_g ~ GPCP_g + GPCP_g_l\n  + gdp_1979\n  + polity2l \n  + ethfrac \n  + relfrac \n  + oil \n  + lmtnest \n  + lpopl1\n  + year:ccode,\n  data = rainconflict,\n  vcov = ~ ccode\n) \n\nrncnf_mod2 %&gt;% \n  print(n = 10)\n\nOLS estimation, Dep. Var.: gdp_g\nObservations: 743\nStandard-errors: Clustered (ccode) \n             Estimate Std. Error   t value  Pr(&gt;|t|)    \n(Intercept) -8.380394   7.836789 -1.069366 0.2913157    \nGPCP_g       0.053402   0.016788  3.180892 0.0028359 ** \nGPCP_g_l     0.031518   0.013739  2.294105 0.0271135 *  \ngdp_1979    -0.568562   0.933728 -0.608916 0.5460230    \npolity2l    -0.000462   0.000697 -0.661827 0.5118772    \nethfrac     -0.290995   5.315419 -0.054745 0.9566138    \nrelfrac      6.344474   6.277193  1.010718 0.3182264    \noil         -0.022946   0.011735 -1.955363 0.0575517 .  \nlmtnest     -0.154883   0.950072 -0.163022 0.8713219    \nlpopl1      -0.103898   0.140671 -0.738588 0.4644693    \n... 41 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.067787   Adj. R2: 0.012893\n\n\n\n# (3)\nrncnf_mod3 &lt;- feols(\n  fml = gdp_g ~ GPCP_g + GPCP_g_l \n  + year:ccode\n  | ccode,\n  data = rainconflict,\n  vcov = ~ ccode\n) \n\nrncnf_mod3 %&gt;% \n  print(n = 2)\n\nOLS estimation, Dep. Var.: gdp_g\nObservations: 743\nFixed-effects: ccode: 41\nStandard-errors: Clustered (ccode) \n         Estimate Std. Error t value  Pr(&gt;|t|)    \nGPCP_g   0.048582   0.016523 2.94024 0.0054275 ** \nGPCP_g_l 0.028004   0.013779 2.03236 0.0487938 *  \n... 41 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.065802     Adj. R2: 0.023299\n                 Within R2: 0.086915\n\n\n\n# (4)\nrncnf_mod4 &lt;- feols(\n  fml = gdp_g ~ GPCP_g + GPCP_g_l + GPCP_g_fl\n  + year:ccode \n  | ccode,\n  data = rainconflict,\n  vcov = ~ ccode\n) \n\nrncnf_mod4 %&gt;% \n  print(n = 3)\n\nOLS estimation, Dep. Var.: gdp_g\nObservations: 743\nFixed-effects: ccode: 41\nStandard-errors: Clustered (ccode) \n          Estimate Std. Error  t value  Pr(&gt;|t|)    \nGPCP_g    0.048944   0.017837 2.743919 0.0090443 ** \nGPCP_g_l  0.028235   0.013783 2.048544 0.0471081 *  \nGPCP_g_fl 0.000617   0.018501 0.033337 0.9735719    \n... 41 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.065801     Adj. R2: 0.021818\n                 Within R2: 0.086917\n\n\n\n# (5)\nrncnf_mod5 &lt;- feols(\n  fml = gdp_g ~ GPCP_g + GPCP_g_l \n  + tot_100_g \n  + year:ccode \n  | ccode,\n  data = rainconflict,\n  vcov = ~ ccode\n) \n\nrncnf_mod5 %&gt;%\n  print(n = 3)\n\nOLS estimation, Dep. Var.: gdp_g\nObservations: 661\nFixed-effects: ccode: 37\nStandard-errors: Clustered (ccode) \n           Estimate Std. Error   t value  Pr(&gt;|t|)    \nGPCP_g     0.053124   0.017432  3.047509 0.0043049 ** \nGPCP_g_l   0.036616   0.014705  2.490060 0.0175258 *  \ntot_100_g -0.002280   0.022286 -0.102318 0.9190722    \n... 37 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.059582     Adj. R2: 0.052542\n                 Within R2: 0.114693\n\n\n\n# Tabellarischer Vergleich mit modelsummary()\n# (Tabelle 3 in Ditella und Schargrodsky, 2004)\nmodelsummary(\n  models = list(\n    \"(1)\" = rncnf_mod1, \n    \"(2)\" = rncnf_mod2, \n    \"(3)\" = rncnf_mod3, \n    \"(4)\" = rncnf_mod4, \n    \"(5)\" = rncnf_mod5\n  ),\n  stars = T, \n  coef_omit = \"^year.*$\",\n  gof_omit = \"^(?!(R2|Num.Obs.|FE.*)$).*\", \n  output = \"gt\"\n)\n\n\n\n\n\n\n\n\n\n(1)\n(2)\n(3)\n(4)\n(5)\n\n\n\n(Intercept)\n-0.006*\n-8.380\n\n\n\n\n\n\n(0.002)\n(7.837)\n\n\n\n\n\nGPCP_g\n0.055**\n0.053**\n0.049**\n0.049**\n0.053**\n\n\n\n(0.016)\n(0.017)\n(0.017)\n(0.018)\n(0.017)\n\n\nGPCP_g_l\n0.034*\n0.032*\n0.028*\n0.028*\n0.037*\n\n\n\n(0.013)\n(0.014)\n(0.014)\n(0.014)\n(0.015)\n\n\ngdp_1979\n\n-0.569\n\n\n\n\n\n\n\n(0.934)\n\n\n\n\n\npolity2l\n\n0.000\n\n\n\n\n\n\n\n(0.001)\n\n\n\n\n\nethfrac\n\n-0.291\n\n\n\n\n\n\n\n(5.315)\n\n\n\n\n\nrelfrac\n\n6.344\n\n\n\n\n\n\n\n(6.277)\n\n\n\n\n\noil\n\n-0.023+\n\n\n\n\n\n\n\n(0.012)\n\n\n\n\n\nlmtnest\n\n-0.155\n\n\n\n\n\n\n\n(0.950)\n\n\n\n\n\nlpopl1\n\n-0.104\n\n\n\n\n\n\n\n(0.141)\n\n\n\n\n\nGPCP_g_fl\n\n\n\n0.001\n\n\n\n\n\n\n\n(0.019)\n\n\n\ntot_100_g\n\n\n\n\n-0.002\n\n\n\n\n\n\n\n(0.022)\n\n\nNum.Obs.\n743\n743\n743\n743\n661\n\n\nR2\n0.024\n0.079\n0.133\n0.133\n0.162\n\n\nFE: ccode\n\n\nX\nX\nX\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\nTabelle 6.3: First-Stage-Regressionen für gdp_g\n\n\n\n\nS1_res &lt;- tibble(\n\n  x = residuals(\n    feols(\n      fml = GPCP_g ~ GPCP_g_l\n      + year:ccode\n      | ccode,\n      data = rainconflict\n    )\n  ),\n  \n  y = residuals(\n    feols(\n      fml = gdp_g ~ GPCP_g_l\n      + year:ccode\n      | ccode,\n      data = rainconflict\n    )\n  )\n  \n)\n\n\nlibrary(ggplot2)\nlibrary(cowplot)\n\nggplot(\n  data = S1_res,\n  mapping = aes(x = x, y = y)) +\n  geom_point(\n    size = .75, \n    alpha = .5\n  ) +\n  geom_smooth(method = \"loess\", span = .5) +\n  coord_cartesian(\n    xlim = c(-.4, .4), \n    ylim = c(-.1, .1)\n  ) +\n  theme_cowplot()\n\n\n\n\n\n\n\n\nfeols(\n  fml = any_prio ~ GPCP_g + GPCP_g_l \n  + year:ccode\n  | ccode,\n  data = rainconflict,\n  vcov = ~ ccode\n) %&gt;% \n  print(n = 2)\n\nOLS estimation, Dep. Var.: any_prio\nObservations: 743\nFixed-effects: ccode: 41\nStandard-errors: Clustered (ccode) \n          Estimate Std. Error   t value Pr(&gt;|t|)    \nGPCP_g   -0.023770   0.041969 -0.566373  0.57430    \nGPCP_g_l -0.121936   0.050328 -2.422836  0.02002 *  \n... 41 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.239168     Adj. R2: 0.671564\n                 Within R2: 0.374052\n\n\n\nfeols(\n  fml = war_prio ~ GPCP_g + GPCP_g_l \n  + year:ccode\n  | ccode,\n  data = rainconflict,\n  vcov = ~ ccode\n) %&gt;% \n  print(n = 2)\n\nOLS estimation, Dep. Var.: war_prio\nObservations: 743\nFixed-effects: ccode: 41\nStandard-errors: Clustered (ccode) \n          Estimate Std. Error  t value Pr(&gt;|t|)    \nGPCP_g   -0.062476   0.029051 -2.15060 0.037605 *  \nGPCP_g_l -0.068689   0.030678 -2.23904 0.030783 *  \n... 41 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.204541     Adj. R2: 0.661198\n                 Within R2: 0.385205\n\n\n\nrf_res &lt;- tibble(\n  \n  x = residuals(\n    feols(\n      fml = GPCP_g_l ~ GPCP_g\n      + year:ccode\n      | ccode,\n      data = rainconflict\n    )\n  ),\n  \n  y = residuals(\n    feols(\n      fml = any_prio ~ GPCP_g\n      + year:ccode\n      | ccode,\n      data = rainconflict\n    )\n  )\n  \n)\n\n\nggplot(\n  data = rf_res , \n  mapping = aes(x = x, y = y)) +\n  geom_point(pch = 19) +\n  geom_smooth(method = \"loess\") +\n  coord_cartesian(\n    xlim = c(-.4, .4), \n    ylim = c(-.2, .4)\n  ) +\n  theme_cowplot()\n\n\n\n\n\n\n\n\n# (1)\nmod_conf_probit &lt;- feglm(\n  fml = any_prio ~\n    gdp_g + \n    gdp_g_l\n  + gdp_1979\n  + polity2l \n  + ethfrac \n  + relfrac \n  + oil \n  + lmtnest \n  + lpopl1 \n  + year,\n  data = rainconflict,\n  vcov = ~ ccode, \n  family = binomial(link = \"probit\")\n) \n\nlibrary(marginaleffects)\n\nmod_conf_probit_avge &lt;- mod_conf_probit %&gt;% \n  avg_slopes() \n\n# (2)\n(\nmod_conf_ols &lt;- feols(\n  fml = any_prio ~\n    gdp_g + \n    gdp_g_l\n  + gdp_1979\n  + polity2l \n  + ethfrac \n  + relfrac \n  + oil \n  + lmtnest \n  + lpopl1 \n  + year,\n  data = rainconflict,\n  vcov = ~ ccode\n) \n)\n\nOLS estimation, Dep. Var.: any_prio\nObservations: 743\nStandard-errors: Clustered (ccode) \n             Estimate Std. Error   t value Pr(&gt;|t|)    \n(Intercept) -5.381928  12.515620 -0.430017 0.669491    \ngdp_g       -0.332716   0.263400 -1.263157 0.213846    \ngdp_g_l     -0.084997   0.240857 -0.352894 0.726021    \ngdp_1979    -0.040662   0.049894 -0.814961 0.419921    \npolity2l     0.000642   0.004515  0.142164 0.887664    \nethfrac      0.230431   0.271367  0.849151 0.400851    \nrelfrac     -0.237764   0.241595 -0.984144 0.330961    \noil          0.045297   0.211526  0.214144 0.831523    \nlmtnest      0.075811   0.039371  1.925548 0.061291 .  \nlpopl1       0.068052   0.051102  1.331675 0.190506    \nyear         0.002483   0.006366  0.390106 0.698528    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.414086   Adj. R2: 0.113662\n\n# (3)\nfeols(\n  fml = any_prio ~ -1\n  +  gdp_g + \n    gdp_g_l\n  + gdp_1979\n  + polity2l \n  + ethfrac \n  + relfrac \n  + oil \n  + lmtnest \n  + lpopl1 \n  + i(ccode, year),\n  data = rainconflict,\n  vcov = ~ ccode\n) %&gt;% \n  summary(n = 10)\n\nOLS estimation, Dep. Var.: any_prio\nObservations: 743\nStandard-errors: Clustered (ccode) \n                 Estimate Std. Error   t value Pr(&gt;|t|)    \ngdp_g           -0.387996   0.208988 -1.856550 0.070751 .  \ngdp_g_l         -0.086461   0.212442 -0.406986 0.686188    \ngdp_1979         2.287334   9.856030  0.232075 0.817663    \npolity2l        -0.001355   0.004148 -0.326768 0.745547    \nethfrac         43.124761  50.926744  0.846800 0.402145    \nrelfrac         39.765573  63.751088  0.623763 0.536324    \noil              0.006172   0.086301  0.071511 0.943347    \nlmtnest         -3.835094   7.462461 -0.513918 0.610137    \nlpopl1           1.211169   0.671842  1.802760 0.078964 .  \nccode::404:year -0.033077   0.019564 -1.690721 0.098669 .  \n... 40 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.294151   Adj. R2: 0.526933\n\n# (4)\nfeols(\n  fml = any_prio ~ -1\n  +  gdp_g \n  +  gdp_g_l\n  + i(ccode, year)\n  | ccode,\n  data = rainconflict,\n  vcov = ~ ccode\n) %&gt;% \n  summary(n = 10)\n\nOLS estimation, Dep. Var.: any_prio\nObservations: 743\nFixed-effects: ccode: 41\nStandard-errors: Clustered (ccode) \n                 Estimate Std. Error    t value  Pr(&gt;|t|)    \ngdp_g           -0.210909   0.156046  -1.351587   0.18410    \ngdp_g_l          0.066801   0.158944   0.420279   0.67653    \nccode::404:year  0.028626   0.001635  17.510274 &lt; 2.2e-16 ***\nccode::420:year -0.015243   0.000745 -20.452968 &lt; 2.2e-16 ***\nccode::432:year  0.007220   0.000373  19.349039 &lt; 2.2e-16 ***\nccode::433:year  0.059746   0.000225 265.584211 &lt; 2.2e-16 ***\nccode::434:year  0.000449   0.000485   0.924683   0.36068    \nccode::435:year  0.000223   0.000544   0.410843   0.68338    \nccode::436:year  0.035483   0.000574  61.802750 &lt; 2.2e-16 ***\nccode::437:year  0.000284   0.001085   0.261893   0.79475    \n... 33 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.239816     Adj. R2: 0.669782\n                 Within R2: 0.370655\n\n#### IV models ####\n\n# (5)\nfeols(\n  fml = any_prio ~\n  + gdp_1979\n  + polity2l \n  + ethfrac \n  + relfrac \n  + oil \n  + lmtnest \n  + lpopl1 \n  + i(ccode, year)\n  | gdp_g + gdp_g_l ~ GPCP_g + GPCP_g_l, \n  data = rainconflict,\n  vcov = ~ ccode\n) %&gt;% \n  summary(n = 10)\n\nTSLS estimation - Dep. Var.: any_prio\n                  Endo.    : gdp_g, gdp_g_l\n                  Instr.   : GPCP_g, GPCP_g_l\nSecond stage: Dep. Var.: any_prio\nObservations: 743\nStandard-errors: Clustered (ccode) \n               Estimate Std. Error   t value Pr(&gt;|t|)    \n(Intercept) -153.157460  60.518562 -2.530752 0.015419 *  \nfit_gdp_g     -1.343217   1.462578 -0.918390 0.363920    \nfit_gdp_g_l   -2.714015   1.036990 -2.617205 0.012453 *  \ngdp_1979       9.446193  11.069500  0.853353 0.398545    \npolity2l      -0.005806   0.004843 -1.198875 0.237631    \nethfrac       83.847478  47.883805  1.751061 0.087601 .  \nrelfrac       95.038889  64.178048  1.480863 0.146478    \noil           -0.058890   0.066111 -0.890779 0.378375    \nlmtnest        2.159746   7.025786  0.307403 0.760132    \nlpopl1        -0.336984   0.868944 -0.387809 0.700213    \n... 41 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.346685   Adj. R2: 0.342806\nF-test (1st stage), gdp_g  : stat = 7.81825, p = 4.389e-4, on 2 and 692 DoF.\nF-test (1st stage), gdp_g_l: stat = 5.56598, p = 0.003999, on 2 and 692 DoF.\n                 Wu-Hausman: stat = 2.56365, p = 0.077756, on 2 and 690 DoF.\n\n# (6)\nfeols(\n  fml = any_prio ~ \n  + i(ccode, year)\n  | ccode\n  | gdp_g + gdp_g_l ~ GPCP_g + GPCP_g_l, \n  data = rainconflict,\n  vcov = ~ ccode\n) %&gt;% \n  summary(n = 10)\n\nTSLS estimation - Dep. Var.: any_prio\n                  Endo.    : gdp_g, gdp_g_l\n                  Instr.   : GPCP_g, GPCP_g_l\nSecond stage: Dep. Var.: any_prio\nObservations: 743\nFixed-effects: ccode: 41\nStandard-errors: Clustered (ccode) \n                 Estimate Std. Error   t value   Pr(&gt;|t|)    \nfit_gdp_g       -1.131763   1.362254 -0.830802 4.1102e-01    \nfit_gdp_g_l     -2.546473   1.070475 -2.378825 2.2230e-02 *  \nccode::404:year  0.006632   0.013806  0.480372 6.3358e-01    \nccode::420:year -0.005215   0.006294 -0.828648 4.1222e-01    \nccode::432:year  0.012689   0.003059  4.148704 1.6945e-04 ***\nccode::433:year  0.063170   0.001807 34.960834  &lt; 2.2e-16 ***\nccode::434:year  0.006202   0.004195  1.478344 1.4715e-01    \nccode::435:year  0.008547   0.004353  1.963488 5.6568e-02 .  \nccode::436:year  0.043387   0.004817  9.007338 3.5998e-11 ***\nccode::437:year  0.017506   0.008435  2.075379 4.4425e-02 *  \n... 33 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.302046     Adj. R2: 0.476172\n                 Within R2: 0.001663\nF-test (1st stage), gdp_g  : stat = 6.67399, p = 0.001345, on 2 and 699 DoF.\nF-test (1st stage), gdp_g_l: stat = 5.70442, p = 0.003488, on 2 and 699 DoF.\n                 Wu-Hausman: stat = 3.14562, p = 0.043689, on 2 and 657 DoF.\n\n# (7)\nfeols(\n  fml = war_prio ~ \n    + i(ccode, year)\n  | ccode\n  | gdp_g + gdp_g_l ~ GPCP_g + GPCP_g_l, \n  data = rainconflict,\n  vcov = ~ ccode\n) %&gt;% \n  summary(n = 10)\n\nTSLS estimation - Dep. Var.: war_prio\n                  Endo.    : gdp_g, gdp_g_l\n                  Instr.   : GPCP_g, GPCP_g_l\nSecond stage: Dep. Var.: war_prio\nObservations: 743\nFixed-effects: ccode: 41\nStandard-errors: Clustered (ccode) \n                 Estimate Std. Error   t value  Pr(&gt;|t|)    \nfit_gdp_g       -1.479970   0.800386 -1.849071  0.071848 .  \nfit_gdp_g_l     -0.768785   0.678533 -1.133010  0.263956    \nccode::404:year -0.001514   0.007526 -0.201188  0.841571    \nccode::420:year  0.007088   0.003431  2.066077  0.045340 *  \nccode::432:year  0.003375   0.001670  2.020730  0.050037 .  \nccode::433:year  0.015992   0.000992 16.119071 &lt; 2.2e-16 ***\nccode::434:year  0.004765   0.002306  2.065964  0.045351 *  \nccode::435:year  0.004698   0.002393  1.963229  0.056599 .  \nccode::436:year  0.005405   0.002624  2.059408  0.046005 *  \nccode::437:year  0.008802   0.004699  1.872980  0.068392 .  \n... 33 coefficients remaining\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.228949     Adj. R2: 0.575516\n                 Within R2: 0.229726\nF-test (1st stage), gdp_g  : stat = 6.67399, p = 0.001345, on 2 and 699 DoF.\nF-test (1st stage), gdp_g_l: stat = 5.70442, p = 0.003488, on 2 and 699 DoF.\n                 Wu-Hausman: stat = 1.46546, p = 0.231725, on 2 and 657 DoF.\n\nlibrary(modelsummary)\n\nmodelsummary(\n  models = list(\n    mod_conf_probit_avge, \n    mod_conf_ols\n    )\n  )\n\n \n\n  \n    \n\ntinytable_3bz99cfzogjycmj3qfrn\n\n\n      \n\n \n                (1)\n                (2)\n              \n\n\nethfrac    \n                  0.220  \n                  0.230    \n                \n\n           \n                  (0.242)\n                  (0.271)  \n                \n\ngdp_1979   \n                  -0.063 \n                  -0.041   \n                \n\n           \n                  (0.058)\n                  (0.050)  \n                \n\ngdp_g      \n                  -0.350 \n                  -0.333   \n                \n\n           \n                  (0.301)\n                  (0.263)  \n                \n\ngdp_g_l    \n                  -0.127 \n                  -0.085   \n                \n\n           \n                  (0.251)\n                  (0.241)  \n                \n\nlmtnest    \n                  0.072  \n                  0.076    \n                \n\n           \n                  (0.036)\n                  (0.039)  \n                \n\nlpopl1     \n                  0.074  \n                  0.068    \n                \n\n           \n                  (0.049)\n                  (0.051)  \n                \n\noil        \n                  0.015  \n                  0.045    \n                \n\n           \n                  (0.210)\n                  (0.212)  \n                \n\npolity2l   \n                  0.001  \n                  0.001    \n                \n\n           \n                  (0.005)\n                  (0.005)  \n                \n\nrelfrac    \n                  -0.271 \n                  -0.238   \n                \n\n           \n                  (0.241)\n                  (0.242)  \n                \n\nyear       \n                  0.003  \n                  0.002    \n                \n\n           \n                  (0.006)\n                  (0.006)  \n                \n\n(Intercept)\n                         \n                  -5.382   \n                \n\n           \n                         \n                  (12.516) \n                \n\nNum.Obs.   \n                  743    \n                  743      \n                \n\nR2         \n                  0.122  \n                  0.126    \n                \n\nR2 Adj.    \n                  0.099  \n                  0.114    \n                \n\nAIC        \n                  779.8  \n                  820.4    \n                \n\nBIC        \n                  830.6  \n                  871.1    \n                \n\nRMSE       \n                  0.42   \n                  0.41     \n                \n\nStd.Errors \n                         \n                  by: ccode\n                \n\n\n\n\n    \n\n\n\n\n\n\n\n\nAcemoglu, Daron, Giuseppe De Feo, und Giacomo Davide De Luca. 2020. „Weak States: Causes and Consequences of the Sicilian Mafia“. The Review of Economic Studies. https://doi.org/10.1093/restud/rdz009.\n\n\nFearon, James D., und David D. Laitin. 2003. „Ethnicity, Insurgency, and Civil War.“ American Political Science Review 97 (01): 75–90. https://doi.org/10.1017/s0003055403000534.\n\n\nHuntington-Klein, Nick. 2021. The Effect: An Introduction to Research Design and Causality. Chapman; Hall/CRC. https://doi.org/10.1201/9781003226055.\n\n\nMiguel, Edward, Shanker Satyanath, und Ernest Sergenti. 2004. „Economic Shocks and Civil Conflict: An Instrumental Variables Approach“. Journal of Political Economy 112 (4): 725–53. https://doi.org/10.1086/421174.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>IV-Regression</span>"
    ]
  },
  {
    "objectID": "Machine Learning.html",
    "href": "Machine Learning.html",
    "title": "10  Machine Learning",
    "section": "",
    "text": "Das Gradientenabstiegsverfahren (Gradient Descent) ist ein iteratives Optimierungsverfahren zur Minimierung einer differenzierbaren Zielfunktion \\(f(x)\\). Es wird häufig eingesetzt, um die Verlustfunktionen in maschinellen Lernmodellen zu minimieren. Der Algorithmus aktualisiert die Variablen schrittweise in die entgegengesetzte Richtung des Gradienten der Funktion an der aktuellen Position. Der Gradient gibt dabei die Richtung des steilsten Anstiegs an, wodurch die entgegengesetzte Richtung zum schnellsten Abstieg (Descent) führt.\nDer folgende Pseudocode zeigt die grundlegende Vorgehensweise des Gradientenabstiegsverfahrens unter Einbeziehung eines Momentum-Terms, der dazu dient, das Konvergenzverhalten zu verbessern und lokale Minima effektiver zu überwinden.\n\\[\\begin{align}\n& \\textbf{Algorithmus: Gradientenabstiegsverfahren mit Momentum} \\\\\n& \\text{Initialisiere: }\\\\\n& \\quad x_0 \\text{ (Startpunkt) }\\\\\n& \\quad \\eta \\text{ (Lernrate) }\\\\\n& \\quad \\alpha \\text{ (Momentum-Faktor) }\\\\\n& \\quad v_0 = 0 \\text{ (Anfangsmomentum) } \\\\[1em]\n& \\text{Für } t = 0, 1, 2, \\dots \\text{ bis Konvergenz} \\\\\n& \\quad \\text{1. Berechne den Gradienten: } \\nabla f(x_t) \\\\\n& \\quad \\text{2. Aktualisiere den Momentum-Term: } v_{t+1} = \\alpha v_t - \\eta \\nabla f(x_t) \\\\\n& \\quad \\text{3. Aktualisiere die Position: } x_{t+1} = x_t + v_{t+1} \\\\\n& \\quad \\text{4. Überprüfe das Abbruchkriterium (z.B. } \\| \\nabla f(x_t) \\| &lt; \\epsilon\\text{)} \\\\\n\\end{align}\\]",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Machine Learning</span>"
    ]
  },
  {
    "objectID": "SyntheticControl.html",
    "href": "SyntheticControl.html",
    "title": "\n11  Synthetic Control\n",
    "section": "",
    "text": "11.1 Schätzung von Interventionseffekten mit SCM\nÄhnlich wie bei manchen Matching-Methoden wird bei SCM die Ähnlichkeit der synthetischen Einheit mit der untersuchten Einheit durch eine gewichtete Kombination von Kontrolleinheiten basierend auf ihren Prä-Interventionsmerkmalen erreicht. Seien \\(i = 1, 2, \\ldots, N\\) die Einheiten in der Stichprobe, wobei \\(i = 1\\) die behandelte Einheit und \\(i = 2, \\ldots, N\\) potenziellen Kontrolleinheiten (auch Donor pool genannt) sind. Die Daten liegen für die Perioden \\(t = 1, 2, \\ldots, T\\) vor, mit \\(T_0\\) dem Zeitpunkt direkt vor der Intervention und \\(T_1, \\ldots, T\\) den Perioden nach der Intervention.\nFür SCM bestimmen wir einen Vektor von Gewichten \\(\\mathbf{w}^* := (w_2^*, \\ldots, w_k^*)^T\\), der die Summe der quadrierten Differenzen zwischen den Ausprägungen von \\(k\\) Charakteristika der behandelten Einheit vor der Intervention, \\(X_{1,\\,m}^{\\text{Pre}}\\), \\(m=1,\\dots,k\\), und der gewichteten Summe dieser Charakteristika für die Kontrolleinheiten, \\(X_{i,\\,m}^{\\text{Pre}}\\), minimiert:\n\\[\\begin{align}\n  \\mathbf{w}^* := \\arg\\min_{\\mathbf{w}} \\sum_{m=1}^{k} v_m \\left( X_{1,\\,m}^{\\text{Pre}} - \\sum_{i=2}^{N} w_i X_{i,m}^{\\text{Pre}} \\right)^2,\\label{eq:scopt}\n\\end{align}\\]\nunter der Nebenbedingung, dass \\(\\sum_{i=2}^{N} w_i = 1\\) und \\(w_i \\geq 0\\) für alle \\(i\\). Die \\(v_m\\) sind weitere Gewichte, welche die Relevanz der Variablen für die Vorhersage der Outcome-Variable der interessierenden Einheit, \\(Y_{1,\\,t}\\), beinflussen. Diese Gewichte werden meist in einem weiteren Optimierungsverfahren (bspw. mit Cross-Validation) bestimmt (vgl. A. Abadie, Diamond, und Hainmueller 2014). Als Verlustfunktion hierbei wird meist der mittlere quadratische Fehler bei der Vorhersage von \\(Y_{1,\\,t}\\) (MSPE)1 vor der Behandlung anhand der synthetischen Einheit verwendet,\n\\[\\begin{align}\n  \\sum_{t=1}^{T_0} \\left( Y_{1,\\,t} - \\sum_{i=2}^N w_i(\\mathbf{v}) Y_{i,\\,t} \\right)^2, \\label{eq:scopt2}\n\\end{align}\\] mit \\(\\mathbf{v} := (v_1,\\dots,v_k)'\\).\nDurch die Lösung des Optimierungsproblems \\(\\eqref{eq:scopt}\\) unter Berücksichtigung von \\(\\eqref{eq:scopt2}\\) erhalten wir die geschätzten Gewichte \\(\\widehat{w}_i\\), welche den Einfluss der Kontrolleinheit \\(i=2,\\dots,N\\)-ten bei der Zusammensetzung der Kontrollgruppe festlegen. Anhand der \\(\\widehat{w}_i\\) wird die Outcome-Variable der synthetischen Kontrolleinheit konstruiert, welche als Referenz für die Schätzung des kausalen Effekts der Intervention dient. Die Outcome-Variable der synthetischen Kontrollgruppe für die Nach-Interventionsperiode kann formal ausgedrückt werden als\n\\[\\begin{align}\n  Y_{1,\\,t}^{\\text{Synth}} = \\sum_{i=2}^{N} \\widehat{w}_i Y_{i,\\,t},\\quad t &gt; T_0,\\label{eq:dgkonst}\n\\end{align}\\]\nwobei \\(Y_{1,t}^{\\text{Synth}}\\) der Wert der Outcome-Variable \\(Y\\) für die synthetische Kontrollgruppe zum Zeitpunkt \\(t\\) und \\(Y_{i,t}\\) der entsprechende Wert des Outcomes für die \\(i\\)-te Kontrolleinheit ist. Bei SCM schätzen wir den kausalen Effekt \\(\\tau_t\\) der Intervention zum Zeitpunkt \\(t\\) als die Differenz der Post-Interventionswerte von \\(Y\\) zwischen der behandelten Einheit und dem synthetischen Doppelgänger,\n\\[\n\\widehat{\\tau}_t = Y_{1,\\,t} - Y_{1,\\,t}^{\\text{synth}},\\quad t &gt; T_0.\n\\]\nDer mit SCM geschätzte Effekt ermittelt also für \\(t &gt; T_0\\), wie sich die Intervention auf die behandelte Einheit ausgewirkt hat durch einen Vergleich mit der Situation, die eingetreten wäre, wenn die Einheit nicht behandelt worden wäre, repräsentiert durch die synthetische Kontrollgruppe.\nDer SCM-Schätzer von A. D. Abadie Alberto und Hainmueller (2010) ist im R-Paket Synth (Hainmueller, Diamond, und Abadie 2011) implementiert. Wir illustrieren die Methode nachfolgend mit einer empirischen Anwendung zu den Konsequenzen des Brexit auf die nachfolgende Entwicklung der britischen Volkswirtschaft.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Synthetic Control</span>"
    ]
  },
  {
    "objectID": "SyntheticControl.html#sec-siscm",
    "href": "SyntheticControl.html#sec-siscm",
    "title": "\n11  Synthetic Control\n",
    "section": "",
    "text": "1 Engl. für Mean squared prediction error",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Synthetic Control</span>"
    ]
  },
  {
    "objectID": "SyntheticControl.html#case-study-ökonomische-kosten-des-brexit",
    "href": "SyntheticControl.html#case-study-ökonomische-kosten-des-brexit",
    "title": "\n11  Synthetic Control\n",
    "section": "\n11.2 Case Study: Ökonomische Kosten des Brexit",
    "text": "11.2 Case Study: Ökonomische Kosten des Brexit\nBorn u. a. (2019) untersuchen die ökonomischen Kosten des Brexits mit einem kausalanalytischen Forschungsansatz. Der Kern der empirischen Analyse ist eine Kombination von quasi-experimenteller Identifikation und struktureller Zeitreihenanalyse. Hiermit können nicht nur die aggregierten Kosten des EU-Ausstiegs für Großbrittanien zu quantifiziert, sondern auch die Kanäle indentifiziert werden, durch die die erwartete wirtschaftliche Desintegration die britische Makroökonomie beeinflusst hat. Hierbei identifizieren Born u. a. (2019) einen Anstieg der wirtschaftspolitischen Unsicherheit und eine Abwärtskorrektur der Wachstumserwartungen als Haupttreiber für den Rückgang der Wirtschaftsleistung.\nDer quasi-experimentelle Ansatz betrachtet das Brexit-Referendum als ein natürliches makroökonomisches Experiment und untersucht die Konsequenzn der wirtschaftlichen Desintegration für das Bruttoinlandsprodukt (BIP) im Nachfolgezeitraum mit SCM. Hierzu wird gemäß der in Kapitel 11.1 erläuterten Vorgehensweise ein syntetischer Doppelgänger für die britische Wirtschaft aus einem Donor Pool von 23 Volkswirtschaften konstruiert, und der Effekt des Referendums als Unterschied zwischen der tatsächlichen und synthetischen Trajektorien des BIP für Folgeperioden ermittelt. Die Analyse zeigt, dass das Brexit-Votum bis Ende 2018 zu einem BIP-Rückgang von etwa 1.7% bis 2.5% geführt hat.\nWie reproduzieren nun die wesentlichen Ergebnisse des SCM-Ansatzes der Studie mit R. Hierfür lesen zunächst den Datensatz brexit.csv (hier verfügbar) in R ein. Dieser enthält vierteljährliche Beobachtungen makroökonomischer Variablen für 24 Länder für den Zeitraum 1995-Q1–2021-Q4.\n\nlibrary(readr)\nlibrary(dplyr)\n\n# Datensatz 'brexit.csv' einlesen\nbrexit &lt;- read_csv(\"datasets/brexit.csv\") %&gt;%\n  as.data.frame()\n\nbrexit ist ein Datensatz mit einer Panel-Struktur. Die Zeit- und Entitätsvariablen sind Year/quarter und Country/ID. Beachte, dass die Variable Time zusätzlich das Jahr und das Quartal als numerische Variable angibt.\n\n# Überblick über 'brexit'\nglimpse(brexit)\n\nRows: 2,496\nColumns: 21\n$ Time          &lt;dbl&gt; 1995.00, 1995.00, 1995.00, 1995.00, 1995.00, 1995.00, 19…\n$ Year          &lt;dbl&gt; 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 19…\n$ quarter       &lt;chr&gt; \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q…\n$ Country       &lt;chr&gt; \"Australia\", \"Austria\", \"Belgium\", \"Canada\", \"Finland\", …\n$ real_con_raw  &lt;dbl&gt; 4.660970e+11, 1.214713e+11, 1.608240e+11, 5.558142e+11, …\n$ real_inv_raw  &lt;dbl&gt; 1.683258e+11, 5.537994e+10, 6.118800e+10, 1.894910e+11, …\n$ real_exp_raw  &lt;dbl&gt; 1.246639e+11, 6.634091e+10, 1.501160e+11, 3.353030e+11, …\n$ real_imp_raw  &lt;dbl&gt; 9.781032e+10, 7.439282e+10, 1.468880e+11, 2.572610e+11, …\n$ real_gdp_raw  &lt;dbl&gt; 8.495864e+11, 2.165699e+11, 2.910360e+11, 1.084659e+12, …\n$ real_gdp_2016 &lt;dbl&gt; 0.5080841, 0.6832146, 0.6877292, 0.6057397, 0.6370480, 0…\n$ tot_emp_raw   &lt;dbl&gt; 8077377.2, 3737003.3, 3920400.0, 13274100.0, 2050262.7, …\n$ pop_quarterly &lt;dbl&gt; 13144039.8, 6043266.6, 7666495.5, 21714093.3, 3827395.7,…\n$ lab_prod      &lt;dbl&gt; 0.9988637, 0.9863141, 0.9942753, 0.9997992, 0.9885239, 1…\n$ ConGDP        &lt;dbl&gt; 0.5486164, 0.5608871, 0.5525914, 0.5124322, 0.5244422, 0…\n$ InvGDP        &lt;dbl&gt; 0.1981267, 0.2557140, 0.2102420, 0.1747010, 0.2085606, 0…\n$ ExpGDP        &lt;dbl&gt; 0.14673485, 0.30632565, 0.51579873, 0.30913218, 0.268451…\n$ ImpGDP        &lt;dbl&gt; 0.1151270, 0.3435049, 0.5047073, 0.2371815, 0.2485870, 0…\n$ LPG           &lt;dbl&gt; -0.0078972729, -0.0093478618, 0.0033636783, 0.0054461911…\n$ EmpSha        &lt;dbl&gt; 0.6145277, 0.6183747, 0.5113679, 0.6113127, 0.5356809, 0…\n$ gdp           &lt;dbl&gt; -49.19159, -31.67854, -31.22708, -39.42603, -36.29520, -…\n$ ID            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n\n# 'Time' zeigt Jahr + Quartal\nbrexit %&gt;% \n  filter(Country == \"United Kingdom\") %&gt;% \n  select(Time) %&gt;%\n  slice_head(n = 5)\n\n     Time\n1 1995.00\n2 1995.25\n3 1995.50\n4 1995.75\n5 1996.00\n\n\nFür die Schätzung der Gewichte \\(w_i\\) für die Konstruktion des UK-Doppelgängers werden die in gelisteten Charakteristika der Volkswirtschaften verwendet.\n\n\n\n\n\n\n\n\nVariable\nDefinition\n\n\n\ngdp\nVeränderung des BIP relativ zu 2016\n\n\nConGDP\nAnteil: Konsum/BIP (%)\n\n\nInvGDP\nAnteil: Investitionen/BIP (%)\n\n\nExpGDP\nAnteil: Exporte/BIP (%)\n\n\nImpGDP\nAnteil: Importe/BIP (%)\n\n\nEmpSha\nAnteil: Beschäftigte/Erwerbsbevölkerung (%)\n\n\nLPG\nWachstum der Arbeitsproduktivität (%)\n\n\n\n\n\nTabelle 11.1: brexit – Variablen und Definitionen\n\n\nZur Berechnung von SCM mit dem R-Paket Synth müssen die Daten zunächst mit der Funktion Synth::dataprep() aufbereitet werden, s. ?Synth::dataprep() für weitere Details. Neben dem Datensatz (foo) unter expliziter Nennung der Prädiktoren (predictors) und der Outcome-Variable (dependent) übergeben wir Variablen für die Indentifikation von Einheiten (ID) und Zeitpunkten (Time), sowie Donor Pool (controls.identifier) und behandelter Einheit (treatment.identifier). Weiterhin werden die Vorbehandlungsperiode (time.predictors.prior) sowie der Zeitraum über den die Regressor-Gewichte \\(v_m\\) bestimmt werden sollen (time.optimize.ssr), festgelegt. Für letztere übergeben wir einen numerischen Vektor für sämtliche Zeitpunkte von 1995-Q1 bis zum Brexit-Referendum in 2016-Q2.\nUm einen ersten Überblick über die Entwicklung der BIP im Datensatz zu gewinnen, vergleichen wir die Zeitreihen für Donor-Pool-Länder (grau) und Großbritannien (blau) mit ggplot.\n\nlibrary(cowplot)\n\nbrexit %&gt;%\n  mutate(\n    group = ifelse(\n      Country == \"United Kingdom\", \n      yes = \"UK\", \n      no =\"else\"\n    )\n  ) %&gt;%\n  \n  ggplot(\n    mapping = aes(\n      x = Time, \n      y = gdp, \n      color = group, \n      group = Country, \n      lwd = group\n    )\n  ) +\n  scale_color_manual(\n    values = c(\n      \"UK\" = \"#00BFC4\", \"else\" = alpha(\"gray\", .75)\n    )\n  ) +\n  scale_linewidth_manual(\n    values = c(\"UK\" = 1, \"else\" = .5)\n  ) +\n  geom_line() +\n  # Brexit-Referendum\n  geom_vline(\n    xintercept = 2016.25, \n    lty = \"dotted\"\n  ) +\n  theme_cowplot() +\n  guides(\n    lwd = \"none\", \n    color = guide_legend(position = \"inside\")\n  ) +\n  theme(legend.position.inside = c(.1, .9))\n\n\n\n\n\n\nAbbildung 11.1: BIP relativ zu 2016\n\n\n\n\nAbbildung 11.1 zeigt, dass das BIP von Großbritannien zwar auch nach dem Brexit-Referendum (gepunktete Linie) gewachsen ist, jedoch vergleichsweise schwach. Eine Analyse mit SCM kann statistische Evidenz für den mutmaßlich negativen Effekt des Referendums auf das Wachstum in den Folgeperioden liefern.\nWir laden nun das Paket Synth und bereiten die Daten für die Analyse vor.\n\n# R-Paket 'Synth' laden\nlibrary(Synth)\n\n# Daten für die Optimierung vorbereiten\ndataprep_out &lt;- dataprep(\n  foo = brexit, \n  predictors = c(\n    \"ConGDP\", \"InvGDP\", \n    \"ExpGDP\", \"ImpGDP\", \n    \"LPG\", \"EmpSha\"\n  ), \n  dependent = \"gdp\", \n  unit.variable = \"ID\",\n  time.variable = \"Time\", \n  treatment.identifier = 23, \n  controls.identifier = (brexit$ID %&gt;% unique())[-23], \n  time.predictors.prior = seq(1995, 2016.25, .25),\n  time.optimize.ssr = seq(1995, 2016.25, .25),\n  unit.names.variable = \"Country\"\n)\n\nAnhand der vorbereiteten Daten dataprep_out wird nun die Bestimmung der Gewichte mit Synth::synth() durchgeführt.\n\n# Gewichte per Optimierung bestimmen\nsynth_out &lt;- synth(dataprep_out)\n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 0.6083746 \n\nsolution.v:\n 0.1488472 0.08840361 0.1480946 0.153318 0.1815462 0.2797904 \n\nsolution.w:\n 1.42199e-05 4.00616e-05 8.47284e-05 0.00014488 4.45754e-05 4.84009e-05 0.001608051 4.77577e-05 0.06654494 2.07094e-05 0.1446237 1.188e-05 2.377e-06 0.04837474 1.33542e-05 0.0001405933 4.61625e-05 0.0001592545 1.49993e-05 4.14211e-05 3.78112e-05 0.0002273924 0.737708 \n\n\nSynth::synth() gibt Infos über den Optimierungsprozess und dessen Ergebnisse automatisch in der Konsole aus. Wir können diese mit Synth::synth.tab() leicht tabellarisch zusammenfassen und mit gt::gt() darstellen.\n\n# Zusammenfassung der Ergebnisse\n(\n  tb &lt;- synth.tab(\n    synth.res = synth_out, \n    dataprep.res = dataprep_out\n  )  \n)\n\n$tab.pred\n       Treated Synthetic Sample Mean\nConGDP   0.655     0.635       0.534\nInvGDP   0.168     0.202       0.226\nExpGDP   0.254     0.219       0.454\nImpGDP   0.256     0.232       0.423\nLPG      0.003     0.003       0.003\nEmpSha   0.634     0.625       0.611\n\n$tab.v\n       v.weights\nConGDP 0.149    \nInvGDP 0.088    \nExpGDP 0.148    \nImpGDP 0.153    \nLPG    0.182    \nEmpSha 0.28     \n\n$tab.w\n   w.weights      unit.names unit.numbers\n1      0.000       Australia            1\n2      0.000         Austria            2\n3      0.000         Belgium            3\n4      0.000          Canada            4\n5      0.000         Finland            5\n6      0.000          France            6\n7      0.002         Germany            7\n8      0.000         Hungary            8\n9      0.067         Iceland            9\n10     0.000         Ireland           10\n11     0.145           Italy           11\n12     0.000           Japan           12\n13     0.000           Korea           13\n14     0.048      Luxembourg           14\n15     0.000     Netherlands           15\n16     0.000     New Zealand           16\n17     0.000          Norway           17\n18     0.000        Portugal           18\n19     0.000 Slovak Republic           19\n20     0.000           Spain           20\n21     0.000          Sweden           21\n22     0.000     Switzerland           22\n24     0.738   United States           24\n\n$tab.loss\n       Loss W    Loss V\n[1,] 0.135733 0.6083746\n\n\nFür die tabellarische Darstellung mit gt::gt() berücksichtigen wir lediglich Volkswirtschaften mit Gewicht &gt; .0001.\n\n# Darstellung mit gt()\ntb$tab.w %&gt;% \n  # Berücksichtige nur Länder mit relevanten Gewichten\n  filter(w.weights &gt; .0001) %&gt;% \n  arrange(desc(w.weights)) %&gt;% \n  gt::gt() %&gt;%\n  tabopts\n\n\n\n\n\n\n\n\nw.weights\nunit.names\nunit.numbers\n\n\n\n0.738\nUnited States\n24\n\n\n0.145\nItaly\n11\n\n\n0.067\nIceland\n9\n\n\n0.048\nLuxembourg\n14\n\n\n0.002\nGermany\n7\n\n\n\n\n\n\n\n\nTabelle 11.2: Gewichte für den synthetischen UK-Doppelgänger\n\n\n\nDer synthetische UK-Doppelgänger kann nun gemäß der Vorschrift \\(\\eqref{eq:dgkonst}\\) konstruiert werden. Wir erzeugen hierzu ein tibble-Objekt mit den entsprechenden ID-Variablen.\n\n# Doppelgänger konstruieren\ndoppelganger &lt;- left_join(\n  x = brexit, \n  y = tb$tab.w, \n  by = c(\"Country\" = \"unit.names\")\n) %&gt;% \n  select(Time, Year, Country, gdp, w.weights) %&gt;%\n  group_by(Time, Year) %&gt;%\n  summarise(\n    gdp = sum(gdp * w.weights, na.rm = T)\n  ) %&gt;%\n  mutate(type = \"Doppelgaenger\") %&gt;%\n  ungroup()\n\nglimpse(doppelganger)\n\nRows: 104\nColumns: 4\n$ Time &lt;dbl&gt; 1995.00, 1995.25, 1995.50, 1995.75, 1996.00, 1996.25, 1996.50, 19…\n$ Year &lt;dbl&gt; 1995, 1995, 1995, 1995, 1996, 1996, 1996, 1996, 1997, 1997, 1997,…\n$ gdp  &lt;dbl&gt; -36.87991, -36.70512, -36.32948, -35.72637, -35.34392, -34.57688,…\n$ type &lt;chr&gt; \"Doppelgaenger\", \"Doppelgaenger\", \"Doppelgaenger\", \"Doppelgaenger…\n\n\nFür die nachfolgenden Schritte der Analyse führen wir das beobachtete GDP für Großbritannien mit dem syntethischen GDP des Doppelgängers zusammen.\n\n# tibble mit UK-GDP erstellen\nUK &lt;- brexit %&gt;% \n  filter(Country == \"United Kingdom\") %&gt;% \n  select(Time, Year, gdp) %&gt;%\n  mutate(type = \"UK\")\n\n# UK und Doppelgänger zusammenführen\nthe_gdps &lt;- bind_rows(\n  doppelganger, UK\n)\n\nFür einen Vergleich von UK- und Doppelgänger-BIP folgen wir Born u. a. (2019) und berechnen die Differenz der BIP über den gesamten Zeitraum, die so genannte Doppelgänger-Gap.\n\n# UK-Doppelgänger-Gap berechnen\ngdp_gap &lt;- the_gdps %&gt;% \n  pivot_wider(\n    values_from = gdp, \n    names_from = \"type\"\n  ) %&gt;%\n  mutate(gdp_gap = UK - Doppelgaenger)\n\nAls ein Maß für die Unsicherheit bei der Schätzung des GDPs für den Doppelgänger berechnen Born u. a. (2019) die Standardabweichung der Doppelgänger-Gap für den Zeitraum vor dem Brexit-Referendum.\n\n# Standardabweichung der Gap vor dem Brexit-Vote\nsd_gap &lt;- gdp_gap %&gt;%\n  filter(Time &lt; 2016.25) %&gt;% \n  summarise(\n    sd = sd(gdp_gap)\n  ) %&gt;% \n  pull(sd)\n\nWir nutzen nun ggplot2::ggplot(), um den syntetischen Doppelgänger und das BIP für Großbritannien über den gesamten Zeitraum darzustellen. Für die Darstellung von Unsicherheit bei der Konstruktion des Doppelgängers unterlegen wir die Doppelgänger-Zeitreihe mit einer Schattierung in der Breite der geschätzten Standardabweichung von 0.78 für die Periode vor dem Referendum.\n\n(\n  p_gdp &lt;- ggplot() +\n    # 1-SD-Band um das Doppelgänger-GDP\n    geom_ribbon(\n      data = the_gdps %&gt;% \n        filter(type == \"Doppelgaenger\"), \n      mapping = aes(\n        x = Time, \n        ymin = gdp - sd_gap, \n        ymax = gdp + sd_gap\n      ), \n      fill = alpha(\"red\", alpha = .2), \n      color = \"white\"\n    ) +\n    # UK- und Doppelgänger-GDP\n    geom_line(\n      data = the_gdps, \n      mapping = aes(\n        x = Time, \n        y = gdp, \n        col = type\n      ),\n      lwd = 1\n    ) +\n    # Brexit-Referendum\n    geom_vline(\n      xintercept = 2016.25, \n      lty = \"dotted\"\n    ) +\n    scale_color_discrete(name = \"\") +\n    # Legende hinzufügen\n    cowplot::theme_cowplot() +\n    theme(legend.position = c(.025, .9))  \n)\n\n\n\n\n\n\nAbbildung 11.2: UK-BIP und synthetischer Doppelgänger\n\n\n\n\nAbbildung 11.2 zeigt, dass der synthetische Doppelgänger über weite Teile der Vorperiode eine gute Anpassung an das beobachtete BIP von Großbritannien aufweist, insbesondere für den Zeitraum unmittelbar vor dem Brexit-Referendum. Nach dem Referendum zeigt sich bereits nach wenigen Quartalen eine deutliche Abweichung zwischen der geschätzten und der beobachteten Trajektorie. Eine Beschränkung der in p_gdp verwendeten Datenpunkte auf einen Bereich nahe des Referendums bestärkt diese Schlussfolgerung.\n\n# Close-up im Bereich des Referendums\np_gdp +\n  scale_x_continuous(\n    limits = c(2015, 2021), \n    expand = c(0, .1)\n    ) +\n  scale_y_continuous(limits = c(-4, 12))\n\n\n\n\n\n\nAbbildung 11.3: UK-BIP und synthetischer Doppelgänger – Close-Up\n\n\n\n\nIn Abbildung 11.2 ist eine ab Mitte 2017 außerhalb des Standardabweichungsbereichs verlaufende Divergenz der Zeitreihen zu erkennen. Diese stellen wir nachfolgend anhand der Doppelgänger-Gap mit ggplot2::ggplot() dar.\n\n# BIP-Doppelgänger-Gap\nggplot(data = gdp_gap) +\n  geom_hline(yintercept = 0) +\n  geom_line(\n    mapping = aes(x = Time, y = gdp_gap),\n    lwd = 1\n  ) + \n  geom_ribbon(\n    mapping = aes(\n      x = Time, \n      ymin = gdp_gap - sd_gap, \n      ymax = gdp_gap + sd_gap\n    ), \n    fill = alpha(\"darkgray\", alpha = .2), \n    color = \"white\"\n  ) +\n  # Referendum\n  geom_vline(\n    xintercept = 2016.25,\n    lty = \"dotted\"\n  ) +\n  scale_x_continuous(\n    expand = c(0, .1), \n    limits = c(2015, 2021)\n  ) +\n  scale_y_continuous(limits = c(-6, 1.5)) +\n  cowplot::theme_cowplot()\n\n\n\n\n\n\nAbbildung 11.4: UK-BIP und synthetischer Doppelgänger – Doppelgänger-Gap\n\n\n\n\nDie in Abbildung 11.4 gezeigte Doppelgänger-Gap stimmt gut mit dem von Born u. a. (2019) geschätzten verlorenen Wachstums des BIP relativ zu 2016 um bis zu 2.5% bis Ende des Jahres 2018 überein.\nAls weiteres Maß für den Effekt des Referendums im Folgezeitraum können wir die mittlere Doppelgänger-Gap für sämtliche Beobachtungsperioden nach dem Brexit-Referendum schnell bestimmen.\n\n# Mittlerer Unterschied nach dem Brexit-Referendum\ngdp_gap %&gt;% \n  filter(Time &gt; 2016.25) %&gt;% \n  pull(gdp_gap) %&gt;% \n  mean()\n\n[1] -2.343273\n\n\n\n11.2.1 Placebo-Tests: Grafische Inferenz\nAuch für SCM sind Placebo-Tests ein hilfreiches Instrument zur Überprüfung der Gültigkeit von Studienergebnissen. Eine gründliche Placebo-Analyse kann festzustellen, ob der beobachtete Effekt tatsächlich auf die Intervention zurückzuführen ist und nicht auf unberücksichtigte (möglicherweise unbeobachtbare) Faktoren.\nEin Ansatz ist hierfür ist es, den synthetische-Doppelgänger für fiktive Interventionszeitpunkte vor dem tatsächlichen Behandlungszeitpunkt zu konstruieren, und die entsprechenden Trajektorien mit dem ursprünglichen Doppelgänger zu vergleichen. So kann die Validität der ursprünglichen Doppelgänger-Trajektorie im Hinblick auf mögliche anderweitige Ereignisse vor der Intervention geprüft werden: Doppelgänger-Trajektorien für fiktive, frühere Interventionen sollten sich nicht systematisch von der andhand von Daten bis zur tatsächlichen Intervention berechneten Trajektorie unterscheiden.\nWir definieren hierzu eine Funktion placebo(), die einen syntethischen Doppelgänger des BIP Großbritanniens mit Gewichten auf Basis eines vorgegebenen Interventionszeitpunktes (treat) zurückgibt. Abgesehen vom früheren Interventionszeitpunkt (und der damit einhergehenden verkleinerten Stichprobe) erfolgt die Berechnung der Gewichte mit derselben Spezifikation wie zuvor.\n\n# Funktion für Placebo-Doppelgänger:\n# Fiktive frühere Intervention\nplacebo &lt;- function(treat) {\n  \n  # Datenvorbereitung für fiktives Datum 'treat'\n  dataprep_out &lt;- dataprep(\n    foo = brexit, \n    predictors = c(\n      \"ConGDP\", \"InvGDP\",\n      \"ExpGDP\", \"ImpGDP\",\n      \"LPG\", \"EmpSha\"\n    ), \n    dependent = \"gdp\", \n    unit.variable = \"ID\",\n    time.variable = \"Time\", \n    treatment.identifier = 23, \n    controls.identifier = (brexit$ID %&gt;% unique())[-23], \n    time.predictors.prior = seq(1995, treat, .25),\n    time.optimize.ssr = seq(1995, treat, .25),\n    unit.names.variable = \"Country\"\n    )\n  \n  # Doppelgänger bestimmen\n  synth_out &lt;- quietly(synth)(dataprep_out)$result\n  \n  # Ergebnisse auslesen\n  tb &lt;- synth.tab(\n    synth.res = synth_out, \n    dataprep.res = dataprep_out\n    )\n  \n  return(\n    \n    # Doppelgänger konstruieren \n    left_join(\n      x = brexit, \n      y = tb$tab.w, \n      by = c(\"Country\" = \"unit.names\")\n    ) %&gt;% \n      select(Time, Country, gdp, w.weights) %&gt;%\n      group_by(Time) %&gt;%\n      summarise(\n        gdp = sum(gdp * w.weights, na.rm = T)\n      ) %&gt;%\n      mutate(type = paste0(\"Placebo\", treat))  \n    )\n  \n}\n\nWie in Born u. a. (2019) berechnen wir nun 12 Placebo-Doppelgänger des BIP von Großbritannien für fiktive Zeitpunkte eines Referendums über sämtliche Quartale im Zeitraum 2010-Q1 bis 2016-Q1. Dies ist komfortabel durch Iteration von placebo() über diese Zeitpunkte mit purrr::map_dfr() umsetzbar.\n\n# Iteration über fiktive frühere Referenden\nplacebos_tbl &lt;- map_dfr(\n  .x = seq(2010, 2016, .25), \n  .f =  \\(x) placebo(x) \n)\n\nplacebos_tbl ist ein tibble-Objekt im tidy-Format. Wir können die Placebo-Doppelgänger sowie den ursprünglich berechneten Doppelgänger und das tatsächliche BIP also ähnlich wie in Abbildung 11.2 mit ggplot2::ggplot() darstellen.\n\n# Vergleich mit Placebo-Doppelgänger\n(\n  p_UKDG &lt;- ggplot(\n    data = placebos_tbl,\n    mapping = aes(\n      x = Time, \n      y = gdp, \n      group = type\n    )\n  ) +\n    # Placebos (mit jitter)\n    geom_line(\n      lwd = .25, \n      col = \"gray80\",\n      position = position_jitter(height = .25)\n    ) +\n    # Ursprünglicher Doppelgänger\n    geom_line(\n      data = the_gdps %&gt;% \n        filter(type == \"Doppelgaenger\"), \n      mapping = aes(col = type), \n      lwd = 1\n    ) +\n    # Beobachtetes BIP\n    geom_line(\n      data = the_gdps %&gt;% \n        filter(type == \"UK\"), \n      mapping = aes(col = type), \n      lwd = 1\n    ) +\n    # Intikator für Referendum\n    geom_vline(xintercept = 2016.25, lty = \"dotted\") +\n    # Formatierung\n    cowplot::theme_cowplot() +\n    theme(legend.position = c(.05, .9))\n)\n\n\n\n\n\n\nAbbildung 11.5: Placebo-Doppelgänger\n\n\n\n\n\n# Close-up bei Referendum\np_UKDG +\n      scale_x_continuous(\n      limits = c(2015, 2021), expand = c(0, .05)\n    ) +\n      scale_y_continuous(\n      limits = c(-3, 13),  expand = c(0, 0)\n    )\n\n\n\n\n\n\nAbbildung 11.6: Placebo-Doppelgänger – Close-Up\n\n\n\n\nBeachte, dass position = position_jitter(height = .25) eine zufällige, kleine Verschiebung (jitter) der Trajektorien der Placebo-Doppelgänger für eine bessere Unterscheidbarkeit bewirkt. Abbildung 11.5 und Abbildung 11.6 zeigen, dass sich die Placebo-Pfade für fiktive frühere Referenden (grau) nicht systematisch vom ursprünglich berechneten synthetischen Doppelgänger (rot) unterscheiden. Insbesondere finden wir keinen Rückgang der synthetischen BIP relativ zum beobachteten BIP für Großbritannien vor dem Referendum. Deutliche Abweichungen vom tatsächlichen BIP ergeben sich erst jenseits der tatsächlichen Referendums. Diese Placebo-Analyse bekräftigt also die Validität der Konstruktion des “Benchmark-Doppelgängers” für die Periode bis 2016-Q2 und die Schätzung des kausalen Effekts des Referendums anhand der entsprechenden Doppelgänger-Gap.\nEin weiterer Placebo-Test in Born u. a. (2019) ist ein Vergleich der Doppelgänger-Gap Großbritanniens mit Doppelgänger-Gaps für fiktive Referenden in 2016-Q2 in Ländern mit wesentlichem Einfluss bei der Konstruktion des synthetischen Doppelgängers für Großbritannien: Die Schätzung des kausalen Effekts des Referendums auf das BIP in Großbritannien ist glaubwürdig, wenn lediglich die Doppelgänger-Gap für Großbritannien durch das Referendum beeinflusst wird, nicht aber die Doppelgänger-Gaps für Länder in der Kontrollgruppe.\nFür diese grafische Placebo-Analyse modifizieren wir die Funktion placebo() entsprechend. placebo_gap() berechnet die Doppelgänger-Gap für das mit treat identifizierte Land. Das if-Statement zu Beginn stellt sicher, dass Großbritannien nicht als Kontroll-Einheit für die Placebo-Gaps verwendet wird.\n\n# Funktion für Placebo-Gaps\nplacebo_gap &lt;- function(treat) {\n  \n  # Kontrollgruppe definieren\n  if(treat != 23) {\n    controls &lt;- (1:24)[-c(23, treat)]\n  } else {\n    controls &lt;- (1:24)[-23]\n  }\n  \n  # Daten vorbereiten\n  dataprep_out &lt;- dataprep(\n    foo = brexit, \n    predictors = c(\n      \"ConGDP\", \"InvGDP\",\n      \"ExpGDP\", \"ImpGDP\",\n      \"LPG\", \"EmpSha\"\n    ), \n    dependent = \"gdp\", \n    unit.variable = \"ID\",\n    time.variable = \"Time\", \n    treatment.identifier = treat, \n    controls.identifier = controls, \n    time.predictors.prior = seq(1995, 2016.25, .25),\n    time.optimize.ssr = seq(1995, 2016.25, .25),\n    unit.names.variable = \"Country\"\n  )\n  \n  # Gewichte bestimmen\n  synth_out &lt;- quietly(synth)(dataprep_out)$result\n  \n  # Ergebnisse zusammenfassen\n  tb &lt;- synth.tab(\n    synth.res = synth_out, \n    dataprep.res = dataprep_out\n  )\n  \n  # Doppelgänger bestimmen\n  doppel &lt;- left_join(\n    x = brexit, \n    y = tb$tab.w, \n    by = c(\"Country\" = \"unit.names\")\n  ) %&gt;% \n    select(Time, gdp, Country, w.weights) %&gt;%\n    group_by(Time) %&gt;%\n    summarise(\n      gdp_synth = sum(gdp * w.weights, na.rm = T), \n    )\n  \n  # Beobachtetes BIP auslesen\n  gdp &lt;- brexit %&gt;% filter(ID == treat) %&gt;% pull(gdp)\n  \n  return(\n    \n    # Doppelgänger-Gap berechnen\n    doppel %&gt;% \n      mutate(\n        ID = treat,\n        gdp = gdp,\n        gdp_gap = gdp - gdp_synth\n      )\n    \n  )\n  \n}\n\nFür die Berechnung der Placebo-Gaps iterieren wir über die Indizes der in Tabelle 11.2 gelisteten Volkswirtschaften der Kontrollgruppe für Großbritannien.\n\n# Indizes für \"Donor Countries\" und UK\ndonors_and_UK &lt;- brexit %&gt;% \n  select(ID, Country) %&gt;% \n  distinct() %&gt;%\n  filter(\n    Country %in% \n      c(\n        \"United States\", \"Italy\", \"Iceland\", \n        \"Luxembourg\", \"Germany\", \"United Kingdom\"\n      )\n  ) %&gt;%\n  pull(ID)\n\n\n# Placebo-Doppelgänger-Gaps berechnen\nplacebo_gaps_tbl &lt;- map_dfr(\n  .x = donors_and_UK, \n  .f =  \\(x) placebo_gap(x) \n)\n\nFür die grafische Darstellung ergänzen wir die Variable Country zur Unterscheidung der Doppelgänger-Gaps für Großbritannien und die Kontroll-Länder.\n\n# ID-Variable für UK und Kontroll-Länder\nplacebo_gaps_tbl &lt;- placebo_gaps_tbl %&gt;%\n  mutate(\n    Country = ifelse(ID == 23, \"UK\", \"else\")\n  )\n\nUm die Vergleichbarkeit der Doppelgänger-Gaps zu gewährleisten, standardisieren Born u. a. (2019) die Schätzungen der Gaps anhand der jeweiligen Mittelwerte für das Jahr 2015 und der Standardabweichungen im Zeitraum vor dem Brexit-Referendum. Wir berechnen diese Statistiken zunächst.\n\n# Mittelwerte für 2015\nmeans &lt;- placebo_gaps_tbl %&gt;% \n  group_by(ID) %&gt;% \n  filter(between(Time, 2015, 2015.75)) %&gt;% \n  summarise(\n    mean2015 = mean(gdp_gap)\n  )\n\n# Standardabweichungen vor Referendum\nsds &lt;- placebo_gaps_tbl %&gt;% \n  group_by(ID) %&gt;% \n  filter(Time &lt; 2016.25) %&gt;% \n  summarise(\n    thesd = sd(gdp_gap)\n  )\n\nMit dplyr::left_join() führen wir diese Statistiken mit placebo_gaps_tbl zusammen und berechnen die standardisierten Doppelgänger-Gaps.\n\n# Join + Standardisierung\nplacebo_gaps_std &lt;- \n  left_join(placebo_gaps_tbl, means) %&gt;% \n  left_join(sds) %&gt;%\n  mutate(gdp_gap_std = (gdp_gap - mean2015)/thesd)\n\nAnalog zum Code für Abbildung 11.4 plotten wir die Placebo-Gap-Zeitreihen mit ggplot2::ggplot().\n\n# Placebo-Gaps mit UK-Gap vergleichen\nggplot(\n  data = placebo_gaps_std,\n  mapping = aes(\n    x = Time, \n    y = gdp_gap_std,\n    group = ID,\n    lwd = Country,\n    color = Country\n  )\n) +\n  # Hilfslinie bei Differenz = 0\n  geom_hline(yintercept = 0) +\n  # Gaps\n  geom_line() +\n  # Referendum\n  geom_vline(xintercept = 2016.25, lty = \"dotted\") +\n  # Formatierung\n  scale_color_manual(\n    values = c(\"UK\" = \"steelblue\", \"else\" = alpha(\"darkgray\", .5))\n  ) +\n  scale_linewidth_manual(\n    values = c(\"UK\" = 1, \"else\" = .5)\n  ) +\n  scale_x_continuous(\n    limits = c(2015, 2021), expand = c(0, .05)\n  ) +\n  theme_cowplot() +\n  theme(legend.position = c(.05, .9))\n\n\n\n\n\n\nAbbildung 11.7: Placebo- und UK-Doppelgänger-Gaps\n\n\n\n\nAbbildung 11.7 zeigt die standardisierten Placebo-Doppelgänger-Gaps für ein fiktives Referendum zum Zeitpunkt 2016-Q2 in den 5 Kontroll-Volkswirtschaften, die für Konstruktion des BIP-Doppelgängers von Großbrittannien relevant sind (grau). Der Vergleich mit der standardisierten Doppelgänger-Gap für Großbritannien (blau). Der Verlauf der Placebo-Gaps zeigt an, dass keine Abweichungen mit negativem Trend von der Referenzlinie bei 0 (kein Unterschied zwischen beobachtetem und syntetischem BIP) nach dem Referendum vorliegen. Damit liefert die Grafik keine Hinweise auf einen Effekt fiktiver Interventionen in den Kontroll-Ländern. Für Großbritannien jedoch ist, ähnlich wie in Abbildung 11.4, ein negativer Trend nach dem Referendum deutlich erkennbar.\n\n11.2.2 Statistische Inferenz\nDie bisherigen Placebo-Tests liefern lediglich grafische Evidenz für die Signifikanz des negativen Effekts des Brexit-Referendums auf die Britische Volkswirtschaft. Methoden für statistische Inferenz für SCM sind Gegenstand aktueller Forschung. Born u. a. (2019) verwenden den End-Of-Sample Instability Test (\\(S\\)) von Andrews (2003). Dieses Verfahren kann für einen Test auf einen Strukturbruch gegen Ende einer Zeitreihe verwendet werden. In der vorliegende Studie wird der Test angewendet, um zu überprüfen, ob die Verteilung der Doppelgänger-Gap Großbritanniens für die letzen \\(m\\) Perioden jenseits des Referendums signifikant verschieden ist von Verteilung vorheriger Perioden.\nWir zeigen nachfolgend, wie diese Analyse in R mit der Funktion CPAT::Andrews.test() aus dem Paket CPAT durchgeführt werden kann. Wir testen zunächst auf eine signifikante Diskrepanz der Doppelgänger-Gap in Form eines Sturkturbruchs ab 2017 und fassen die Ergebnisse tabellarisch mit broom::tidy() und gt::gt() zusammen.\n\nlibrary(CPAT)\n\n# Andrews' (2003) Test für 2017 durchführen\nAndrews.test(\n  x = gdp_gap$gdp_gap, \n  M = which(gdp_gap$Time == 2017)\n) %&gt;% \n  broom::tidy() %&gt;% \n  gt::gt() %&gt;%\n  tabopts\n\n\n\n\n\n\n\n\nstatistic\np.value\nmethod\n\n\n14.196\n0.693\nAndrews' Test for Structural Change\n\n\n\n\n\n\n\nTabelle 11.3: Andrews’ (1993) End-of-Sample Instability Test\n\n\n\nGem. des großen \\(p\\)-Werts kann die Nullhypothese (keine strukturelle Veränderung ab 2017) nicht abgelehnt werden. Wir führen den Test nun für sämtliche Zeitpunkte ab 2017 durch und plotten die \\(p\\)-Werte nebst gepunkteten roten Hilfslinien für die gängigen Signifikanzniveaus (10%, 5%, 1%).\n\n# Andrews' (1993) test für \n# Post-Referendumsperioden\npvals_andrews &lt;- map(seq(2017, 2020.5, .25), \\(time) {\n  tibble(\n    Time = time,\n    gap = gdp_gap %&gt;% filter(Time == time) %&gt;% pull(gdp_gap),\n    pvalue = CPAT::Andrews.test(\n      x = gdp_gap$gdp_gap, \n      M = which(gdp_gap$Time == time)\n    )$p.value\n  )\n}) %&gt;% \n  bind_rows()\n\n\n# p-Werte für Post-Interventionsperioden\npvals_andrews %&gt;%\n  ggplot(mapping = aes(x = Time, y = pvalue)) + \n  geom_hline(\n    yintercept = c(.1,.05, .01), \n    lty = \"dotted\", \n    col = \"red\"\n  ) +\n  geom_line() +\n  scale_x_continuous(expand = c(0, 0)) +\n  cowplot::theme_cowplot()\n\n\n\n\n\n\nAbbildung 11.8: P-Werte für Andrews’ (2003) Test\n\n\n\n\nDer Verlauf der \\(p\\)-Werte zeigt deutlich, dass es für Zeitpunkte jenseits von 2018-Q3 Evidenz für eine strukturelle Veränderung der Doppelgänger-Gap für Großbrittannien gibt. Diese Ergebnisse untermauern die Signifikanz der in Born u. a. (2019) mit SCM gefundenen negativen Effekte des Brexit-Votums auf die Britische Volkswirtschaft weiter.\n\n\n\n\n\n\nAbadie, Alberto, Alexis Diamond, und Jens Hainmueller. 2014. „Comparative Politics and the Synthetic Control Method: COMPARATIVE POLITICS AND THE SYNTHETIC CONTROL METHOD“. American Journal of Political Science 59 (2): 495–510. https://doi.org/10.1111/ajps.12116.\n\n\nAbadie, Alexis Diamond, Alberto, und Jens Hainmueller. 2010. „Synthetic Control Methods for Comparative Case Studies: Estimating the Effect of California’s Tobacco Control Program.“ Journal of the American Statistical Association 105 (490): 493–505. https://doi.org/10.1198/jasa.2009.ap08746.\n\n\nAndrews, D. W. K. 2003. „End-of-Sample Instability Tests“. Econometrica 71 (6): 1661–94. https://doi.org/10.1111/1468-0262.00466.\n\n\nBorn, Benjamin, Gernot J Müller, Moritz Schularick, und Petr Sedláček. 2019. „The Costs of Economic Nationalism: Evidence from the Brexit Experiment*“. The Economic Journal 129 (623): 2722–44. https://doi.org/10.1093/ej/uez020.\n\n\nHainmueller, Jens, Alexis Diamond, und Alberto Abadie. 2011. „Synth: An R Package for Synthetic Control Methods in Comparative Case Studies“. Journal of Statistical Software 42 (13): 1–17. https://www.jstatsoft.org/v42/i13/.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Synthetic Control</span>"
    ]
  },
  {
    "objectID": "Literatur.html",
    "href": "Literatur.html",
    "title": "Literatur",
    "section": "",
    "text": "Abadie, Alberto, Alexis Diamond, and Jens Hainmueller. 2014.\n“Comparative Politics and the Synthetic Control Method:\nCOMPARATIVE POLITICS AND THE SYNTHETIC CONTROL METHOD.”\nAmerican Journal of Political Science 59 (2): 495–510. https://doi.org/10.1111/ajps.12116.\n\n\nAbadie, Alberto, and Guido W. Imbens. 2008. “On the Failure of the\nBootstrap for Matching Estimators.” Econometrica. Journal of\nthe Econometric Society 76 (6): 1537–57. https://doi.org/10.3982/ECTA6474.\n\n\nAbadie, Alberto, and Jann Spiess. 2022. “Robust Post-Matching\nInference.” Journal of the American Statistical\nAssociation 117 (538): 983–95. https://doi.org/10.1080/01621459.2020.1840383.\n\n\nAbadie, Alexis Diamond, Alberto, and Jens Hainmueller. 2010.\n“Synthetic Control Methods for Comparative Case Studies:\nEstimating the Effect of California’s Tobacco Control Program.”\nJournal of the American Statistical Association 105 (490):\n493–505. https://doi.org/10.1198/jasa.2009.ap08746.\n\n\nAcemoglu, Daron, Giuseppe De Feo, and Giacomo Davide De Luca. 2020.\n“Weak States: Causes and Consequences of the Sicilian\nMafia.” The Review of Economic Studies. https://doi.org/10.1093/restud/rdz009.\n\n\nAcemoglu, Daron, Simon Johnson, James A. Robinson, and Pierre Yared.\n2008a. “Income and Democracy.” American Economic\nReview 98 (3): 808–42. https://doi.org/10.1257/aer.98.3.808.\n\n\n———. 2008b. “Replication Data for: Income and Democracy.”\nICPSR - Interuniversity Consortium for Political; Social Research. https://doi.org/10.3886/E113251V1.\n\n\nAdireksombat, Kampon. 2010. “The Effects of the 1993 Earned Income\nTax Credit Expansion on the Labor Supply of Unmarried Women.”\nPublic Finance Review 38 (1): 11–40. https://doi.org/https://doi.org/10.1177/1091142109358626.\n\n\nAnderson, T. W., and Cheng Hsiao. 1981. “Estimation of Dynamic\nModels with Error Components.” Journal of the American\nStatistical Association 76 (375): 598–606. https://doi.org/10.2307/2287517.\n\n\nAndrews, D. W. K. 2003. “End-of-Sample Instability Tests.”\nEconometrica 71 (6): 1661–94. https://doi.org/10.1111/1468-0262.00466.\n\n\nArellano, Manuel, and Stephen Bond. 1991. “Some Tests of\nSpecification for Panel Data: Monte Carlo Evidence and an Application to\nEmployment Equations.” The Review of Economic Studies 58\n(2): 277. https://doi.org/10.2307/2297968.\n\n\nAustin, P. 2011. “An Introduction to Propensity Score Methods for\nReducing the Effects of Confounding in Observational Studies.”\nMultivariate Behavioral Research 46 (3): 399–424. https://doi.org/10.1080/00273171.2011.568786.\n\n\nAustin, Peter C., and Dylan S. Small. 2014. “The Use of\nBootstrapping When Using Propensity-Score Matching Without Replacement:\nA Simulation Study.” Statistics in Medicine 33 (24):\n4306–19. https://doi.org/10.1002/sim.6276.\n\n\nAustin, Peter C., and Elizabeth A. Stuart. 2017. “Estimating the\nEffect of Treatment on Binary Outcomes Using Full Matching on the\nPropensity Score.” Statistical Methods in Medical\nResearch 26 (6): 2505–25. https://doi.org/10.1177/0962280215601134.\n\n\nBarro, Robert J., and Jong Wha Lee. 2013. “A New Data Set of\nEducational Attainment in the World, 1950–2010.” Journal of\nDevelopment Economics 104: 184–98. https://doi.org/https://doi.org/10.1016/j.jdeveco.2012.10.001.\n\n\nBasten, Christoph, and Frank Betz. 2013. “Beyond Work Ethic:\nReligion, Individual, and Political Preferences.” American\nEconomic Journal: Economic Policy 5 (3): 67–91.\n\n\nBelloni, Alexandre, Daniel Chen, Victor Chernozhukov, and Christian\nHansen. 2012. “Sparse Models and Methods for Optimal Instruments\nwith an Application to Eminent Domain.” Econometrica 80\n(6): 2369–429.\n\n\nBelloni, Alexandre, and Victor Chernozhukov. 2013. “Least Squares\nAfter Model Selection in High-Dimensional Sparse Models.”\nBernoulli, 521–47.\n\n\nBelloni, Alexandre, Victor Chernozhukov, and Christian Hansen. 2014.\n“High-Dimensional Methods and Inference on Structural and\nTreatment Effects.” Journal of Economic Perspectives 28\n(2): 29–50.\n\n\nBodory, Hugo, Lorenzo Camponovo, Martin Huber, and Michael Lechner.\n2020. “The Finite Sample Performance of Inference Methods for\nPropensity Score Matching and Weighting Estimators.” Journal\nof Business & Economic Statistics. https://doi.org/10.2139/ssrn.2731969.\n\n\nBorn, Benjamin, Gernot J Müller, Moritz Schularick, and Petr Sedláček.\n2019. “The Costs of Economic Nationalism: Evidence from the Brexit\nExperiment*.” The Economic Journal 129 (623): 2722–44.\nhttps://doi.org/10.1093/ej/uez020.\n\n\nCallaway, Brantly, and Pedro H. C. Sant’Anna. 2021.\n“Difference-in-Differences with Multiple Time Periods.”\nJournal of Econometrics 225 (2): 200–230. https://doi.org/10.1016/j.jeconom.2020.12.001.\n\n\nCattaneo, Matias D, Michael Jansson, and Xinwei Ma. 2020. “Simple\nLocal Polynomial Density Estimators.” Journal of the American\nStatistical Association 115 (531): 1449–55.\n\n\nCortez, Paulo, and Alice Maria Gonçalves Silva. 2008. “Using Data\nMining to Predict Secondary School Student Performance.”\n\n\nDahl, Robert Alan. 1971. Polyarchy: Participation and Opposition:\nParticipation and Opposition. New Haven: Yale Univ. Press.\n\n\nDi Tella, Rafael, and Ernesto Schargrodsky. 2004. “Do Police\nReduce Crime? Estimates Using the Allocation of Police Forces After a\nTerrorist Attack.” American Economic Review 94 (1):\n115–33. https://doi.org/10.1257/000282804322970733.\n\n\nEfron, Bradley, Trevor Hastie, Iain Johnstone, and Robert Tibshirani.\n2004. “Least Angle Regression.”\n\n\nEissa, N., and J. B. Liebman. 1996. “Labor Supply Response to the\nEarned Income Tax Credit.” The Quarterly Journal of\nEconomics 111 (2): 605–37. https://doi.org/10.2307/2946689.\n\n\nFearon, James D., and David D. Laitin. 2003. “Ethnicity,\nInsurgency, and Civil War.” American Political Science\nReview 97 (01): 75–90. https://doi.org/10.1017/s0003055403000534.\n\n\nGelman, Andrew, and Guido Imbens. 2019. “Why High-Order\nPolynomials Should Not Be Used in Regression Discontinuity\nDesigns.” Journal of Business & Economic Statistics\n37 (3): 447–56.\n\n\nGoodman-Bacon, Andrew. 2021. “Difference-in-Differences with\nVariation in Treatment Timing.” Journal of Econometrics\n225 (2): 254–77. https://doi.org/10.1016/j.jeconom.2021.03.014.\n\n\nHahn, P Richard, Carlos M Carvalho, David Puelz, and Jingyu He. 2018.\n“Regularization and Confounding in Linear Regression for Treatment\nEffect Estimation.”\n\n\nHainmueller, Jens. 2012. “Entropy Balancing for Causal Effects: A\nMultivariate Reweighting Method to Produce Balanced Samples in\nObservational Studies.” Political Analysis 20 (1):\n25–46. https://doi.org/10.1093/pan/mpr025.\n\n\nHainmueller, Jens, Alexis Diamond, and Alberto Abadie. 2011.\n“Synth: An r Package for Synthetic Control Methods in Comparative\nCase Studies.” Journal of Statistical Software 42 (13):\n1–17. https://www.jstatsoft.org/v42/i13/.\n\n\nHájek, J. 1971. “Comment on ‘an Essay on the Logical\nFoundations of Survey Sampling’ by Basu, d.”\nFoundations of Statistical Inference 236.\n\n\nHill, Jennifer, and Jerome P. Reiter. 2006. “Interval Estimation\nfor Treatment Effects Using Propensity Score Matching. Statistics in\nMedicine.” Statistics in Medicine 25 (13): 2230–56. https://doi.org/10.1002/sim.2277.\n\n\nHirano, Keisuke, Guido Imbens, and Geert Ridder. 2003. “Efficient\nEstimation of Average Treatment Effects Using the Estimated Propensity\nScore.” Econometrica 71 (4): 1161–89. https://doi.org/10.1111/1468-0262.00442.\n\n\nHoerl, Arthur E, and Robert W Kennard. 1970. “Ridge regression: Biased estimation for nonorthogonal\nproblems.” Technometrics 12 (1): 55–67.\n\n\nHuntington, Samuel P. 1991. The Third Wave: Democratization in the\nLate Twentieth Century: Democratization in the Late Twentieth\nCentury. Norman, OK: Univ. of Oklahoma Press.\n\n\nHuntington-Klein, Nick. 2021. The Effect: An Introduction to\nResearch Design and Causality. Chapman; Hall/CRC. https://doi.org/10.1201/9781003226055.\n\n\nImbens. 2016. “Matching on the Estimated Propensity Score.”\nEconometrica 84 (2): 781–807. https://doi.org/10.3982/ecta11293.\n\n\nImbens, G. W., and Thomas Lemieux. 2008. “Regression Discontinuity\nDesigns: A Guide to Practice.” Journal of Econometrics\n142 (2): 615–35.\n\n\nImbens, Guido, and Karthik Kalyanaraman. 2012. “Optimal Bandwidth\nChoice for the Regression Discontinuity Estimator.” The\nReview of Economic Studies 79 (3): 933–59.\n\n\nLee, David S. 2008. “Randomized Experiments from Non-Random\nSelection in US House Elections.” Journal of\nEconometrics 142 (2): 675–97.\n\n\nLove, Thomas. 2004. “Graphical Display of Covariate\nBalance.” Presentation.\n\n\nMcCrary, Justin. 2008. “Manipulation of the Running Variable in\nthe Regression Discontinuity Design: A Density Test.” Journal\nof Econometrics 142 (2): 698–714.\n\n\nMiguel, Edward, Shanker Satyanath, and Ernest Sergenti. 2004.\n“Economic Shocks and Civil Conflict: An Instrumental Variables\nApproach.” Journal of Political Economy 112 (4): 725–53.\nhttps://doi.org/10.1086/421174.\n\n\nNickell, Stephen. 1981. “Biases in Dynamic Models with Fixed\nEffects.” Econometrica 49 (6): 1417. https://doi.org/10.2307/1911408.\n\n\nRosenbaum, Paul R., and Donald R. Rubin. 1983. “The Central Role\nof the Propensity Score in Observational Studies for Causal\nEffects.” Biometrika 70 (1): 170–84. https://doi.org/10.1017/cbo9780511810725.016.\n\n\nRueschemeyer, Dietrich, Evelyne H. Stephens, and John D. Stephens. 1992.\nCapitalist Development and Democracy. Cambridge: Polity Pr.\n\n\nTibshirani, Robert. 1996. “Regression Shrinkage and Selection via\nthe Lasso.” Journal of the Royal Statistical Society Series\nB: Statistical Methodology 58 (1): 267–88.\n\n\nWeber, Max. 2004. Die Protestantische Ethik Und Der Geist Des\nKapitalismus. Vol. 1614. CH Beck.\n\n\nWooldridge, Jeffrey. 2010. Econometric Analysis of Cross Section and\nPanel Data. Second edition. Cambridge, Massachusetts: MIT.",
    "crumbs": [
      "Literatur"
    ]
  }
]