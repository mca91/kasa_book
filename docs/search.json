[
  {
    "objectID": "FixedEffects.html",
    "href": "FixedEffects.html",
    "title": "\n5  Panel-Daten\n",
    "section": "",
    "text": "5.1 Backdoors durch unbeobachtbare Heterogenitäten\nBetrachte das Panel-Regression-Modell\n\\[\\begin{align}\n  Y_{it} = \\beta_0 + \\beta_1 B_{it} + \\beta_2 X_i + \\beta_3 U_i \\epsilon_{it},\\label{eq:unobshetmodel}\n\\end{align}\\]\nwobei \\(U_i\\) unbeobachtete und \\(X_i\\) beobachtete, zeitlich-invariante Heterogenitäten zwischen den Beobachtungseinheiten \\(i=1,\\dots,n\\) sind. Wie üblich ist \\(B_i\\) die Behandlungsvariable und \\(\\beta_1\\) der interessierende Effekt einer Veränderung von \\(B_i\\) auf \\(Y_i\\).\nAngenommen wir beobachten \\(Y_{it}\\) und \\(B_{it}\\) für \\(T=1\\), also für eine Periode. Bei Korrelation zwischen den (aufgrund der \\(U_i\\)) unbeobachtbaren zeit-invarianten Effekten \\(\\delta_i\\) und der Behandlungsvariable \\(B\\) kann der kausale Effekt \\(\\beta_1\\) nicht identifiziert werden. Diese Situation ist in Abbildung 5.1 dargestellt.\nFE_dag_single_period\nU\nUX\nXU-&gt;X\nB\nBU-&gt;B\nY\nYU-&gt;Y\nX-&gt;B\nX-&gt;Y\nB-&gt;Y\n\n\n\n\nAbbildung 5.1: Backdoors durch beobachtete und unbeobachtete Variablen\nEs bestehen Backdoors durch die \\(U_i\\), die wir nicht mit der Schätzung von \\[\\begin{align}\n  Y_{it} = \\beta_0 + \\beta_1 B_{it} + \\beta_2 X_i + \\varepsilon_{it},\\label{eq:femodelfail}\n\\end{align}\\] einer (fehlspezifizierten) Regression, schließen können.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html#beispiel-einkommen-und-demokratie",
    "href": "FixedEffects.html#beispiel-einkommen-und-demokratie",
    "title": "\n5  Panel-Daten\n",
    "section": "\n5.4 Beispiel: Einkommen und Demokratie",
    "text": "5.4 Beispiel: Einkommen und Demokratie\nEine Vielzahl polit-ökonomischer Standardwerke und Studien (bspw. Dahl 1971; Huntington 1991; Rueschemeyer, Stephens, und Stephens 1992) liefert vermeindliche Belege für einen zentralen Grundsatz der Modernisierungstheorie: Ein höheres Pro-Kopf-Einkommen erhöht die Nachfrage der Bevölkerung nach politischer Freiheit und demokratischen Insitutionen. Acemoglu u. a. (2008a) argumentieren, dass der in derartigen länderübergreifenden Analysen mit Pooling häufig als positiv geschätzte Zusammenhang zwischen Einkommen und Demokratisierung nicht kausal interpetiert werden sollte. Ein Grund hierfür ist, dass ausgelassene länderspezifische zeit-invariante (möglicherweise unbeobachtbare) Faktoren, die sowohl die ökonomische Entwicklung als auch die Stärke demokratischer Institutionen beeinflussen, wahrscheinlich sind. Um diese mögliche Ursache für Endogenität des Zusammenhangs \\[\\begin{align}\n  \\text{Demokratisierung}_i = \\beta_0 + \\beta_1\\,\\text{PK-Einkommen}_i + \\epsilon_i\n\\end{align}\\] zu adressieren, nutzen Acemoglu u. a. (2008a) einen Panel-Regressionsansatz ähnlich zu \\[\\begin{align}\n  \\text{Demokratisierung}_{it} = \\delta_i + \\beta_1\\,\\text{PK-Einkommen}_{it} + \\epsilon_{it}\n\\end{align}\\] mit Fixed Effects \\(\\delta_i\\), die für länderspezifische zeitinvariante Faktoren kontrollieren.\nDas Kernergebnis von Acemoglu u. a. (2008a) ist, dass es keinen kausalen Zusammenhang zwischen dem Einkommen (Wirtschaftswachstum) und der Demokratisierung gibt. Die Autoren zeigen, dass historische und geografische Faktoren, die sowohl das Einkommen als auch die politischen Institutionen beeinflussen, den beobachteten Zusammenhang verzerren können.\nFür die nachfolgenden Code-Beispiele nutzen wir einen Auszug des Datensatzes aus dem Replikationspaket für Acemoglu u. a. (2008a), siehe Acemoglu u. a. (2008b).\n\nacem &lt;- readxl::read_xls(\n  \"~/Downloads/113251-V1/Income-and-Democracy-Data-AER-adjustment.xls\", \n  sheet = \"5 Year Panel\"\n)\n\n\nacem &lt;- acem %&gt;% \n  filter(\n    dplyr::between(year, 1955, 2000),\n    ) %&gt;%\n  arrange(year) \n\n\n# Pooling\nfeols(\n  fml = fhpolrigaug ~ lrgdpch,\n  panel.id = ~ country + year,\n  data = acem, \n)\n\nOLS estimation, Dep. Var.: fhpolrigaug\nObservations: 1,090\nStandard-errors: Clustered (country) \n             Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept) -1.210494   0.094546 -12.8032 &lt; 2.2e-16 ***\nlrgdpch      0.217745   0.011194  19.4518 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.273788   Adj. R2: 0.404579\n\n\n\nacem_f &lt;- acem %&gt;%\n  filter(year %in% c(1970, 1995)) %&gt;%\n  group_by(code) %&gt;%\n  summarise(\n    dlrgdpch = diff(lrgdpch),\n    dfhpolrigaug = diff(fhpolrigaug)\n    ) %&gt;%\n  drop_na()\n\nlm(\n  formula = dfhpolrigaug ~ dlrgdpch,\n  data = acem_f\n) %&gt;% \n  summary()\n\n\nCall:\nlm(formula = dfhpolrigaug ~ dlrgdpch, data = acem_f)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.9582 -0.1541 -0.1172  0.2081  0.7079 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  0.12629    0.04008   3.151  0.00214 **\ndlrgdpch     0.03298    0.06354   0.519  0.60486   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3422 on 101 degrees of freedom\nMultiple R-squared:  0.00266,   Adjusted R-squared:  -0.007214 \nF-statistic: 0.2694 on 1 and 101 DF,  p-value: 0.6049\n\n\n\nggplot(\n  data = acem_f,\n  mapping = aes(\n    x = dlrgdpch,\n    y = dfhpolrigaug\n  ) \n  ) +\n  geom_hline(yintercept = 0, lty = 2) +\n  geom_text(\n    mapping = aes(label = code),\n    position = position_jitter(\n      height = .05, \n      seed = 1234\n      )\n    ) +\n  geom_smooth(method = \"lm\", se = F) +\n  labs(\n    x = \"Diff. Log(Pro-Kopf-BIP) (1970 - 1995)\",\n    y = \"Diff. Demokratie-Index (1970 - 1995)\"\n  ) +\n  theme_cowplot()\n\n\n\n\n\n\n\n\n# time + country fixed effects\nfeols(\n  fml = fhpolrigaug ~ l(fhpolrigaug) + l(lrgdpch) \n  | year + country,\n  panel.id = ~ country + year,\n  cluster = ~ country,\n  data = acem, \n)\n\nOLS estimation, Dep. Var.: fhpolrigaug\nObservations: 955\nFixed-effects: year: 9,  country: 150\nStandard-errors: Clustered (country) \n                  Estimate Std. Error  t value   Pr(&gt;|t|)    \nl(fhpolrigaug, 1) 0.377490   0.048071 7.852772 7.4009e-13 ***\nl(lrgdpch, 1)     0.008417   0.031587 0.266461 7.9025e-01    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.16588     Adj. R2: 0.748871\n                Within R2: 0.140859\n\n\n\n# time-fixed effects\nfeols(\n  fml = fhpolrigaug ~ l(fhpolrigaug) + l(lrgdpch) \n  | year,\n  panel.id = ~ country + year,\n  cluster = ~ country,\n  data = acem, \n)\n\nOLS estimation, Dep. Var.: fhpolrigaug\nObservations: 955\nFixed-effects: year: 9\nStandard-errors: Clustered (country) \n                  Estimate Std. Error  t value   Pr(&gt;|t|)    \nl(fhpolrigaug, 1) 0.702504   0.036023 19.50147  &lt; 2.2e-16 ***\nl(lrgdpch, 1)     0.073042   0.009861  7.40714 8.8791e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.191614     Adj. R2: 0.7178  \n                 Within R2: 0.705629\n\n\n\n\n\n\n\n\nAcemoglu, Daron, Simon Johnson, James A. Robinson, und Pierre Yared. 2008a. „Income and Democracy“. American Economic Review 98 (3): 808–42. https://doi.org/10.1257/aer.98.3.808.\n\n\n———. 2008b. „Replication data for: Income and Democracy“. ICPSR - Interuniversity Consortium for Political; Social Research. https://doi.org/10.3886/E113251V1.\n\n\nDahl, Robert Alan. 1971. Polyarchy: Participation and Opposition: Participation and opposition. New Haven: Yale Univ. Press.\n\n\nHuntington, Samuel P. 1991. The Third Wave: Democratization in the Late Twentieth Century: Democratization in the late twentieth century. Norman, OK: Univ. of Oklahoma Press.\n\n\nRueschemeyer, Dietrich, Evelyne H. Stephens, und John D. Stephens. 1992. Capitalist development and democracy. Cambridge: Polity Pr.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "Machine Learning.html",
    "href": "Machine Learning.html",
    "title": "10  Machine Learning",
    "section": "",
    "text": "Das Gradientenabstiegsverfahren (Gradient Descent) ist ein iteratives Optimierungsverfahren zur Minimierung einer differenzierbaren Zielfunktion \\(f(x)\\). Es wird häufig eingesetzt, um die Verlustfunktionen in maschinellen Lernmodellen zu minimieren. Der Algorithmus aktualisiert die Variablen schrittweise in die entgegengesetzte Richtung des Gradienten der Funktion an der aktuellen Position. Der Gradient gibt dabei die Richtung des steilsten Anstiegs an, wodurch die entgegengesetzte Richtung zum schnellsten Abstieg (Descent) führt.\nDer folgende Pseudocode zeigt die grundlegende Vorgehensweise des Gradientenabstiegsverfahrens unter Einbeziehung eines Momentum-Terms, der dazu dient, das Konvergenzverhalten zu verbessern und lokale Minima effektiver zu überwinden.\n\\[\\begin{align}\n& \\textbf{Algorithmus: Gradientenabstiegsverfahren mit Momentum} \\\\\n& \\text{Initialisiere: }\\\\\n& \\quad x_0 \\text{ (Startpunkt) }\\\\\n& \\quad \\eta \\text{ (Lernrate) }\\\\\n& \\quad \\alpha \\text{ (Momentum-Faktor) }\\\\\n& \\quad v_0 = 0 \\text{ (Anfangsmomentum) } \\\\[1em]\n& \\text{Für } t = 0, 1, 2, \\dots \\text{ bis Konvergenz} \\\\\n& \\quad \\text{1. Berechne den Gradienten: } \\nabla f(x_t) \\\\\n& \\quad \\text{2. Aktualisiere den Momentum-Term: } v_{t+1} = \\alpha v_t - \\eta \\nabla f(x_t) \\\\\n& \\quad \\text{3. Aktualisiere die Position: } x_{t+1} = x_t + v_{t+1} \\\\\n& \\quad \\text{4. Überprüfe das Abbruchkriterium (z.B. } \\| \\nabla f(x_t) \\| &lt; \\epsilon\\text{)} \\\\\n\\end{align}\\]",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Machine Learning</span>"
    ]
  },
  {
    "objectID": "SyntheticControl.html",
    "href": "SyntheticControl.html",
    "title": "\n11  Synthetic Control\n",
    "section": "",
    "text": "11.1 Schätzung von Interventionseffekten mit SCM\nÄhnlich wie bei manchen Matching-Methoden wird bei SCM die Ähnlichkeit der synthetischen Einheit mit der untersuchten Einheit durch eine gewichtete Kombination von Kontrolleinheiten basierend auf ihren Prä-Interventionsmerkmalen erreicht. Seien \\(i = 1, 2, \\ldots, N\\) die Einheiten in der Stichprobe, wobei \\(i = 1\\) die behandelte Einheit und \\(i = 2, \\ldots, N\\) potenziellen Kontrolleinheiten (auch Donor pool genannt) sind. Die Daten liegen für die Perioden \\(t = 1, 2, \\ldots, T\\) vor, mit \\(T_0\\) dem Zeitpunkt direkt vor der Intervention und \\(T_1, \\ldots, T\\) den Perioden nach der Intervention.\nFür SCM bestimmen wir einen Vektor von Gewichten \\(\\mathbf{w}^* := (w_2^*, \\ldots, w_k^*)^T\\), der die Summe der quadrierten Differenzen zwischen den Ausprägungen von \\(k\\) Charakteristika der behandelten Einheit vor der Intervention, \\(X_{1,\\,m}^{\\text{Pre}}\\), \\(m=1,\\dots,k\\), und der gewichteten Summe dieser Charakteristika für die Kontrolleinheiten, \\(X_{i,\\,m}^{\\text{Pre}}\\), minimiert:\n\\[\\begin{align}\n  \\mathbf{w}^* := \\arg\\min_{\\mathbf{w}} \\sum_{m=1}^{k} v_m \\left( X_{1,\\,m}^{\\text{Pre}} - \\sum_{i=2}^{N} w_i X_{i,m}^{\\text{Pre}} \\right)^2,\\label{eq:scopt}\n\\end{align}\\]\nunter der Nebenbedingung, dass \\(\\sum_{i=2}^{N} w_i = 1\\) und \\(w_i \\geq 0\\) für alle \\(i\\). Die \\(v_m\\) sind weitere Gewichte, welche die Relevanz der Variablen für die Vorhersage der Outcome-Variable der interessierenden Einheit, \\(Y_{1,\\,t}\\), beinflussen. Diese Gewichte werden meist in einem weiteren Optimierungsverfahren (bspw. mit Cross-Validation) bestimmt (vgl. A. Abadie, Diamond, und Hainmueller 2014). Als Verlustfunktion hierbei wird meist der mittlere quadratische Fehler bei der Vorhersage von \\(Y_{1,\\,t}\\) (MSPE)1 vor der Behandlung anhand der synthetischen Einheit verwendet,\n\\[\\begin{align}\n  \\sum_{t=1}^{T_0} \\left( Y_{1,\\,t} - \\sum_{i=2}^N w_i(\\mathbf{v}) Y_{i,\\,t} \\right)^2, \\label{eq:scopt2}\n\\end{align}\\] mit \\(\\mathbf{v} := (v_1,\\dots,v_k)'\\).\nDurch die Lösung des Optimierungsproblems \\(\\eqref{eq:scopt}\\) unter Berücksichtigung von \\(\\eqref{eq:scopt2}\\) erhalten wir die geschätzten Gewichte \\(\\widehat{w}_i\\), welche den Einfluss der Kontrolleinheit \\(i=2,\\dots,N\\)-ten bei der Zusammensetzung der Kontrollgruppe festlegen. Anhand der \\(\\widehat{w}_i\\) wird die Outcome-Variable der synthetischen Kontrolleinheit konstruiert, welche als Referenz für die Schätzung des kausalen Effekts der Intervention dient. Die Outcome-Variable der synthetischen Kontrollgruppe für die Nach-Interventionsperiode kann formal ausgedrückt werden als\n\\[\\begin{align}\n  Y_{1,\\,t}^{\\text{Synth}} = \\sum_{i=2}^{N} \\widehat{w}_i Y_{i,\\,t},\\quad t &gt; T_0,\\label{eq:dgkonst}\n\\end{align}\\]\nwobei \\(Y_{1,t}^{\\text{Synth}}\\) der Wert der Outcome-Variable \\(Y\\) für die synthetische Kontrollgruppe zum Zeitpunkt \\(t\\) und \\(Y_{i,t}\\) der entsprechende Wert des Outcomes für die \\(i\\)-te Kontrolleinheit ist. Bei SCM schätzen wir den kausalen Effekt \\(\\tau_t\\) der Intervention zum Zeitpunkt \\(t\\) als die Differenz der Post-Interventionswerte von \\(Y\\) zwischen der behandelten Einheit und dem synthetischen Doppelgänger,\n\\[\n\\widehat{\\tau}_t = Y_{1,\\,t} - Y_{1,\\,t}^{\\text{synth}},\\quad t &gt; T_0.\n\\]\nDer mit SCM geschätzte Effekt ermittelt also für \\(t &gt; T_0\\), wie sich die Intervention auf die behandelte Einheit ausgewirkt hat durch einen Vergleich mit der Situation, die eingetreten wäre, wenn die Einheit nicht behandelt worden wäre, repräsentiert durch die synthetische Kontrollgruppe.\nDer SCM-Schätzer von A. D. Abadie Alberto und Hainmueller (2010) ist im R-Paket Synth (Hainmueller, Diamond, und Abadie 2011) implementiert. Wir illustrieren die Methode nachfolgend mit einer empirischen Anwendung zu den Konsequenzen des Brexit auf die nachfolgende Entwicklung der britischen Volkswirtschaft.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Synthetic Control</span>"
    ]
  },
  {
    "objectID": "SyntheticControl.html#sec-siscm",
    "href": "SyntheticControl.html#sec-siscm",
    "title": "\n11  Synthetic Control\n",
    "section": "",
    "text": "1 Engl. für Mean squared prediction error",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Synthetic Control</span>"
    ]
  },
  {
    "objectID": "SyntheticControl.html#case-study-ökonomische-kosten-des-brexit",
    "href": "SyntheticControl.html#case-study-ökonomische-kosten-des-brexit",
    "title": "\n11  Synthetic Control\n",
    "section": "\n11.2 Case Study: Ökonomische Kosten des Brexit",
    "text": "11.2 Case Study: Ökonomische Kosten des Brexit\nBorn u. a. (2019) untersuchen die ökonomischen Kosten des Brexits mit einem kausalanalytischen Forschungsansatz. Der Kern der empirischen Analyse ist eine Kombination von quasi-experimenteller Identifikation und struktureller Zeitreihenanalyse. Hiermit können nicht nur die aggregierten Kosten des EU-Ausstiegs für Großbrittanien zu quantifiziert, sondern auch die Kanäle indentifiziert werden, durch die die erwartete wirtschaftliche Desintegration die britische Makroökonomie beeinflusst hat. Hierbei identifizieren Born u. a. (2019) einen Anstieg der wirtschaftspolitischen Unsicherheit und eine Abwärtskorrektur der Wachstumserwartungen als Haupttreiber für den Rückgang der Wirtschaftsleistung.\nDer quasi-experimentelle Ansatz betrachtet das Brexit-Referendum als ein natürliches makroökonomisches Experiment und untersucht die Konsequenzn der wirtschaftlichen Desintegration für das Bruttoinlandsprodukt (BIP) im Nachfolgezeitraum mit SCM. Hierzu wird gemäß der in Kapitel 11.1 erläuterten Vorgehensweise ein syntetischer Doppelgänger für die britische Wirtschaft aus einem Donor Pool von 23 Volkswirtschaften konstruiert, und der Effekt des Referendums als Unterschied zwischen der tatsächlichen und synthetischen Trajektorien des BIP für Folgeperioden ermittelt. Die Analyse zeigt, dass das Brexit-Votum bis Ende 2018 zu einem BIP-Rückgang von etwa 1.7% bis 2.5% geführt hat.\nWie reproduzieren nun die wesentlichen Ergebnisse des SCM-Ansatzes der Studie mit R. Hierfür lesen zunächst den Datensatz brexit.csv (hier verfügbar) in R ein. Dieser enthält vierteljährliche Beobachtungen makroökonomischer Variablen für 24 Länder für den Zeitraum 1995-Q1–2021-Q4.\n\nlibrary(readr)\nlibrary(dplyr)\n\n# Datensatz 'brexit.csv' einlesen\nbrexit &lt;- read_csv(\"datasets/brexit.csv\") %&gt;%\n  as.data.frame()\n\nbrexit ist ein Datensatz mit einer Panel-Struktur. Die Zeit- und Entitätsvariablen sind Year/quarter und Country/ID. Beachte, dass die Variable Time zusätzlich das Jahr und das Quartal als numerische Variable angibt.\n\n# Überblick über 'brexit'\nglimpse(brexit)\n\nRows: 2,496\nColumns: 21\n$ Time          &lt;dbl&gt; 1995.00, 1995.00, 1995.00, 1995.00, 1995.00, 1995.00, 19…\n$ Year          &lt;dbl&gt; 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 19…\n$ quarter       &lt;chr&gt; \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q…\n$ Country       &lt;chr&gt; \"Australia\", \"Austria\", \"Belgium\", \"Canada\", \"Finland\", …\n$ real_con_raw  &lt;dbl&gt; 4.660970e+11, 1.214713e+11, 1.608240e+11, 5.558142e+11, …\n$ real_inv_raw  &lt;dbl&gt; 1.683258e+11, 5.537994e+10, 6.118800e+10, 1.894910e+11, …\n$ real_exp_raw  &lt;dbl&gt; 1.246639e+11, 6.634091e+10, 1.501160e+11, 3.353030e+11, …\n$ real_imp_raw  &lt;dbl&gt; 9.781032e+10, 7.439282e+10, 1.468880e+11, 2.572610e+11, …\n$ real_gdp_raw  &lt;dbl&gt; 8.495864e+11, 2.165699e+11, 2.910360e+11, 1.084659e+12, …\n$ real_gdp_2016 &lt;dbl&gt; 0.5080841, 0.6832146, 0.6877292, 0.6057397, 0.6370480, 0…\n$ tot_emp_raw   &lt;dbl&gt; 8077377.2, 3737003.3, 3920400.0, 13274100.0, 2050262.7, …\n$ pop_quarterly &lt;dbl&gt; 13144039.8, 6043266.6, 7666495.5, 21714093.3, 3827395.7,…\n$ lab_prod      &lt;dbl&gt; 0.9988637, 0.9863141, 0.9942753, 0.9997992, 0.9885239, 1…\n$ ConGDP        &lt;dbl&gt; 0.5486164, 0.5608871, 0.5525914, 0.5124322, 0.5244422, 0…\n$ InvGDP        &lt;dbl&gt; 0.1981267, 0.2557140, 0.2102420, 0.1747010, 0.2085606, 0…\n$ ExpGDP        &lt;dbl&gt; 0.14673485, 0.30632565, 0.51579873, 0.30913218, 0.268451…\n$ ImpGDP        &lt;dbl&gt; 0.1151270, 0.3435049, 0.5047073, 0.2371815, 0.2485870, 0…\n$ LPG           &lt;dbl&gt; -0.0078972729, -0.0093478618, 0.0033636783, 0.0054461911…\n$ EmpSha        &lt;dbl&gt; 0.6145277, 0.6183747, 0.5113679, 0.6113127, 0.5356809, 0…\n$ gdp           &lt;dbl&gt; -49.19159, -31.67854, -31.22708, -39.42603, -36.29520, -…\n$ ID            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n\n# 'Time' zeigt Jahr + Quartal\nbrexit %&gt;% \n  filter(Country == \"United Kingdom\") %&gt;% \n  select(Time) %&gt;%\n  slice_head(n = 5)\n\n     Time\n1 1995.00\n2 1995.25\n3 1995.50\n4 1995.75\n5 1996.00\n\n\nFür die Schätzung der Gewichte \\(w_i\\) für die Konstruktion des UK-Doppelgängers werden die in gelisteten Charakteristika der Volkswirtschaften verwendet.\n\n\n\n\n\n\n\n\nVariable\nDefinition\n\n\n\ngdp\nVeränderung des BIP relativ zu 2016\n\n\nConGDP\nAnteil: Konsum/BIP (%)\n\n\nInvGDP\nAnteil: Investitionen/BIP (%)\n\n\nExpGDP\nAnteil: Exporte/BIP (%)\n\n\nImpGDP\nAnteil: Importe/BIP (%)\n\n\nEmpSha\nAnteil: Beschäftigte/Erwerbsbevölkerung (%)\n\n\nLPG\nWachstum der Arbeitsproduktivität (%)\n\n\n\n\n\nTabelle 11.1: brexit – Variablen und Definitionen\n\n\nZur Berechnung von SCM mit dem R-Paket Synth müssen die Daten zunächst mit der Funktion Synth::dataprep() aufbereitet werden, s. ?Synth::dataprep() für weitere Details. Neben dem Datensatz (foo) unter expliziter Nennung der Prädiktoren (predictors) und der Outcome-Variable (dependent) übergeben wir Variablen für die Indentifikation von Einheiten (ID) und Zeitpunkten (Time), sowie Donor Pool (controls.identifier) und behandelter Einheit (treatment.identifier). Weiterhin werden die Vorbehandlungsperiode (time.predictors.prior) sowie der Zeitraum über den die Regressor-Gewichte \\(v_m\\) bestimmt werden sollen (time.optimize.ssr), festgelegt. Für letztere übergeben wir einen numerischen Vektor für sämtliche Zeitpunkte von 1995-Q1 bis zum Brexit-Referendum in 2016-Q2.\nUm einen ersten Überblick über die Entwicklung der BIP im Datensatz zu gewinnen, vergleichen wir die Zeitreihen für Donor-Pool-Länder (grau) und Großbritannien (blau) mit ggplot.\n\nlibrary(cowplot)\n\nbrexit %&gt;%\n  mutate(\n    group = ifelse(\n      Country == \"United Kingdom\", \n      yes = \"UK\", \n      no =\"else\"\n    )\n  ) %&gt;%\n  \n  ggplot(\n    mapping = aes(\n      x = Time, \n      y = gdp, \n      color = group, \n      group = Country, \n      lwd = group\n    )\n  ) +\n  scale_color_manual(\n    values = c(\n      \"UK\" = \"#00BFC4\", \"else\" = alpha(\"gray\", .75)\n    )\n  ) +\n  scale_linewidth_manual(\n    values = c(\"UK\" = 1, \"else\" = .5)\n  ) +\n  geom_line() +\n  # Brexit-Referendum\n  geom_vline(\n    xintercept = 2016.25, \n    lty = \"dotted\"\n  ) +\n  theme_cowplot() +\n  guides(\n    lwd = \"none\", \n    color = guide_legend(position = \"inside\")\n  ) +\n  theme(legend.position.inside = c(.1, .9))\n\n\n\n\n\n\nAbbildung 11.1: BIP relativ zu 2016\n\n\n\n\nAbbildung 11.1 zeigt, dass das BIP von Großbritannien zwar auch nach dem Brexit-Referendum (gepunktete Linie) gewachsen ist, jedoch vergleichsweise schwach. Eine Analyse mit SCM kann statistische Evidenz für den mutmaßlich negativen Effekt des Referendums auf das Wachstum in den Folgeperioden liefern.\nWir laden nun das Paket Synth und bereiten die Daten für die Analyse vor.\n\n# R-Paket 'Synth' laden\nlibrary(Synth)\n\n# Daten für die Optimierung vorbereiten\ndataprep_out &lt;- dataprep(\n  foo = brexit, \n  predictors = c(\n    \"ConGDP\", \"InvGDP\", \n    \"ExpGDP\", \"ImpGDP\", \n    \"LPG\", \"EmpSha\"\n  ), \n  dependent = \"gdp\", \n  unit.variable = \"ID\",\n  time.variable = \"Time\", \n  treatment.identifier = 23, \n  controls.identifier = (brexit$ID %&gt;% unique())[-23], \n  time.predictors.prior = seq(1995, 2016.25, .25),\n  time.optimize.ssr = seq(1995, 2016.25, .25),\n  unit.names.variable = \"Country\"\n)\n\nAnhand der vorbereiteten Daten dataprep_out wird nun die Bestimmung der Gewichte mit Synth::synth() durchgeführt.\n\n# Gewichte per Optimierung bestimmen\nsynth_out &lt;- synth(dataprep_out)\n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 0.6083746 \n\nsolution.v:\n 0.1488472 0.08840361 0.1480946 0.153318 0.1815462 0.2797904 \n\nsolution.w:\n 1.42199e-05 4.00616e-05 8.47284e-05 0.00014488 4.45754e-05 4.84009e-05 0.001608051 4.77577e-05 0.06654494 2.07094e-05 0.1446237 1.188e-05 2.377e-06 0.04837474 1.33542e-05 0.0001405933 4.61625e-05 0.0001592545 1.49993e-05 4.14211e-05 3.78112e-05 0.0002273924 0.737708 \n\n\nSynth::synth() gibt Infos über den Optimierungsprozess und dessen Ergebnisse automatisch in der Konsole aus. Wir können diese mit Synth::synth.tab() leicht tabellarisch zusammenfassen und mit gt::gt() darstellen.\n\n# Zusammenfassung der Ergebnisse\n(\n  tb &lt;- synth.tab(\n    synth.res = synth_out, \n    dataprep.res = dataprep_out\n  )  \n)\n\n$tab.pred\n       Treated Synthetic Sample Mean\nConGDP   0.655     0.635       0.534\nInvGDP   0.168     0.202       0.226\nExpGDP   0.254     0.219       0.454\nImpGDP   0.256     0.232       0.423\nLPG      0.003     0.003       0.003\nEmpSha   0.634     0.625       0.611\n\n$tab.v\n       v.weights\nConGDP 0.149    \nInvGDP 0.088    \nExpGDP 0.148    \nImpGDP 0.153    \nLPG    0.182    \nEmpSha 0.28     \n\n$tab.w\n   w.weights      unit.names unit.numbers\n1      0.000       Australia            1\n2      0.000         Austria            2\n3      0.000         Belgium            3\n4      0.000          Canada            4\n5      0.000         Finland            5\n6      0.000          France            6\n7      0.002         Germany            7\n8      0.000         Hungary            8\n9      0.067         Iceland            9\n10     0.000         Ireland           10\n11     0.145           Italy           11\n12     0.000           Japan           12\n13     0.000           Korea           13\n14     0.048      Luxembourg           14\n15     0.000     Netherlands           15\n16     0.000     New Zealand           16\n17     0.000          Norway           17\n18     0.000        Portugal           18\n19     0.000 Slovak Republic           19\n20     0.000           Spain           20\n21     0.000          Sweden           21\n22     0.000     Switzerland           22\n24     0.738   United States           24\n\n$tab.loss\n       Loss W    Loss V\n[1,] 0.135733 0.6083746\n\n\nFür die tabellarische Darstellung mit gt::gt() berücksichtigen wir lediglich Volkswirtschaften mit Gewicht &gt; .0001.\n\n# Darstellung mit gt()\ntb$tab.w %&gt;% \n  # Berücksichtige nur Länder mit relevanten Gewichten\n  filter(w.weights &gt; .0001) %&gt;% \n  arrange(desc(w.weights)) %&gt;% \n  gt::gt() %&gt;%\n  tabopts\n\n\n\n\n\n\n\n\nw.weights\nunit.names\nunit.numbers\n\n\n\n0.738\nUnited States\n24\n\n\n0.145\nItaly\n11\n\n\n0.067\nIceland\n9\n\n\n0.048\nLuxembourg\n14\n\n\n0.002\nGermany\n7\n\n\n\n\n\n\n\n\nTabelle 11.2: Gewichte für den synthetischen UK-Doppelgänger\n\n\n\nDer synthetische UK-Doppelgänger kann nun gemäß der Vorschrift \\(\\eqref{eq:dgkonst}\\) konstruiert werden. Wir erzeugen hierzu ein tibble-Objekt mit den entsprechenden ID-Variablen.\n\n# Doppelgänger konstruieren\ndoppelganger &lt;- left_join(\n  x = brexit, \n  y = tb$tab.w, \n  by = c(\"Country\" = \"unit.names\")\n) %&gt;% \n  select(Time, Year, Country, gdp, w.weights) %&gt;%\n  group_by(Time, Year) %&gt;%\n  summarise(\n    gdp = sum(gdp * w.weights, na.rm = T)\n  ) %&gt;%\n  mutate(type = \"Doppelgaenger\") %&gt;%\n  ungroup()\n\nglimpse(doppelganger)\n\nRows: 104\nColumns: 4\n$ Time &lt;dbl&gt; 1995.00, 1995.25, 1995.50, 1995.75, 1996.00, 1996.25, 1996.50, 19…\n$ Year &lt;dbl&gt; 1995, 1995, 1995, 1995, 1996, 1996, 1996, 1996, 1997, 1997, 1997,…\n$ gdp  &lt;dbl&gt; -36.87991, -36.70512, -36.32948, -35.72637, -35.34392, -34.57688,…\n$ type &lt;chr&gt; \"Doppelgaenger\", \"Doppelgaenger\", \"Doppelgaenger\", \"Doppelgaenger…\n\n\nFür die nachfolgenden Schritte der Analyse führen wir das beobachtete GDP für Großbritannien mit dem syntethischen GDP des Doppelgängers zusammen.\n\n# tibble mit UK-GDP erstellen\nUK &lt;- brexit %&gt;% \n  filter(Country == \"United Kingdom\") %&gt;% \n  select(Time, Year, gdp) %&gt;%\n  mutate(type = \"UK\")\n\n# UK und Doppelgänger zusammenführen\nthe_gdps &lt;- bind_rows(\n  doppelganger, UK\n)\n\nFür einen Vergleich von UK- und Doppelgänger-BIP folgen wir Born u. a. (2019) und berechnen die Differenz der BIP über den gesamten Zeitraum, die so genannte Doppelgänger-Gap.\n\n# UK-Doppelgänger-Gap berechnen\ngdp_gap &lt;- the_gdps %&gt;% \n  pivot_wider(\n    values_from = gdp, \n    names_from = \"type\"\n  ) %&gt;%\n  mutate(gdp_gap = UK - Doppelgaenger)\n\nAls ein Maß für die Unsicherheit bei der Schätzung des GDPs für den Doppelgänger berechnen Born u. a. (2019) die Standardabweichung der Doppelgänger-Gap für den Zeitraum vor dem Brexit-Referendum.\n\n# Standardabweichung der Gap vor dem Brexit-Vote\nsd_gap &lt;- gdp_gap %&gt;%\n  filter(Time &lt; 2016.25) %&gt;% \n  summarise(\n    sd = sd(gdp_gap)\n  ) %&gt;% \n  pull(sd)\n\nWir nutzen nun ggplot2::ggplot(), um den syntetischen Doppelgänger und das BIP für Großbritannien über den gesamten Zeitraum darzustellen. Für die Darstellung von Unsicherheit bei der Konstruktion des Doppelgängers unterlegen wir die Doppelgänger-Zeitreihe mit einer Schattierung in der Breite der geschätzten Standardabweichung von 0.78 für die Periode vor dem Referendum.\n\n(\n  p_gdp &lt;- ggplot() +\n    # 1-SD-Band um das Doppelgänger-GDP\n    geom_ribbon(\n      data = the_gdps %&gt;% \n        filter(type == \"Doppelgaenger\"), \n      mapping = aes(\n        x = Time, \n        ymin = gdp - sd_gap, \n        ymax = gdp + sd_gap\n      ), \n      fill = alpha(\"red\", alpha = .2), \n      color = \"white\"\n    ) +\n    # UK- und Doppelgänger-GDP\n    geom_line(\n      data = the_gdps, \n      mapping = aes(\n        x = Time, \n        y = gdp, \n        col = type\n      ),\n      lwd = 1\n    ) +\n    # Brexit-Referendum\n    geom_vline(\n      xintercept = 2016.25, \n      lty = \"dotted\"\n    ) +\n    scale_color_discrete(name = \"\") +\n    # Legende hinzufügen\n    cowplot::theme_cowplot() +\n    theme(legend.position = c(.025, .9))  \n)\n\n\n\n\n\n\nAbbildung 11.2: UK-BIP und synthetischer Doppelgänger\n\n\n\n\nAbbildung 11.2 zeigt, dass der synthetische Doppelgänger über weite Teile der Vorperiode eine gute Anpassung an das beobachtete BIP von Großbritannien aufweist, insbesondere für den Zeitraum unmittelbar vor dem Brexit-Referendum. Nach dem Referendum zeigt sich bereits nach wenigen Quartalen eine deutliche Abweichung zwischen der geschätzten und der beobachteten Trajektorie. Eine Beschränkung der in p_gdp verwendeten Datenpunkte auf einen Bereich nahe des Referendums bestärkt diese Schlussfolgerung.\n\n# Close-up im Bereich des Referendums\np_gdp +\n  scale_x_continuous(\n    limits = c(2015, 2021), \n    expand = c(0, .1)\n    ) +\n  scale_y_continuous(limits = c(-4, 12))\n\n\n\n\n\n\nAbbildung 11.3: UK-BIP und synthetischer Doppelgänger – Close-Up\n\n\n\n\nIn Abbildung 11.2 ist eine ab Mitte 2017 außerhalb des Standardabweichungsbereichs verlaufende Divergenz der Zeitreihen zu erkennen. Diese stellen wir nachfolgend anhand der Doppelgänger-Gap mit ggplot2::ggplot() dar.\n\n# BIP-Doppelgänger-Gap\nggplot(data = gdp_gap) +\n  geom_hline(yintercept = 0) +\n  geom_line(\n    mapping = aes(x = Time, y = gdp_gap),\n    lwd = 1\n  ) + \n  geom_ribbon(\n    mapping = aes(\n      x = Time, \n      ymin = gdp_gap - sd_gap, \n      ymax = gdp_gap + sd_gap\n    ), \n    fill = alpha(\"darkgray\", alpha = .2), \n    color = \"white\"\n  ) +\n  # Referendum\n  geom_vline(\n    xintercept = 2016.25,\n    lty = \"dotted\"\n  ) +\n  scale_x_continuous(\n    expand = c(0, .1), \n    limits = c(2015, 2021)\n  ) +\n  scale_y_continuous(limits = c(-6, 1.5)) +\n  cowplot::theme_cowplot()\n\n\n\n\n\n\nAbbildung 11.4: UK-BIP und synthetischer Doppelgänger – Doppelgänger-Gap\n\n\n\n\nDie in Abbildung 11.4 gezeigte Doppelgänger-Gap stimmt gut mit dem von Born u. a. (2019) geschätzten verlorenen Wachstums des BIP relativ zu 2016 um bis zu 2.5% bis Ende des Jahres 2018 überein.\nAls weiteres Maß für den Effekt des Referendums im Folgezeitraum können wir die mittlere Doppelgänger-Gap für sämtliche Beobachtungsperioden nach dem Brexit-Referendum schnell bestimmen.\n\n# Mittlerer Unterschied nach dem Brexit-Referendum\ngdp_gap %&gt;% \n  filter(Time &gt; 2016.25) %&gt;% \n  pull(gdp_gap) %&gt;% \n  mean()\n\n[1] -2.343273\n\n\n\n11.2.1 Placebo-Tests: Grafische Inferenz\nAuch für SCM sind Placebo-Tests ein hilfreiches Instrument zur Überprüfung der Gültigkeit von Studienergebnissen. Eine gründliche Placebo-Analyse kann festzustellen, ob der beobachtete Effekt tatsächlich auf die Intervention zurückzuführen ist und nicht auf unberücksichtigte (möglicherweise unbeobachtbare) Faktoren.\nEin Ansatz ist hierfür ist es, den synthetische-Doppelgänger für fiktive Interventionszeitpunkte vor dem tatsächlichen Behandlungszeitpunkt zu konstruieren, und die entsprechenden Trajektorien mit dem ursprünglichen Doppelgänger zu vergleichen. So kann die Validität der ursprünglichen Doppelgänger-Trajektorie im Hinblick auf mögliche anderweitige Ereignisse vor der Intervention geprüft werden: Doppelgänger-Trajektorien für fiktive, frühere Interventionen sollten sich nicht systematisch von der andhand von Daten bis zur tatsächlichen Intervention berechneten Trajektorie unterscheiden.\nWir definieren hierzu eine Funktion placebo(), die einen syntethischen Doppelgänger des BIP Großbritanniens mit Gewichten auf Basis eines vorgegebenen Interventionszeitpunktes (treat) zurückgibt. Abgesehen vom früheren Interventionszeitpunkt (und der damit einhergehenden verkleinerten Stichprobe) erfolgt die Berechnung der Gewichte mit derselben Spezifikation wie zuvor.\n\n# Funktion für Placebo-Doppelgänger:\n# Fiktive frühere Intervention\nplacebo &lt;- function(treat) {\n  \n  # Datenvorbereitung für fiktives Datum 'treat'\n  dataprep_out &lt;- dataprep(\n    foo = brexit, \n    predictors = c(\n      \"ConGDP\", \"InvGDP\",\n      \"ExpGDP\", \"ImpGDP\",\n      \"LPG\", \"EmpSha\"\n    ), \n    dependent = \"gdp\", \n    unit.variable = \"ID\",\n    time.variable = \"Time\", \n    treatment.identifier = 23, \n    controls.identifier = (brexit$ID %&gt;% unique())[-23], \n    time.predictors.prior = seq(1995, treat, .25),\n    time.optimize.ssr = seq(1995, treat, .25),\n    unit.names.variable = \"Country\"\n    )\n  \n  # Doppelgänger bestimmen\n  synth_out &lt;- quietly(synth)(dataprep_out)$result\n  \n  # Ergebnisse auslesen\n  tb &lt;- synth.tab(\n    synth.res = synth_out, \n    dataprep.res = dataprep_out\n    )\n  \n  return(\n    \n    # Doppelgänger konstruieren \n    left_join(\n      x = brexit, \n      y = tb$tab.w, \n      by = c(\"Country\" = \"unit.names\")\n    ) %&gt;% \n      select(Time, Country, gdp, w.weights) %&gt;%\n      group_by(Time) %&gt;%\n      summarise(\n        gdp = sum(gdp * w.weights, na.rm = T)\n      ) %&gt;%\n      mutate(type = paste0(\"Placebo\", treat))  \n    )\n  \n}\n\nWie in Born u. a. (2019) berechnen wir nun 12 Placebo-Doppelgänger des BIP von Großbritannien für fiktive Zeitpunkte eines Referendums über sämtliche Quartale im Zeitraum 2010-Q1 bis 2016-Q1. Dies ist komfortabel durch Iteration von placebo() über diese Zeitpunkte mit purrr::map_dfr() umsetzbar.\n\n# Iteration über fiktive frühere Referenden\nplacebos_tbl &lt;- map_dfr(\n  .x = seq(2010, 2016, .25), \n  .f =  \\(x) placebo(x) \n)\n\nplacebos_tbl ist ein tibble-Objekt im tidy-Format. Wir können die Placebo-Doppelgänger sowie den ursprünglich berechneten Doppelgänger und das tatsächliche BIP also ähnlich wie in Abbildung 11.2 mit ggplot2::ggplot() darstellen.\n\n# Vergleich mit Placebo-Doppelgänger\n(\n  p_UKDG &lt;- ggplot(\n    data = placebos_tbl,\n    mapping = aes(\n      x = Time, \n      y = gdp, \n      group = type\n    )\n  ) +\n    # Placebos (mit jitter)\n    geom_line(\n      lwd = .25, \n      col = \"gray80\",\n      position = position_jitter(height = .25)\n    ) +\n    # Ursprünglicher Doppelgänger\n    geom_line(\n      data = the_gdps %&gt;% \n        filter(type == \"Doppelgaenger\"), \n      mapping = aes(col = type), \n      lwd = 1\n    ) +\n    # Beobachtetes BIP\n    geom_line(\n      data = the_gdps %&gt;% \n        filter(type == \"UK\"), \n      mapping = aes(col = type), \n      lwd = 1\n    ) +\n    # Intikator für Referendum\n    geom_vline(xintercept = 2016.25, lty = \"dotted\") +\n    # Formatierung\n    cowplot::theme_cowplot() +\n    theme(legend.position = c(.05, .9))\n)\n\n\n\n\n\n\nAbbildung 11.5: Placebo-Doppelgänger\n\n\n\n\n\n# Close-up bei Referendum\np_UKDG +\n      scale_x_continuous(\n      limits = c(2015, 2021), expand = c(0, .05)\n    ) +\n      scale_y_continuous(\n      limits = c(-3, 13),  expand = c(0, 0)\n    )\n\n\n\n\n\n\nAbbildung 11.6: Placebo-Doppelgänger – Close-Up\n\n\n\n\nBeachte, dass position = position_jitter(height = .25) eine zufällige, kleine Verschiebung (jitter) der Trajektorien der Placebo-Doppelgänger für eine bessere Unterscheidbarkeit bewirkt. Abbildung 11.5 und Abbildung 11.6 zeigen, dass sich die Placebo-Pfade für fiktive frühere Referenden (grau) nicht systematisch vom ursprünglich berechneten synthetischen Doppelgänger (rot) unterscheiden. Insbesondere finden wir keinen Rückgang der synthetischen BIP relativ zum beobachteten BIP für Großbritannien vor dem Referendum. Deutliche Abweichungen vom tatsächlichen BIP ergeben sich erst jenseits der tatsächlichen Referendums. Diese Placebo-Analyse bekräftigt also die Validität der Konstruktion des “Benchmark-Doppelgängers” für die Periode bis 2016-Q2 und die Schätzung des kausalen Effekts des Referendums anhand der entsprechenden Doppelgänger-Gap.\nEin weiterer Placebo-Test in Born u. a. (2019) ist ein Vergleich der Doppelgänger-Gap Großbritanniens mit Doppelgänger-Gaps für fiktive Referenden in 2016-Q2 in Ländern mit wesentlichem Einfluss bei der Konstruktion des synthetischen Doppelgängers für Großbritannien: Die Schätzung des kausalen Effekts des Referendums auf das BIP in Großbritannien ist glaubwürdig, wenn lediglich die Doppelgänger-Gap für Großbritannien durch das Referendum beeinflusst wird, nicht aber die Doppelgänger-Gaps für Länder in der Kontrollgruppe.\nFür diese grafische Placebo-Analyse modifizieren wir die Funktion placebo() entsprechend. placebo_gap() berechnet die Doppelgänger-Gap für das mit treat identifizierte Land. Das if-Statement zu Beginn stellt sicher, dass Großbritannien nicht als Kontroll-Einheit für die Placebo-Gaps verwendet wird.\n\n# Funktion für Placebo-Gaps\nplacebo_gap &lt;- function(treat) {\n  \n  # Kontrollgruppe definieren\n  if(treat != 23) {\n    controls &lt;- (1:24)[-c(23, treat)]\n  } else {\n    controls &lt;- (1:24)[-23]\n  }\n  \n  # Daten vorbereiten\n  dataprep_out &lt;- dataprep(\n    foo = brexit, \n    predictors = c(\n      \"ConGDP\", \"InvGDP\",\n      \"ExpGDP\", \"ImpGDP\",\n      \"LPG\", \"EmpSha\"\n    ), \n    dependent = \"gdp\", \n    unit.variable = \"ID\",\n    time.variable = \"Time\", \n    treatment.identifier = treat, \n    controls.identifier = controls, \n    time.predictors.prior = seq(1995, 2016.25, .25),\n    time.optimize.ssr = seq(1995, 2016.25, .25),\n    unit.names.variable = \"Country\"\n  )\n  \n  # Gewichte bestimmen\n  synth_out &lt;- quietly(synth)(dataprep_out)$result\n  \n  # Ergebnisse zusammenfassen\n  tb &lt;- synth.tab(\n    synth.res = synth_out, \n    dataprep.res = dataprep_out\n  )\n  \n  # Doppelgänger bestimmen\n  doppel &lt;- left_join(\n    x = brexit, \n    y = tb$tab.w, \n    by = c(\"Country\" = \"unit.names\")\n  ) %&gt;% \n    select(Time, gdp, Country, w.weights) %&gt;%\n    group_by(Time) %&gt;%\n    summarise(\n      gdp_synth = sum(gdp * w.weights, na.rm = T), \n    )\n  \n  # Beobachtetes BIP auslesen\n  gdp &lt;- brexit %&gt;% filter(ID == treat) %&gt;% pull(gdp)\n  \n  return(\n    \n    # Doppelgänger-Gap berechnen\n    doppel %&gt;% \n      mutate(\n        ID = treat,\n        gdp = gdp,\n        gdp_gap = gdp - gdp_synth\n      )\n    \n  )\n  \n}\n\nFür die Berechnung der Placebo-Gaps iterieren wir über die Indizes der in Tabelle 11.2 gelisteten Volkswirtschaften der Kontrollgruppe für Großbritannien.\n\n# Indizes für \"Donor Countries\" und UK\ndonors_and_UK &lt;- brexit %&gt;% \n  select(ID, Country) %&gt;% \n  distinct() %&gt;%\n  filter(\n    Country %in% \n      c(\n        \"United States\", \"Italy\", \"Iceland\", \n        \"Luxembourg\", \"Germany\", \"United Kingdom\"\n      )\n  ) %&gt;%\n  pull(ID)\n\n\n# Placebo-Doppelgänger-Gaps berechnen\nplacebo_gaps_tbl &lt;- map_dfr(\n  .x = donors_and_UK, \n  .f =  \\(x) placebo_gap(x) \n)\n\nFür die grafische Darstellung ergänzen wir die Variable Country zur Unterscheidung der Doppelgänger-Gaps für Großbritannien und die Kontroll-Länder.\n\n# ID-Variable für UK und Kontroll-Länder\nplacebo_gaps_tbl &lt;- placebo_gaps_tbl %&gt;%\n  mutate(\n    Country = ifelse(ID == 23, \"UK\", \"else\")\n  )\n\nUm die Vergleichbarkeit der Doppelgänger-Gaps zu gewährleisten, standardisieren Born u. a. (2019) die Schätzungen der Gaps anhand der jeweiligen Mittelwerte für das Jahr 2015 und der Standardabweichungen im Zeitraum vor dem Brexit-Referendum. Wir berechnen diese Statistiken zunächst.\n\n# Mittelwerte für 2015\nmeans &lt;- placebo_gaps_tbl %&gt;% \n  group_by(ID) %&gt;% \n  filter(between(Time, 2015, 2015.75)) %&gt;% \n  summarise(\n    mean2015 = mean(gdp_gap)\n  )\n\n# Standardabweichungen vor Referendum\nsds &lt;- placebo_gaps_tbl %&gt;% \n  group_by(ID) %&gt;% \n  filter(Time &lt; 2016.25) %&gt;% \n  summarise(\n    thesd = sd(gdp_gap)\n  )\n\nMit dplyr::left_join() führen wir diese Statistiken mit placebo_gaps_tbl zusammen und berechnen die standardisierten Doppelgänger-Gaps.\n\n# Join + Standardisierung\nplacebo_gaps_std &lt;- \n  left_join(placebo_gaps_tbl, means) %&gt;% \n  left_join(sds) %&gt;%\n  mutate(gdp_gap_std = (gdp_gap - mean2015)/thesd)\n\nAnalog zum Code für Abbildung 11.4 plotten wir die Placebo-Gap-Zeitreihen mit ggplot2::ggplot().\n\n# Placebo-Gaps mit UK-Gap vergleichen\nggplot(\n  data = placebo_gaps_std,\n  mapping = aes(\n    x = Time, \n    y = gdp_gap_std,\n    group = ID,\n    lwd = Country,\n    color = Country\n  )\n) +\n  # Hilfslinie bei Differenz = 0\n  geom_hline(yintercept = 0) +\n  # Gaps\n  geom_line() +\n  # Referendum\n  geom_vline(xintercept = 2016.25, lty = \"dotted\") +\n  # Formatierung\n  scale_color_manual(\n    values = c(\"UK\" = \"steelblue\", \"else\" = alpha(\"darkgray\", .5))\n  ) +\n  scale_linewidth_manual(\n    values = c(\"UK\" = 1, \"else\" = .5)\n  ) +\n  scale_x_continuous(\n    limits = c(2015, 2021), expand = c(0, .05)\n  ) +\n  theme_cowplot() +\n  theme(legend.position = c(.05, .9))\n\n\n\n\n\n\nAbbildung 11.7: Placebo- und UK-Doppelgänger-Gaps\n\n\n\n\nAbbildung 11.7 zeigt die standardisierten Placebo-Doppelgänger-Gaps für ein fiktives Referendum zum Zeitpunkt 2016-Q2 in den 5 Kontroll-Volkswirtschaften, die für Konstruktion des BIP-Doppelgängers von Großbrittannien relevant sind (grau). Der Vergleich mit der standardisierten Doppelgänger-Gap für Großbritannien (blau). Der Verlauf der Placebo-Gaps zeigt an, dass keine Abweichungen mit negativem Trend von der Referenzlinie bei 0 (kein Unterschied zwischen beobachtetem und syntetischem BIP) nach dem Referendum vorliegen. Damit liefert die Grafik keine Hinweise auf einen Effekt fiktiver Interventionen in den Kontroll-Ländern. Für Großbritannien jedoch ist, ähnlich wie in Abbildung 11.4, ein negativer Trend nach dem Referendum deutlich erkennbar.\n\n11.2.2 Statistische Inferenz\nDie bisherigen Placebo-Tests liefern lediglich grafische Evidenz für die Signifikanz des negativen Effekts des Brexit-Referendums auf die Britische Volkswirtschaft. Methoden für statistische Inferenz für SCM sind Gegenstand aktueller Forschung. Born u. a. (2019) verwenden den End-Of-Sample Instability Test (\\(S\\)) von Andrews (2003). Dieses Verfahren kann für einen Test auf einen Strukturbruch gegen Ende einer Zeitreihe verwendet werden. In der vorliegende Studie wird der Test angewendet, um zu überprüfen, ob die Verteilung der Doppelgänger-Gap Großbritanniens für die letzen \\(m\\) Perioden jenseits des Referendums signifikant verschieden ist von Verteilung vorheriger Perioden.\nWir zeigen nachfolgend, wie diese Analyse in R mit der Funktion CPAT::Andrews.test() aus dem Paket CPAT durchgeführt werden kann. Wir testen zunächst auf eine signifikante Diskrepanz der Doppelgänger-Gap in Form eines Sturkturbruchs ab 2017 und fassen die Ergebnisse tabellarisch mit broom::tidy() und gt::gt() zusammen.\n\nlibrary(CPAT)\n\n# Andrews' (2003) Test für 2017 durchführen\nAndrews.test(\n  x = gdp_gap$gdp_gap, \n  M = which(gdp_gap$Time == 2017)\n) %&gt;% \n  broom::tidy() %&gt;% \n  gt::gt() %&gt;%\n  tabopts\n\n\n\n\n\n\n\n\nstatistic\np.value\nmethod\n\n\n14.196\n0.693\nAndrews' Test for Structural Change\n\n\n\n\n\n\n\nTabelle 11.3: Andrews’ (1993) End-of-Sample Instability Test\n\n\n\nGem. des großen \\(p\\)-Werts kann die Nullhypothese (keine strukturelle Veränderung ab 2017) nicht abgelehnt werden. Wir führen den Test nun für sämtliche Zeitpunkte ab 2017 durch und plotten die \\(p\\)-Werte nebst gepunkteten roten Hilfslinien für die gängigen Signifikanzniveaus (10%, 5%, 1%).\n\n# Andrews' (1993) test für \n# Post-Referendumsperioden\npvals_andrews &lt;- map(seq(2017, 2020.5, .25), \\(time) {\n  tibble(\n    Time = time,\n    gap = gdp_gap %&gt;% filter(Time == time) %&gt;% pull(gdp_gap),\n    pvalue = CPAT::Andrews.test(\n      x = gdp_gap$gdp_gap, \n      M = which(gdp_gap$Time == time)\n    )$p.value\n  )\n}) %&gt;% \n  bind_rows()\n\n\n# p-Werte für Post-Interventionsperioden\npvals_andrews %&gt;%\n  ggplot(mapping = aes(x = Time, y = pvalue)) + \n  geom_hline(\n    yintercept = c(.1,.05, .01), \n    lty = \"dotted\", \n    col = \"red\"\n  ) +\n  geom_line() +\n  scale_x_continuous(expand = c(0, 0)) +\n  cowplot::theme_cowplot()\n\n\n\n\n\n\nAbbildung 11.8: P-Werte für Andrews’ (2003) Test\n\n\n\n\nDer Verlauf der \\(p\\)-Werte zeigt deutlich, dass es für Zeitpunkte jenseits von 2018-Q3 Evidenz für eine strukturelle Veränderung der Doppelgänger-Gap für Großbrittannien gibt. Diese Ergebnisse untermauern die Signifikanz der in Born u. a. (2019) mit SCM gefundenen negativen Effekte des Brexit-Votums auf die Britische Volkswirtschaft weiter.\n\n\n\n\n\n\nAbadie, Alberto, Alexis Diamond, und Jens Hainmueller. 2014. „Comparative Politics and the Synthetic Control Method: COMPARATIVE POLITICS AND THE SYNTHETIC CONTROL METHOD“. American Journal of Political Science 59 (2): 495–510. https://doi.org/10.1111/ajps.12116.\n\n\nAbadie, Alexis Diamond, Alberto, und Jens Hainmueller. 2010. „Synthetic Control Methods for Comparative Case Studies: Estimating the Effect of California’s Tobacco Control Program.“ Journal of the American Statistical Association 105 (490): 493–505. https://doi.org/10.1198/jasa.2009.ap08746.\n\n\nAndrews, D. W. K. 2003. „End-of-Sample Instability Tests“. Econometrica 71 (6): 1661–94. https://doi.org/10.1111/1468-0262.00466.\n\n\nBorn, Benjamin, Gernot J Müller, Moritz Schularick, und Petr Sedláček. 2019. „The Costs of Economic Nationalism: Evidence from the Brexit Experiment*“. The Economic Journal 129 (623): 2722–44. https://doi.org/10.1093/ej/uez020.\n\n\nHainmueller, Jens, Alexis Diamond, und Alberto Abadie. 2011. „Synth: An R Package for Synthetic Control Methods in Comparative Case Studies“. Journal of Statistical Software 42 (13): 1–17. https://www.jstatsoft.org/v42/i13/.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Synthetic Control</span>"
    ]
  },
  {
    "objectID": "Literatur.html",
    "href": "Literatur.html",
    "title": "Literatur",
    "section": "",
    "text": "Abadie, Alberto, Alexis Diamond, and Jens Hainmueller. 2014.\n“Comparative Politics and the Synthetic Control Method:\nCOMPARATIVE POLITICS AND THE SYNTHETIC CONTROL METHOD.”\nAmerican Journal of Political Science 59 (2): 495–510. https://doi.org/10.1111/ajps.12116.\n\n\nAbadie, Alberto, and Guido W. Imbens. 2008. “On the Failure of the\nBootstrap for Matching Estimators.” Econometrica. Journal of\nthe Econometric Society 76 (6): 1537–57. https://doi.org/10.3982/ECTA6474.\n\n\nAbadie, Alberto, and Jann Spiess. 2022. “Robust Post-Matching\nInference.” Journal of the American Statistical\nAssociation 117 (538): 983–95. https://doi.org/10.1080/01621459.2020.1840383.\n\n\nAbadie, Alexis Diamond, Alberto, and Jens Hainmueller. 2010.\n“Synthetic Control Methods for Comparative Case Studies:\nEstimating the Effect of California’s Tobacco Control Program.”\nJournal of the American Statistical Association 105 (490):\n493–505. https://doi.org/10.1198/jasa.2009.ap08746.\n\n\nAcemoglu, Daron, Giuseppe De Feo, and Giacomo Davide De Luca. 2020.\n“Weak States: Causes and Consequences of the Sicilian\nMafia.” The Review of Economic Studies. https://doi.org/10.1093/restud/rdz009.\n\n\nAcemoglu, Daron, Simon Johnson, James A. Robinson, and Pierre Yared.\n2008a. “Income and Democracy.” American Economic\nReview 98 (3): 808–42. https://doi.org/10.1257/aer.98.3.808.\n\n\n———. 2008b. “Replication Data for: Income and Democracy.”\nICPSR - Interuniversity Consortium for Political; Social Research. https://doi.org/10.3886/E113251V1.\n\n\nAdireksombat, Kampon. 2010. “The Effects of the 1993 Earned Income\nTax Credit Expansion on the Labor Supply of Unmarried Women.”\nPublic Finance Review 38 (1): 11–40. https://doi.org/https://doi.org/10.1177/1091142109358626.\n\n\nAndrews, D. W. K. 2003. “End-of-Sample Instability Tests.”\nEconometrica 71 (6): 1661–94. https://doi.org/10.1111/1468-0262.00466.\n\n\nAustin, P. 2011. “An Introduction to Propensity Score Methods for\nReducing the Effects of Confounding in Observational Studies.”\nMultivariate Behavioral Research 46 (3): 399–424. https://doi.org/10.1080/00273171.2011.568786.\n\n\nAustin, Peter C., and Dylan S. Small. 2014. “The Use of\nBootstrapping When Using Propensity-Score Matching Without Replacement:\nA Simulation Study.” Statistics in Medicine 33 (24):\n4306–19. https://doi.org/10.1002/sim.6276.\n\n\nAustin, Peter C., and Elizabeth A. Stuart. 2017. “Estimating the\nEffect of Treatment on Binary Outcomes Using Full Matching on the\nPropensity Score.” Statistical Methods in Medical\nResearch 26 (6): 2505–25. https://doi.org/10.1177/0962280215601134.\n\n\nBarro, Robert J., and Jong Wha Lee. 2013. “A New Data Set of\nEducational Attainment in the World, 1950–2010.” Journal of\nDevelopment Economics 104: 184–98. https://doi.org/https://doi.org/10.1016/j.jdeveco.2012.10.001.\n\n\nBasten, Christoph, and Frank Betz. 2013. “Beyond Work Ethic:\nReligion, Individual, and Political Preferences.” American\nEconomic Journal: Economic Policy 5 (3): 67–91.\n\n\nBelloni, Alexandre, Daniel Chen, Victor Chernozhukov, and Christian\nHansen. 2012. “Sparse Models and Methods for Optimal Instruments\nwith an Application to Eminent Domain.” Econometrica 80\n(6): 2369–429.\n\n\nBelloni, Alexandre, and Victor Chernozhukov. 2013. “Least Squares\nAfter Model Selection in High-Dimensional Sparse Models.”\nBernoulli, 521–47.\n\n\nBelloni, Alexandre, Victor Chernozhukov, and Christian Hansen. 2014.\n“High-Dimensional Methods and Inference on Structural and\nTreatment Effects.” Journal of Economic Perspectives 28\n(2): 29–50.\n\n\nBodory, Hugo, Lorenzo Camponovo, Martin Huber, and Michael Lechner.\n2020. “The Finite Sample Performance of Inference Methods for\nPropensity Score Matching and Weighting Estimators.” Journal\nof Business & Economic Statistics. https://doi.org/10.2139/ssrn.2731969.\n\n\nBorn, Benjamin, Gernot J Müller, Moritz Schularick, and Petr Sedláček.\n2019. “The Costs of Economic Nationalism: Evidence from the Brexit\nExperiment*.” The Economic Journal 129 (623): 2722–44.\nhttps://doi.org/10.1093/ej/uez020.\n\n\nCallaway, Brantly, and Pedro H. C. Sant’Anna. 2021.\n“Difference-in-Differences with Multiple Time Periods.”\nJournal of Econometrics 225 (2): 200–230. https://doi.org/10.1016/j.jeconom.2020.12.001.\n\n\nCattaneo, Matias D, Michael Jansson, and Xinwei Ma. 2020. “Simple\nLocal Polynomial Density Estimators.” Journal of the American\nStatistical Association 115 (531): 1449–55.\n\n\nCortez, Paulo, and Alice Maria Gonçalves Silva. 2008. “Using Data\nMining to Predict Secondary School Student Performance.”\n\n\nDahl, Robert Alan. 1971. Polyarchy: Participation and Opposition:\nParticipation and Opposition. New Haven: Yale Univ. Press.\n\n\nDi Tella, Rafael, and Ernesto Schargrodsky. 2004. “Do Police\nReduce Crime? Estimates Using the Allocation of Police Forces After a\nTerrorist Attack.” American Economic Review 94 (1):\n115–33. https://doi.org/10.1257/000282804322970733.\n\n\nEfron, Bradley, Trevor Hastie, Iain Johnstone, and Robert Tibshirani.\n2004. “Least Angle Regression.”\n\n\nEissa, N., and J. B. Liebman. 1996. “Labor Supply Response to the\nEarned Income Tax Credit.” The Quarterly Journal of\nEconomics 111 (2): 605–37. https://doi.org/10.2307/2946689.\n\n\nFearon, James D., and David D. Laitin. 2003. “Ethnicity,\nInsurgency, and Civil War.” American Political Science\nReview 97 (01): 75–90. https://doi.org/10.1017/s0003055403000534.\n\n\nGelman, Andrew, and Guido Imbens. 2019. “Why High-Order\nPolynomials Should Not Be Used in Regression Discontinuity\nDesigns.” Journal of Business & Economic Statistics\n37 (3): 447–56.\n\n\nGoodman-Bacon, Andrew. 2021. “Difference-in-Differences with\nVariation in Treatment Timing.” Journal of Econometrics\n225 (2): 254–77. https://doi.org/10.1016/j.jeconom.2021.03.014.\n\n\nHahn, P Richard, Carlos M Carvalho, David Puelz, and Jingyu He. 2018.\n“Regularization and Confounding in Linear Regression for Treatment\nEffect Estimation.”\n\n\nHainmueller, Jens. 2012. “Entropy Balancing for Causal Effects: A\nMultivariate Reweighting Method to Produce Balanced Samples in\nObservational Studies.” Political Analysis 20 (1):\n25–46. https://doi.org/10.1093/pan/mpr025.\n\n\nHainmueller, Jens, Alexis Diamond, and Alberto Abadie. 2011.\n“Synth: An r Package for Synthetic Control Methods in Comparative\nCase Studies.” Journal of Statistical Software 42 (13):\n1–17. https://www.jstatsoft.org/v42/i13/.\n\n\nHájek, J. 1971. “Comment on ‘an Essay on the Logical\nFoundations of Survey Sampling’ by Basu, d.”\nFoundations of Statistical Inference 236.\n\n\nHill, Jennifer, and Jerome P. Reiter. 2006. “Interval Estimation\nfor Treatment Effects Using Propensity Score Matching. Statistics in\nMedicine.” Statistics in Medicine 25 (13): 2230–56. https://doi.org/10.1002/sim.2277.\n\n\nHirano, Keisuke, Guido Imbens, and Geert Ridder. 2003. “Efficient\nEstimation of Average Treatment Effects Using the Estimated Propensity\nScore.” Econometrica 71 (4): 1161–89. https://doi.org/10.1111/1468-0262.00442.\n\n\nHoerl, Arthur E, and Robert W Kennard. 1970. “Ridge regression: Biased estimation for nonorthogonal\nproblems.” Technometrics 12 (1): 55–67.\n\n\nHuntington, Samuel P. 1991. The Third Wave: Democratization in the\nLate Twentieth Century: Democratization in the Late Twentieth\nCentury. Norman, OK: Univ. of Oklahoma Press.\n\n\nHuntington-Klein, Nick. 2021. The Effect: An Introduction to\nResearch Design and Causality. Chapman; Hall/CRC. https://doi.org/10.1201/9781003226055.\n\n\nImbens. 2016. “Matching on the Estimated Propensity Score.”\nEconometrica 84 (2): 781–807. https://doi.org/10.3982/ecta11293.\n\n\nImbens, G. W., and Thomas Lemieux. 2008. “Regression Discontinuity\nDesigns: A Guide to Practice.” Journal of Econometrics\n142 (2): 615–35.\n\n\nImbens, Guido, and Karthik Kalyanaraman. 2012. “Optimal Bandwidth\nChoice for the Regression Discontinuity Estimator.” The\nReview of Economic Studies 79 (3): 933–59.\n\n\nLee, David S. 2008. “Randomized Experiments from Non-Random\nSelection in US House Elections.” Journal of\nEconometrics 142 (2): 675–97.\n\n\nLove, Thomas. 2004. “Graphical Display of Covariate\nBalance.” Presentation.\n\n\nMcCrary, Justin. 2008. “Manipulation of the Running Variable in\nthe Regression Discontinuity Design: A Density Test.” Journal\nof Econometrics 142 (2): 698–714.\n\n\nMiguel, Edward, Shanker Satyanath, and Ernest Sergenti. 2004.\n“Economic Shocks and Civil Conflict: An Instrumental Variables\nApproach.” Journal of Political Economy 112 (4): 725–53.\nhttps://doi.org/10.1086/421174.\n\n\nRosenbaum, Paul R., and Donald R. Rubin. 1983. “The Central Role\nof the Propensity Score in Observational Studies for Causal\nEffects.” Biometrika 70 (1): 170–84. https://doi.org/10.1017/cbo9780511810725.016.\n\n\nRueschemeyer, Dietrich, Evelyne H. Stephens, and John D. Stephens. 1992.\nCapitalist Development and Democracy. Cambridge: Polity Pr.\n\n\nTibshirani, Robert. 1996. “Regression Shrinkage and Selection via\nthe Lasso.” Journal of the Royal Statistical Society Series\nB: Statistical Methodology 58 (1): 267–88.\n\n\nWeber, Max. 2004. Die Protestantische Ethik Und Der Geist Des\nKapitalismus. Vol. 1614. CH Beck.\n\n\nWooldridge, Jeffrey. 2010. Econometric Analysis of Cross Section and\nPanel Data. Second edition. Cambridge, Massachusetts: MIT.",
    "crumbs": [
      "Literatur"
    ]
  },
  {
    "objectID": "FixedEffects.html#fixed-effects",
    "href": "FixedEffects.html#fixed-effects",
    "title": "\n5  Panel-Daten\n",
    "section": "\n5.2 Fixed Effects",
    "text": "5.2 Fixed Effects\nAnhand von Panel-Daten mit \\(T\\geq2\\) kann das in Kapitel 5.1 beschreibene Problem unbeobachtbarer zeit-invarianter Heterogenitäten behoben werden. Betrachte den in Abbildung 5.2 dargestellten DGP für \\(T=2\\) Zeitperioden.\n\n\n\n\n\nFE_dag2\nU\nUX\nXU-&gt;X\nB1\nBt=1U-&gt;B1\nY1\nYt=1U-&gt;Y1\nB2\nBt=2U-&gt;B2\nY2\nYt=2U-&gt;Y2\nX-&gt;B1\nX-&gt;Y1\nX-&gt;B2\nX-&gt;Y2\nB1-&gt;Y1\nB1-&gt;B2\nB2-&gt;Y2\n\n\n\n\nAbbildung 5.2: FE-Design mit Backdoors durch beobachtete und unbeobachtete zeit-invariante Variablen\n\n\n\n\nDie \\(\\delta_i\\) können als individuelle Achsenabschnitte (“feste Effekte”) interpretieren werden, weshalb Modell \\(\\eqref{eq:femodel}\\) auch als “Fixed-Effects-Modell” bezeichnet wird. Modell \\(\\eqref{eq:femodel}\\) kann als ein Regressionsmodell mit \\(n-1\\) Dummy-Variablen und einer Konstante umgeschrieben werden:\n\\[\\begin{align}\nY_{it} = \\beta_0 + \\beta_1 X_{it} + \\gamma_2 D^{(2)}_i + \\gamma_3 D^{(3)}_i + \\cdots + \\gamma_n D^{(n)}_i + u_{it} \\label{eq:drmodel}.\n\\end{align}\\]\nDas Modell \\(\\eqref{eq:drmodel}\\) hat \\(n\\) verschiedene Intercepts — einen für jede Entität. Die Modelle (ref?)(eq:femodel) und \\(\\eqref{eq:drmodel}\\) sind gleichwertige Darstellungen des Fixed-Effects-Modells (Hinweis: \\(\\beta_0\\) ist der Intercept des Fixed-Effects-Modells in Gleichung 10.2).\nFixed Effects können Endogenität aufgrund simultaner Kausalität oder ausgelassender zeitlich variierender Faktoren (Variablen, welche die abhängige Variable beeinflussen und mit der Behandlungsvariable korreliert sind) nicht beheben. In solchen Szenarien können Panel-Methoden in Kombination mit einer Schätzstrategie basierend auf Instrument-Variablen hilfreich sein. Wir betrachten solche Schätzer in Kapitel Kapitel 6.\n\n\n\n\n# Datensatz 'paneldata.csv' einlesen\npaneldata &lt;- read_csv(\"datasets/paneldata.csv\") %&gt;% \n  select(X, Y, ID, time, col)\n\n\n# Datensatz balanced?\nlibrary(plm)\n\nis.pbalanced(\n  x = paneldata, \n  index = c(\"ID\", \"time\")\n)\n\n[1] TRUE\n\n\n\n# Panel-Dimensionen bestimmen\npaneldata %&gt;%\n  summarise(\n    N = unique(ID) %&gt;% length(),\n    T = unique(time) %&gt;% length()\n  )\n\n# A tibble: 1 × 2\n      N     T\n  &lt;int&gt; &lt;int&gt;\n1    12     8\n\n\n\nlibrary(fixest)\n\n# Naive KQ-Schätzung\npanel_KQ &lt;- feols(\n  fml = Y ~ X, \n  data = paneldata\n)\n\nsummary(panel_KQ)\n\nOLS estimation, Dep. Var.: Y\nObservations: 96\nStandard-errors: IID \n            Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept) -1.45318   1.008859 -1.44042   0.15307    \nX            3.76470   0.134364 28.01868 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 4.63461   Adj. R2: 0.891928\n\n\n\n# Fixed-Effects-Schätzung\npanel_FE &lt;- feols(\n  fml = Y ~ X | ID,  \n  data = paneldata\n)\n\nsummary(panel_FE)\n\nOLS estimation, Dep. Var.: Y\nObservations: 96\nFixed-effects: ID: 12\nStandard-errors: Clustered (ID) \n  Estimate Std. Error  t value   Pr(&gt;|t|)    \nX -1.04507    0.10473 -9.97865 7.5526e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.746006     Adj. R2: 0.996829\n                 Within R2: 0.602694\n\n\n\nlibrary(plm)\n\n# Random-Effects-Schätzung\npanel_RE &lt;- plm(\n  formula = Y ~ X,  \n  model = \"random\",\n  index = c(\"ID\", \"time\"),  \n  data = paneldata\n)\n\nsummary(panel_RE)\n\nOneway (individual) effect Random Effect Model \n   (Swamy-Arora's transformation)\n\nCall:\nplm(formula = Y ~ X, data = paneldata, model = \"random\", index = c(\"ID\", \n    \"time\"))\n\nBalanced Panel: n = 12, T = 8, N = 96\n\nEffects:\n                 var std.dev share\nidiosyncratic 0.6437  0.8023 0.229\nindividual    2.1732  1.4742 0.771\ntheta: 0.811\n\nResiduals:\n   Min. 1st Qu.  Median 3rd Qu.    Max. \n-6.0355 -1.9888 -0.1651  1.9196  6.4374 \n\nCoefficients:\n            Estimate Std. Error z-value  Pr(&gt;|z|)    \n(Intercept) 18.34586    2.31566  7.9225 2.328e-15 ***\nX            0.77031    0.26346  2.9238  0.003458 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    818.14\nResidual Sum of Squares: 749.94\nR-Squared:      0.083362\nAdj. R-Squared: 0.07361\nChisq: 8.54862 on 1 DF, p-value: 0.0034579\n\n\n\nlibrary(cowplot)\n\npaneldata &lt;- paneldata %&gt;% \n  mutate(\n    # Vorhergesagte Werte für FE-Schätzung\n    yhat_FE = fitted(panel_FE),\n    # Vorhergesagte Werte für RE-Schätzung\n    yhat_RE = predict(panel_RE)\n  )\n\nggplot(\n  data = paneldata,\n  mapping = aes(x = X, y = Y)\n) +\n  geom_point(\n    mapping = aes(color = col), \n    show.legend = F\n  ) +\n  # Pooling\n  geom_smooth(\n    method = \"lm\", \n    se = F,\n    col = \"black\"\n  ) +\n  # Fixed Effects\n  geom_line(\n    mapping = aes(y = yhat_FE, group = ID, col = col), \n    show.legend = F\n  ) +\n  # Random Effects\n  geom_line(\n    mapping = aes(y = yhat_RE), \n    lty = \"dashed\", \n    show.legend = F\n  ) +\n  theme_cowplot()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html#differenzen-und-fixed-effects",
    "href": "FixedEffects.html#differenzen-und-fixed-effects",
    "title": "\n5  Panel-Daten\n",
    "section": "\n5.2 Differenzen und Fixed Effects",
    "text": "5.2 Differenzen und Fixed Effects\nAnhand von Panel-Daten mit \\(T\\geq2\\) können die in Kapitel 5.1 beschreibene Backdoors durch unbeobachtbare zeit-invariante Heterogenitäten mit Regression geschlossen werden.\n\n\n\n\n\nFE_dag2\nU\nUX\nXU-&gt;X\nB1\nBt=1U-&gt;B1\nY1\nYt=1U-&gt;Y1\nB2\nBt=2U-&gt;B2\nY2\nYt=2U-&gt;Y2\nX-&gt;B1\nX-&gt;Y1\nX-&gt;B2\nX-&gt;Y2\nB1-&gt;Y1\nB1-&gt;B2\nB2-&gt;Y2\n\n\n\n\nAbbildung 5.2: FE-Design mit Backdoors durch beobachtete und unbeobachtete zeit-invariante Variablen\n\n\n\n\nDefiniere \\[\\delta_i = \\beta_0 + \\beta_3 U_i.\\] Nach einsetzen in \\(\\eqref{eq:unobshetmodel}\\) erhalten wir\n\\[\\begin{align}\n  Y_{it} = \\delta_i + \\beta_1 B_{it} + \\beta_2 X_i + \\epsilon_{it} \\label{eq:femodel},\n\\end{align}\\]\nmit einheiten-spezifischen Konstanten \\(\\delta_i\\), \\(i=1,\\dots,n\\). Die \\(\\delta_i\\) können als individuelle Achsenabschnitte (“feste Effekte”) interpretieren werden, weshalb Modell \\(\\eqref{eq:femodel}\\) auch als “Fixed-Effects-Modell” bezeichnet wird.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  },
  {
    "objectID": "FixedEffects.html#regression-in-differenzen",
    "href": "FixedEffects.html#regression-in-differenzen",
    "title": "\n5  Panel-Daten\n",
    "section": "\n5.3 Regression in Differenzen",
    "text": "5.3 Regression in Differenzen\nWir betrachten zunächst den in Abbildung 5.2 dargestellten DGP für \\(T=2\\) Zeitperioden. In dieser Situation können Backdoors durch \\(U\\) anhand einer simplen Transformation von Modell \\(\\eqref{eq:femodel}\\) geschlossen werden: Regression in Zeit-Differenzen zwischen den Perioden \\(t=2\\) und \\(t=1\\), \\[\\begin{align}\n  \\Delta Y_{it} = \\beta_1 \\Delta B_{it} + e_{it}, \\qquad i=1,\\dots,n,\\qquad t=1,2 \\label{eq:femodeldiff},\n\\end{align}\\] wobei \\(\\Delta\\,Y_{it} := Y_{i2} - Y_{i1}\\) und \\(e_{it} := \\epsilon_{i2} - \\epsilon_{i1}\\) für \\(t=2\\). Beachte, dass \\(\\Delta\\delta_i=\\Delta X_i=0\\). Differenzieren ergibt also ein Modell, in dem weder für \\(X_i\\) noch für die (unbeobachtbaren) \\(\\delta_i\\) kontrolliert werden muss, damit \\(\\beta_1\\) identifiziert werden kann. Der Behandlungseffekt kann mit KQ geschätzt werden.\nWir veranschaulichen die Schätzung eines Behandlungseffekts mit dem Differenzen-Ansatz für einen simulierten Datensatz paneldata.csv. Der mit \\(n=12\\) Beobachtungseinheiten, die über \\(T=8\\) Perioden beobachtet wurden. Alle Einheiten weisen unbeobachtbare zeit-invariante Heterogenitäten auf. Der wahre Behandlungseffekt beträgt jeweils \\(\\beta_1 = -1\\).1\n1 Der (R code für den) DGP ist diesem StackExchange-Post entnommen.\n# Datensatz 'paneldata.csv' einlesen\npaneldata &lt;- read_csv(\"datasets/paneldata.csv\") %&gt;% \n  select(X, Y, ID, time, col)\n\n\n# Datensatz balanced?\nlibrary(plm)\n\nis.pbalanced(\n  x = paneldata, \n  index = c(\"ID\", \"time\")\n)\n\n[1] TRUE\n\n\n\n# Panel-Dimensionen bestimmen\npaneldata %&gt;%\n  summarise(\n    N = unique(ID) %&gt;% length(),\n    T = unique(time) %&gt;% length()\n  )\n\n# A tibble: 1 × 2\n      N     T\n  &lt;int&gt; &lt;int&gt;\n1    12     8\n\n\n\n# Subsetting für 2 Perioden (t = {1, 2})\npaneldata_T2 &lt;- paneldata %&gt;% \n  filter(\n    dplyr::between(time, 1, 2)\n  )\n\n\nlibrary(fixest)\n\n# Naive KQ-Schätzung für t = 1\npanel_KQ &lt;- feols(\n  fml = Y ~ X, \n  data = paneldata %&gt;% \n    filter(time == 1)\n)\n\nsummary(panel_KQ)\n\nOLS estimation, Dep. Var.: Y\nObservations: 12\nStandard-errors: IID \n             Estimate Std. Error  t value   Pr(&gt;|t|)    \n(Intercept) -0.325557   1.977509 -0.16463 8.7252e-01    \nX            3.512724   0.255879 13.72804 8.1671e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 3.12745   Adj. R2: 0.944573\n\n\n\nlibrary(cowplot)\n\n# Plot: Naiver KQ-Schätzer für t = 1\n(\n  p_panel &lt;- ggplot(\n    mapping = aes(x = X, y = Y)\n  ) +\n    geom_point(\n      data = paneldata %&gt;% \n        filter(time &gt; 1),\n      color = \"gray\",\n      show.legend = F\n    ) +\n    geom_point(\n      data = paneldata %&gt;% \n        filter(time == 1),\n      mapping = aes(color = col),\n      show.legend = F\n    ) +\n    # Naive KQ-Schätzung f. t = 1\n    geom_smooth(\n      data = paneldata %&gt;% \n        filter(time == 1),\n      method = \"lm\", \n      se = F,\n      col = \"black\"\n    ) +\n    theme_cowplot()\n)\n\n\n\n\n\n\n\n\n# Panel-Schätzer: KQ-Regression in Differenzen\npanel_diff &lt;- feols(\n  fml = d(Y) ~ d(X), \n  data = paneldata %&gt;% \n      filter(\n        dplyr::between(time, 1, 2)\n      ),\n  panel.id = ~ ID + time\n)\n\nsummary(panel_diff)\n\nOLS estimation, Dep. Var.: d(Y, 1)\nObservations: 12\nStandard-errors: Clustered (ID) \n            Estimate Std. Error   t value Pr(&gt;|t|)    \n(Intercept) -0.16789   0.280039 -0.599525 0.560968    \nd(X, 1)     -1.02316   0.335264 -3.051800 0.011012 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.891809   Adj. R2: 0.522708\n\n\n\n# Plot: KQ-Schätzer in Differenzen\npaneldata_diff &lt;- paneldata %&gt;% \n  mutate(\n    DeltaX = X - dplyr::lag(X),\n    DeltaY = Y - dplyr::lag(Y)\n  ) %&gt;%\n  drop_na()\n  \n  ggplot(\n    mapping = aes(x = DeltaX, y = DeltaY)\n  ) + \n    geom_point(\n      data = paneldata_diff %&gt;% \n        filter(time &gt; 2),\n      color = \"gray\",\n      show.legend = F\n    ) +\n    geom_point(\n      data = paneldata_diff %&gt;% \n        filter(time == 2),\n      mapping = aes(color = col),\n      show.legend = F\n    ) +\n  geom_smooth(\n    data = paneldata_diff %&gt;% \n      filter(time == 2),\n    method = \"lm\", \n    se = F,\n    color = \"black\"\n  ) + \n  theme_cowplot()\n\n\n\n\n\n\n\nErweiterung auf alle Perioden:\n\n# Naive KQ-Schätzung für t = 1,...,8\npanel_KQ &lt;- feols(\n  fml = Y ~ X, \n  data = paneldata \n)\n\nsummary(panel_KQ)\n\nOLS estimation, Dep. Var.: Y\nObservations: 96\nStandard-errors: IID \n            Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept) -1.45318   1.008859 -1.44042   0.15307    \nX            3.76470   0.134364 28.01868 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 4.63461   Adj. R2: 0.891928\n\n\n\nlibrary(cowplot)\n\n# Plot: Naiver KQ-Schätzer für t = 1,...,8\nggplot(\n  mapping = aes(x = X, y = Y)\n) +\n  geom_point(\n    data = paneldata %&gt;% \n      filter(time &gt; 1),\n    color = \"gray\",\n    show.legend = F\n  ) +\n  geom_point(\n    data = paneldata %&gt;% \n      filter(time == 1),\n    mapping = aes(color = col),\n    show.legend = F\n  ) +\n  # Naive KQ-Schätzung f. t = 1\n  geom_smooth(\n    data = paneldata %&gt;% \n      filter(time == 1),\n    method = \"lm\", \n    se = F,\n    col = \"black\"\n  ) +\n  theme_cowplot()\n\n\n\n\n\n\n\n\n# Panel-Schätzer: KQ-Regression in Differenzen\npanel_diff &lt;- feols(\n  fml = d(Y) ~ d(X) - 1, \n  data = paneldata,\n  panel.id = ~ ID + time\n)\n\nsummary(panel_diff)\n\nOLS estimation, Dep. Var.: d(Y, 1)\nObservations: 84\nStandard-errors: Clustered (ID) \n         Estimate Std. Error  t value   Pr(&gt;|t|)    \nd(X, 1) -0.982042   0.135217 -7.26269 1.6178e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 1.12641   Adj. R2: 0.571235\n\n\n\n# Plot: KQ-Schätzer in Differenzen (alle t)\n\n  ggplot(\n    data = paneldata_diff,\n    mapping = aes(x = DeltaX, y = DeltaY)\n  ) + \n    geom_point(\n      color = \"gray\",\n      show.legend = F\n    ) +\n    geom_point(\n      mapping = aes(color = col),\n      show.legend = F\n    ) +\n  geom_smooth(\n    method = \"lm\", \n    se = F,\n    color = \"black\"\n  ) + \n  theme_cowplot()\n\n\n\n\n\n\n\n\n5.3.1 Fixed Effects\nModell \\(\\eqref{eq:femodel}\\) kann weiterhin als eine Regression mit \\(n-1\\) Dummy-Variablen und einer Konstante umgeschrieben werden:\n\\[\\begin{align}\n  Y_{it} = \\beta_0 + \\beta_1 X_{it} + \\gamma_2 D^{(2)}_i + \\gamma_3 D^{(3)}_i + \\cdots + \\gamma_n D^{(n)}_i + \\epsilon_{it} \\label{eq:drmodel}.\n\\end{align}\\]\nDas Modell \\(\\eqref{eq:drmodel}\\) hat \\(n\\) verschiedene Achsenabschnitte — einen für jede Beobachtungseinheit.2 Die Modelle \\(\\eqref{eq:femodel}\\) und \\(\\eqref{eq:drmodel}\\) sind gleichwertige Darstellungen des Fixed-Effects-Modells.\n2 Für \\(n-1\\) Einheiten ist der individuelle Achsenabschnitt damit \\(\\beta_0 + D^{(i)}_i\\) und für eine Einheit \\(\\beta_0\\). Diese Einheit wird auch als Referenzkategorie bezeichnet. Alternativ kann das Modell mit \\(n\\) Dummies und ohne die Konstante \\(\\beta_0\\) geschrieben werden.Fixed Effects können Endogenität aufgrund simultaner Kausalität oder ausgelassender zeitlich variierender Faktoren (Variablen, welche die abhängige Variable beeinflussen und mit der Behandlungsvariable korreliert sind) nicht beheben. In solchen Szenarien können Panel-Methoden in Kombination mit einer Schätzstrategie basierend auf Instrument-Variablen hilfreich sein. Wir betrachten solche Schätzer in Kapitel Kapitel 6.\n\nInteraktive Illustration von Panel-Schätzern\n\n\n\n# Fixed-Effects-Schätzung\npanel_FE &lt;- feols(\n  fml = Y ~ X | ID,  \n  data = paneldata\n)\n\nsummary(panel_FE)\n\nOLS estimation, Dep. Var.: Y\nObservations: 96\nFixed-effects: ID: 12\nStandard-errors: Clustered (ID) \n  Estimate Std. Error  t value   Pr(&gt;|t|)    \nX -1.04507    0.10473 -9.97865 7.5526e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.746006     Adj. R2: 0.996829\n                 Within R2: 0.602694\n\n\n\nlibrary(plm)\n\n# Random-Effects-Schätzung\npanel_RE &lt;- plm(\n  formula = Y ~ X,  \n  model = \"random\",\n  index = c(\"ID\", \"time\"),  \n  data = paneldata\n)\n\nsummary(panel_RE)\n\nOneway (individual) effect Random Effect Model \n   (Swamy-Arora's transformation)\n\nCall:\nplm(formula = Y ~ X, data = paneldata, model = \"random\", index = c(\"ID\", \n    \"time\"))\n\nBalanced Panel: n = 12, T = 8, N = 96\n\nEffects:\n                 var std.dev share\nidiosyncratic 0.6437  0.8023 0.229\nindividual    2.1732  1.4742 0.771\ntheta: 0.811\n\nResiduals:\n   Min. 1st Qu.  Median 3rd Qu.    Max. \n-6.0355 -1.9888 -0.1651  1.9196  6.4374 \n\nCoefficients:\n            Estimate Std. Error z-value  Pr(&gt;|z|)    \n(Intercept) 18.34586    2.31566  7.9225 2.328e-15 ***\nX            0.77031    0.26346  2.9238  0.003458 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    818.14\nResidual Sum of Squares: 749.94\nR-Squared:      0.083362\nAdj. R-Squared: 0.07361\nChisq: 8.54862 on 1 DF, p-value: 0.0034579\n\n\n\npaneldata &lt;- paneldata %&gt;% \n  mutate(\n    # Vorhergesagte Werte für FE-Schätzung\n    yhat_FE = fitted(panel_FE),\n    # Vorhergesagte Werte für RE-Schätzung\n    yhat_RE = predict(panel_RE)\n  )\n\nggplot(\n  data = paneldata,\n  mapping = aes(x = X, y = Y)\n) +\n  geom_point(\n    mapping = aes(color = col), \n    show.legend = F\n  ) +\n  # Pooling\n  geom_smooth(\n    method = \"lm\", \n    se = F,\n    col = \"black\"\n  ) +\n  # Fixed Effects\n  geom_line(\n    mapping = aes(y = yhat_FE, group = ID, col = col), \n    show.legend = F\n  ) +\n  # Random Effects\n  geom_line(\n    mapping = aes(y = yhat_RE), \n    lty = \"dashed\", \n    show.legend = F\n  ) +\n  theme_cowplot()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Panel-Daten</span>"
    ]
  }
]