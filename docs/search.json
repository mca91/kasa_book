[
  {
    "objectID": "Machine Learning.html",
    "href": "Machine Learning.html",
    "title": "\n16  Neuronale Netzwerke\n",
    "section": "",
    "text": "16.1 Grundlagen und Vokabeln\nNN bestehen aus einer (often großen) Anzahl so genannter künstlicher Neuronen. Ein Neuron ist eine mathematische Funktion, die mehrere Eingaben empfängt, diese unter Verwendung von Gewichten linear kombiniert und eine Ausgabe durch Verwendung einer Aktivierungsfunktion generiert.\nDie Neuronen eines NN sind in Schichten (Layers) organisiert. Jedes Layer verarbeitet die Eingabedaten und gibt die Ergebnisse an das nächste Layer weiter, wobei die Neuronen verschiedener Layer miteinander verknüpft werden. Während das Eingabe-Layer (Input) die “Rohdaten” (bspw. beobachtete Regressorwerte) aufnimmt und sie an die erste versteckte Schicht (Hidden Layer) weiterleitet, ist die Hauptaufgabe der Neuronen in den Hidden Layers, komplexe Muster und Merkmale in den Daten zu erkennen und zu verarbeiten. Jedes Hidden Layer transformiert die empfangenen Daten anhand seiner Neuronen, bevor diese an das nächste Layer weitergeleitet werden. Das letzte Layer in einem neuronalen Netzwerk ist das Ausgabe-Layer (Output Layer), das die endgültige Vorhersage für die Outcome-Variable basierend auf den verarbeiteten Daten liefert.\nDie Stärke der Verknüpfungen zwischen den Neuronen wird durch die Gewichte \\(w\\) bestimmt, welche während des Trainingsprozesses angepasst werden, um das Modell hinsichtlich der (Vorhersage) einer Zielvariable zu optimieren. Die \\(w\\) bestimmen, wie stark die Aktivierung eines Neurons in einer Schicht die Aktivierung der Neuronen in der nächsten Schicht beeinflusst. Das Netzwerk kann so tiefe und abstrakte Strukturen eines Datensatzes abbilden.\nNNEX\nX1\nX1V1\nV1(A)X1-&gt;V1\nw11V2\nV2(A)X1-&gt;V2\nw12V3\nV3(A)X1-&gt;V3\nw13X2\nX2X2-&gt;V1\nw21X2-&gt;V2\nw22X2-&gt;V3\nw23Y\nY(A)V1-&gt;Y\nw31V2-&gt;Y\nw32V3-&gt;Y\nw33\n\n\n\nAbbildung 16.1: Neuronales Netzwerk mit einem Hidden Layer\nAngenommen wir interessieren uns für die Vorhersage einer Outcome-Variable \\(Y\\) mit den Regressoren \\(X_1\\) und \\(X_2\\). Abbildung 16.1 zeigt ein mögliches NN mit 3 Neuronen \\(V_1\\), \\(V_2\\), \\(V_3\\) in einem Hidden Layer. Die Neuronen im Hidden Layer empfangen Eingaben aus dem Input Layer, bestehend aus Beobachtungen der Variablen \\(X_1\\) und \\(X_2\\), und gewichten diese Informationen gemäß der Vorschrift\n\\[\\begin{align*}\n  h_i = A\\left(\\sum_{j=1}^{2} w_{ji} \\cdot x_j + b_i\\right) \\quad \\text{für } i = 1, 2, 3.\n\\end{align*}\\]\nHierbei sind \\(w_{ji}\\) die Gewichte der Verbindung von Input \\(j\\) zu Neuron \\(i\\) und \\(b_i\\) ist ein Bias.1 \\(A(\\cdot)\\) ist eine Aktivierungsfunktion, die in Abhängigkeit der zu modellierenden Daten gewählt wird.\nDas Ausgabe-Neuron für \\(Y\\) verarbeitet die Informationen aus dem Hidden Layer ebenfalls anhand einer Linearkombination, die mit einer Aktivierungsfunktion transformiert wird,\n\\[\\begin{align*}\n  y = A\\left(\\sum_{i=1}^{3} w_{i} \\cdot h_i + b_y\\right).\n\\end{align*}\\]\nEin solches NN “lernt” Relationen zwischen \\(Y\\) und den Regressoren \\(X_1\\) und \\(X_2\\), indem die Gewichte anhand eines Algorithmus derart gewählt werden, dass der Fehler zwischen den vorhergesagten und den tatsächlichen Werten von \\(Y\\) — gemessen mit einer Verlustfunktion (Loss-Funktion) — minimiert wird. Dieser Lernprozess erfolgt unter Verwendung numerischer Optimierungsverfahren wie Gradientenabstieg (Gradient Descent).",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Neuronale Netzwerke</span>"
    ]
  },
  {
    "objectID": "Machine Learning.html#sec-nn-basics",
    "href": "Machine Learning.html#sec-nn-basics",
    "title": "\n16  Neuronale Netzwerke\n",
    "section": "",
    "text": "1 Der Bias ist analog zur Konstante in einer Regression.\n\n\n\n16.1.1 Training Neuronaler Netze\nDer Anpassungsprozess eines NN an einen Datensatz (Training) wird grob durch folgende Schritte bestimmt:\n\nDas Netz (Gewichte) wird initialisiert.\nDie Inputs jeder Beobachtung im Trainingsdatensatz werden durch das NN geleitet (Forward Pass): Jedes Layer transformiert die Daten mit Hilfe von Gewichten und Aktivierungsfunktionen, um eine Vorhersage von \\(Y\\) zu erzeugen.\nDer Loss wird berechnet, indem die Vorhersage von \\(Y\\) mit dem tatsächlichen Wert verglichen wird. Die Verlustfunktion wird entsprechend der Definition von \\(Y\\) gewählt. Typische Verlustfunktionen sind Quadratic Loss (analog zur Schätzung von linearen Regressionsmodellen mit KQ) oder Logistic Loss (analog zu logistischer Regression).\n\nZur Anpassung der Gewichte wird der Gradient2 der Verlustfunktion hinsichtlich der Gewichte des NN ermittelt.3 Ein Gradient-Descent-Algorithmus bestimmt, in welche Richtung die Gewichte verändert werden müssen, um den Vorhersagefehler zu verringern.\nFür diese Berechnung wird ein Backward Pass (auch Backpropagation genannt) genutzt. Hierbei wird der anhand des Ausgabelayers ermittelte Loss rückwärts durch das Netzwerk propagiert, um die Gewichte so anzupassen, dass der Fehler bei der Vorhersage von \\(Y\\) minimiert wird.\n\n\nDie Gewichte werden in kleinen Schritten, die durch die so genannte Lernrate bestimmt werden, in Richtung des negativen Gradienten angepasst. Dies bewirkt, dass die Gewichte so verändert werden, dass der Loss im Vergleich zur letzten Iteration verringert wird.\nUm den Lernprozess effizienter und stabiler zu machen, nutzen moderne Algorithmen weitere Schritte, bspw. eine Kombination von Gradientenabstieg mit Momentum. Dies beschleunigt die Anpassung der Gewichte und stabilisiert den Lernprozess. Fortgeschrittene Methoden verwenden adaptiven Lernraten, die die Schrittgröße für jedes Gewicht individuell anpassen können.\n\n\n2 Der Gradient einer Funktion \\(f(\\boldsymbol{x}) = f(x_1, x_2, \\ldots, x_k)\\) ist der Vektor der partiellen Ableitungen: \\(\\nabla f = \\left( \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\ldots, \\frac{\\partial f}{\\partial x_k} \\right)\\). \\(\\nabla f(\\boldsymbol{x})\\) zeigt die Richtung und Stärke der steilsten Änderung von \\(f\\) am Punkt \\(\\boldsymbol{x}\\) an.3 \\(\\nabla f\\) ist in NN grundsätzlich unbekannt. Gradient-Desenct-Algorithmen verwenden numerische Verfahren, um den Gradienten anhand von \\(f\\) zu approximieren.Die Schritte 4 und 5 werden wiederholt, bis ein Abbruchkriterium erfüllt ist: Der Fehler ist ausreichend klein, oder weitere Iterationen bewirken keine signifikante Änderung des Gradienten.\nEpochen und Iterationen\nDer Gesamte Prozess wird für mehrere Epochen (Epocs) durchlaufen, in denen jeweils der gesamte Trainingsdatensatz durch das NN geleitet wird. Um das Training auch für große Datensätze durchführen zu können, werden die Trainingsdaten hierbei üblicherweise in zufällig zusammengesetzen, kleineren Datensätzen (Batches) gruppiert. In jeder Epoche erfolgt die Anpassung der Gewichte für jedes durch das Netz geleitete Batch (jede Iteration):\n\n\nEpoche\n\n\nBatch\nForward Pass \\(\\rightarrow\\) Loss-Berechnung \\(\\rightarrow\\) Backpropagation \\(\\rightarrow\\) Gradient-Descent-Update\n\n\nBatch\nForward Pass \\(\\rightarrow\\) Loss-Berechnung \\(\\rightarrow\\) Backpropagation \\(\\rightarrow\\) Gradient-Descent-Update\n…\n\n\n\n\nEpoche\n     ...\n…\n\n\nFür das Training eines NN sind mehrere Epochen notwendig, weil ein einzelner Durchlauf der Daten oft nicht ausreicht, um die zugrundeliegenden Muster zu lernen. Durch Anpassung über mehrere Epochen können die Gewichte des Modells verfeinert werden, was insbesondere die Fähigkeit zur Generalisierung für ungesehene Daten verbessert. Die zufällige Einteilung der Daten in Batches zu Beginn jeder Epoche verhindert unter anderem, dass das NN lediglich die Reihenfolge der durchgeleiteten Datenpunkte lernt.\nDie Anzahl an zu durchlaufender Epochen ist ein Tuning-Parameter: Zu wenige Epochen führen zu einer schlechten Anpassung an die Daten, während zu viele Epochen das Risiko von Overfitting erhöhen. Um den Vorhersagefehler für ungesehene Daten einzuschätzen, wird ein Testdatensatz vorbehalten. Dieser Datensatz wird während des Trainings nicht zum Anpassen der Gewichte genutzt, sondern erst nach Abschluss einer Epoche für die Berechnung der Vorhersagequalität herangezogen. So kann jeweils nach dem Durchlauf einer Epoche beurteilt werden, wie gut das Modell auf neue, unbekannte Daten generalisiert. Hierbei können ein hoher Vorhersagefehler für den Testdatensatz und ein (viel) geringerer Fehler für den Trainingsdatensatz nach mehreren Epochen auf Overfitting hinweisen. Im empirischen Teil dieses Kapitels diskutieren wir (grafische) Methoden zur Beurteilung der Anpassung des Modells.\nBeim Training von NN können sogenannte Callback-Funktionen eingesetzt werden, um den Anpassungsprozess unter Einbezug von Zwischenergebnissen zu bestimmten Zeitpunkten während des Trainingsprozesses, z. B. am Ende jeder Epoche oder nach einer bestimmten Anzahl von Iterationen, zu evaluieren. Callbacks werden verwendet, um bestimmte Aktionen auszuführen, wie das Anpassen der Lernrate oder das Überwachen der Trainingsleistung: Ein Callback kann das Training automatisch stoppen (Early Stopping), wenn Anzeichen von Overfitting erkannt werden, beispielsweise wenn die Vorhersagegüte auf dem Test-Datensatz über mehrere Epochen hinweg stagniert. Dadurch wird ein unnötiges Fortsetzen des Trainings vermieden und ein Verlust der Generalisierungsfähigkeit auf neuen Daten verhindert.\nWir fassen die wichtigsten Begriffe für die Beschreibung von NN nachfolgend kurz zusammen.\nWesentliche Definitionen\n\nLayer: Eine Ebene von Neuronen im neuronalen Netzwerk. Es gibt das Eingabe-Layer, versteckte Layers (Hidden Layers) und das Ausgabe-Layer. Jedes Layer verarbeitet Informationen aus dem vorangegangenen Layer und gibt die Ergebnisse an das nächste Layer weiter.\nInput: Die Eingangsdaten oder Merkmale, die in das NN eingespeist werden. Jeder Input wird durch ein oder mehrere Neuronen im Eingabe-Layer repräsentiert.\nOutput: Das Ergebnis, welches das NN nach der Verarbeitung der Inputs liefert. Der Output wird durch die Neuronen im Output-Layer des NN erstellt.\nNeuron: Die kleinste Komponente eines NN. Jedes Neuron empfängt Inputs, multipliziert sie mit Gewichten, addiert einen Bias und gibt das Ergebnis nach Anwendung einer Aktivierungsfunktion weiter: Ein Neuron ist also eine mathematische Funktion, die Inputs aus dem vorherigen Layer mit einer transformierten Linearkombination verarbeitet und das Ergebnis das nächste Layers weiterleitet.\nForward Pass: Leitung der Trainingsdaten durch das NN und Berechnung der Vorhersage des Outcomes.\nLoss-Funktion: Mathematische Funktion, welche die Güte der Vorhersage des NN für das Outcome quantifiziert. Der Loss ist eine Funktion der zu trainierenden Parameter des NN.\nBackward Pass / Backpropagation: Ermittlung des Gradienten der Loss-Funktion durch Verkettung des Effekts der Gewichte über die Layers des NN.\n\nAktivierungsfunktion: Eine mathematische Funktion, die auf die gewichtete Summe der Eingaben eines Neurons angewendet wird. Die Aktivierungsfunktion bestimmt, ob ein Neuron aktiviert wird. Beispiele sind\n\\[\\begin{align*}\n    \\textup{ReLU}(z) =& \\max(0, z), \\\\[.5ex]\n    \\sigma(z) =&\\, \\frac{1}{1 + e^{-z}}, \\\\[.5ex]\n    \\tanh(z) =&\\, \\frac{e^z - e^{-z}}{e^z + e^{-z}}.\n  \\end{align*}\\]\n\nEpoche: Ein Trainingszyklus, bei dem der gesamte Trainingsdatensatz, aufgeteilt in Batches, das NN durchläuft.\nBatches: Zufällig eingeteilte Teilmengen der Beobachtungen des Trainingsdatensatzes.\nCallback: Eine Funktion, die im Zuge der Überwachung des des Trainings-Prozesses automatisch ausgeführt wird, um Aktionen wie Lernratenanpassung oder Trainingsstopp zu auszulösen.\n\nIm nächsten Abschnitt erläutern wir die Optimierung der Gewichte mit Gradient Descent beispielhaft anhand interaktiver Visualisierungen.",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Neuronale Netzwerke</span>"
    ]
  },
  {
    "objectID": "Machine Learning.html#optimierung-mit-gradient-descent",
    "href": "Machine Learning.html#optimierung-mit-gradient-descent",
    "title": "\n16  Neuronale Netzwerke\n",
    "section": "\n16.2 Optimierung mit Gradient Descent",
    "text": "16.2 Optimierung mit Gradient Descent\nGradient Descent ist ein iteratives Optimierungsverfahren zur Minimierung einer differenzierbaren Zielfunktion \\(f(w)\\). Ausgehend von einem Startwert \\(w_0\\) aktualisiert der Algorithmus die Variable \\(w\\) schrittweise gemäß einer Lernrate \\(\\eta\\) in die entgegengesetzte Richtung des Gradienten \\(\\nabla f(w)\\) der Funktion an der aktuellen \\(w\\). Mit \\(\\nabla f(w)\\) wird mathematisch die Richtung des steilsten Anstiegs von \\(f(w)\\) im Punkt \\(w\\) ermittelt. Der Algorithmus vollzieht eine Veränderung von \\(w\\) in die entgegengesetzten Richtung – die Richtung mit dem schnellsten Abstieg (Descent) der Zielfunktion.\nDer folgende Algorithmus zeigt die grundlegende Vorgehensweise des Gradientenabstiegsverfahrens für einen einziegen zu optimierenden Parameter \\(w\\) unter Einbeziehung eines Momentum-Terms \\(v_t\\).4 Der Momentum-Term dient dazu, das Konvergenzverhalten zu verbessern und lokale Minima effektiver zu überwinden. Die Stärke des Momentums \\(v_t\\) wird durch den Momentum-Faktor \\(\\alpha \\in [0,1)\\) bestimmt.\n4 In der Literatur wird \\(v_t\\) häufig auch als Velocity bezeichnet.\\[\\begin{align*}\n  \\small\n  & \\textbf{Algorithmus: Gradientenabstiegsverfahren mit Momentum} \\\\\n  & \\textup{Initialisiere: }\\\\[.5ex]\n  & \\quad w_0 \\text{ (Startpunkt) }\\\\\n  & \\quad \\eta \\text{ (Lernrate) }\\\\\n  & \\quad \\alpha \\text{ (Momentum-Faktor) }\\\\\n  & \\quad v_0 = 0 \\text{ (Anfangsmomentum) } \\\\[1em]\n  & \\text{Iteriere für } t = 0, 1, 2, \\dots \\text{ bis Konvergenz:} \\\\[.5ex]\n  & \\quad \\text{1. Berechne den Gradienten: } \\nabla f(w_t) \\\\\n  & \\quad \\text{2. Aktualisiere den Momentum-Term: } v_{t+1} = \\alpha v_t - \\eta \\nabla f(w_t) \\\\\n  & \\quad \\text{3. Aktualisiere die Position: } w_{t+1} = w_t + v_{t+1} \\\\\n  & \\quad \\text{4. Überprüfe das Abbruchkriterium } |\\nabla f(w_t)| &lt; \\epsilon\\text{ (für ein kleines $\\epsilon&gt;0$)} \\\\\n\\end{align*}\\]\nIn der nachfolgenden interaktiven Visualisierung illustrieren wir die Minimierung einer univariaten Funktion \\(\\color{blue}{f(w_t)}\\) über \\(w_t\\) anhand des obigen Algorithmus mit Lernrate \\(\\eta = .001\\) und Momentum-Faktor \\(\\alpha = .925\\).\nDer Gradient\\(\\color{orange}{\\nabla f(w_t)}\\) ist hier die 1. Ableitung von \\(\\color{blue}{f(w_t)}\\) nach \\(w_t\\). Die Richtung der Änderung von \\(\\color{blue}{f(w_t)}\\) in \\(w_t\\) wird durch den orangenen Pfeil angezeigt. Beachte, wie sich der Gradient bei Variation des Start-Punkts mit dem Slider ändert. Während die Animation der Optimierung mit Gradient Descent läuft, zeigt der lilane Pfeil das Momentum (Velocity \\(v_t\\)) für Schirtt \\(t\\) an.5 Der Algorithmus iteriert die Schritte 1. bis 3. solange, bis das Abbruchkriterium \\(|\\textcolor{orange}{\\nabla f(w_t)}| &lt; \\epsilon = 0.001\\) erreicht ist, die Änderung in \\(\\color{orange}{\\nabla f(w_t)}\\) also hinreichend klein ist, dass ein Parameterwert \\(w_t\\) mit \\(\\color{blue}{f(w_t)}\\) nahe des (globalen) Minimums von \\(f\\) plausibel ist.\n5 Unterschiedliche Längen der Pfeile zeigen hier nicht Änderungen der tatsächlichen Beträge, sondern dienen lediglich der Interpretierbakeit der Grafik.Folgende Eigenschaften der Optimierung mit Gradient Descent können anhand der Parameter geprüft werden:\n\n\nFür Startpunkte mit großen Werten des Gradienten beginnt der Algorithmus mit einem starken Momentum: Der Abstieg in Richtung des negativen Gradients erfolgt also in großen Schritten, sodass die Optimierung schneller erfolgt als für Startpunkte in flachen Regionen von \\(\\color{blue}{f}\\).\nDieser Effekt des Momentum auf den Pfad der zu optimierenden Parameter bei Gradient Descent ist vergleichbar mit dem Effekt der Schwerkraft auf eine Murmel, die auf einer hügeligen Oberfläche rollt: Anfangs gewinnt die Murmel an Geschwindigkeit und bewegt sich beschleunigt in Richtung des steilsten Gefälles. In flacheren Regionen wird die Bewegung langsamer und die Murmel kann in Tälern stecken bleiben, ähnlich wie der Optimierungsprozess in flachen Regionen von \\(\\color{blue}{f}\\) langsamer verläuft oder gar stoppt, weil ein Abbruchkriterium erfüllt ist (geringe Änderung des Gradienten). Das Momentum hilft, auch in solchen flachen Bereichen weiter voranzukommen, indem es dem Parameterpfad eine gewisse “Trägheit” verleiht, die es ermöglicht, flache Stellen schneller zu durchqueren und die Optimierung effizienter zu gestalten.\n\nBei ungünstiger Wahl der Parameter konvergiert der Algorithmus nicht zum globalen Minimum, sondern stoppt im lokalen Minimum bei \\(w = -0.5\\). Dies unterstreicht die Notwendigkeit, die Hyperparameter Lernrate \\(\\eta\\) und Momentum-Faktor \\(\\alpha\\) sorgfältig zu wählen, beispielsweise indem die Modellgüte nach erfolgter Anpassung für verschiedene Parameter-Kombinationen verglichen wird.\n\nIn empirischen Anwendungen ist es für eine hohe Modellgüte eines neuronalen Netzwerks nicht unbedingt erforderlich, das globale Minimum zu finden: Viele Optimierungsprobleme weisen zahlreiche lokale Minima auf, die eine ausreichend gute Annäherung an das Optimum bieten können. Besonders bei hochdimensionalen Optimierungsproblemen mit komplexen Loss-Funktionen können diese lokalen Minima zufriedenstellende Lösungen darstellen. In einigen Fällen existiert möglicherweise kein globales Minimum, und der Algorithmus konvergiert zwangsläufig zu einem stabilen lokalen Minimum, das dennoch eine gute Performance gewährleistet. Daher kann es sinnvoller sein, Algorithmen zu verwenden, die das Erreichen einer robusten Lösung legen, anstatt strikt nach dem globalen Minimum zu suchen.\nIn Software-Implementierungen für Machine und Deep Learning wie tensorflow6 und keras werden fortgeschrittene Techniken wie Momentum Tuning oder Stochastic Gradient Descent (SGD) eingesetzt, um die Wahrscheinlichkeit zu erhöhen, dass der Algorithmus nicht in einem (ungünstigen) lokalen Minimum endet. Ein für die Anpassung von NN häufig verwendeter Algorithmus, der SGD verwendet, ist Adaptive Moment Estimation (Adam). Wir verwenden u.a. den Adam-Optimizer in den empirischen Beispielen.\n6 Wir nutzen die tensorflow-Version 2.20.0\n\nIn empirischen Anwendungen sind die zu lernenden Zusammenhänge komplex und damit die Anzahl der zu optimierenden Parameter eines NN häufig groß. Der oben erläuterte Algorithmus für Gradient Descent mit Momentum kann einfach auf Optimierungsprobleme mit \\(k\\) Parametern generalisiert werden. Dann ist \\(\\boldsymbol{w}_t\\) ein Vektor mit \\(k\\) Gewichten, \\(\\boldsymbol{v}_{t+1}\\) eine vektorwertige Funktion von \\(\\boldsymbol{v}_t\\) und \\(\\nabla f(\\boldsymbol{w}_t)\\) mit Dimension \\(k\\) und \\(f(\\boldsymbol{w}_t)\\) ist eine Oberfläche in einem \\(k+1\\)-dimensionalen Raum.\nDie nachfolgende interaktive Grafik illustriert Gradient Descent mit Momentum für \\(k=2\\) zu optimierende Gewichte. Statt der Parameter des Algorithmus kann hier die Form der zu optimierenden Funktion manipuliert werden, sodass bis zu 6 Extremstellen vorliegen können. Der rote Punkt zeigt den Verlauf der Optimierung von \\(\\boldsymbol{w}_t\\).\nDie Animation verdeutlicht, dass lokale Minima insbesondere in höheren Dimensionen herausfordernd für Optimierungsalgorithmen sind: Durch Variation der Extrema lassen sich leicht Funktionen \\(f(w_1,w_1)\\) konstruieren, für die Gradient Descent mit den voreingestellten Parametern nicht gegen das globale Minimum konvergiert, sofern vorhanden. Ein günstiger Initialwert für \\(\\boldsymbol{w}_t\\) kann die Wahrscheinlichkeit von Stops in lokalen Minima verringern: Grid Search Initialization wertet die Funktion über ein gleichmäßiges Gitter von Werten für \\(\\boldsymbol{w}_t\\) aus und wählt als Startwert \\(\\boldsymbol{w}_{0,\\textup{init}}\\) den Punkt mit dem minimalen Funktionswert von \\(f\\) über alle Punkte im Gitter.",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Neuronale Netzwerke</span>"
    ]
  },
  {
    "objectID": "Machine Learning.html#funktionale-zusammenhänge-lernen-regression",
    "href": "Machine Learning.html#funktionale-zusammenhänge-lernen-regression",
    "title": "\n16  Neuronale Netzwerke\n",
    "section": "\n16.3 Funktionale Zusammenhänge lernen: Regression",
    "text": "16.3 Funktionale Zusammenhänge lernen: Regression\nFür einen leichten Einstieg in die Modellierung funktionaler Zusammenhänge durch NN mit statistischer Programmierung in R betrachten wir zunächst den einfachsten Zusammenhang zwischen einer Outcome-Variable \\(Y\\) und einem Regressor \\(X\\): Die einfache lineare Funktion \\[\\begin{align*}\n  Y = w_1 X + b,\n\\end{align*}\\] wobei der Regressionskoeffizient \\(w_1\\) den Einfluss von \\(X\\) auf \\(Y\\) misst und \\(b\\) eine Konstante ist. Gemäß der Definitionen in Kapitel 16.1 kann dieser Funktionale Zusammenhang als NN ohne Hidden Layer dargestellt werden, wobei \\(X\\) ein Input-Neuron ist, dessen Information mit \\(w_1\\) gewichtet an das Output Layer mit einem einzigen Neuron für \\(Y\\) weitergegeben wird. Die Konstante \\(b\\) ist ein Bias, der als von \\(X\\) unabhängiger Einfluss von \\(Y\\) behandelt wird, vgl. Abbildung 16.2.\n\n\n\n\n\nNEURALNET\nX\nXY\nYX-&gt;Y\nw1B\n1B-&gt;Y\nBias (b)\n\n\n\nAbbildung 16.2: Neuronales Netzwerk: Lineare Regression mit einer Variable und Konstante\n\n\n\n\nFür die Illustration der Schätzung des in Kapitel 16.1 dargestellten NN verwenden wir \\(n=1000\\) simulierte Datenpunkte gemäß der Vorschrift \\[\\begin{align}\n  Y = 5 + 3 \\cdot X + u\n\\end{align}\\] mit \\(X\\sim U[0,10]\\) und \\(u\\sim N(0,1)\\).\n\n# Daten simulieren\nset.seed(1234)\n\nn &lt;- 1000\nx &lt;- runif(n, min = 0, max = 10)\ny &lt;- 5 + 3 * x + rnorm(n) \n\nFür das Training von NN verwenden wir das Python-Paket keras. Hierzu muss lediglich eine lokale Python-Installation vorhanden sein.\nDie in diesem Kapitel betrachteten NN sind sequentielle NN. Solche Modelle können in keras mit der Funktion keras_model_sequential() definiert werden. Die Struktur des Modells kann über eine Verkettung von Funktionen für Layers (keras::layer_dense()) und Aktivierungen (keras::layer_activation()) definiert werden.\nFür die Implementierung des Modells in Abbildung 16.2 wählen wir mit units = 1 und input_shape = 1 ein Modell mit einem Neuron im Output Layer, das skalare Informationen verarbeitet. activation = 'linear' in layer_dense() führt zu der Aktivierungsfunktion \\(A(x) = x\\), d.h. die Ausgabe des Input Layers ist die gewichtete Summe der Eingaben plus Bias, ohne eine zusätzliche Transformation.\n\nlibrary(dplyr)\nlibrary(keras)\n\n# NN für einfache Regression\nmodel &lt;- keras_model_sequential(\n  list(\n    layer_dense(units = 1, activation = 'linear', input_shape = c(1))\n  )\n)\n\n# Modell-Definition prüfen\nsummary(model)\n\n&lt;Sequential name=sequential, built=True&gt;\n\n\nDie Übersicht zeigt, dass model aus einem Layer für skalare Inputs und Outputs sowie zwei trainierbaren Parameters (\\(w_1\\) und \\(b\\)) besteht.\nBevor das im Objekt model definierte Modell trainiert werden kann, muss der Code kompiliert werden. Dieser Vorgang ist notwendig, da sämtliche Berechnungen in Python durchgeführt werden. Der Python-Code wird beim kompilieren in eine Zwischendarstellung (Bytecode) übersetzt, die dann von der Python-Interpreter-Laufzeitumgebung ausgeführt wird.7\n7 Im Gegensatz zu Python ist R eine interpretierte Programmiersprache. Kompilierung von R-Ccode ist daher nicht notwendig.Mit keras::compile() kompilieren wir das Modell und wählen als Optimierungsfunktion Adam mit einer Lernrate von \\(.01\\). Die Loss-Funktion wird über das Argument loss festgelegt, hier der mittlere absolute Fehler, \\[\\begin{align*}\n  \\textup{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} \\lvert y_i - \\widehat{y}_i\\rvert.\n\\end{align*}\\]\n\n# Modell kompilieren\nmodel$compile(\n    optimizer = optimizer_adam(learning_rate = 0.01),\n    loss = 'mean_absolute_error'\n)\n\nDie Kompilierung erfolgt meist innerhalb von Sekundenbruchteilen und geschieht in-place: Eine Zuweisung des kompilierten Modells in model ist nicht notwendig.\nUm das Modell zu trainieren verwenden wir keras::fit(). Neben den (simulierten) Daten übergeben wir die Anzahl der zudurchlaufenden Epochen epocs. Über das Argument validation_split legen wir fest, dass 20% der Datensatzes zufällig ausgewählt und als Test-Datensatz für die Modell-Validierung während des Trainings genutzt werden sollen.\n\n# Modell trainieren\nhistory_snn &lt;- model$fit(\n    x = as.matrix(x), \n    y = as.matrix(y), \n    epochs = 50L, \n    validation_split = 0.2,\n    verbose = 0\n)\n\nDen Trainingsverlauf lesen wir direkt aus dem History-Objekt aus und fassen die letzten Epochen tabellarisch zusammen.\n\nhistory_snn_metrics &lt;- history_snn$history %&gt;%\n  reticulate::py_to_r() %&gt;%\n  lapply(as.numeric)\n\nhistory_snn_df &lt;- tibble::tibble(epoch = seq_along(history_snn_metrics[[1]]))\nfor(metric_name in names(history_snn_metrics)) {\n  history_snn_df[[metric_name]] &lt;- history_snn_metrics[[metric_name]]\n}\n\nhistory_snn_df %&gt;%\n  tail(6) %&gt;%\n  knitr::kable(digits = 4, caption = \"Letzte 6 Epochen der Trainingshistorie\")\n\n\n\n\nepoch\nloss\nval_loss\n\n\n\n45\n0.7634\n0.7209\n\n\n46\n0.7640\n0.7192\n\n\n47\n0.7611\n0.7204\n\n\n48\n0.7621\n0.7159\n\n\n49\n0.7602\n0.7172\n\n\n50\n0.7615\n0.7137\n\n\n\nLetzte 6 Epochen der Trainingshistorie\n\nDiese Informationen können mit ggplot() visualisiert werden.\n\nlibrary(ggplot2)\nlibrary(cowplot)\n\n# Entwicklung des Loss über Epochen plotten\n# Extrahiere History-Daten aus dem Keras-Objekt\nhistory_df &lt;- history_snn_df\nhistory_long &lt;- tidyr::pivot_longer(\n  history_df, \n  cols = -epoch, \n  names_to = \"metric\", \n  values_to = \"value\"\n)\n\nggplot(history_long, aes(x = epoch, y = value, color = metric)) +\n  geom_line() +\n  labs(\n    x = \"Epoche\",\n    y = \"Wert der Verlustfunktion\",\n    color = \"Metrik\"\n  ) +\n  theme_cowplot() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\nAbbildung 16.3: Einfaches lineares NN: Entwicklung des Loss für 25 Epochen\n\n\n\n\nAbbildung 16.3 zeigt, dass sich sowohl die Anpassung des NN auf dem Trainingsdatenstz als auch die Generalisierung auf dem Testdatensatz innerhalb der ersten Epochen dramatisch verbessert. Jenseits der 15. Epoche hingegen bewirken weitere Trainingszyklen keine weitere Verbesserung des Loss.\nMit keras::get_weights() können wir die optimierten Parameter aus dem Modell-Objekt auslesen.\n\n# Gewichtung und Bias des trainierten NN auslesen\nmodel %&gt;% \n  keras::get_weights() %&gt;% \n  purrr::flatten_dbl() %&gt;% \n  rlang::set_names(\n    c(\"w_1\", \"bias\")\n  )\n\n     w_1     bias \n3.012764 4.930189 \n\n\nDas NN hat den funktionalen Zusammengang zwischen x und y erfolgreich gelernt: Die optimierten Parameter-Werte bias und w_1 liegen nahe der wahren Parameter. Bei Parameter sind mit ihren KQ-Schätzungen vergleichbar.8\n8 Beachte, dass die KQ-Schätzung der Einfachheit halber hier den gesamten Datensatz nutzt und daher präziser sein kann als das NN.\n# lineares Modell\nlm_model &lt;- lm(\n  formula = y ~ x\n  )\n\nsummary(lm_model)\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91933 -0.62956  0.01084  0.63819  2.73178 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  5.04449    0.06028   83.69   &lt;2e-16 ***\nx            2.98893    0.01031  290.01   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9486 on 998 degrees of freedom\nMultiple R-squared:  0.9883,    Adjusted R-squared:  0.9883 \nF-statistic: 8.411e+04 on 1 and 998 DF,  p-value: &lt; 2.2e-16\n\n\n\n# Koeffizienten der KQ-Schätzung auslesen\ncoef(lm_model)\n\n(Intercept)           x \n   5.044491    2.988928 \n\n\nMit predict() erhalten wir Vorhersagen des NN und können so beispielsweise die Residuen für den gesamten Datensatz mit denen der KQ-Schätzung vergleichen.\n\n# Residuen vergleichen\n tibble(\n   NN = y - c(\n     model$predict(\n       as.matrix(x),\n       verbose = 0\n     )\n   ),\n   lm = lm_model$residuals\n ) %&gt;%\n  \n  ggplot(mapping = aes(x = NN, y = lm)) +\n  geom_point(alpha = .5, color = \"steelblue\") +\n  theme_cowplot()\n\n\n\n\n\n\nAbbildung 16.4: Vergleich von Residuen für NN und KQ-Schätzung\n\n\n\n\nAbbildung 16.4 zeigt eine gute Korrespondenz zwischen der Anpassung des NN und der KQ-Schätzung des einfachen linearen Modells.",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Neuronale Netzwerke</span>"
    ]
  },
  {
    "objectID": "Machine Learning.html#multiple-regression",
    "href": "Machine Learning.html#multiple-regression",
    "title": "\n16  Neuronale Netzwerke\n",
    "section": "\n16.4 Multiple Regression",
    "text": "16.4 Multiple Regression\nEin neuronales Netz für multiple Regression kann als eine Erweiterung des Netzes für einfache Regression betrachtet werden. Das Netz enthält nun mehrere Input-Neuronen, von denen jedes eine der unabhängigen Variablen \\(X_1, X_2, \\dots, X_k\\) repräsentiert. Diese Input-Neuronen sind mit einem einzigen Output-Neuron verbunden, das die Vorhersage für \\(Y\\) liefert. Jede dieser Verbindungen wird mit einem Gewicht \\(w_i\\) multipliziert, das die Stärke des Einflusses der jeweiligen unabhängigen Variable \\(X_i\\) auf die abhängige Variable \\(Y\\) repräsentiert. Wie im einfachen Modell gibt es einen Bias-Term \\(b\\), der ähnlich wie in der einen konstanten Einfluss darstellt.\nDie Struktur eines NN für multiple Regression ist in Abbildung 16.5 dargestellt. In diesem Beispiel gibt es drei unabhängige Variablen \\(X_1\\), \\(X_2\\) und \\(X_3\\), die jeweils ein eigenes Input-Neuron haben und mit dem Output-Neuron \\(Y\\) verbunden sind. \\(Y\\) ist eine Linear-Kombination der Inputs, gewichtet mit den jeweiligen Gewichten \\(w_1\\), \\(w_2\\) und \\(w_3\\), sowie dem Bias \\(b\\).\n\n\n\n\n\nNEURALNET\nX1\nX1SUM\n∑X1-&gt;SUM\nw1X2\nX2X2-&gt;SUM\nw2X3\nX3X3-&gt;SUM\nw3Y\nYSUM-&gt;Y\nB\n1B-&gt;SUM\nb\n\n\n\nAbbildung 16.5: Neuronales Netzwerk: Multiple lineare Regression\n\n\n\n\nUm die Vorgehensweise in R zu zeigen, generieren wir zunächst \\(n=250\\) Datenpunkte gemäß der Vorschrift \\[\\begin{align}\n  Y = 5 + 3 \\cdot X_1 + 2\\cdot X_2 - 1.5 \\cdot X_k + u\n\\end{align}\\] mit \\(X_1,X_2,X_3 \\sim\\textup{u.i.v.} N(0, 1)\\) und \\(u\\sim N(0,1)\\).\n\n# Erstellen von Trainingsdaten\nset.seed(42)\n\nn &lt;- 250\nk &lt;- 3\n\nX &lt;- matrix(rnorm(n = n * k), ncol = k)\nw &lt;- c(3, 2, -1.5)\n\nY &lt;- 5 + X %*% w + rnorm(n)\n\nAnschließend definieren wir ein einfaches NN und fügen ein Layer hinzu. Da wir eine multiple Regression durchführen, wählen wir input_shape = k, wobei k die Anzahl der unabhängigen Variablen ist. Wie im einfachen Modell ist die Aktivierungsfunktion linear, da wir an der Anpassung von \\(Y\\) mit einer linearen Kombination der Inputs interessiert sind.\n\n# Erstellen und Kompilieren des Modells\nmodel &lt;- keras_model_sequential(\n  list(\n    layer_dense(units = 1, activation = 'linear', input_shape = c(k))\n  )\n)\n\n# Modelldefinition prüfen\nsummary(model)\n\n&lt;Sequential name=sequential_1, built=True&gt;\n\n\nWir kompilieren das Modell mit dem mittleren quadratischen Fehler (mean squared error, MSE) und SGD als Loss-Funktion mit einer moderaten Lernrate.\n\nmodel$compile(\n    loss = 'mean_squared_error',\n    optimizer = optimizer_sgd(learning_rate = 0.01)\n  )\n\nDie Anpassung des Modells erfolgt wie bei einfacher Regression mit keras::fit().\n\n# Training des Modells\nhistory_mnn &lt;- model$fit(\n    x = as.matrix(X), \n    y = as.matrix(Y), \n    validation_split = 0.2,\n    epochs = 25L,\n    verbose = 0\n  )\n\n\nhistory_mnn_metrics &lt;- history_mnn$history %&gt;%\n  reticulate::py_to_r() %&gt;%\n  lapply(as.numeric)\n\nhistory_mnn_df &lt;- tibble::tibble(epoch = seq_along(history_mnn_metrics[[1]]))\nfor(metric_name in names(history_mnn_metrics)) {\n  history_mnn_df[[metric_name]] &lt;- history_mnn_metrics[[metric_name]]\n}\n\nhistory_mnn_df %&gt;%\n  tail(5) %&gt;%\n  knitr::kable(digits = 4, caption = \"Letzte 5 Epochen der Trainingshistorie\")\n\n\n\n\nepoch\nloss\nval_loss\n\n\n\n21\n1.1462\n1.8158\n\n\n22\n1.1166\n1.7883\n\n\n23\n1.0910\n1.7692\n\n\n24\n1.0709\n1.7770\n\n\n25\n1.0618\n1.7503\n\n\n\nLetzte 5 Epochen der Trainingshistorie\n\n\n# Entwicklung des Loss über Epochen plotten\n# Extrahiere History-Daten aus Keras 3 Objekt\n# Extrahiere History-Daten aus dem Keras-Objekt\nhistory_df &lt;- history_mnn_df\nhistory_long &lt;- tidyr::pivot_longer(\n  history_df, \n  cols = -epoch, \n  names_to = \"metric\", \n  values_to = \"value\"\n)\n\nggplot(history_long, aes(x = epoch, y = value, color = metric)) +\n  geom_line() +\n  labs(\n    x = \"Epoche\",\n    y = \"Wert der Verlustfunktion\",\n    color = \"Metrik\"\n  ) +\n  theme_cowplot() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\nAbbildung 16.6: NN für mult. Regression: Entwicklung des Loss für 25 Epochen\n\n\n\n\nWie bei der einfachen Regression zeigt ein Vergleich der angepassten Gewichte mit den KQ-Schätzungen eines entsprechenden linearen Regressionsmodells ähnliche Ergebnisse beider Ansätze.\n\n# Gewichtung und Bias des trainierten NN auslesen\nmodel %&gt;% \n  keras::get_weights() %&gt;% \n  purrr::flatten_dbl() %&gt;% \n  rlang::set_names(\n    c(\"w_1\", \"w_2\", \"w_3\", \"bias\")\n  )\n\n      w_1       w_2       w_3      bias \n 2.986754  1.883037 -1.475648  4.807487 \n\n\n\n# Multiples lineares Modell mit KQ schätzen\nlm_model &lt;- lm(\n  formula = Y ~ X\n)\n\nsummary(lm_model)\n\n\nCall:\nlm(formula = Y ~ X)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.3129 -0.7286  0.0900  0.7439  3.4086 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  5.01583    0.06843   73.30   &lt;2e-16 ***\nX1           2.97449    0.07028   42.32   &lt;2e-16 ***\nX2           1.94345    0.07061   27.52   &lt;2e-16 ***\nX3          -1.47278    0.06914  -21.30   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.079 on 246 degrees of freedom\nMultiple R-squared:  0.9271,    Adjusted R-squared:  0.9262 \nF-statistic:  1042 on 3 and 246 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Neuronale Netzwerke</span>"
    ]
  },
  {
    "objectID": "Machine Learning.html#nicht-lineare-zusammenhänge",
    "href": "Machine Learning.html#nicht-lineare-zusammenhänge",
    "title": "\n16  Neuronale Netzwerke\n",
    "section": "\n16.5 Nicht-Lineare Zusammenhänge",
    "text": "16.5 Nicht-Lineare Zusammenhänge\nIn diesem Abschnitt verwenden trainieren wir ein NN, um eine logistische Regression durchzuführen. Dieser Ansatz wird häufig verwendet, um eine binäre Outcome-Variablen \\(Y\\) zu modellieren, also Variablen, die zwei mögliche Ausgänge haben (oft als 0 oder 1 dargestellt), siehe Kapitel 4.2.3 für Details. Anstatt die Eingaben lediglich linear zu kombinieren, verwenden wir eine Sigmoid-Aktivierungsfunktion9, \\[\\begin{align*}\n  \\sigma(z) = \\frac{1}{1 + \\exp(-z)},\n\\end{align*}\\] welche die Ausgaben auf einen Wertebereich zwischen 0 und 1 abbildet. Dadurch kann das NN Wahrscheinlichkeiten \\(P(Y=1\\vert \\boldsymbol{X} = \\boldsymbol{x})\\) vorhersagen, die anschließend für die Klassifikation von Beobachtungen verwendet werden können.\n9 Die Sigmoid-Aktivierungsfunktion entspricht der logistischen Funktion \\(\\Lambda(z)\\) aus Kapitel 4.2.3.Für die Illustration der Schätzung mit keras verwenden wir den DGP aus Kapitel 4.2.2.\n\n# Erstellen von Trainingsdaten\nset.seed(1234)\n\nn &lt;- 500\nX &lt;- rnorm(n = n, mean = 5, sd = 2) # Regressor\nP &lt;- pnorm(-4 + 0.7 * X)\nY &lt;- as.integer(runif(n) &lt; P)\n\nAbbildung 16.7 zeigt ein einfaches NN für eine binäre Outcome-Variable.\n\n\n\n\n\nNNlogit\nX\nX1SUM\n∑X-&gt;SUM\nw1sigmoid\nσSUM-&gt;sigmoid\nY\nYsigmoid-&gt;Y\nB\n1B-&gt;SUM\nb\n\n\n\nAbbildung 16.7: Neuronales Netzwerk mit Sigmoid-Aktivierungsfunktion\n\n\n\n\nNach der Definition des NN wird das Modell mit dem Binary-Cross-Entropy-Loss (BCEL) und dem Adam-Optimierer kompiliert. BCEL ist für binäre Klassifikationsprobleme geeignet: Diese Loss-Funktion misst die die Unterschiede zwischen den vorhergesagten Wahrscheinlichkeiten \\(\\widehat{p}_i\\) und den tatsächlichen binären Zielen \\(y_i\\), \\[\\begin{align*}\n  \\textup{BCEL} = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\cdot \\log(\\widehat{p}_i) + (1 - y_i) \\cdot \\log(1 - \\widehat{p}_i) \\right].\n\\end{align*}\\] Als weitere zu berechnende Metrik wählen wir \\(\\textup{Accuracy}\\), ein geläufiges Maß zur Bewertung der Leistung von Klassifikationsmodellen. \\(\\textup{Accuracy}\\) gibt an, wie oft das Modell korrekte Vorhersagen getroffen hat, ausgedrückt als Verhältnis der Anzahl der korrekten Vorhersagen zur Gesamtzahl der Vorhersagen, \\[\\begin{align*}\n  \\text{Accuracy} = \\frac{\\textup{TP} + \\textup{TN} }{ \\textup{TP} + \\textup{TN} + \\textup{FP} + \\textup{FN} } = \\frac{\\textup{Anz. korrekte Vorhersagen}}{\\textup{Anz. alle Vorhersagen}}.\n\\end{align*}\\] Hierbei sind \\(\\textup{TP}\\) und \\(\\textup{FP}\\) die Anazhl korrekter (true positive) und falscher (false positiv) Vorhersagen für Beobachtungen mit \\(y_i = 1\\). \\(\\textup{TN}\\) und \\(\\textup{FN}\\) sind analog für Beobachtungen mit tatsächlichen Werten \\(y_i = 0\\) definiert.\nDie Vorhersage von \\(y_i\\) zur Berechnung von \\(\\textup{Accuracy}\\) erfolgt durch keras::fit() standardmäßig nach der Regel \\[\\begin{align*}\n  \\hat{y}_i =\n  \\begin{cases}\n    1 & \\text{wenn } \\hat{p}_i \\geq 0.5, \\\\\n    0 & \\text{wenn } \\hat{p}_i &lt; 0.5.\n  \\end{cases}\n\\end{align*}\\]\nWir definieren nachchfolgend das Modell-Objekt und passen das NN über 150 Epochen an.\n\n# Erstellen und Kompilieren des Modells\nmodel_nn_logit &lt;- keras_model_sequential(\n  list(\n    layer_dense(units = 1, activation = 'sigmoid', input_shape = c(1)) # &lt;= für Logit-Modell\n  )\n)\n\nsummary(model_nn_logit)\n\n&lt;Sequential name=sequential_2, built=True&gt;\n\n\n\n# Modell kompilieren\nmodel_nn_logit$compile(\n    loss = 'binary_crossentropy', # Für BCEL\n    optimizer = optimizer_adam(learning_rate = 0.01),\n    metrics = list('accuracy')\n  )\n\n\n# Anpassen des Modells\nhistory_nn_logit &lt;- model_nn_logit$fit(\n    x = as.matrix(X), \n    y = as.matrix(as.numeric(Y)), \n    validation_split = 0.2,\n    epochs = 150L,\n    verbose = 0\n  )\n\n\nhistory_nn_logit_metrics &lt;- history_nn_logit$history %&gt;%\n  reticulate::py_to_r() %&gt;%\n  lapply(as.numeric)\n\nhistory_nn_logit_df &lt;- tibble::tibble(epoch = seq_along(history_nn_logit_metrics[[1]]))\nfor(metric_name in names(history_nn_logit_metrics)) {\n  history_nn_logit_df[[metric_name]] &lt;- history_nn_logit_metrics[[metric_name]]\n}\n\nhistory_nn_logit_df %&gt;%\n  tail(8) %&gt;%\n  knitr::kable(digits = 4, caption = \"Letzte 8 Epochen der Trainingshistorie\")\n\n\n\n\nepoch\naccuracy\nloss\nval_accuracy\nval_loss\n\n\n\n143\n0.8025\n0.3958\n0.87\n0.3364\n\n\n144\n0.8075\n0.3955\n0.87\n0.3364\n\n\n145\n0.7950\n0.3963\n0.85\n0.3385\n\n\n146\n0.8025\n0.3952\n0.85\n0.3368\n\n\n147\n0.8050\n0.3953\n0.87\n0.3353\n\n\n148\n0.8100\n0.3984\n0.85\n0.3380\n\n\n149\n0.7950\n0.3967\n0.88\n0.3346\n\n\n150\n0.8025\n0.3944\n0.87\n0.3356\n\n\n\nLetzte 8 Epochen der Trainingshistorie\n\n\n# Entwicklung des Loss über Epochen plotten\n# Extrahiere History-Daten aus dem Keras-Objekt\nhistory_df &lt;- history_nn_logit_df\nhistory_long &lt;- tidyr::pivot_longer(\n  history_df, \n  cols = -epoch, \n  names_to = \"metric\", \n  values_to = \"value\"\n)\n\nggplot(history_long, aes(x = epoch, y = value, color = metric)) +\n  geom_line() +\n  labs(\n    x = \"Epoche\",\n    y = \"\",\n    color = \"Metrik\"\n  ) +\n  theme_cowplot() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\nAbbildung 16.8: NN für Logit-Regression: Entwicklung der Metriken für 25 Epochen\n\n\n\n\n\n# Gewicht und Bias extrahieren\nmodel_nn_logit %&gt;% \n  keras::get_weights() %&gt;% \n  purrr::flatten_dbl() %&gt;% \n  rlang::set_names(\n    c(\"w_1\", \"bias\")\n  )\n\n      w_1      bias \n 1.039087 -5.775351 \n\n\nFür einen Vergleich der Vorhersagegüter mit logistischer Regression schätzen wir zunächst ein entsprechendes GLM mit glm().\n\n# Logistisches Modell mit glm() anpassen\nglm_mod &lt;- glm(\n  formula = Y ~ X, \n  family = binomial(link = \"logit\")\n)\n\nsummary(glm_mod)\n\n\nCall:\nglm(formula = Y ~ X, family = binomial(link = \"logit\"))\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -7.3289     0.6520  -11.24   &lt;2e-16 ***\nX             1.3140     0.1191   11.04   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 673.01  on 499  degrees of freedom\nResidual deviance: 375.96  on 498  degrees of freedom\nAIC: 379.96\n\nNumber of Fisher Scoring iterations: 6\n\n\nWir erzeugen nun einen Testdatensatz mit 250 Beobachtungen gemäß des oben gewählten DGP.\n\nset.seed(4321)\n\nn &lt;- 250\ndata_new &lt;- tibble(\n  X = rnorm(n = n, mean = 5, sd = 2),\n  P = pnorm(-4 + 0.7 * X),\n  Y = as.integer(runif(n) &lt; P)\n)\n\nFür die neuen Datenpunkte data_new erzeugen wir Vorhersagen von \\(P(Y=1\\vert X=x)\\) mit model_nn_logit und glm_mod und erweitern data_new um diese.\n\n# Vorhersagen für Trainingsdaten erstellen\npredictions_nn_logit &lt;- c(\n  model_nn_logit$predict(\n    as.matrix(data_new$X),\n    verbose = 0\n  )\n)\n\npredictions_glm_logit &lt;- predict(\n    glm_mod, \n    newdata = data_new, \n    type = \"response\"\n  )\n\n# Zusammenfassen\nresults &lt;- data_new %&gt;% \n  mutate(\n    nn_logit = predictions_nn_logit,\n    glm_logit = predictions_glm_logit\n)\n\nslice_head(results, n = 10)\n\n# A tibble: 10 × 5\n       X      P     Y nn_logit glm_logit\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1  4.15 0.136      1    0.187    0.132 \n 2  4.55 0.208      0    0.260    0.206 \n 3  6.44 0.693      1    0.713    0.755 \n 4  6.68 0.751      1    0.763    0.810 \n 5  4.74 0.248      0    0.300    0.250 \n 6  8.22 0.960      1    0.941    0.970 \n 7  4.41 0.180      0    0.232    0.177 \n 8  5.39 0.411      0    0.457    0.439 \n 9  7.48 0.892      0    0.881    0.924 \n10  3.56 0.0660     0    0.112    0.0661\n\n\nFür eine erste Beurteilung anhand der Vorhersagen auf dem Testdatensatz plotten wir die vorhergesagten Wahrscheinlichkeiten als Funktion von X gemeinsam mit den tatsächlichen Ausprägungen der Outcome-Variable Y.\n\nlibrary(ggplot2)\nlibrary(cowplot)\n\n# Plot der tatsächlichen Werte gegen die vorhergesagten Wahrscheinlichkeiten\nggplot(\n  data = results,\n  mapping =  aes(x = X, y = Y)\n  ) +\n  geom_point(\n    position = position_jitter(height = 0.05), \n    alpha = 0.5\n  ) +\n  geom_line(\n     mapping = aes(y = nn_logit),\n    col = \"darkred\"\n  ) +\n  geom_smooth(\n    method = \"glm\", \n    method.args = list(family = \"binomial\"), \n    se = FALSE\n  ) +\n  labs(\n    title = \"Logistische Regression vs. NN\",\n       x = \"x\",\n       y = \"Schätzung v. P(Y=1|X=x)\"\n  ) +\n  theme_cowplot()\n\n\n\n\n\n\n\nDie geschätzten Wahrscheinlichkeitsfunktionen zeigen eine gute Übereinstimmung. Um die Vorhersagegüte von model_nn_logit und model_glm_logit genauer zu untersuchen, erstellen wir Plots der jeweilgen Receiver Operating Characteristic (ROC). ROC zeigt den Zusammenhang zwischen der True Positive Rate (TPR), dem Anteil korrekter Vorhersagen für \\(y_i=1\\) (auch Sensitivität gennant) und der False Positive Rate (FPR), dem Anteil falscher Vorhersagen für \\(y_i=1\\) in Abhängigkeit des Schwellenwerts von \\(\\widehat{p}\\) für die Klassifikation des Outcomes einer Beobachtung \\(y_i = 1\\). Es gilt\n\\[\\begin{align*}\n  TPR =&\\, \\frac{TP}{TP + FN},\\\\\n  \\\\\n  FPR =&\\, \\frac{FP}{FP + TN}.\n\\end{align*}\\]\nDer Schwellenwert \\(\\widehat{p}\\) reguliert den Trade-Off zwischen \\(\\textup{FPR}\\) und \\(\\textup{TPR}\\): Kleine \\(\\widehat{p}\\) führen tendenziell zu großer \\(\\textup{TPR}\\) (gut), aber auch zu großer \\(\\textup{FPR}\\) (schlecht). Für ein Modell, das zufällig klassifiziert, entspricht die ROC-Kurve der Winkelhalbierenden. Wünschenwert ist ein verlauf der ROC-Kurve möglichst oberhalb der Winkelhalbierenden.\nEine ROC-Kurve kann in R mit dem plotROC anhand der Vorhergesagten und tatsächlichen Werte der Outcome-Varibale berechnet und geplottet werden. Hierzu transformieren wir results in langes Format und verwenden ggplot() mit dem Layer geom_roc().\n\nlibrary(plotROC)\nlibrary(tidyr)\n\nroc_data &lt;- results %&gt;%\n  pivot_longer(\n    cols = glm_logit:nn_logit,\n    names_to = \"model\", \n    values_to = \"pp\"\n    )\n\n# ROC-Kurve plotten\n  ggplot(\n    data = roc_data, \n    mapping = aes(\n      m = pp, \n      d = Y, \n      colour = model\n    )\n  ) +\n  geom_roc() +\n  style_roc() + \n  facet_wrap(~ model) +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\nAbbildung 16.9: ROC-Kurve für logistische Modelle\n\n\n\n\nAbbildung 16.9 zeigt sehr ähnliche ROC-Kurven für model_nn_logit und model_glm_logit.10 Für die Quantifizierung der Vorhersageleistung wird Area under the Curve (AUC), die Fläche unterhalb der ROC-Kurve, herangezogen. Mit plotROC::calc_auc() kann AUC aus dem geom_roc()-Layer berechnet werden. Für ein geschätztes Modell \\(\\widehat{M}\\) gilt \\(0\\leq\\textup{AUC}(\\widehat{M})\\leq1\\).11\n10 Beide Plots enthalten Indikatoren des ROC für bestimmte Schwellenwerte \\(\\widehat{p}\\).11 Ein geschätzes, dass nicht besser als raten ist, gilt \\(\\textup{AUC}(\\widehat{M})=.5\\).\n# AUC berechnen\nroc_data %&gt;%\n  group_by(model) %&gt;%\n  summarise(\n    AUC = calc_auc(\n      ggplot(mapping = aes(m = pp, d = Y)) +\n        geom_roc()\n    )$AUC\n  )\n\n# A tibble: 2 × 2\n  model       AUC\n  &lt;chr&gt;     &lt;dbl&gt;\n1 glm_logit 0.890\n2 nn_logit  0.890\n\n\nDer Vergleich der AUC-Statistiken beider Modelle für den Testdatensatz zeigt, dass das NN ähnlich gut klassifizert, wie das GLM mit logistischer Link-Funktion.",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Neuronale Netzwerke</span>"
    ]
  },
  {
    "objectID": "Machine Learning.html#empirisches-beispiel-boston-housing",
    "href": "Machine Learning.html#empirisches-beispiel-boston-housing",
    "title": "\n16  Neuronale Netzwerke\n",
    "section": "\n16.6 Empirisches Beispiel: Boston Housing",
    "text": "16.6 Empirisches Beispiel: Boston Housing\nIn diesem Beispiel illustrieren wir die Anwendung von (NN) für den Boston Housing-Datensatz MASS::Boston. Boston enthält enthält verschiedene Charakteristika von Häusern in Boston, wie z.B. Kriminalitätsrate, Anzahl der Räume und Alter der Gebäude. Ziel ist esm den Medianpreis der Häuser (medv) vorherzusagen.\nFür die Analyse verwenden wir insbesondere die Pakete tidymodels und recipes. Das recipes-Paket erlaubt eine automatisierte und leicht reproduzierbare Vorbereitung von Datensätzen für statistische Modellierung mit tidymodels. Es stellt Verben zur Konstruktion von Pipelines mit Schritten wie Skalierung, Kodierung und Handling fehlender Werte bereit. Diese Schritte werden mit einem Rezept (recipe()) definiert, vorbereitet (prep()) und dann auf Trainings- und/oder Testdaten angewendet (bake()).\nZunächst laden wir den Boston Housing-Datensatz und teilen boston_tbl in Trainings- und Testdaten auf. Hierbei verwenden wir 80% der Daten für das Training und reservieren 20% zum Testen.\n\nlibrary(tidymodels)\n\n# Datensatz in tibble umwandeln \nboston_tbl &lt;- as_tibble(MASS::Boston)\n\n# Trainings- und Testdaten einteilen \n# (80% / 20%)\nset.seed(1234)\n\nsplit &lt;- initial_split(boston_tbl, prop = 0.8)\ntrain_data &lt;- training(split)\ntest_data &lt;- testing(split)\n\n# Zielvariable und Prädiktoren aufteilen\ntrain_x &lt;- select(train_data, -medv)\ntrain_y &lt;- train_data$medv\n\ntest_x &lt;- select(test_data, -medv)\ntest_y &lt;- test_data$medv\n\nDa neuronale Netze empfindlich auf unterschiedlich skalierte Eingabedaten reagieren (ähnlich wie regularisierte Schätzer, vgl. Kapitel 13), normalisieren wir sämtliche (numerischen) Prädiktoren, ausgenommen chas und rad, mit recipes::step_normalize().\n\n# Daten normalisieren\n\n# Rezept\nrecipe_obj &lt;- recipe(\n  formula = medv ~ ., \n  data = train_data\n  ) %&gt;%\n  step_normalize(\n    all_predictors(), -chas, -rad\n  )\n\n# Vorbreiten\ndata_prep &lt;- prep(\n  x = recipe_obj, \n  training = train_data\n)\n\n# Anwenden\ntrain_x &lt;- bake(\n  object = data_prep, \n  new_data = train_data\n  ) %&gt;% \n  select(-medv)\n\ntest_x &lt;- bake(\n  object = data_prep, \n  new_data = test_data) %&gt;% \n  select(-medv)\n\nZunächst führen wir eine KQ-Regression durch, um den Zusammenhang zwischen sämtlichen verfügbaren Prädiktoren und dem Zielwert medv zu schätzen. Hierfür nutzen wir das linear_reg()-Modell aus tidymodels und passen es mit der Methode der kleinsten Quadrate (KQ) an.\n\n# Lineare Regression mit KQ\nkq_spec &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\")\n\nkq_fit &lt;- fit(\n  object = kq_spec, \n  formula = medv ~ ., \n  data = train_data\n)\n\n# KQ-Vorhersagen für Testdaten\nkq_predictions &lt;- predict(\n  object = kq_fit, \n  new_data = test_data\n  ) %&gt;%\n  bind_cols(test_data) %&gt;%\n  rename(kq_pred = .pred)\n\nFür das NN wählen wir eine Spezifikation mit zwei Hidden Layers, die jeweils 64 Neuronen haben. Mit input_shape = ncol(train_x) verarbeitet das 1. Hidden Layer die Inputs sämtlicher Prädiktoren in boston_tbl. Als Aktivierungsfunktion verwenden wir Recified Linear Unit, \\[\\begin{align}\n      \\textup{ReLU}(z) \\max(0, z).\\\\\n\\end{align}\\]\nDie ReLU-Aktivierungsfunktion setzt also negative Werte auf 0 und lässt positive Werte unverändert. In NN ermöglicht sie eine sparsame anpassung und ist numerisch leicht handhabbar bei der Berechnung des Gradienten: Die Verwendung von Layers mit ReLU verringert das Vanishing-Gradient-Problem.12\n12 Bei nicht-linearen Aktivierungsfunktionen kann der Gradient der Loss-Funktion extrem klein werden, was das Training von NN mit vielen Layers schwierig machen kann.Das Output Layer des Netzes besteht aus einem einzigen Neuron, dass einen numerischen Wert (den geschätzten Hauspreis) zurückgibt.\n\n# NN mit Keras erstellen\nmodel &lt;- keras_model_sequential(\n  list(\n    # Hidden Layer 1\n    layer_dense(units = 64, activation = \"relu\", input_shape = c(ncol(train_x))),\n    # Hidden Layer 2\n    layer_dense(units = 64, activation = \"relu\"),\n    # Output Layer\n    layer_dense(units = 1)\n  )\n)\n\n# Modell kompilieren\nmodel$compile(\n  optimizer = \"rmsprop\",\n  loss = \"mse\",\n  metrics = list(\"mae\")\n)\n\nWir trainieren das NN über 100 Epochen mit einem Batch-Größe von 32 Datenpunkten.\n\n# Modell trainieren\nhistory &lt;- model$fit(\n    x = as.matrix(train_x), \n    y = as.matrix(train_y),\n    epochs = 100L,\n    batch_size = 32L,\n    validation_split = 0.2,\n    verbose = 0L\n  )\n\n\nhistory_bh_metrics &lt;- history$history %&gt;%\n  reticulate::py_to_r() %&gt;%\n  lapply(as.numeric)\n\nhistory_bh_df &lt;- tibble::tibble(epoch = seq_along(history_bh_metrics[[1]]))\nfor(metric_name in names(history_bh_metrics)) {\n  history_bh_df[[metric_name]] &lt;- history_bh_metrics[[metric_name]]\n}\n\nhistory_bh_df %&gt;%\n  tail(10) %&gt;%\n  knitr::kable(digits = 4, caption = \"Letzte 10 Epochen der Trainingshistorie\")\n\n\n\n\nepoch\nloss\nmae\nval_loss\nval_mae\n\n\n\n91\n9.8229\n2.1366\n5.1699\n1.8842\n\n\n92\n9.8109\n2.0802\n5.6932\n1.9711\n\n\n93\n9.6690\n2.0967\n5.1001\n1.8537\n\n\n94\n9.7648\n2.1274\n6.4081\n2.0548\n\n\n95\n9.5097\n2.2103\n5.1484\n1.8805\n\n\n96\n9.6333\n2.1124\n6.1581\n2.0150\n\n\n97\n9.4692\n2.0514\n6.2952\n2.0512\n\n\n98\n10.1844\n2.1493\n6.0307\n2.0215\n\n\n99\n8.8228\n2.0136\n12.1167\n2.6163\n\n\n100\n8.8949\n2.0390\n6.8573\n1.9909\n\n\n\nLetzte 10 Epochen der Trainingshistorie\n\nMit dem trainierten NN verwenden wir model, um Vorhersagen auf den Testdaten test_data zu machen.\n\n# Vorhersagen mit trainiertem NN\nnn_pred &lt;- model$predict(\n  as.matrix(test_x),\n  verbose = 0L\n)\n\n# Testdaten erweitern\nnn_predictions &lt;- test_data %&gt;%\n  mutate(\n    nn_pred = c(nn_pred)\n  )\n\nUm die Leistung der Modelle zu vergleichen, berechnen wir den MSE für beide Modelle.\n\n# MSE berechnen\nols_mse &lt;- kq_predictions %&gt;%\n  summarise(mse = mean((medv - kq_pred)^2)) %&gt;%\n  pull(mse)\n\nnn_mse &lt;- nn_predictions %&gt;%\n  summarise(mse = mean((medv - nn_pred)^2)) %&gt;%\n  pull(mse)\n\nc(\n  \"MSE KQ\" = ols_mse,\n  \"MSE NN\" = nn_mse\n)\n\n  MSE KQ   MSE NN \n28.79773 16.39859 \n\n\nDa das NN ist in der Lage ist, nicht-lineare Zusammenhänge zwischen den Prädiktoren und der Zielvariablen zu modellieren, liefert hat es eine höhere Vorhersagegenauigkeit auf dem Testdatensatz.\nFür eine Visualisierung der Vorhersagen tragen wir den wahren und die vorhergesagten Werte von medv für beide Modelle in einem Punkteplot ab.\n\n# KQ- und NN-Vorhersagen sammeln\npreds &lt;- kq_predictions %&gt;%\n  select(medv, kq_pred) %&gt;%\n  mutate(nn_pred = nn_predictions$nn_pred)\n\n# Visualisierung der Ergebnisse mit ggplot2\npreds %&gt;%\n  ggplot(aes(x = medv)) +\n  geom_point(aes(y = kq_pred, color = \"OLS\"), alpha = 0.6) +\n  geom_point(aes(y = nn_pred, color = \"Neuronales Netz\"), alpha = 0.6) +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +\n  labs(\n    x = \"Wahre Werte (medv)\",\n    y = \"Vorhersagen\",\n    color = \"Modell\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(\n    values = c(\n      \"OLS\" = \"red\", \n      \"Neuronales Netz\" = \"steelblue\"\n    )\n  )\n\n\n\n\n\n\nAbbildung 16.10: Boston Housing: KQ vs. NN\n\n\n\n\nAbbildung 16.10 zeigt, dass KQ und NN weitgehend vergleichbare Vorhersagen von medv auf dem Testdatensatz liefern. Das NN scheint jedoch im Mittel besser in der Vorhersage hoher Verkaufspreise zu sein – möglicherweise weil extreme Preise auf nicht-lineare Beziehungen zwischen bestimmten Regressoren und medv zurückzuführen sind, die in einer linearen KQ-Regression nicht erfasst werden können.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBishop, Christopher M. 2007. Pattern recognition and machine learning. Information Science and Statistics. New York, NY: Springer Science+Business Media, LLC.\n\n\nChollet, Francois, und J. J. Allaire. 2018. Deep Learning with R. New York: Manning Publications Co. LLC.\n\n\nGoodfellow, Ian, Yoshua Bengio, und Aaron Courville. 2016. Deep Learning. MIT Press.",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Neuronale Netzwerke</span>"
    ]
  },
  {
    "objectID": "Reg.html",
    "href": "Reg.html",
    "title": "4  Regression",
    "section": "",
    "text": "4.1 Regression schließt Backdoors: Frisch-Waugh-Lovell-Theorem\nDas Frisch-Waugh-Lovell-Theorem (FWL) besagt, dass die geschätzten Koeffizienten für eine interessierende Teilmenge der Regressoren in einer multiplen linearen Regression numerisch identisch mit den Koeffizientenschätzungen aus folgenden Schritten sind:\nIn einem multiplen Modell mit zwei Regressoren \\(X_1,\\ X_2\\), \\[\\begin{align}\n  Y = \\beta_0 + \\beta_1 X + \\beta_2 X_2 + \\epsilon \\label{eq:fwlfullreg}\n\\end{align}\\] kann der Effekt von \\(X_1\\) auf \\(Y\\) also mit der Regression \\[\\begin{align*}\n  \\widehat{u}_{Y,X_2} = \\beta_1 \\widehat{u}_{X_1,X_2} + e \\label{eq:fwl2reg}\n\\end{align*}\\] geschätzt werden, wobei \\(\\widehat{u}_{Y,X_2}\\) und \\(\\widehat{u}_{X_1,X_2}\\) die Residuen der Regression von \\(Y\\) auf \\(X_2\\) und von \\(X_1\\) auf \\(X_2\\) sind.\nFWL ermöglicht daher eine Vereinfachung der Schätzung komplexer Modelle durch die Zerlegung der Schätzung in Teilschritte.\nFür das Verständnis der Schätzung kausaler Effekte mit linearer Regression ist FWL hilfreich, denn es zeigt, wie sowohl die Variation in der Outcome-Variable (\\(\\widehat{u}_{Y,X_2}\\)) als auch die Variation in der Behandlungsvariable (\\(\\widehat{u}_{X_1,X_2}\\)), die jeweils nicht durch Kovariablen (\\(X_2\\)) verursacht wird, mit multipler Regression isoliert werden kann, sodass Backdoors geschlossen werden.\nWir illustrieren dieses Konzept anhand einer multiplen Regression für das Gewicht (body_mass) von Pinguinen aus dem Datensatz palmerpenguins::penguins,\n\\[\\begin{align}\n  \\textup{body\\_mass} = \\beta_0 + \\beta_1\\cdot\\textup{bill\\_length} + \\beta_2\\cdot \\textup{flipper\\_length} + \\epsilon,\\label{eq:billdepthmodel}\n\\end{align}\\] unter der Annahme, dass \\(\\beta_1\\) der interessierende Effekt ist: Die erwartete Änderung des Gewichts eines Pinguins (in Gramm) für eine Änderung der Schnabel-Länge um 1mm.\nVor der Schätzung von Modell \\(\\eqref{eq:billdepthmodel}\\) lesen wir den Datensatz ein und erstellen eine bereinigte Variante penguins_cleaned, analog zur Vorgehensweise in Kapitel 2.1.2.\nWir schätzen nun Modell \\(\\eqref{eq:billdepthmodel}\\) mit lm() und erhalten eine Zusammenfassung der geschätzten Koeffizienten mit broom::tidy().\nDas Ergebnis der Schätzung ist \\(\\widehat{\\beta}_1\\approx3.80\\). Der nächste Code-Block berechnet die Residuen aus den Regressionen \\[\\begin{align*}\n  \\textup{body\\_mass} =&\\, \\alpha_0 + \\alpha_1 \\textup{flipper\\_length} + u_{\\textup{body\\_mass},\\,\\textup{flipper\\_length}},\\\\\n  \\textup{bill\\_length} =&\\, \\delta_0 + \\delta_1 \\textup{flipper\\_length} + u_{\\textup{bill\\_length},\\,\\textup{flipper\\_length}},\n\\end{align*}\\]\nund speichert diese in body_mass_res und bill_length_res.\nFür den zweiten Schritt regressieren wir body_mass_res auf bill_length_res.\nDer geschätzte Koeffizient aus der Regression der Residuen stimmt mit dem geschätzten Koeffizienten von bill_length aus der großen Regression \\(\\eqref{eq:billdepthmodel}\\) überein.\nWir können den Effekt der Kontrolle für flipper_length visualisieren. Wir plotten hierzu:\nWir erweitern p um die ursprünglichen Datenpunkte und die zugehörige Regressionslinie.\nDer grafische Vergleich beider Vorgehensweisen zeigt den Effekt der Kontrolle für flipper_length: Die geschätzte (lila) Regressionslinie für die bereinigten Daten hat eine deutlich geringere Steigung als die anhand der ursprünglichen Daten geschätzte (schwarze) Linie. Der Effekt von bill_length auf body_mass wird mit der einfachen Regression lm(body_mass ~ bill_length) vermutlich überschätzt, weil es andere Faktoren (wie flipper_length gibt, die mit bill_length und body_mass korrelieren. Kontrollieren für flipper_length in der multiplen Regression lm(body_mass ~ bill_length + flipper_length) schließt die Backdoor durch flipper_length. Die Konsequenz ist eine deutlich geringere Steigung der lilanen Regressionslinie.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "Reg.html#regression-schließt-backdoors-frisch-waugh-lovell-theorem",
    "href": "Reg.html#regression-schließt-backdoors-frisch-waugh-lovell-theorem",
    "title": "4  Regression",
    "section": "",
    "text": "Rechne die Effekte der übrigen Regressoren auf (a) die Outcome-Variable und (b) die interessierende Teilmenge der Regressoren mit Regression heraus.\nRegressiere anschließend die Residuen von Schritt (a) auf die Residuen aus Schritt (b).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie originalen Datenpunkte für bill_length und body_mass1 gemeinsam mit der geschätzten Regressionslinie für das Modell \\[ \\textup{body\\_mass} = \\beta_0 + \\beta_1\\textup{bill\\_length} + u \\] (keine Kontrolle für flipper_length!)2.\nDie um flipper_length bereinigten Datenpunkte und die zugehörige geschätzte Regressionslinie.\n\n1 Für eine bessere Lesbarkeit der Grafik zentrieren wir beide Variablen um den jeweiligen Stichprobenmittelwert.2 Der R-Befehl für diese Regression ist lm(I(body_mass - mean(body_mass)) ~ I(bill_length - mean(bill_length)) - 1, data = penguins_cleaned).",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "Reg.html#sec-bov",
    "href": "Reg.html#sec-bov",
    "title": "4  Regression",
    "section": "\n4.2 Binäre Outcome-Variable",
    "text": "4.2 Binäre Outcome-Variable\nEine binäre Variable, auch als dichotome Variable oder Indikator-Variable bezeichnet, ist eine Variable, die nur zwei Ausprägungen annehmen kann. Diese beiden Ausprägungen werden typischerweise durch die Werte 0 und 1 repräsentiert und dienen dazu, zwei verschiedene Zustände oder Kategorien zu unterscheiden. Formal kann eine binäre Variable \\(B\\) wie folgt definiert werden:\n\\[\\begin{align}\n  B = \\begin{cases}\n  1, & \\text{Eigenschaft trifft zu,} \\\\\n  0, & \\text{Eigenschaft trifft nicht zu.}\n  \\end{cases}\n\\end{align}\\]\nEin in späteren Kapiteln dieses Companions verwendeter binärer Regressor ist der Indikator für die Zuordnung von Beobachtungen zur Behandlungs- oder Kontrollgruppe (1 = Behandlungsgruppe, 0 = Kontrollgruppe).\nFür viele ökonomische Forschungsfragen ist es hilfreich, eine binäre Outcome-Variable mit Regression zu modellieren. Hierzu gibt es verschiedene Ansätze, die wir nachfolgend zusammenfassen und ihre Anwendung mit R zeigen.\n\n4.2.1 Das lineare Wahrscheinlichkeitsmodell\nDas lineare Regressionsmodell\n\\[Y = \\beta_0 + \\beta_1 X_{1} + \\beta_2 X_{2} + \\dots + \\beta_k X_{k} + u\\] mit einer binären abhängigen Variablen \\(Y_i\\in\\{0,1\\}\\) wird als lineares Wahrscheinlichkeitsmodell bezeichnet. Wie üblich modellieren wir den Erwartungswert der abhängigen Variable gegeben der Regressoren \\(X_1,\\dots,X_k\\) als lineare Funktion,\n\\[E(Y\\vert X_1,X_2,\\dots,X_k) = P(Y=1\\vert X_1, X_2,\\dots, X_3).\\] Da \\(Y\\) eine binäre Variable ist, gilt hier\n\\[ P(Y = 1 \\vert X_1, X_2, \\dots, X_k) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_k X_k.\\]\nDas lineare Wahrscheinlichkeitsmodell beschreibt also die Wahrscheinlichkeit, dass \\(Y=1\\) als lineare Funktion der Regressoren: \\(\\beta_j\\) misst die Änderung in der Wahrscheinlichkeit für das Ereignis \\(Y_i=1\\), unter der Bedingung, dass die anderen \\(k-1\\) Regressoren konstant gehalten werden. Genau wie bei multipler Regression mit einer kontinuierlichen abhängigen Variablen können die \\(\\beta_j\\) mit der KQ-Methode geschätzt werden.\nAufgrund der Beschränktheit der \\(Y_i\\) auf \\(\\{0,1\\}\\) ist \\(u_i\\) heteroskedastisch. Folglich sollten Inferenzstatistiken mit robusten Standardfehlern berechnet werden. Weiterhin ist zu beachten, dass \\(R^2\\) in den meisten Anwendungen von linearen Wahrscheinlichkeitsmodellen keine hilfreiche Interpretation hat, da das geschätzte Modell die Daten nicht perfekt erklären kann, wenn die abhängige Variable binär, aber die Regressoren kontinuierlich verteilt sind.\nDas lineare Wahrscheinlichkeitsmodell hat einen wesentlichen Nachteil: Das Modell nimmt an, dass die bedingte Wahrscheinlichkeitsfunktion linear ist und \\(P(Y=1\\vert X_1,\\dots,X_k)\\) über das für Wahrscheinlichkeiten definierte Intervall \\([0,1]\\) hinausgehen kann. Ein angepasstes Modell hat dann für Regressorwerte, die zu Vorhersagen von \\(Y\\) jenseits von \\([0,1]\\) führen keine sinnvolle Interpretation.\nDieser Umstand verlangt nach Regressionsansätzen, die \\(P(Y=1)\\) durch eine auf \\([0,1]\\) beschränkte (nicht-lineare) Funktion der Regressoren modellieren. Häufig verwendete Methoden sind Probit- und Logit-Regression.\nEin lineares Wahrscheinlichkeitsmodell kann mit lm() geschätzt werden, wobei die abhängige Variable den Typ numeric oder integer haben muss.\n\n4.2.2 Probit-Regression\nBei der Probit-Regression wird die Standardnormalverteilungsfunktion \\(\\Phi(\\cdot)\\) verwendet, um die Regressionsfunktion einer binären abhängigen Variable zu modellieren. Wir nehmen an, dass \\[\\begin{align}\n  E(Y\\vert X) = P(Y=1\\vert X) = \\Phi(\\beta_0 + \\beta_1 X), \\label{eq:probitmodel}\n\\end{align}\\] sodass der mit der Verknüpfungsfunktion (Link-Funktion) \\[\\textup{probit}(\\cdot) = \\Phi^{-1}(\\cdot)\\] transformierte Erwartungswert \\(P(Y=1\\vert X)\\) dem linearen Prädiktor \\(z=\\beta_0 + \\beta_1 X\\) entspricht, \\[\\begin{align*}\n  \\Phi^{-1}\\big[P(Y=1\\vert X)\\big] = \\beta_0 + \\beta_1 X.\n\\end{align*}\\]\n\\(z=\\beta_0 + \\beta_1 X\\) in \\(\\eqref{eq:probitmodel}\\) modelliert hier also ein Quantil der Standardnormalverteilung, \\[\\begin{align*}\n\\Phi(z) = P(Z \\leq z) \\ , \\ Z \\sim \\mathcal{N}(0,1).\n\\end{align*}\\] Der Koeffizient \\(\\beta_1\\) in \\(\\eqref{eq:probitmodel}\\) misst die Änderung in \\(z\\), die mit einer Änderung von \\(X\\) um eine Einheit verbunden ist. Obwohl der Effekt einer Änderung in \\(X\\) auf \\(z\\) linear ist, ist der Zusammenhang zwischen \\(z\\) und \\(\\textup{E}(Y\\vert X) = P(Y=1\\vert X)\\) nicht linear, denn \\(\\Phi(\\cdot)\\) ist eine nicht-lineare Funktion von \\(X\\).\n\n\n\n\n\n\n\n\nAufgrund der Nicht-Linearität der Link-Funktion hat der Koeffizient von \\(X\\) keine einfache Interpretation hinsichtlich des Effekts auf \\(P(Y=1\\vert X)\\). Die Änderung in der Wahrscheinlichkeit, dass \\(Y=1\\) ist, durch eine Änderung in \\(X\\) (partieller Effekt von \\(X\\)) kann berechnet werden als:\n\\[\\begin{align*}\n  \\frac{\\partial\\textup{E}(Y\\vert X)}{\\partial X} = \\frac{\\partial\\textup{P}(Y=1\\vert X)}{\\partial X} = \\frac{\\partial\\Phi(\\beta_0 + \\beta_1 X)}{\\partial X} = \\phi(\\beta_0 + \\beta_1 X) \\beta_1,\n\\end{align*}\\] wobei \\(\\phi(\\cdot)\\) die Dichtefunktion der Standardnormalverteilung ist. In empirischen Anwendungen wird der partielle Effekt häufig als Differenz in geschätzten Wahrscheinlichkeiten angegeben:\n\nBerechne die geschätzte Wahrscheinlichkeit, dass \\(Y=1\\) für einen Bezugswert \\(X\\).\nBerechne die geschätzte Wahrscheinlichkeit, dass \\(Y=1\\) für \\(X + \\Delta X\\).\nBerechne die Differenz zwischen der geschätzten Wahrscheinlichkeiten.\n\nWie im linearen Wahrscheinlichkeitsmodell kann das Modell \\(\\eqref{eq:probitmodel}\\) auf eine Probit-Regression mit \\(k+1\\) Regressoren \\(\\boldsymbol{X} := (1, X_1, \\dots, X_k)\\) verallgemeinert werden, um das Risiko einer Verzerrung durch ausgelassene Variablen zu mindern. Die Schritte 1 bis 3 für die Berechnung des partiellen Effekts einer Änderung in \\(X_j\\) erfolgen dann unter der Annahme, dass die übrigen \\(k-1\\) Regressoren konstant gehalten werden, wobei der partielle Effekt von den jeweiligen Regressorwerten abhängt. Im nächsten Abschnitt erläutern wir die Schätzung von Probit-Modellen mit \\(k+1\\) Regressoren.\n\n4.2.2.1 Schätzung\nDie Likelihood-Funktion für Probit-Regression ist\n\\[\\begin{align*}\n  L(\\boldsymbol{\\beta}) = \\prod_{i=1}^n \\Phi(\\mathbf{X}_i^\\top \\boldsymbol{\\beta})^{y_i} \\left[1 - \\Phi(\\mathbf{X}_i^\\top \\boldsymbol{\\beta})\\right]^{1-y_i}\n\\end{align*}\\]\nHierbei ist \\(\\Phi(\\mathbf{X}_i^\\top \\boldsymbol{\\beta})\\) die Wahrscheinlichkeit, dass \\(Y_i = 1\\) ist und \\(1 - \\Phi(\\mathbf{X}_i^\\top \\boldsymbol{\\beta})\\) ist die Wahrscheinlichkeit, dass \\(Y_i = 0\\) ist.\nDie Log-Likelihood-Funktion ergibt sich als\n\\[\\begin{align*}\n  \\mathcal{L}(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left[ y_i \\log \\Phi(\\mathbf{X}_i^\\top \\boldsymbol{\\beta}) + (1 - y_i) \\log \\left(1 - \\Phi(\\mathbf{X}_i^\\top \\boldsymbol{\\beta})\\right) \\right]\n\\end{align*}\\]\nUm den Maximum-Likelihood-Schätzer \\(\\widehat{\\boldsymbol{\\beta}}\\) zu finden, muss die Log-Likelihood-Funktion \\(\\mathcal{L}(\\boldsymbol{\\beta})\\) maximiert werden. In der Praxis erfolgt dies häufig durch numerische Optimierung, da die Log-Likelihood-Funktion der Probit-Regression im Allgemeinen keine geschlossene Form hat, sodass eine analytische Lösung nicht möglich ist.\nFür eine Anwendung in R und einen Vergleich mit dem linearen Wahrscheinlichkeitsmodell erzeugen wir einen Beispieldatensatz simdata für einen datenerzeugenden Prozess (DGP)3 mit einem normalverteilten Regressor \\(X\\sim N(5,2^2)\\) und \\[\\begin{align*}\n  P(Y=1\\vert X) = \\Phi(z), \\quad z = -4 + 0.7 X.\n\\end{align*}\\]\n3 Siehe Kapitel 5 für Erläuterungen von Simulationsmethoden in R.\n\n\n\n\n\n\n\nDas lineare Wahrscheinlichkeitsmodell schätzen wir wie gewohnt mit lm() und berechnen robuste Standardfehler mit lmtest::coeftest().\n\n\n\n\n\n\n\n\nBeachte, dass lediglich die Vorzeichen der geschätzten Koeffizienten mit denen der wahren Werten übereinstimmmen. Da das lineare Modell fehlspezifiziert ist, sind die KQ-Schätzer der Koeffizienten hier inkonsistent.\nEin Probit-Modell kann mit stats::glm() geschätzt werden. Hierbei ist formula die Formel für den linearen Prädiktor \\(z\\) und family eine Link-Funktion für den Zusammenhang von \\(z\\) und \\(P(Y\\vert X)\\). Mit family = binomial(link = \"probit\") wählen wir die Link-Funktion probit.\n\n\n\n\n\n\n\n\nDie geschätzten Koeffizienten in der Probit-Regression liegen, wie erwartet, nahe bei Parametern des DGPs.\nUm beide Schätzungen gemeinsam zu plotten, erzeugen wir mit predict() Vorhersagen für eine Menge von Werten X im Intervall \\([0,11]\\). Beachte, dass bei Vorhersagen für das Probit-Modell die gewünschte Transformation der vorherzusagenden Variable über type gewählt werden muss.4 Der Standardfall ist type = \"link\", d.h. wir erhalten Vorhersagen für den linearen Prädiktor: \\(\\widehat{z} = \\widehat\\beta_0 + \\widehat{\\beta}_1X\\). Mit type = \"response\" werden diese Werte mit der Link-Funktion, hier \\(\\Phi(\\cdot)\\) zu vorhergesagten Wahrscheinlichkeiten \\(\\widehat{P}(Y=1\\vert X = x)\\) transformiert.\n4 Dies gilt für jedes Modell mit einer anderen Link-Funktion als \\(f(x) = x\\) ist (lineare Regression).\n\n\n\n\n\n\n\nDer nachfolgende Code-Chunk erstellt einen Punkte-Plot mit Jitter-Effekt (position_jitter), wobei die Beobachtungen zufällig leicht vertikal verschoben werden, um Überlappungen zu vermeiden. Zusätzlich zeichnen wir die geschätzten Regressionslinien für mod_lp (LPM) und mod_probit (Probit) sowie die tatsächliche Wahrscheinlichkeitsfunktion \\(P(Y=1\\vert X)\\) ein.\n\n\n\n\n\n\n\n\nDie Grafik zeigt, dass beide Modelle den positiven Zusammenhang für \\(X\\) und \\(P(Y=1\\vert X)\\) erfassen. Das lineare Wahrscheinlichkeitsmodell approximiert die tatsächliche nicht-lineare Wahrscheinlichkeitsfunktion nur schlecht und liefert insbesondere in den Rändern der Verteilung von \\(X\\) (kleine und große Werte) unzulässige Vorhersagen außerhalb des Intervalls \\([0,1]\\). Die Probit-Spezifikation hingegen erfasst den nicht-linearen Verlauf der tatsächlichen Wahrscheinlichkeitsfunktion gut.\n\n4.2.3 Logistische Regression\nBei logistischer Regression wird die logistische Funktion \\(\\Lambda(\\cdot)\\) \\[\\begin{align}\n\\Lambda(z) = \\frac{1}{1 + \\exp(-z)},\n\\end{align}\\] als Link-Funktion genutzt, um die Wahrscheinlichkeitsfunktion von \\(Y\\) gegeben \\(X\\) zu modellieren. Ähnlich wie im Probit-Modell nehmen wir hier an, dass \\[\\begin{align}\nE(Y\\vert X) = P(Y=1\\vert X) = \\Lambda(\\beta_0 + \\beta_1 X). \\label{eq:logitmodel}\n\\end{align}\\] In diesem Modell ist die Link-Funktion \\(\\Lambda^{-1}(\\cdot)\\). Für \\(z=\\beta_0 + \\beta_1 X\\) ist \\(\\Lambda^{-1}(t)\\) der sogenannte logit: Dass logarithmierte Verhältnis von \\(p := P(Y=1\\vert X)\\) zu \\(1 - p = P(Y=0\\vert X)\\), \\[\\begin{align*}\n  \\textup{logit(p)} = \\log\\bigg(\\frac{p}{1-p}\\bigg) = \\beta_0 + \\beta_1 X.\n\\end{align*}\\] Der Koeffizient \\(\\beta_1\\) misst also die Veränderung des Logits pro Einheit Änderung im Regressor \\(X\\).\nÄhnlich wie bei Probit-Regression ist der Einfluss von \\(X\\) auf den Logit linear, jedoch besteht auch hier eine nicht-lineare Beziehung zwischen dem linearen Prädiktor und der Wahrscheinlichkeit \\(P(Y=1\\vert X)\\), denn \\(\\Lambda(\\cdot)\\) ist eine nicht-lineare Funktion mit dem Wertebereich \\([0,1]\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie nachstehende interaktive Grafik illustriert, wie die Wahrscheinlichkeitsfunktion der latenten Variable \\(z=\\beta_0 + \\beta_1 X\\) von den Parametern \\(\\beta_0\\) und \\(\\beta_1\\) jeweils für Logit- und Probit-Regression beeinflusst wird.\n\n\nAufgrund der Nicht-Linearität von \\(\\Lambda(z)\\) kann der Koeffizient \\(\\beta_1\\) wie im Probit-Modell nicht direkt als Effekt auf die Wahrscheinlichkeit \\(P(Y=1\\vert X)\\) interpretiert werden.\nUm den partiellen Effekt einer Änderung in \\(X\\) am Punkt \\(X\\) auf \\(P(Y=1\\vert X)\\) zu ermitteln, berechnen wir die Ableitung des bedingten Erwartungswerts:\n\\[\\begin{align*}\n\\frac{\\partial\\textup{E}(Y\\vert X)}{\\partial X} = \\frac{\\partial\\textup{P}(Y=1\\vert X)}{\\partial X} = \\frac{\\partial\\Lambda(\\beta_0 + \\beta_1 X)}{\\partial X} = \\lambda(\\beta_0 + \\beta_1 X) \\beta_1,\n\\end{align*}\\] wobei \\(\\lambda(\\cdot)\\), ähnlich wie die Dichtefunktion der Normalverteilung im Probit-Modell, die Dichtefunktion der logistischen Verteilung darstellt. Diese ist gegeben durch \\[\\begin{align*}\n\\lambda(z) = \\Lambda(z) \\cdot (1 - \\Lambda(z)).\n\\end{align*}\\]\nDie Interpretation des angepassten Modells ist aufgrund der Modellierung des Logits intuitiver als für Probit-Regression. Angenommen eine Bank möchte die Wahrscheinlichkeit modellieren, dass ein Kunde einen Kredit nicht zurückzahlt: \\(P(Y=\\textup{Zahlungsausfall}\\vert X)\\), wobei der Regressor \\(X\\) das Verhältnis von aktuellem Schuldenstand und Monatseinkommen ist. Die Schätzung einer logistischen Regression ergibt, dass ein Anstieg von \\(X =x\\) um 0.1 den Logit für die Wahrscheinlichkeit eines Kreditausfalls \\(p(x)\\) um 0.4 erhöht: \\[\\begin{align*}\n  \\textup{logit} \\big[P(Y=\\textup{Zahlungsausfall}\\vert X = x + 0.1)\\big] = \\textup{logit}[p(x)] + 0.4.\n\\end{align*}\\]\nDas Modell besagt dann, dass die Wahrscheinlichkeit der Zahlungsunfähigkeit etwa um den Faktor 1.5 ansteigt, denn \\[\\begin{align*}\n  \\exp\\big(\\textup{logit}[p(x)] + 0.4\\big) = \\frac{p(x)}{1-p(x)} \\cdot \\exp(0.4)\n\\end{align*}\\] mit \\[\\begin{align*}\n  \\exp(0.4) \\approx 1.50.\n\\end{align*}\\]\n\n4.2.4 Schätzung\nÄhnlich wie bei Probit-Regressionen können Logit-Modelle mit Maximum-Likelihood geschätzt werden. Die Likelihood-Funktion für Logit-Regression lautet\n\\[\\begin{align}\n  L(\\boldsymbol{\\beta}) &= \\prod_{i=1}^n \\left(\\frac{1}{1 + \\exp(-\\mathbf{X}_i^\\top \\boldsymbol{\\beta})}\\right)^{y_i} \\left(1 - \\frac{1}{1 + \\exp(-\\mathbf{X}_i^\\top \\boldsymbol{\\beta})}\\right)^{1-y_i},\n\\end{align}\\]\nmit \\[\\frac{1}{1 + \\exp(-\\mathbf{X}_i^\\top \\boldsymbol{\\beta})}\\] der Wahrscheinlichkeit, dass \\(Y_i = 1\\). Für das Ereignis \\(Y_i = 0\\) ist die Wahrscheinlichkeit entsprechend \\[1 - \\frac{1}{1 + \\exp(-\\mathbf{X}_i^\\top \\boldsymbol{\\beta})}.\\]\nDie Log-Likelihood-Funktion lautet\n\\[\\begin{align*}\n  \\mathcal{L}(\\boldsymbol{\\beta}) &= \\sum_{i=1}^n \\left[ y_i \\log \\left(\\frac{1}{1 + \\exp(-\\mathbf{X}_i^\\top \\boldsymbol{\\beta})}\\right) + (1 - y_i) \\log \\left(1 - \\frac{1}{1 + \\exp(-\\mathbf{X}_i^\\top \\boldsymbol{\\beta})}\\right) \\right]\n\\end{align*}\\]\nund erlaubt die Schätzung von \\(\\boldsymbol{\\beta}\\) durch Maximierung mit numerischen Methoden.\nFür Anwendungen mit R nutzen wir stats::glm() und wählen die logistische Link-Funktion mit family = binomial(link = \"logit\"). Für die simulierten Daten simdata aus Kapitel 4.2.2:\n\n\n\n\n\n\n\n\nWir erweitern nun pred um die anhand von predict() für mod_logit geschätzten Wahrscheinlichkeiten von \\(Y=1\\vert X\\) für die Regressorwerte in X.\n\n\n\n\n\n\n\n\nAnhand der Vorhersagen in pred können wir die im Objekt p gespeicherte Grafik um die geschätzte Regressionsfunktion für das Logit-Modell erweitern.\n\n\n\n\n\n\n\n\nDie Logit-Regression kann den wahren Zusammenhang gut abbilden und ist praktisch nicht von der Probit-Schätzung unterscheidbar.\n\n4.2.5 Modellgüte\nÄhnlich wie bei linearer Regression kann die Anpassung von generalisierten linearen Modellen an die Daten mit Anpassungsmaßen verglichen werden. In generalisierten linearen Modellen für binäre Outcome-Variablen kann hierzu die Deviance verwendet werden. Für eine Schätzung anhand der Beobachtungen \\(i=1,\\dots,n\\) berechnet man die Deviance \\(D\\) als \\[\\begin{align*}\n  D = -2 \\sum_{i=1}^{n} \\left[ y_i \\cdot \\log\\left(\\widehat{P}_i\\right) + (1 - y_i) \\cdot \\log\\left(1 - \\widehat{P}_i\\right) \\right].\n\\end{align*}\\] \\(D\\) quantifiziert die Abweichung eines geschätzten Modells von einem perfekt passenden Modell.5 Eine geringere Deviance deutet darauf hin, dass das Modell die Daten besser erklärt. Eine R-Funktion zur Anwendung für Objekte des Typs glm ist deviance().\n5 Im Allgemeinen vergleicht Deviance die Log-Likelihood des geschätzten Modells mit der Log-Likelihood des perfekten Modells.\n\n\n\n\n\n\n\nDie Deviance für das Probit-Modell ist tatsächlich etwas geringer als für das Logit-Modell.\nÄhnlich wie \\(R^2\\) für lineare Regression misst die Deviance \\(D\\) lediglich die Anpassung des Modells an die beobachteten Daten. Daher eignet sich \\(D\\) nur bedingt als Maß zur Einschätzung der Tauglichkeit eines Modells für Out-of-sample-Vorhersagen. Abhängig vom Ziel der Modellierung kann es hilfreich sein, eine robuste Einschätzung der Vorhersage-Güte unter Berücksichtigung der Modellkomplexität vorzunehmen. Hierfür werden oft Informationskriterien verwendet. Das Akaike-Informationskriterium (AIC) \\[\\begin{align*}\n  \\text{AIC} = 2k - 2 \\log(\\widehat{\\mathcal{L}})\n\\end{align*}\\] ist ein Maß zur Bewertung der Güte eines Modells unter Berücksichtigung der Modellkomplexität. Das AIC wägt die Anpassung des Modells an die Daten (gemessen durch die maximierte Likelihood-Funktion \\(\\widehat{\\mathcal{L}}\\)6) und die Komplexität (gemessen als Funktion der Regressoranzahl \\(k\\)) gegeneinander ab. Hierbei werden Modelle mit weniger Parametern bevorzugt, wenn sie die Daten ähnlich gut erklären, sodass eine Überanpassung und damit eine schlechte Vorhersagefähigkeit vermieden werden. In R können wir das AIC für Modell-Objekte mit AIC() berechnen.\n6 \\(\\widehat{\\mathcal{L}}\\) meint die Likelihood-Funktion für die geschätzten Koeffizienten.\n\n\n\n\n\n\n\nAuch das AIC zeigt an, dass die Schätzung des Probit-Modells in mod_probit besser geeignet für die Modiellierung von simdata ist als das Logit-Modell mod_logit.\n\n4.2.6 Beispiel: Klassifikation von Palmer-Piniguinen\nMit den in diesem Kapitel betrachteten Methoden können wir Modelle zur Klassifikation von Pinguinen in palmerpenguins::penguins hinsichtlich ihres Geschlechts konstruieren. Hierfür nutzen wir den bereinigten Datensatz penguins_cleaned und transformieren zunächst die abhängige Variable sex in ein numerisches Format.\n\n\n\n\n\n\n\n\nWir schätzen nachfolgend ein lineares Wahrscheinlichkeitsmodell penguins_lp, ein Probit-Modell penguins_probit sowie ein Logit-Modell penguins_logit die jeweils sex anhand der simplen Spezikation des linearen Prädiktors \\[z = \\beta_0 + \\beta_1 \\textup{bill\\_depth}\\] erklären.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMit modelsummary::modelsummary() können wir die wichtigsten Ergebnisse der Regressionen in einer publikationsfähigen Tabelle darstellen. Hierzu übergeben wir dem Argument models eine (benannte) Liste der geschätzten Modelle. Bei Angabe von vcov = \"HC1\" werden robuste Standardfehler ausgegeben.\n\n\n\n\n\n\n\n\nDie geschätzten negativen und signifikanten Koeffizienten von \\(\\textup{bill\\_depth}\\) erfassen den Zusammenhang, dass Pinguine mit größeren Schnäbeln tendenziell männlich sind: Je größer \\(\\textup{bill\\_depth}\\), desto geringer die geschätzte Wahrscheinlichkeit, dass ein Pinguin weiblich ist. Ein Vergleich anhand des AIC zeigt, dass das Probit-Modell penguins_probit am besten geeignet ist.\nAnalog zur Vorgehensweise in Kapitel 4.2.3 können wir die geschätzten Modelle vergleichen, in dem wir geschätzte Wahrscheinlichkeiten \\(P(Y=\\textup{weiblich}\\vert\\textup{bill\\_depth})\\) für eine Menge repräsentativer Werte des Regressors bill_depth berechnen und gemeinsam mit den Beobachtungen plotten.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie geschätzten Regressionsfunktionen unterscheiden sich für den Bereich beobachteter Werte von \\(bill\\_depth\\) nur wenig. Die Grafik zeigt, dass die Schätzungen mit Probit- und Logit-Ansatz nur wenig Nicht-Linearität aufweisen, sodass eine (leichter interpretierbare) Modellierung mit dem linearen Wahrscheinlichkeitsmodell penguins_lp hier zulässig scheint.\nDie Klassifizierung der Pinguine im Datensatz hinsichtlich ihres Geschlechts anhand vorhergesagter Wahrscheinlichkeiten \\(\\widehat{P}_i\\) kann durch Abgleich mit einem Grenzwert erfolgen. Ein Beispiel ist \\[\\begin{align}\n  \\widehat{Y}_i = \\begin{cases}\n    \\textup{weiblich}, & \\widehat{P}_i \\geq .5,\\\\\n    \\textup{männlich}, & \\textup{sonst.}\n  \\end{cases}\\label{eq:pengclass}\n\\end{align}\\]\nWir können diesen Ansatz in R implementieren, indem wir zunächst die für den Datensatz angepassten Wahrscheinlichkeiten fitted aus den Modell-Objekten auslesen.\n\n\n\n\n\n\n\n\nFür die Klassifikation der Pinguine anhand der jeweiligen geschätzten Wahrscheinlichkeiten wenden wir die Regel \\(\\eqref{eq:pengclass}\\) mit across() spaltenweise für die Modelle an und erzeugen neue Spalten mit vorhersagen des Geschlechts. Mit .names = \"{.col}_pred\" erhalten die neuen Spalten das Suffix _pred.\n\n\n\n\n\n\n\n\nMit summarise() berechnen wir nun den Anteil korrekter Vorhersagen.\n\n\n\n\n\n\n\n\nIn diesem Beispiel unterscheiden sich die Vorhersagen der drei Modelle für den Grenzwert 0.5 nicht.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "Reg.html#sec-poissonreg",
    "href": "Reg.html#sec-poissonreg",
    "title": "4  Regression",
    "section": "\n4.3 Modellierung von Zählvariablen",
    "text": "4.3 Modellierung von Zählvariablen\nEine weitere Klasse von \\(Y\\) für die sich der Regressionsansatz von einfacher linearer Regression unterscheidet, sind Zählvariablen: Variablen, die diskrete, nicht-negative Werte annehmen. Wenn die abhängige Variable \\(Y\\) Ereignisse in einem bestimmten Zeitraum misst (wie z.B. die Anzahl der Verkehrsunfälle in Essen innerhalb eines Monats) und weitere Bedingungen erfüllt sind, folgt \\(Y\\) einer Poisson-Verteilung und kann mit Poisson-Regression modelliert werden. Wir erläutern nachfolgend die wesentlichen Komponenten von Poisson-Regression und diskutieren ein R-Beispiel mit fiktiven Daten.\n\n4.3.1 Poisson-Verteilung\nDie Zufallsvariable \\(Y\\) folgt einer Poisson-Verteilung mit Parameter \\(\\lambda\\), wenn\n\ndie Ereignisse unabhängig voneinander auftreten: Das Auftreten eines Ereignisses beeinflusst nicht die Wahrscheinlichkeit, dass ein weiteres Ereignis auftritt.\ndie Ereignisse einzeln auftreten: Die Wahrscheinlichkeit, dass in einem sehr kleinen Intervall (im Sinne von \\([a,b]\\) für \\(a \\to b\\)) mehr als ein Ereignis auftritt, ist vernachlässigbar.\ndie Rate der Ereignisse konstant ist: Die durchschnittliche Anzahl der Ereignisse pro Zeiteinheit oder pro Raumeinheit \\(\\lambda\\) ist konstant.\n\nDie Wahrscheinlichkeitsfunktion von \\(Y\\) ist\n\\[\\begin{align}\nP(Y = y) = \\frac{\\lambda^y e^{-\\lambda}}{y!} \\quad \\text{für} \\quad y = 0, 1, 2, \\ldots,\\label{eq:poissonpmf}\n\\end{align}\\] wobei \\(\\lambda\\) sowohl der Erwartungswert als auch die Varianz der Verteilung ist, \\[\\textup{E}(Y) = \\textup{Var}(Y) = \\lambda.\\]\nDie nächste Grafik zeigt die diskrete (Wahrscheinlichkeitsmasse-)Funktion \\(\\eqref{eq:poissonpmf}\\) für eine Poisson-verteilte Zufallsvariable \\(Y\\) mit \\(\\lambda = 5\\) für den Wertebereich von 0 bis 15.\n\n\n\n\n\n\n\n\n\n4.3.2 Poisson-Regression\nWie für die bisher betrachteten Regressionsansätzen modelliert Poisson-Regression den Erwartungswert (und damit gleichzeitig die Varianz) \\(\\lambda\\) der abhängigen Variable \\(Y\\) als eine Funktion der Regressoren \\(\\mathbf{X} = (X_1, X_2, \\ldots, X_k)\\). Unter Annahme einer Poisson-Verteilung kann Poisson-Regression als generalisiertes lineares Modell verstanden werden, wobei eine logarithmische Verknüpfungsfunktion für den linearen Prädiktor \\(\\mathbf{X}_i^\\top \\boldsymbol{\\beta}\\) verwendet wird:\n\\[\\begin{align*}\n\\log(\\lambda_i) &= \\mathbf{X}_i^\\top \\boldsymbol{\\beta},\n\\end{align*}\\] sodass \\[\\begin{align*}\n\\lambda_i &= \\exp(\\mathbf{X}_i^\\top \\boldsymbol{\\beta}),\n\\end{align*}\\] wobei\n\n\n\\(\\lambda_i = \\textup{E}(Y_i\\vert \\mathbf{X}_i) = \\textup{Var}(Y_i\\vert \\mathbf{X}_i)\\) für Beobachtung \\(i\\),\n\n\\(\\mathbf{X}_i\\) der Vektor der unabhängigen Variablen für Beobachtung \\(i\\) ist, und\n\n\\(\\boldsymbol{\\beta}\\) der Vektor der Regressionskoeffizienten ist.\n\n4.3.3 Schätzung\nDie Likelihood-Funktion für \\(n\\) Beobachtungen ist\n\\[\\begin{align}\nL(\\boldsymbol{\\beta}) = \\prod_{i=1}^n \\frac{\\lambda_i^{y_i} e^{-\\lambda_i}}{y_i!}.\n\\end{align}\\]\nDie Log-Likelihood-Funktion ist daher\n\\[\\begin{align}\n\\mathcal{L}(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left( y_i \\log(\\lambda_i) - \\lambda_i - \\log(y_i!). \\right)\n\\end{align}\\]\nDa \\(\\lambda_i = \\exp(\\mathbf{X}_i^\\top \\boldsymbol{\\beta})\\), wird die Log-Likelihood-Funktion zu\n\\[\\begin{align}\n\\mathcal{L}(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left( y_i (\\mathbf{X}_i^\\top \\boldsymbol{\\beta}) - \\exp(\\mathbf{X}_i^\\top \\boldsymbol{\\beta}) - \\log(y_i!) \\right)\n\\end{align}\\]\nDen ML-Schätzer \\(\\widehat{\\boldsymbol{\\beta}}\\) erhalten wir durch Maximierung der Log-Likelihoodfunktion \\(\\mathcal{L}(\\boldsymbol{\\beta})\\). Die R-Implementierung von Poisson-Regression in stats::glm() wird mittels family = poisson(link = \"log\") aufgerufen.\n\n4.3.4 Interpretation der Koeffizienten\nDie Koeffizienten \\(\\boldsymbol{\\beta}\\) in der Poisson-Regression haben eine logarithmisch-lineare Beziehung zur Zählvariable. Für einen bestimmten Koeffizienten \\(\\beta_j\\) ist die Interpretation wie folgt:\nEine Änderung der unabhängigen Variable \\(X_j\\) um eine Einheit führt zu einer Änderung des Logarithmus des Erwartungswertes von \\(Y\\) um \\(\\beta_j\\). Der Erwartungswert \\(\\lambda\\) ändert sich also multiplikativ um den Faktor \\(\\exp(\\beta_j)\\).\nAls Beispiel betrachten wir den linearen Prädiktor\n\\[\\begin{align*}\n  \\log(\\lambda) = \\beta_0 + \\beta_1 X.\n\\end{align*}\\]\nFür eine Änderung von \\(X\\) um \\(\\Delta X\\) erhalten wir\n\\[\\begin{align*}\n   \\lambda =&\\, \\exp(\\beta_0 + \\beta_1 X) \\\\\n    \\lambda + \\delta\\lambda =&\\, \\exp(\\beta_0 + \\beta_1 (X + \\Delta X)) \\\\\n    =&\\, \\exp(\\beta_0 + \\beta_1 X) \\cdot \\exp(\\beta\\Delta X) \\\\\n    =&\\, \\lambda \\cdot \\exp(\\beta\\Delta X)\n\\end{align*}\\]\nAngenommen \\(X\\) ist die Anzahl durchgeführter Werbekampagnen und die abhängige Zählvariable \\(Y\\) misst die Anzahl der Verkäufe des beworbenen Produkts pro Monat.\nWenn \\(\\beta_1 = 0.5\\), bedeutet dies, dass jede zusätzliche Werbekampagne (\\(\\Delta X = 1\\)) die erwartete Anzahl der Verkäufe pro Monat um einen Faktor von \\(\\exp(0.5) \\approx 1.65\\) erhöht:\nDas heißt, die Rate der Verkäufe steigt um 65% für jede zusätzliche Werbekampagne.\nZur Veranschaulichung der Schätzung einer Poisson-Regression für dieses Beispiel erzeugen wir Poisson-verteilte Daten für \\[\\begin{align*}\n  \\log(\\lambda) = 2 + 0.4 \\cdot X\n\\end{align*}\\] und ziehen \\(X\\) gleichverteilt aus \\(\\{1,2,\\dots,8\\}\\).\n\n\n\n\n\n\n\n\nDie Züge aus der abhängigen Variablen visualieren wir mit einem Häufigkeits-Histogramm.\n\n\n\n\n\n\n\n\nWir schätzen das Modell und extrahieren die robuste Zusammenfassung mit broom::tidy().\n\n\n\n\n\n\n\n\nDie ML-Schätzung des Poisson-Modells liefert für die verwendete Stichprobe von 500 Beobachtungen Koeffizienten-Schätzungen nahe der wahren Parameter. Zur Veranschaulichung des geschätzten Modells überlagern wir die simulierten Datenpunkte aus dat mit der anhand von mod_poisson geschätzten Anzahl der Verkäufe je Anzahl an Werbekampagnen.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "Reg.html#zusammenfassung",
    "href": "Reg.html#zusammenfassung",
    "title": "4  Regression",
    "section": "\n4.4 Zusammenfassung",
    "text": "4.4 Zusammenfassung\nIn diesem Kapitel haben wir erweiterte Konzepte der Regressionsanalyse diskutiert. Anhand des Frisch-Waugh-Lovell-Theorems wurde die Wirkungsweise der Kontrolle von Kovariablen mit multipler Regression auf den interessierenden Koeffizienten (Effekt) einer Variable veranschaulicht. Weiterhin haben wir gängige Typen generalisierter linearer Modelle für binäre und Poisson-verteilte Outcome-Variablen eingeführt. Anhand relevanter Beispiele wurde gezeigt, wie diese generalisierten Regressionsmodelle in R spezifiziert, geschätzt und der resultierende Output mit Paketen wie broom, ggplot2 und modelsummary interpretiert werden kann.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "RegReg.html",
    "href": "RegReg.html",
    "title": "13  Regularisierte Regression",
    "section": "",
    "text": "13.1 Ridge Regression\nRidge Regression wurde von Hoerl und Kennard (1970) als Alternative zur KQ-Schätzung bei hoch-korrelierten Regressoren eingeführt. Die Verlustfunktion lautet \\[\\begin{align}\n  \\mathrm{RSS}(\\boldsymbol{\\beta},p=2,\\lambda) = \\mathrm{RSS}(\\boldsymbol{\\beta}) + \\lambda \\lVert\\boldsymbol{\\beta}\\rVert_2,\\label{eq:ridgeloss}\n\\end{align}\\] d.h. der Parameter \\(\\lambda\\) reguliert den Einfluss eines \\(\\ell_2\\)-Strafterms \\[\\begin{align*}\n  \\lVert\\boldsymbol{\\beta}\\rVert_2 = \\sqrt{\\sum_{j=1}^k\\beta_j^2}\n\\end{align*}\\] auf die Verlustfunktion \\(\\mathrm{RSS}(\\boldsymbol{\\beta},p=2,\\lambda)\\). Der Ridge-Schätzer ergibt sich als \\[\\begin{align}\n  \\widehat{\\boldsymbol{\\beta}}^{\\mathrm{R}}_\\lambda := \\arg\\min_{\\boldsymbol{\\beta}}\\mathrm{RSS}(\\boldsymbol{\\beta}) + \\lambda \\lVert\\boldsymbol{\\beta}\\rVert_2.\\label{eq:ridgereg}\n\\end{align}\\]\nFür Das Optimierungsproblem \\(\\eqref{eq:ridgereg}\\) kann wir aus den Bedingungen 1. Ordnung \\[\\begin{align}\n  -2\\boldsymbol{X}'(\\boldsymbol{Y} - \\boldsymbol{X}\\boldsymbol{\\beta}) + 2\\lambda\\boldsymbol{\\beta} = \\boldsymbol{0}\n\\end{align}\\] die analytische Lösung \\[\\begin{align}\n  \\widehat{\\boldsymbol{\\beta}}^{\\mathrm{R}}_\\lambda = (\\boldsymbol{X}'\\boldsymbol{X} + \\lambda\\boldsymbol{I}_p)^{-1}\\boldsymbol{X}'\\boldsymbol{Y},\\label{eq:ridgecf}\n\\end{align}\\] bestimmt werden, wobei \\(\\boldsymbol{I}_k\\) die \\(k\\times k\\) Einheitsmatrix ist. Aus Gleichung \\(\\eqref{eq:ridgecf}\\) kann die Wirkungsweise des Strafterms \\(\\lambda \\lVert\\boldsymbol{\\beta}\\rVert_2\\) abgeleitet werden: Ridge Regression modifiziert die Diagonale der zu invertierenden Matrix \\(\\boldsymbol{X}'\\boldsymbol{X}\\) durch Addition von \\(\\lambda&gt;0\\). Dies ist hilfreich, wenn\nFür eine grafische Betrachtung des Optimierungskalküls \\(\\eqref{eq:ridgereg}\\) betrachten wir die äquivalente Darstellung als Lagrange-Problem \\[\\begin{align}\n  \\widehat{\\boldsymbol{\\beta}}^{\\mathrm{R}}_\\lambda := \\arg\\min_{\\lVert\\boldsymbol{\\beta}\\rVert&lt;t}\\mathrm{RSS}(\\boldsymbol{\\beta}).\\label{eq:ridgeLg}\n\\end{align}\\] In der folgenden interaktiven Grafik illustrieren wir das Optimierungsproblem \\(\\eqref{eq:ridgeLg}\\) sowie den resultierenden Schätzer der Koeffizienten \\((\\beta_1, \\beta_2)\\) in einem multiplen Regressionsmodell mit den Regressoren \\(X_1\\) und \\(X_2\\).",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regularisierte Regression</span>"
    ]
  },
  {
    "objectID": "RegReg.html#ridge-regression",
    "href": "RegReg.html#ridge-regression",
    "title": "13  Regularisierte Regression",
    "section": "",
    "text": "\\(k\\geq n\\) und damit \\(\\boldsymbol{X}'\\boldsymbol{X}\\) nicht invertiertbar (singulär) ist. Dann kann der KQ-Schätzer nicht berechnet werden.3 Die Inverse \\((\\boldsymbol{X}'\\boldsymbol{X} + \\lambda\\boldsymbol{I}_p)^{-1}\\) hingegen existiert unter milden Bedingungen.\nhohe Kollinearität vorliegt, sodass \\((\\boldsymbol{X}'\\boldsymbol{X})^{-1}\\) zwar existiert, aber zu einer instablilen KQ-Schätzung mit hoher Varianz führt.\n\n3 Beispiel: X &lt;- matrix(rnorm(100), ncol = 10). Vergleiche solve(t(X) %*% X) und solve(t(X) %*% X + diag(.01, nrow = 10))\n\nDie blaue Ellipse ist die Menge aller Schätzwerte \\(\\left(\\widehat\\beta_{1},\\, \\widehat\\beta_{2}\\right)\\) für den angegebenen Wert von \\(\\mathrm{RSS}\\). Im Zentrum der Ellipse liegt der KQ-Schätzer, welcher \\(\\mathrm{RSS}\\) minimiert.\nDer blaue Kreis ist die Menge aller Koeffizienten-Paare \\((\\beta_1, \\beta_2)\\), welche die Restriktion \\(\\beta_1^2 + \\beta_2^2\\leq t\\) erfüllen. Beachte, dass die Größe des Kreises nur durch den Parameter \\(t\\) bestimmt wird, welcher für einen vorgegebenen Wertebereich variiert werden kann.\nDer blaue Punkt ist der Ridge-Schätzer \\((\\widehat\\beta^R_{1,t},\\, \\widehat\\beta^R_{2,t})\\). Dieser ergibt sich als Schnittpunkt zwischen der blauen \\(\\mathrm{RSS}\\)-Ellipse und der Restriktionsregion und variiert mit \\(t\\). Die gestrichelte rote Kurve zeigt den Ridge-Lösungspfad.\nFür kleine Werte \\(t\\) drückt die Shrinkage die geschätzten Koeffizienten Richtung 0, wobei der Lösungspfad i.d.R. nicht-linear verläuft, d.h. die Shrinkage auf den Koeffizienten ist grundsätzlich unterschiedlich. Die Lösung \\((\\widehat\\beta^R_{1,t},\\, \\widehat\\beta^R_{2,t}) = (0,0)\\) existiert nur als Grenzwert für \\(t\\to0\\).\nBeachte, dass der Effekt von \\(t\\) auf die Schätzung umgekehrt für \\(\\lambda\\) verläuft: Größere \\(\\lambda\\) führen zu stärkerer Regularisierung.\n\n\n\n\n13.1.1 Eigenschaften des Schätzers\nDer Ridge-Schätzer \\(\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{R}}_\\lambda\\) ist nicht invariant gegenüber der Skalierung der Regressoren. Für empirische Daten sollte daher vorab eine Standardisierung der erklärenden Variablen durchgeführt werden.4 Um die Eigenschaften des Ridge-Schätzers besser zu verstehen, betrachten wir hier den Fall orthonormaler Regressoren \\(\\boldsymbol{X}_j\\).5 Dann ist \\[\\begin{align}\n  \\widehat{\\beta}^{\\mathrm{R}}_{\\lambda,\\,j} = (1+\\lambda)^{-1} \\cdot\\widehat{\\beta}_j,\\quad j = 1,\\dots,k,\\label{eq:ridgeortho}\n\\end{align}\\] d.h. der Ridge-Schätzer skaliert die KQ-Lösung mit einem von \\(\\lambda\\) abhängigen Faktor.6\n4 Bspw. mit der Funktion scale().5 Orthonormalität heißt \\(\\boldsymbol{X}_i'\\boldsymbol{X}_j = 1\\) für \\(i=j\\) und \\(0\\) sonst. Dann ist \\(\\boldsymbol{X}\\)’\\(\\boldsymbol{X} = \\boldsymbol{I}_k\\).6 \\((1+\\lambda)^{-1}\\) wird auch als Shrinkage-Faktor bezeichnet.Wir illustrieren dies, indem wir den Zusammenhang zwischen KQ- und Ridge-Schätzer im orthonormalen Fall als R-Funktion ridge_ortho() implementieren und für die Parameterwerte \\(\\lambda\\in\\{0,0.5,2\\}\\) plotten.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie obige Grafik zeigt, dass der Ridge-Schätzer eine lineare Transformation des KQ-Schätzers (gestrichelte Linie) ist. Größere Werte des Regularisierungsparameters \\(\\lambda\\) führen zu stärkerer Shrinkage des Koeffizientenschätzers in Richtung 0. Die \\(\\ell_2\\)-Norm führt zu proportional zum Absolutwert des KQ-Schätzers verlaufender Shrinkage: Größere Koeffizienten werden stärker bestraft als kleine Koeffizienten.\nDie Eigenschaft \\[\\mathrm{E}\\left(\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{R}}_{\\lambda,\\,j}\\right) = (1+\\lambda)^{-1} \\cdot \\beta_j\\] zeigt, dass \\(\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{R}}_{\\lambda,\\,j}\\) (für fixes \\(\\lambda&gt;0\\)) nicht erwartungstreu für \\(\\beta_j\\) ist. Weiterhin ist \\[\\begin{align*}\n  \\mathrm{Var}\\left(\\widehat{\\beta}^{\\mathrm{R}}_{\\lambda,\\,j}\\right) =&\\,\n  \\mathrm{Var}\\left(\\widehat{\\beta}_j\\right) \\cdot \\left(\\frac{\\lambda}{1+\\lambda^2}\\right)\\\\\n    =&\\, \\sigma^2\\cdot \\left(\\frac{\\lambda}{1+\\lambda^2}\\right),\n\\end{align*}\\] wobei \\(\\sigma^2\\) die Varianz des Regressionsfehlers \\(u\\) ist. Wegen \\(\\lambda&lt;(1+\\lambda)^2\\) für \\(\\lambda&gt;0\\) gilt \\[\\mathrm{Var}\\left(\\widehat{\\beta}^{\\mathrm{R}}_{\\lambda,\\,j}\\right)&lt;\\mathrm{Var}\\left(\\widehat{\\beta}_j\\right).\\] Der Ridge-Schätzer hat also eine kleinere Varianz als der KQ-Schätzer. Diese Eigenschaften können auch für korrelierte Regressoren gezeigt werden.\n\n13.1.2 Ridge Regression mit glmnet\n\nWir zeigen nun anhand simulierter Daten, wie der Ridge-Lösungspfad mit dem R-Paket glmnet berechnet werden kann. Wir erzeugen zunächst Daten gemäß der Vorschrift \\[\\begin{align}\n  \\begin{split}\n  Y_i =&\\, \\boldsymbol{X}_i' \\boldsymbol{\\beta} + u_i,\\\\\n  \\\\\n  \\beta_j =&\\,  \\frac{5}{j^2}, \\qquad\\qquad\\ j=1,\\dots,5,\\\\\n  \\beta_j =&\\, -\\frac{5}{(j-5)^2}, \\quad j=6,\\dots,10,\\\\\n  \\\\\n  \\boldsymbol{X}_i \\sim&\\, N(\\boldsymbol{0}, \\boldsymbol{\\Sigma}), \\quad u_i \\overset{u.i.v.}{\\sim} N(0, 1), \\quad i = 1,\\dots,25.\n  \\end{split} \\label{eq:ridgedgp1}\n\\end{align}\\] Hierbei wird \\(\\boldsymbol{\\Sigma}\\) so definiert, dass jeder Regressor \\(N(0,1)\\)-verteilt ist und eine Korrelation von \\(0.8\\) mit allen anderen Regressoren aufweist. Mit der Vorschrift für die \\(\\beta_j\\) stellen wir sicher, dass es wenige Variablen gibt, die \\(Y\\) stark beeinflussen, da der Absolutbetrag der Koeffizienten in \\(j\\) abnimmt.7\n7 Für bessere Interpretierbarkeit der Grafischen Auswertung, wählen wir positive und negative Koeffizienten mit gleichem Betrag.\n\n\n\n\n\n\n\nWir schätzen nun ein Modell mit allen k Regressoren mit glmnet. Beachte, dass für den Ridge-Strafterm alpha = 0 gesetzt werden muss.8\n8 alpha ist ein Mischparameter im Algorithmus für elastic net, siehe ?glmnet.\n\n\n\n\n\n\n\nDer Lösungspfad der Ridge-Schätzung kann nach Transformation der geschätzen Koeffizienten und der zugehörigen \\(\\lambda\\)-Werte in ein langes Format überführt und komfortabel mit ggplot2 dargestellt werden.\n\n\n\n\n\n\n\n\nWir sehen den nicht-linearen Verlauf der Shrinkage auf den geschätzten Modellkoeffizienten in der Abbildung. Die Koeffizienten werden mit zunehmendem \\(\\lambda\\) von der KQ-Lösung ausgehend (linkes Ende der Skala) in Richtung 0 gezwungen.\nÜber die Funktion cv.glmnet() kann ein optimales \\(\\lambda\\) mit Cross Validation (CV) ermittelt werden. Ähnlich wie bei glmnet() wird für die Validierung automatisch eine \\(\\lambda\\)-Sequenz erzeugt. Wir nutzen autoplot() aus dem R-Paket ggfortify für die Visualisierung der Ergebnisse mit ggplot2.\n\n\n\n\n\n\n\n\nDer Plot zeigt ridge_cvfit$lambda.min, das optimale \\(\\lambda\\) mit dem geringsten CV Mean-Squarred-Error (linke gestrichelte Linie) und ridge_cvfit$lambda.1se, das größte \\(\\lambda\\), welches innerhalb einer Standardabweichung entfernt ist (rechte gestrichelte Linie).9 Wir berechnen die Schätzung für lambda.min.\n9 Die Wahl von lambda.1se ist eine Heuristik, welche die Schätzunsicherheit berücksichtigt und zu einem “sparsameren” Modell tendiert.\n\n\n\n\n\n\n\nWir schätzen das Modell nun mit KQ und vergleichen die Koeffizienten mit der Ridge-Schätzung.\n\n\n\n\n\n\n\n\nDer Vergleich in der obigen Abbildung zeigt deutlich, dass Ridge Regression im Vergleich mit KQ zu absolut kleineren Koeffizientenschätzungen tendiert. Inwiefern dies Konsequenzen für die Prognosegüte der Schätzung hat, können wir Anhand eines Testdatensatzes bestimmen. Hierzu vergleichen wir die mittleren Fehler (MSE) bei der Prognose von \\(Y\\) für die Beobachtungen im Testdatensatz. Für die Simulation des Testdatensatzes nutzen wir erneut die Vorschrift \\(\\eqref{eq:ridgedgp1}\\) um N neue Beobachtungen zu erzeugen.\n\n\n\n\n\n\n\n\nFür beide Methoden können wir predict() für die Prognosen von \\(Y\\) für den Testdatensatz (new_Y) nutzen.\n\n\n\n\n\n\n\n\nDie Vorhersage für lm() benötigt dieselben Variablennamen wie im angepassten Modell, s. KQ_fit$coefficients.\n\n\n\n\n\n\n\n\nDie Ergebnisse zeigen, dass der Ridge-Schätzer trotz seiner Verzerrung einen deutlich geringeren mittleren Vorhersagefehler für die Testdaten erzielt als der KQ-Schätzer. Diese Eigenschaft der Koeffizientenschätzung kann die Prognosegüte von Ridge Regression gegenüber der KQ-Regression verbessern.\n\n13.1.3 Beispiel: Vorhersage von Abschlussnoten in Mathe\nZur Illustration von Ridge Regression nutzen wir den Datensatz SP aus Cortez und Silva (2008).10 SP enhält Beobachtungen zu Leistungen von insgesamt 100 Schülerinnen und Schülern im Fach Mathematik in der Sekundarstufe an zwei portugiesischen Schulen. Neben der Abschlussnote in Mathe (G3, Skala von 0 bis 20) beinhaltet SP diverse demografische, soziale und schulbezogene Merkmale, die mithilfe von Schulberichten und Fragebögen erhoben wurden. Ziel ist es, ein Modell für die Prognose von G3 anzupassen.\n10 Wir verwenden eine Auszug aus dem Orignaldatensatz, der nebst ausführlicher Variablenbeschreibung hier verfügbar ist.Wir lesen zunächst die Daten (im .csv-Format) ein.\n\n\n\n\n\n\n\n\nEin Überblick zeigt, dass der Großteil der Regressoren aus kategorialen Variablen mit sozio-ökonomischen Informationen besteht.\n\n\n\n\n\n\n\n\nUm die Prognosegüte des Modells beurteilen zu können, partitionieren wir SP zufällig in einen Test- sowie einen Trainingsdatensatz (mit 30 und 70 Beobachtungen), jeweils für die Regressoren und die abhängige Variable.\n\n\n\n\n\n\n\n\nAls nächstes passen wir ein Ridge-Regressionsmodell für alle Regressoren in SP_train an und ermitteln ein optimales \\(\\lambda\\) mit Cross Validation. Beachte, dass cv.glmnet nicht für Regressoren im data.frame/tibble-Format ausgelegt ist, sondern ein matrix-Format erwartet. Wir transformieren SP_train daher mit data.matrix().\n\n\n\n\n\n\n\n\nWie für das Beispiel mit simulierten Daten erhalten wir mit predict() Vorhersagen für die erzielte Punktzahl. Beachte, dass wir den MSE nicht für die Trainingsdaten SP_train, sondern für die Testdaten SP_test berechnen.\n\n\n\n\n\n\n\n\nAuch in diesem empirischen Beispiel zeigt ein Vergleich der MSEs, dass Ridge Regression dem KQ-Schätzer hinsichtlich der Vorhersagegüte überlegen ist.\n\n\n\n\n\n\n\n\nDer MSE für Ridge ist mit deutlich kleiner als der MSE für KQ.\nFür die Interpretation der Ridge-Schätzung erweitern den Code für die ggplot2-Grafik der Koeffizienten-Pfade um eine vertikale Linie des mit CV ermittelten \\(\\lambda\\) und fügen mit dem Paket ggrepel Labels für die Pfade der größten Koeffizienten hinzu.\n\n\n\n\n\n\n\n\nDer Plot gibt Hinweise darauf, dass neben der Schulzugehörigkeit und Indikatoren für schulische Leistung (bspw. failures) sozio-ökonomische Prädiktoren wie internet (Internetzugang zuhause), Pstatus (Zusammenleben der Eltern) und address/traveltime (sozialer Status) relevante Variablen zu sein scheinen.\nDas optimale \\(\\lambda_\\mathrm{cv}\\) (gestrichelte rote Linie im letzten Plot) führt zu deutlicher Shrinkage, was eine mögliche Erklärung für den besseren Testset-MSE von Ridge Regression ist: Die Koeffizienten von Variablen mit wenig Erklärungskraft werden durch die Regularisierung in Richtung 0 gezwungen und reduzieren so die Varianz der Vorhersage gegenüber der (idealerweise) unverzerrten KQ-Schätzung.\n\n\n\n\n\n\nKey Facts zu Ridge Regression\n\n\n\n\nRidge-Regression regularisiert den KQ-Schätzer mit der \\(\\ell_2\\)-Norm der Koeffizienten. Diese Form von Regularisierung ist eine Alternative für KQ in Anwendungen mit mehr Regressoren als Beobachtugen (\\(k\\geq n\\)) und/oder wenn KQ aufgrund starker Kollinearität eine hohe Varianz aufweist.\nDer Ridge-Schätzer \\(\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{R}}_\\lambda\\) ist nicht erwartungstreu. Die geschätzten Koeffizienten sind auch für \\(n\\to\\infty\\) verzerrt.\nAufgrund der verzerrten Schätzung ist statistische Inferenz für Koeffizienten mit \\(\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{R}}_\\lambda\\) problematisch. Anstatt für strukturelle Modelle oder die Schätzung kausaler Effekte wird Ridge Regression in der Praxis daher überwiegend für Prognosen verwendet.\nDie Wahl von \\(\\lambda\\) impliziert einen Tradeoff zwischen Verzerrung und Varianz: Große \\(\\lambda\\) schrumpfen die Koeffizientenschätzer Richtung 0 (mehr Verzerrung), führen aber zu einer kleineren Varianz der Schätzung. Entsprechend können Vorhersagen mit mehr Verzerrung aber weniger Varianz als mit KQ getroffen werden.\nRidge Regression kann in R mit dem Paket glmnet berechnet werden.",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regularisierte Regression</span>"
    ]
  },
  {
    "objectID": "RegReg.html#lasso-regression",
    "href": "RegReg.html#lasso-regression",
    "title": "13  Regularisierte Regression",
    "section": "\n13.2 Lasso Regression",
    "text": "13.2 Lasso Regression\nLeast Absolute Shrinkage and Selection Operator (Lasso) ist ein von Tibshirani (1996) vorgeschlagener Schätzer, der die Verlustfunktion des KQ-Schätzers um einen Strafterm für die Summe der (absoluten) Größe der Koeffizienten \\(\\boldsymbol\\beta = (\\beta_1, \\dots,\\beta_k)'\\) erweitert. Die Verlustfunktion des Lasso-Schätzers von \\(\\boldsymbol{\\beta}\\) lautet \\[\\begin{align}\n  \\mathrm{RSS}(\\boldsymbol{\\beta},p=1,\\lambda) = \\mathrm{RSS}(\\boldsymbol{\\beta}) + \\lambda \\lVert\\boldsymbol{\\beta}\\rVert_1.\n  \\label{eq:lassoloss}\n\\end{align}\\] Für den Strafterm wird also die \\(\\ell_1\\)-norm \\[\n\\lVert\\boldsymbol{\\beta}\\rVert_1 = \\sum_{j=1}^k \\lvert\\beta_j \\rvert\n\\] verwendet. Der Lasso-Schätzer \\(\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{L}}_\\lambda\\) für \\(\\boldsymbol{\\beta}\\) minimiert \\(\\eqref{eq:lassoloss}\\), \\[\\begin{align}\n  \\boldsymbol{\\beta}^{\\mathrm{L}}_\\lambda = \\arg\\min_{\\boldsymbol{\\beta}} \\ \\mathrm{RSS}(\\boldsymbol{\\beta},p=1,\\lambda).\n\\end{align}\\] Entsprechend erhalten wir in Abhängigkeit von \\(\\lambda\\) ein Kontinuum an Lösungen \\[\\begin{align}\n  \\left\\{\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{L}}_\\lambda\\right\\}_{\\lambda=0}^{\\lambda=\\infty},\n  \\label{eq:LassoPath}\n\\end{align}\\] der sogenannte Lasso-Pfad.\nDas Optimierungsproblem \\(\\eqref{eq:lassoloss}\\) hat die äquivalente Darstellung \\[\\begin{align}\n  \\begin{split}\n    \\widehat{\\boldsymbol{\\beta}}^{\\mathrm{L}}_\\lambda =&\\, \\arg\\min_{\\boldsymbol{\\beta}} \\mathrm{RSS}(\\boldsymbol{\\beta}) + \\lambda\\left(\\lVert\\boldsymbol{\\beta}\\rVert_1 - t\\right)\\\\\n    =&\\, \\arg\\min_{\\lVert\\boldsymbol{\\beta}\\rVert_1\\leq t} \\mathrm{RSS}(\\boldsymbol{\\beta}),\n  \\end{split}\\label{eq:lassolagrange}\n\\end{align}\\] welche über den Lagrange-Ansatz unter der Nebenbedingung \\(\\lVert\\boldsymbol{\\beta}\\rVert_1 \\leq t\\) gelöst werden kann.\nÄhnlich wie der KQ-Schätzer ist der Lasso-Schätzer \\(\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{L}}_\\lambda\\) durch Bedingungen 1. Ordnung bestimmt. Diese Bedingungen lassen sich komfortabel in Matrix-Schreibweise darstellen als \\[\\begin{align}\n  -2\\boldsymbol{X}_j'(\\boldsymbol{Y} - \\boldsymbol{X}\\boldsymbol{\\beta}) + \\lambda\\cdot\\mathrm{sgn}(\\beta_j) = 0, \\quad j = 1,\\dots,k.\\label{eq:LassoFOC}\n\\end{align}\\] Aus Gleichung \\(\\eqref{eq:LassoFOC}\\) folgt, dass der Lasso-Schätzer aufgrund des Strafterms im Allgemeinen nicht algebraisch bestimmt werden kann.11\n11 Zur Bestimmung des Schätzers werden Algorithmen der nicht-linearen Optimierung genutzt.In Abhängigkeit von \\(\\lambda\\) zwingt der Lasso-Schätzer die KQ-Schätzung von \\(\\beta_j\\) zu einem (absolut) kleineren Wert: Ähnlich wie bei Ridge Regression bewirkt der \\(\\ell_1\\)-Strafterm eine mit \\(\\lambda\\) zunehmende Schrumpfung der geschätzen Koeffizienten in Richtung 0. Charakteristisch für die Lösung des Lasso-Schätzers ist, dass \\(\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{L}}_j = 0\\), wenn die Bedingung \\[\\begin{align}\n  \\left\\lvert\\boldsymbol{X}_j'(\\boldsymbol{Y} - \\boldsymbol{X}\\widehat{\\boldsymbol{\\beta}}^{\\mathrm{L}}_\\lambda)\\right\\rvert - \\lambda/2 \\leq 0 \\label{eq:lassoselection}\n\\end{align}\\] erfüllt ist. In Abhängigkeit von \\(\\lambda\\) kann der Lasso-Schätzer folglich geschätzte Regressionskoeffizienten nicht nur in Richtung \\(0\\), sondern diese auch exakt mit \\(0\\) schätzen und damit Variablenselektion betreiben. Aufgrund der mit \\(\\lambda\\) zunehmenden Shrinkage bis die Bedingung \\(\\eqref{eq:lassoselection}\\) erfüllt und der Koeffizient gleich \\(0\\) gesetzt wird, bezeichnet man Lasso auch als einen Soft Thresholding Operator. Im nächsten Abschnitt betrachten wir die Eigenschaften von Lasso-Regularisierung unter vereinfachten Annahmen bzgl. der Regressoren.\n\n13.2.1 Lasso ist Soft Thresholding\nWir betrachten nun eine mathematische Darstellung von Selektions- und Shrinkage-Eigenschaft des Lasso-Schätzers in einem vereinfachten Modell. Wenn die Regressoren \\(\\boldsymbol{X}\\) orthonormal zueinander sind, existiert eine analytische Lösung des Lasso-Schätzers, \\[\\begin{align}\n  \\widehat{\\boldsymbol{\\beta}}^{\\mathrm{L}}_\\lambda =\n  \\begin{cases}\n    \\widehat{\\boldsymbol{\\beta}}_j - \\lambda/2 &, \\ \\ \\widehat{\\boldsymbol{\\beta}}_j &gt; \\lambda/2\\\\\n    0 &, \\ \\ \\lvert\\widehat{\\boldsymbol{\\beta}}_j\\rvert\\leq\\lambda/2\\\\\n    \\widehat{\\boldsymbol{\\beta}}_j + \\lambda/2 &, \\ \\ \\widehat{\\boldsymbol{\\beta}}_j &lt; \\lambda/2\n  \\end{cases},\\label{eq:lassoST}\n\\end{align}\\] wobei \\(\\widehat{\\boldsymbol{\\beta}}_j\\) der KQ-Schätzer von \\(\\beta_j\\) ist. Anhand von \\(\\eqref{eq:lassoST}\\) können wir die Selektionseigenschaft sowie die Schrumpfung der KQ-Koeffizientenschätzung in Abhängigkeit der durch \\(\\lambda\\) regulierten \\(\\ell_1\\)-Strafe erkennen. Für eine Visualisierung implementieren wir \\(\\eqref{eq:lassoST}\\) als R-Funktion lasso_st() und zeichnen die resultierenden Koeffizientenschätzungen für die Parameterwerte \\(\\lambda\\in\\{0, 0.2, 0.4\\}\\).\nWir definieren zunächst die Funktion lasso_st().\n\n\n\n\n\n\n\n\nIm nächsten Schritt zeichnen wir lasso_st() für eine Sequenz von KQ-Schätzwerten gegeben \\(\\lambda\\).\n\n\n\n\n\n\n\n\nDer Plot zeigt, dass der \\(\\ell_1\\)-Strafterm des Lasso-Schätzers zu einem linearen Verlauf der auf den KQ-Schätzer (gezeichnet für \\(\\lambda = 0\\), gestrichelte Linie) applizierten Shrinkage führt: Der Lasso-Schätzer ist eine abschnittsweise-lineare Funktion des KQ-Schätzers in \\(\\lambda\\): Je größer der Parameter \\(\\lambda\\), desto größer ist das Intervall von KQ-Schätzwerten \\([-\\lambda/2,\\lambda/2]\\), wo der Lasso-Schätzer zu Variablenselektion führt, d.h. hier den Koeffizienten \\(\\beta_j\\) als \\(0\\) schätzt (rote bzw. blaue Linie).\nAnhand des Plots kann weiterhin abgeleitet werden, dass der Lasso-Schätzer nicht invariant gegenüber der Skalierung der Regressoren ist: Die Stärke der Regularisierung durch \\(\\lambda\\) ist hängt von der Magnitude des KQ-Schätzers ab. Daher müssen die Regressoren vor Berechnung der Schätzung standardsiert werden. Üblich ist hierbei eine Normierung auf einen Mittelwert von \\(0\\) und eine Varianz von \\(1\\).\nDie nachstehende interaktive Grafik illustriert das Lasso-Optimierungsproblem \\(\\eqref{eq:lassolagrange}\\) sowie den resultierenden Schätzer der Koeffizienten \\((\\beta_1, \\beta_2)\\) in einem multiplen Regressionsmodell mit korrelierten Regressoren \\(X_1\\) und \\(X_2\\).\n\nDie blaue Ellipse ist die Menge aller Schätzwerte \\(\\left(\\widehat\\beta_{1},\\, \\widehat\\beta_{2}\\right)\\) für den angegebenen Wert von \\(\\mathrm{RSS}\\). Im Zentrum der Ellipse liegt der KQ-Schätzer, welcher \\(\\mathrm{RSS}\\) minimiert.\nDas graue Quadrat ist die Menge aller Koeffizienten-Paare \\((\\beta_1, \\beta_2)\\), welche die Restriktion \\(\\lvert\\beta_1\\rvert+\\lvert\\beta_2\\rvert\\leq t\\) erfüllen. Beachte, dass die Größe dieser Region nur durch den Parameter \\(t\\) bestimmt wird.\nDer blaue Punkt ist der Lasso-Schätzer \\((\\widehat{\\boldsymbol{\\beta}}^L_{1,t},\\, \\widehat{\\boldsymbol{\\beta}}^L_{2,t})\\). Dieser ergibt sich als Schnittpunkt zwischen der blauen \\(\\mathrm{RSS}\\)-Ellipse und der Restriktionsregion und variiert mit \\(t\\). Die gestrichelte rote Linie zeigt den Lasso-Lösungspfad.\nFür kleine Werte, erhalten wir starke Shrinkage auf \\(\\widehat\\beta_{1,t}\\) bis zum Wertebereich \\(t\\leq50\\), wo \\(\\widehat{\\boldsymbol{\\beta}}^L_{1,t}=0\\). Hier erfolgt Variablenselektion: Die Regularisierung führt zu einem geschätzten Modell, das lediglich \\(X_2\\) als erklärende Variable enthält. In diesem Bereich von \\(t\\) bewirkt die Shrinkage, dass \\(\\widehat{\\boldsymbol{\\beta}}^L_{2,t}\\to0\\) für \\(t\\to0\\).\n\n\n\nBeachte, dass der rote Lasso-Pfad (die Menge aller Lasso-Lösungen) äquivalent als Funktion von \\(\\lambda\\) im Optimierungsproblem \\(\\eqref{eq:lassoloss}\\) dargestellt werden kann. Implementierungen mit statistischer Software berechnen die Lasso-Lösung häufig in Abhängigkeit von \\(\\lambda\\). Ein Algorithmus hierfür ist LARS.\n\n13.2.2 Berechnung der Lasso-Lösung mit dem LARS-Algorithmus\nFür die Berechnung des Lasso-Lösungspfads kann der LARS-Algorithmus von Efron u. a. (2004) im Lasso-Modus genutzt werden.12 Der Lasso-Lösungspfad beinhaltet geschätzte Koeffizienten über einem Intervall für \\(\\lambda\\), welches sämtliche Modellkomplexitäten zwischen der (trivialen) Lösung mit maximaler Shrinkage auf allen Koeffizienten (\\(\\lambda\\) groß, alle gesch. Koeffizienten sind \\(0\\)) und der unregularisierten Lösung (\\(\\lambda = 0\\), KQ-Schätzung) abbildet. Der LARS-Algorithmus erzeugt den Lösungspfad sequentiell, sodass die Schätzung als Funktion von \\(\\lambda\\) veranschaulicht werden kann, ähnlich wie bei Ridge Regression.\n12 LARS steht für Least Angle Regression and Selection.Wir zeigen nun anhand simulierter Daten, wie Lasso-Lösungen mit dem R-Paket lars berechnet werden können. Hierfür erzeugen wir Daten gemäß der Vorschrift \\[\\begin{align}\n  \\begin{split}\n  Y_i =&\\, \\boldsymbol{X}_i' \\boldsymbol{\\beta}_v + u_i\\\\\n  \\\\\n  \\boldsymbol{\\beta}_v =&\\, (-1.25, -.75, 0, 0, 0, 0, 0, .75, 1.25)'\\\\\n  \\\\\n  \\boldsymbol{X}_i \\sim&\\, N(\\boldsymbol{0}, \\boldsymbol{I}_{9\\times9}), \\quad u_i \\overset{u.i.v.}{\\sim} N(0, 1), \\quad i = 1,\\dots,25.\n  \\end{split}\\label{eq:larsdgp}\n\\end{align}\\]\n\n\n\n\n\n\n\n\nEntsprechend des DGP passen wir ein Modell ohne Konstante an. Damit lars::lars() den Lösungspfad des Lasso-Schätzers berechnet, muss type = \"lasso\" gewählt werden.13\n13 lars() standardisiert die Regressoren standardmäßig (aufgrund des DGPs hier nicht nötig).\n\n\n\n\n\n\n\nDie Zusammenfassung zeigt, dass der LARS-Algorithmus als erstes die (relevante) Variable \\(X_9\\) aktiviert.14 Mit abnehmender Regularisierung (kleinere \\(\\lambda\\)) werden in den nächsten 3 Schritten die übrigen relevanten Variablen \\(X_2\\), \\(X_8\\) und \\(X_1\\) aktiviert. Über die weiteren Schritte nähert der Algorithmus die Lösung an die saturierte Schätzung (das Modell mit allen neun Regressoren) an und aktiviert schrittweise die übrigen, irrelevanten Variablen.\n14 Aktivierung meint die Aufnahme einer Variable in der Modell gegeben eines hinreichend kleinen \\(\\lambda\\).Wir visualisieren die geschätzen Koeffizienten an jedem Schritt des Lösungspfads als Funktion von \\(\\lambda\\). In der Praxis wird der Regularisierungsparameter häufig auf der natürlichen log-Skala dargestellt.\n\n\n\n\n\n\n\n\nIn der Abbildung erkennen wir, dass die Shrinkage der geschätzten Koeffizienten nach der Aktivierung rasch abnimmt und sich für kleine Werte von \\(\\lambda\\) der KQ-Lösung annähert. Wir sehen auch, dass es einen Bereich von \\(\\lambda\\)-Werten gibt, für die das wahre Modell mit den Variablen \\(X_1\\), \\(X_2\\), \\(X_8\\) und \\(X_9\\) selektiert werden kann. Je nach Ziel der Analyse kann es sinnvoll sein, ein \\(\\lambda\\) in diesem Intervall zu schätzen.\n\n13.2.3 Wahl des Regularisierungsparameters \\(\\lambda\\) für den Lasso-Schätzer\nWie zuvor bei Ridge Regression muss in empirischen Anwendungen ein Wert für den Tuning-Parameter \\(\\lambda\\) gewählt werden. Hierbei besteht die Herausforderung darin, einen geeigneten Wert zu finden, der zu wünschenswerten Eigenschaften des resultierenden Modells führt. So ist für gute Vorhersagen wichtig, dass das Modell nicht zu sehr an die Daten angepasst ist (Overfitting), um eine gute Generalisierung auf neue Daten zu ermöglichen. Gleichzeitig muss das Modell flexibel genug sein, um wesentliche Eigenschaften des daten-erzeugenden Prozesses hinreichend gut zu erfassen. In der Regel wird hierbei eine sparsame Modellierung angestrebt, die nur eine Teilmenge der Prädiktoren nutzt.\nIn der Praxis werden verschiedene Verfahren verwendet, um den Wert für den Tuning-Parameter \\(\\lambda\\) zu bestimmen. Gängige Methoden sind Cross Validation (CV) und Informationskriterien. In Abhängigkeit der Methode und der Daten ergeben sich über- oder unterparameterisierte Modelle. Aufgrund der Implementierung im R-Paket lars betrachten wir nachfolgend CV.15 Wir zeigen nun anhand der simulierten Daten aus dem letzten Abschnitt, wie für die LARS-Schätzung ein optimales \\(\\lambda\\) mit leave-one-out CV (LOO-CV) bestimmt werden kann. Hierzu nutzen wir lars::cv.lars() unter Verwendung derselben Argumente wie zuvor im Aufruf von lars().\n15 Chetverikov, Liao, and Chernozhukov (2020) zeigen, dass CV zu konsistenter Modellselektion führen kann.\n\n\n\n\n\n\n\nDas Objekt fit_lars_cv ist eine Liste mit den CV-Ergebnissen. Wir können diese einfach mit ggplot visualisieren. index ist hierbei das Verhältnis der \\(\\ell_1\\)-Norm des Lasso-Schätzers für einen spezifischen Wert von \\(\\lambda\\) und der \\(\\ell_1\\)-Norm des KQ-Schätzers. Das optimale \\(\\lambda\\) wird so implizit geschätzt. cv.error ist der mit CV geschätzte MSE.\n\n\n\n\n\n\n\n\nIn der Grafik erkennen wir ein Minimum des CV-MSEs bei etwa 0.73.\n\n\n\n\n\n\n\n\nDie geschätzten Koeffizienten für die optimale Regularisierung können mit coef() ausgelesen werden.\n\n\n\n\n\n\n\n\nDas Ergebnis veranschaulicht die Selektionseigenschaft von Lasso: Gemäß DGP \\(\\eqref{eq:larsdgp}\\) sind die Variablen \\(X_3\\) bis \\(X_7\\) irrelevante Prädiktoren für \\(Y\\); ihre wahren Koeffizienten sind \\(0\\). In der kreuzvalidierten Lasso-Schätzung erreicht die Regularisierung, dass die Koeffizienten der Variablen \\(X_4\\) bis \\(X_7\\) tatsächlich mit 0 geschätzt werden. Wir schätzen für das mit CV bestimmte \\(\\lambda\\) also ein leicht überspezifiziertes Modell mit den Regressoren \\(X_1\\), \\(X_2\\), \\(X_3\\), \\(X_8\\) und \\(X_9\\). Beachte, dass die Lasso-Schätzung einen Kompromiss impliziert: Die Varianz der Schätzung ist geringer als die des KQ-Schätzers im Modell mit allen Variablen.16 Aufgrund der Regularisierung sind die mit Lasso geschätzten Koeffizienten der relevanten Variablen jedoch in Richtung \\(0\\) verzerrt.\n16 Wegen \\(N=25\\) verbleiben bei der KQ-Schätzung mit 9 Regressoren nur 16 Freiheitsgrade.Einen positiven Effekt dieses Kompromisses beobachten wir anhand des mittleren Vorhersagefehlers für Daten, die nicht zur Berechnung des Schätzers verwendet wurden. Wir vergleichen den Vorhersagefehler nachfolgend anhand eines solchen simulierten Test-Datensatzes mit 25 neuen Beobachtungen. Den Vorhersagefehler bestimmen wir als MSE zwischen den vorhergesagten und den tatsächlichen Ausprägungen für \\(Y\\).\n\n\n\n\n\n\n\n\nWir schätzen nun das große Modell mit allen 9 Variablen mit KQ und berechnen ebenfalls den MSE der Prognosen für den Test-Datensatz.\n\n\n\n\n\n\n\n\nOffenbar führt die Lasso-Schätzung zu einem deutlich geringeren MSE der Vorhersage von Y für den Test-Datensatz als die KQ-Schätzung und damit zu einer höheren Vorhersagegüte. Das “sparsame” mit Lasso-Regression geschätzte Modell ist dem “großen” mit KQ geschätztem Modell in dieser Hinsicht also überlegen.\n\n\n\n\n\n\nKey Facts zu Lasso-Regression\n\n\n\n\nLasso-Regression bestraft die Verlustfunktion des KQ-Schätzers mit der \\(\\ell_1\\)-Norm der Koeffizienten.\nNeben Koeffizientenschätzung mit Shrinkage in Richtung \\(0\\) kann der Lasso-Schätzer Variablenselektion durchführen: Regressionskoeffizienten können exakt mit \\(0\\) geschätzt und so ein “sparsames”, leichter zu interpretierendes Modell gewählt werden.\nWie bei Ridge Regression impliziert die Wahl von \\(\\lambda\\) einen Bias-Variance-Tradeoff, der für Vorhersagen nützlich ist: Für größere \\(\\lambda\\) wird mehr Verzerrung induziert und möglicherweise relevante Variablen mit kleinen Koeffizienten aus dem Modell entfernt. Ein solches sparsames Modell kann eine höhere Prognosegüte haben als ein komplexes, unregularisiertes Modell.\nDer Lasso-Schätzer \\(\\widehat{\\boldsymbol{\\beta}}_\\lambda^L\\) ist nicht erwartungstreu.\nLasso Regression kann bspw. mit dem LARS-Algorithmus (Paket lars) oder mit glmnet berechnet werden.",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regularisierte Regression</span>"
    ]
  },
  {
    "objectID": "RegReg.html#vergleich-von-lasso--und-ridge-regression-mit-simulation",
    "href": "RegReg.html#vergleich-von-lasso--und-ridge-regression-mit-simulation",
    "title": "13  Regularisierte Regression",
    "section": "\n13.3 Vergleich von Lasso- und Ridge-Regression mit Simulation",
    "text": "13.3 Vergleich von Lasso- und Ridge-Regression mit Simulation\nIn diesem Kapitel illustrieren wir Vor- und Nachteile von Lasso- und Ridge-Regression in Prognose-Anwendungen anhand von Monte-Carlo-Simulationen. Wir betrachten hierbei datenerzeugende Prozesse, die sich hinsichtlich der Anzahl relevanter Variablen sowie der Korrelation dieser Variablen unterscheiden.17\n17 Aufgrund des hohren Rechenaufwands der Simulationen verzichten wir in diesem Abschnitt und im nächsten Abschnitt auf die Einbindung der WebR-Konsole.Die grundlegende Vorschrift für die Simulationen ist \\[\\begin{align*}\n  Y_i = \\sum_{j=1}^{k=40} \\beta_j X_{i,j} + u_i, \\quad u_i \\overset{u.i.v.}{\\sim} N(0,1), \\quad i=1,\\dots,100,\n\\end{align*}\\] wobei die Regressoren \\(X_j\\) eine Varianz von \\(1\\) haben und aus einer multivariaten Normalverteilung mit Korrelation \\[\\rho\\in(0,0.5,0.8)\\] gezogen werden.\nFür die Koeffizienten \\(\\boldsymbol{\\beta}\\) unterscheiden wir zwei Szenarien. In Szenario A ist \\[\\boldsymbol{\\beta} = (1,\\dots,1)',\\] d.h. alle Variablen sind relevant und haben denselben Einfluss auf \\(Y\\). In Szenario B erzeugen wir \\(\\boldsymbol{\\beta}\\) einmalig vorab so, dass \\[\\beta_j = \\begin{cases}1,\\quad \\text{mit Wsk.  }p\\\\ 0,\\quad \\text{mit Wsk.  }1-p, \\end{cases}\\] d.h. nur eine Teilmenge der Variablen beeinflusst \\(Y\\) jeweils mit demselben Effekt \\(\\beta_j = 1\\). Die übrigen Variablen sind irrelevant.\nAls nächstes schätzen und validieren wir die Modelle mit glmnet().\n\n13.3.1 Prognosegüte in diversen Szenarien\n\n# Simulationsparameter definieren\nrho &lt;- c(0, 0.5, 0.8)   # Korrelation\nk &lt;- 40                 # Anz. Regressoren\nN &lt;- 100                # Anz. Beobachtungen\nn_sim &lt;- 100            # Anz. Simulationen\n\nDamit der Code für die Simulation möglichst wenig repetitiv ist, definieren wir eine Funktion cv.glmnet_MSE(), die unter Angabe der Daten X und Y, des Trainingssets train sowie des Parameters alpha den gewünschten regularisierten Schätzer under Verwendung von Cross Validation anpasst und den Testset-MSE zurückgibt.\n\n# allg. Funktion für Testset-MSE nach CV\ncv.glmnet_MSE &lt;- function(X, Y, train, alpha) {\n  \n  # Modell mit glmnet schätzen; lambda per CV bestimmen\n  fit_cv &lt;- cv.glmnet(\n    x = X[train,],\n    y =Y[train],\n    alpha = alpha\n  )\n  \n  # Vorhersagen treffen\n  Y_pred &lt;- predict(\n    object = fit_cv, \n    s = fit_cv$lambda.min, \n    newx = X[-train,])\n  \n  return(\n    # Testset-MSE berechnen\n    mean(\n      (Y[-train] - Y_pred)^2\n      )\n  )\n}\n\nWir initialisieren zunächst Matrizen, in welche die MSEs aus den n_sim Simulationsdurchläufen reihenweise geschrieben werden. lasso_mse und ridge_mse haben je eine Spalte für jede Korrelation in rho\n\n# Matrizen für simulierte MSEs initialisieren...\nlasso_mse &lt;- matrix(\n  data = NA, \n  nrow = n_sim, \n  ncol = length(rho)\n) \nridge_mse &lt;- lasso_mse\n\n# ... und benennen\ncolnames(lasso_mse) &lt;- paste0(\"Kor=\", rho)\ncolnames(ridge_mse) &lt;- colnames(lasso_mse)\n\nFür die Simulation iterieren wir mit purrr::walk() über den Vektor rho sowie über die Laufvariable 1:n_sim. Beide Schleifen nutzen den Syntax für anonyme Funktionen:\n\n# Die anonyme Funktion\nfunction(x) return(x)\n# ist äquivalent definiert als\n\\(x) return(x)\n\nIn jedem Simulationsdurchlauf erzeugen wir den Datensatz entsprechend der obigen Vorschrift, teilen die Daten auf und berechnen MSEs für Lasso- und Ridge-Regression mit cv.glmnet_MSE().\nSzenario A\n\n# Koeffizienten-Vektor definieren\nbeta &lt;- rep(1, k) \n\n\nlibrary(mvtnorm)\nlibrary(tidyverse)\n\nset.seed(1234)\n\n# Simulation durchführen\nwalk(1:length(rho), \\(j) {\n  \n  # Korrelationsmatrix definieren\n  Sigma &lt;- matrix(\n    data = rho[j], \n    nrow = k, \n    ncol = k\n  )\n  diag(Sigma) &lt;- 1\n  \n  walk(1:n_sim, \\(i) {\n    \n  # Daten simulieren\n  X &lt;- rmvnorm(\n    n = N, \n    mean = rep(0, k), \n    sigma = Sigma\n  )\n  Y &lt;- X %*% beta + rnorm(N)\n    \n  # Trainingsdaten definieren\n  ID_train &lt;- sample(\n    x = c(1:N), \n    size = N/2\n  )\n    \n  # Modelle mit CV schätzen und MSEs berechnen\n  # Ridge-Regression\n  ridge_mse[i, j] &lt;&lt;- cv.glmnet_MSE(\n    X = X, \n    Y = Y, \n    train = ID_train, \n    alpha = 0\n  )\n  \n  # Lasso-Regression\n  lasso_mse[i, j] &lt;&lt;- cv.glmnet_MSE(\n    X = X, \n    Y = Y, \n    train = ID_train, \n    alpha = 1\n  )\n  \n  })\n  \n})\n\nBeachte, dass hier der Super-Assignment-Operator &lt;&lt;- genutzt wird, damit walk die Matrizen ridge_mse und lasso_mse in der globalen Umgebung überschreibt.18\n18 Dies folgt aus der Definition von walk. &lt;- bewirkt hier lediglich Assignment in der Funktionsumgebung.Wir berechnen jeweils den mittleren MSEs, sammeln die Ergebnisse in einer tibble() und nutzen gt() für die tabellarische Darstellung.\n\nlibrary(gt)\n\n# Ergebnisse tabellarisch darstellen\ntibble(\n  Methode = c(\n    \"Lasso-Regression\", \n    \"Ridge-Regression\"\n  ),\n) %&gt;%\n  bind_cols(\n    bind_rows(\n      colMeans(lasso_mse),\n      colMeans(ridge_mse)  \n    )    \n  ) %&gt;%\n  gt() %&gt;%\n  tabopts()\n\n\n\n\n\n\n\nMethode\nKor=0\nKor=0.5\nKor=0.8\n\n\n\nLasso-Regression\nNA\nNA\nNA\n\n\nRidge-Regression\nNA\nNA\nNA\n\n\n\n\n\n\n\nTabelle 13.1: Durchschnittliche Testset-MSEs für Setting A\n\n\n\nDie Tabelle zeigt, dass Ridge-Regression gegenüber Lasso-Regression für jede der drei betrachteten Korrelationen überlegen ist. Insbesondere bei stärker korrelierten Regressoren ist Ridge vorteilhaft.\nFür Szenario B überschreiben wir beta nach Multiplikation mit einem zufälligen binären Vektor, sodass einige der Koeffizienten \\(0\\) und die zugehörigen Variablen irrelevant für \\(Y\\) sind.\nSzenario B\n\n# Wsk. für Relevanz einer Variable\np &lt;- .3\n\nset.seed(123)\n\n# Koeffizienten-Vektor definieren\nbeta &lt;- beta * sample(\n  x = 0:1, \n  size = k, \n  replace = T, \n  prob = c(1-p, p)\n)\n\n# Koeffizienten prüfen\nhead(beta, n = 10)\n\n [1] 0 1 0 1 1 0 0 1 0 0\n\n\nEine wiederholung der Simulation für die modifizierten Koeffizienten beta und liefert folgende tabellarische Auswertung.\n\n\n\n\n\n\n\n\nMethode\nKor=0\nKor=0.5\nKor=0.8\n\n\n\nLasso\n2.51\n2.143\n1.923\n\n\nRidge\n3.331\n2.562\n2.014\n\n\n\n\n\n\n\nTabelle 13.2: Durchschnittliche Testset-MSEs für Szenario B\n\n\n\nDie Ergebnisse in Tabelle 13.2 zeigen, dass Ridge-Regression in Szenario B bis auf den Fall unkorrelierter Regressoren etwas schlechter abschneidet als in Szenario A. Die hohe Anzahl irrelevanter Variablen verbessert die Leistung von Lasso deutlich: Hier ist es plausibel, dass Lasso aufgrund der Thresholding-Eigenschaft die Koeffizienten einiger irrelevanten Variablen häufig exakt \\(0\\) setzt und damit ein sparsameres Modell schätzt als Ridge. Entsprechend erzielt Lasso in diesem Szenario insbesondere für \\(\\rho = 0\\) genauere Vorhersagen als Ridge Regression.\n\n13.3.2 Visualisierung des Bias-Variance-Tradeoffs bei Prognosen\nFür ein besseres Verständnis, wie sich der Regularisierungsparameter \\(\\lambda\\) auf den Bias-Variance-Tradeoff bei Prognosen mit Ridge- und Lasso-Regression auswirkt, vergleichen wir für beide Methoden nachfolgend die Abhängigkeit des MSEs der Prognose \\(\\widehat{Y}_0\\) für den Wert \\(Y_0\\) der abhängigen Variable eines Datenpunkts anhand seiner Regressoren \\(\\boldsymbol{X}_0'\\), wobei \\[\\begin{align}\n  \\text{MSE}(\\widehat{Y}_0) = \\text{Bias}(\\widehat{Y}_0)^2 + \\text{Var}(\\widehat{Y}_0) + \\text{Var}(Y_0) \\label{eq:pbvdecomp}\n\\end{align}\\] Beachte, dass \\(\\text{Var}(Y_0)\\) die durch den datenerzeugenden Prozess (und damit unvermeidbare) Varianz von \\(Y_0\\) ist, wohingegen \\(\\text{Bias}(\\widehat{Y}_0)^2\\) und \\(\\text{Var}(\\widehat{Y}_0)\\) von dem verwendeten Schätzer für \\(\\widehat{Y}_0\\) abhängt.\nFür die Simulation betrachten wir erneut Szenario A aus Kapitel 13.3.1 mit \\(50\\) Beobachtungen für ein Modell mit \\(40\\) unkorrelierten Regressoren. Wir legen zunächst die Simulationsparameter fest und erzeugen den vorherzusagenden Datenpunkt (X_0, Y_0).\n\n# Parameter festlegen\nset.seed(1234)\nn &lt;- 200 # Anz. Iterationen\nN &lt;- 50  # Anz. Beobachtungen\nk &lt;- 40  # Anz. Variablen\n\n# Korrelationsmatrix definieren\nSigma &lt;- diag(k) # Diagonalmatrix\nbeta &lt;- rep(x = 1, k)\n\n# Prognose-Ziel vorab zufällig generieren:\n\n# Regressoren\nX_0 &lt;- rmvnorm(\n  n = 1, \n  mean = rep(x = 0, k)\n)\n\n# Abh. Variable\nY_0 &lt;- X_0 %*% beta + rnorm(n = 1) %&gt;% \n  as.vector()\n\nAnhand der Simulationsergebnisse wollen wir die von der verwendeten Schätzfunktion abhängigen Komponenten von \\(\\eqref{eq:pbvdecomp}\\) untersuchen. Wir initialisieren hierzu die Listen ridge_fits und lasso_fits, in die unsere Simulationsergebnisse geschrieben werden.\n\n# Listen für Simulationsergebnisse initialisieren\nridge_fits &lt;- list()\nlasso_fits &lt;- list()\n\nWeiterhin definieren wir separate \\(\\lambda\\)-Sequenzen für Lasso- und Ridge-Schätzer.19\n19 Die Sequenzen haben wir in Abhängigkeit des DGP so gewählt, dass die Abhängigkeit der Prognosegüte von \\(\\lambda\\) gut visualisiert werden kann.\n# Lambda-Sequenzen festlegen\nlambdas_r &lt;- seq(.25, 2.5, length.out = 100)\nlambdas_l &lt;- seq(.05, 0.5, length.out = 100)\n\nFür die Simulation iterieren wir mit walk() über simulierte Datensätze und schreiben jeweils den vollständigen Output von glmnet() in die zuvor definierten Listen ridge_fits und lasso_fits.\n\nlibrary(mvtnorm)\n\n# Simulation\nwalk(1:n, \\(i) {\n  \n  # Daten simulieren\n  X &lt;- rmvnorm(\n    n = N, \n    mean = rep(0, k), \n    sigma = Sigma\n  )\n  Y &lt;- X %*% beta + rnorm(n = N, sd = 5)\n  \n  # Modelle mit glmnet schätzen\n  # Ridge-Regression\n  ridge_fits[[i]] &lt;&lt;- glmnet(\n    x = X, \n    y = Y, \n    alpha = 0, \n    intercept = F\n  )\n  # Lasso-Regression\n  lasso_fits[[i]] &lt;&lt;- glmnet(\n    x = X, \n    y = Y, \n    alpha = 1, \n    intercept = F\n  )\n  \n})\n\nWir nutzen Funktionen aus purrr und dplyr, um über die in den Simulationsdurchläufen angepassten Modelle zu iterieren. Mit predict() erhalten wir Punktvorhersagen für Y_0 für jedes \\(\\lambda\\) der zuvor definierten \\(\\lambda\\)-Sequenzen. Beachte, dass map() jeweils eine Liste mit 200 Punktvorhersagen für jedes der 100 zurückgibt. Mit list_rbind() können wir die Ergebnisse komfortabel jeweils in einer tibble sammeln.\n\n# Prognosen für Ridge-Regression\npred_r &lt;- map(\n  .x = ridge_fits, \n  .f = ~ as_tibble(\n    predict(\n      object = ., \n      s = lambdas_r, \n      newx = X_0\n    )\n  ) \n) %&gt;%\n  list_rbind() \n\n# Prognosen für Lasso-Regression\npred_l &lt;- map(\n  .x = lasso_fits, \n  .f = ~ as_tibble(\n    predict(\n      object = ., \n      s = lambdas_l, \n      newx = X_0)\n    ) \n) %&gt;%\n  list_rbind() \n\nFür die statistische Auswertung berechnen wir jeweils \\(\\text{MSE}(\\widehat{Y}_0)\\), \\(\\text{Bias}(\\widehat{Y}_0)^2\\) und \\(\\text{Var}(\\widehat{Y}_0)\\) und führen die Ergebnisse mit pivot_longer() in ein langes Format sim_data_r über. Wir berechnen weiterhin mit MSE_min_r das \\(\\lambda\\), für das wir über die Simulationsdurchläufe durchschnittlich den geringsten \\(\\text{MSE}\\) beobachten.\nRidge-Regression\n\n# Ergebnisse für Ridge-Regression zusammenfassen\nsim_data_r &lt;- tibble(\n  \n  lambda = lambdas_r,\n  \n  \"MSE\" = map_dbl(\n    .x = pred_r,  \n    .f = ~ mean((.x - Y_0)^2)\n  ),\n  \n  \"Bias^2\" = map_dbl(\n    .x = pred_r, \n    .f = ~ (mean(.x) - Y_0)^2\n  ),\n  \n  \"Varianz\" = map_dbl(\n    .x = pred_r, \n    .f = ~ var(.x)\n  )\n) %&gt;%\n  pivot_longer(\n    cols = -lambda, \n    values_to = \"Wert\",\n    names_to = \"Statistik\"\n  )\n\n# Lambda bei MSE-Minimum bestimmen\nMSE_min_r &lt;- sim_data_r %&gt;% \n  filter(\n    Statistik == \"MSE\",\n    Wert == min(Wert)\n  ) \n\nLasso-Regression\n\n# Ergebnisse zusammenfassen\nsim_data_l &lt;- tibble(\n  \n  lambda = lambdas_l,\n  \n  \"MSE\" = map_dbl(\n    .x = pred_l,  \n    .f = ~ mean((. - Y_0)^2)\n  ),\n  \n  \"Bias^2\" = map_dbl(\n    .x = pred_l, \n    .f = ~ (mean(.) - Y_0)^2\n  ),\n  \n  \"Varianz\" = map_dbl(\n    .x = pred_l, \n    .f = ~ var(.)\n  )\n) %&gt;%\n  pivot_longer(\n    cols = -lambda, \n    values_to = \"Wert\", \n    names_to = \"Statistik\"\n  )\n\n# Lambda bei MSE-Minimum bestimmen\nMSE_min_l &lt;- sim_data_l %&gt;% \n  filter(\n    Statistik == \"MSE\",\n    Wert == min(Wert)\n  ) \n\nDie Datensätze im langen Format, sim_data_r und sim_data_l, werden nun für die Visualisierung der Ergebnisse mit ggplo2 genutzt.\n# MSE, Bias^2 und Varianz gegen Lambda plotten\n\n# Ridge-Regression\nsim_data_r %&gt;%\n  ggplot(\n    mapping = aes(\n      x = lambda, \n      y = Wert, \n      color = Statistik\n    )\n  ) +\n  geom_line() +\n  geom_point(data = MSE_min_r) +\n  theme_cowplot()\n\n# Lasso-Regression\nsim_data_l %&gt;%\n  ggplot(\n    mapping = aes(\n      x = lambda, \n      y = Wert, \n      color = Statistik\n    )\n  ) +\n  geom_line() +\n  geom_point(data = MSE_min_l) +\n  theme_cowplot()\n\n\n\n\n\n\n\n\n\n(a) Ridge Regression\n\n\n\n\n\n\n\n\n\n\n\n(b) Lasso Regression\n\n\n\n\n\n\nAbbildung 13.1: Simulierte MSE-Komponenten in Abhängigkeit von Lambda\n\n\nAnhand von Abbildung 13.1 lässt sich der Bias-Variance-Tradeoff bei der Vorhersage von \\(Y_0\\) gut erkennen: Bereits für kleine \\(\\lambda\\) erzielen beide Methode eine deutliche Reduktion des MSE. Dies wir durch etwas zusätzlichen Bias, aber eine überproportionale Verringerung der Varianz erreicht. Der erkennbare funktionale Zusammenhang zeigt, dass der MSE eine konvexe Funktion von \\(\\lambda\\) ist. Damit existieren optimale \\(\\lambda\\) mit minimalem MSE (grüne Punkte), die wir mit Cross Validation schätzen können.",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regularisierte Regression</span>"
    ]
  },
  {
    "objectID": "RegReg.html#inferenz-für-treatment-effekt-schätzung-mit-vielen-variablen",
    "href": "RegReg.html#inferenz-für-treatment-effekt-schätzung-mit-vielen-variablen",
    "title": "13  Regularisierte Regression",
    "section": "\n13.4 Inferenz für Treatment-Effekt-Schätzung mit vielen Variablen",
    "text": "13.4 Inferenz für Treatment-Effekt-Schätzung mit vielen Variablen\nIn empirischen Studien des Effekts einer Behandlungsvariable \\(B\\) auf eine Outcome-Variable \\(Y\\) steht häufig eine Vielzahl potentieller Kontrollvariablen zur Verfügung. Häufig ist unklar, welche Variablen in das Modell aufgenommen werden sollten, um das Risiko einer verzerrten Schätzung durch ausgelassene Variablen zu vermindern und gleichzeitig eine Schätzung mit geringer Varianz zu gewährleisten. Ist der Beobachtungsumfang \\(N\\) relativ zur Variablenanzahl \\(k\\) groß, so kann die KQ-Schätzung einer langen Regression (ein Modell mit allen \\(k\\) Kontrollvariablen) gute Ergebnisse liefern. In der Praxis liegt diese wünschenswerte Situation jedoch oft nicht vor und es ist \\(k\\lesssim N\\) oder sogar \\(k&gt;N\\). Dann ist eine KQ-Schätzung des Behandlungseffekts anhand aller \\(k\\) Variablen mit hoher Varianz behaftet bzw. gar nicht möglich.20 Ein weiteres Szenario ist \\(k(N)&gt;N\\), d.h. die Anzahl der Regressoren kann mit dem Beobachtungsumfang wachsen.21 Lasso-Verfahren können dann hilfreich sein, um Determinanten von \\(Y\\) und \\(B\\) zu identifizieren und damit eine Menge an Kontrollvariablen zu selektieren, für die eine erwartungstreue und konsistente Schätzung des interessierenden Effekts wahrscheinlich ist.\n20 Beachte, dass der KQ-Schätzer bei \\(k&gt;N\\) nicht lösbar ist.21 Dieses Szenario wird unter Bedingungen bzgl. der Wachstumsrate und der Größe der Koeffizienten betrachet, siehe (Belloni und Chernozhukov 2013).22 Hahn u. a. (2018) geben eine ausführliche Erläuterung dieser Problematik.Betrachte zunächst das Modell mit allen Kontrollvariablen \\(X_j\\), \\[\\begin{align}\n  Y_i = \\beta_0 + \\alpha_0 B_i + \\sum_{j=1}^k \\beta_{j} X_{i,j} + u_i, \\label{eq:lassotmt}\n\\end{align}\\] wobei einige \\(\\beta_{j}=0\\) sind und wir annehmen, dass \\(B\\) lediglich mit ein paar der \\(X_j\\) korrelliert. Die Shrinkage der geschätzten Koeffizienten aus einer naiven Lasso-Regression von \\(\\eqref{eq:lassotmt}\\) führt grundsätzlich zu einer verzerrten Schätzung des Behandlungseffekts \\(\\alpha_0\\) und damit zu ungültiger Inferenz.22\nDie Verzerrung von geschätzten Koeffizienten kann vermieden werden, indem Lasso lediglich zur Selektion von Kontrollvariablen verwendet wird. Dabei wird mit einer Lasso-Regression von \\(Y\\) auf die \\(X_j\\) eine Teilmenge von Regressoren \\(\\mathcal{S}\\) selektiert und der Treatment-Effekt anschließend mit der KQ-Schätzung von \\[\\begin{align}\n  Y_i = \\beta_0 + \\alpha_0 B_i + \\sum_{j\\in\\mathcal{S}} \\beta_{j} X_{i,j} + e_i,\n\\end{align}\\] basierend auf der Selektion \\(\\mathcal{S}\\) berechnet wird.23 Ein solcher Post-Lasso-Selection-Schätzer (Belloni und Chernozhukov 2013) ist jedoch im Allgemeinen und insbesondere in hoch-dimensionalen Settings nicht konsistent für \\(\\alpha_0\\) und nicht asymptotisch normalverteilt, da weiterhin die Gefahr einer verzerrten Schätzung durch in \\(\\mathcal{S}\\) ausgelassene Variablen besteht, die mit \\(B\\) korrelieren: Lasso selektiert Variablen \\(X_j\\), die “gut” \\(Y\\) erklären. Dabei kann nicht ausgeschlossen werden, das ein Modell gewählt wird, dass relevante Determinanten von \\(B\\) auslässt. Selbst wenn wir ein mit Lasso gewähltes Modell mit KQ (d.h. ohne Shrinkage) schätzen, würde \\(\\alpha_0\\) verzerrt geschätzt!\n23 Solche Verfahren werden Post-Selection-Schätzer gennant.Belloni, Chernozhukov, und Hansen (2014) schlagen ein alternatives Verfahren vor, dass auf Selektion der Determinanten \\(X_j\\) von \\(Y\\) und \\(B\\) basiert. Dieses Verfahren wird als Post-Double Selection bezeichnet und kann wie folgt implementiert werden:\nPost-Double-Selection-Schätzer\n\nBestimme die Determinanten \\(X_j\\) von \\(Y\\) mit Lasso-Regression und bezeichne die Menge der selektierten Variablen als \\(\\mathcal{S}_Y\\).\nBestimme die Determinanten \\(X_j\\) von \\(B\\) mit Lasso-Regression und bezeichne die Menge der selektierten Variablen als \\(\\mathcal{S}_B\\).\nBestimme die Schnittmenge \\(\\mathcal{S}_{YB} = \\mathcal{S}_Y \\cap \\mathcal{S}_B\\). Schätze den Treatment-Effekt als \\(\\widehat{\\alpha}_0\\) in der KQ-Regression \\[\\begin{align}\n   Y_i = \\beta_0 + \\alpha_0 B_i + \\sum_{j\\in\\mathcal{S}_{YB}} \\beta_{j} X_{i,j} + v_i.\n\\end{align}\\]\n\nBelloni, Chernozhukov, und Hansen (2014) zeigen, dass \\(\\widehat{\\alpha}_0\\) aus diesem Verfahren ein asymptotisch normalverteiler Schätzer für \\(\\alpha_0\\) ist und herkömmliche t-Tests und Konfidenzintervalle gültige Inferenz erlauben.\nWir illustrieren die in diesem Abschnitt betrachteten Schätzer nun anhand simulierter Daten mit R. Die fiktive Problemstellung ist die Schätzung eines wahren Treatment-Effekts \\(\\alpha_0 = 2\\), wenn so viele potenzielle Kontrollvariablen vorliegen, dass der KQ-Schätzer gerade noch berechnet werden kann, aber aufgrund hoher Varianz unzuverlässig ist. Hierzu erzeugen wir \\(Y\\) gemäß der Vorschrift \\[\\begin{align*}\n  Y_i =&\\, \\alpha_0 B_i + \\sum_{j=1}^{k_Y} \\beta_{j}^Y X_{i,j}^Y + \\sum_{l=1}^{k_{YB}} \\beta_{l}^{YB} X_{i,l}^{YB} + u_i,\\\\\n  \\\\\n  \\beta_j^{YB} \\overset{u.i.v}{\\sim}&\\,N(10,1), \\quad \\beta_j^{Y} \\overset{u.i.v}{\\sim}U(0,1), \\quad u_i \\overset{u.i.v}{\\sim}N(0,1).\\\\\n  \\\\\n  i=&\\,1,\\dots,550\n\\end{align*}\\]\nDie Behandlungsvariable \\(B_i\\) entspricht der Vorschrift \\[\\begin{align*}\n  B_i =&\\, \\sum_{l=1}^{k_{YB}} \\beta_{l}^{YB} X_{i,l}^{YB} + e_i,\\\\\n  \\\\\n  \\beta_j^{YB} \\overset{u.i.v}{\\sim}&\\,N(2,0.2), \\quad e_i \\overset{u.i.v}{\\sim}N(0,1).\n\\end{align*}\\] Wir wählen \\(k_{YB} = k_{Y} = 25\\). Zusätzlich zu \\(B\\), den Determinanten von \\(Y\\) und \\(B\\) (\\(X^{YB}\\)) sowie den Variablen, die ausschließlich \\(Y\\) beeinflussen (\\(X^{Y}\\)) gibt es \\(k_U = 499\\) Variablen \\(X^U\\), die weder \\(Y\\) noch \\(B\\) beeinflussen und damit irrelevant für die Schätzung des Behandlungseffekts sind. Wir haben also \\(N=550\\) Beobachtungen und insgesamt \\(k = 1+k_{Y} + k_{YB} + k_{U} = 550\\) potenzielle Kontrollvariablen von denen \\(k_{YB} = 25\\) für eine unverzerrte Schätzung von \\(\\alpha_0\\) relevant sind.\nDer nachstehende Code generiert die Daten gemäß der Vorschrift.\n\n\n\n\n\n\n\n\nWünschenswert wäre die KQ-Schätzung des wahren Modells. Diese ergibt eine Schätzung nahe des wahren Treatment-Effekts \\(\\alpha_0 = 2\\). Unter realen Bedingungen wäre diese Regression jedoch nicht implementierbar, weil die relevanten Kovariablen XB unbekannt sind.\n\n\n\n\n\n\n\n\nWir schätzen daher zunächst die “lange” Regression mit allen \\(k\\) verfügbaren Variablen mit KQ. Beachte, dass der KQ-Schätzer für \\(\\alpha_0\\) zwar implementierbar und erwartungstreu ist, jedoch eine hohe Varianz aufweist. Wegen \\(k=N=550\\) erhalten wir eine perfekte Anpassung an die Daten und können mangels Freiheitsgraden keine Hypothesentests durchführen.\n\n\n\n\n\n\n\n\nDie KQ-Schätzung von \\(\\alpha_0\\) anhand der langen Regression weicht deutlich vom wahren Wert \\(\\alpha_0 = 2\\) ab.\nEine “kurze” KQ-Regression nur mit der Behandlungsvariable \\(B\\) führt wegen Korrelation mit den ausgelassenen Determinanten in XB zu einer deutlich verzerrten Schätzung.\n\n\n\n\n\n\n\n\nDie Methoden von Belloni und Chernozhukov (2013) und Belloni, Chernozhukov, und Hansen (2014) sind im R-Paket hdm implementiert. Mit den Funktionen hdm::rlasso() und hdm::rlassoEffect kann Lasso-Regression sowie Post- und Double-Post-Selection durchgeführt werden.24\n24 Diese Funktionen ermitteln ein optimales \\(\\lambda\\) mit dem in Belloni u. a. (2012) vorgeschlagenen Algorithmus.Wir berechnen zunächst den naiven Lasso-Schätzer in einem Modell mit allen Variablen.\n\n\n\n\n\n\n\n\nAuch dieser Schätzer ist deutlich verzerrt. Problematisch ist hier nicht nur die Shrinkage auf \\(\\widehat{\\alpha}_0\\), sondern die Selektion der Variablen in XB:\n\n\n\n\n\n\n\n\nDurch das Auslassen dieser Determinanten von \\(Y\\) und \\(B\\) leidet der Lasso-Schätzer unter OVB.\nAls nächstes berechnen wir den Post-Lasso-Selection-Schätzer.\n\n\n\n\n\n\n\n\nDie Ähnlichkeit der Post-Lasso-Schätzung von \\(\\alpha_0\\) zur Lasso-Schätzung zeigt deutlich, dass die Verzerrung des Lasso-Schätzers überwiegend durch ausgelassene Variablen anstatt durch Shrinkage verursacht wird.\nMit rlassoEffect() können wir den Post-Double-Selection-Schätzer berechnen.\n\n\n\n\n\n\n\n\nDouble Selection führt ebenfalls zu einem Post-Lasso-KQ-Schätzer mit allen 25 relevaten Variablen in XB. Wir selektieren allerdings deutlich weniger irrelevante Variablen aus XU als mit Single Selection und dennoch einige Determinanten von \\(Y\\) aus XY. Double Selection führt also zu einer unverzerrten Schätzen mit geringerer Varianz. Mit summary() erhalten wir gültige Inferenz bzgl. des Treatment-Effekts.\n\n\n\n\n\n\n\n\nDer Post-Double-Selection-Schätzer liefert unter den betrachteten Verfahren die beste Schätzung von \\(\\alpha_0\\) und erlaubt gültige statistische Inferenz mit den von summary() berechneten Inferenzstatistiken. Der geschätzte Effekt ist hoch-signifikant.\n\n\n\n\n\n\nKey Facts zum Post-Double-Selection-Schätzer\n\n\n\n\nDurch die sorgfältige Auswahl von Variablen, die mit Behandlung- und Outcome-Variable zusammenhängen, ermöglicht die Double-Selection eine bessere Kontrolle über das Risiko ausgelassender Variablen in Beobachtungsstudien und ermöglicht gültige (asymptotisch normale) Inferenz.\n\nDer Post-Double-Selection-Schätzer besteht aus drei Regressionen:\n\nEs werden Variablen mit Lasso selektiert, welche die Behandlungsvariable erklären.\nEs werden Variablen mit Lasso selektiert, welche die Outcome-Variable erklären.\nDer Post-Double-Selection-Schätzer ist der KQ-Schätzer in einer Regression, die für die Schnittmenge der ausgewählten Variablen kontrolliert.\n\n\nDank der Selektion mit Lasso kann der Schätzer auch bei hoch-dimensionalen Daten (\\(k&gt;n\\)) angewendet werden.\nPost-Double-Selection-Schätzer für Behandlungseffekte sind im R-Paket hdm implementiert.\n\n\n\n\n13.4.1 Case Study: Makroökonomisches Wachstum\nZur Illustration des Post-Double-Selection Schätzers betrachten wir eine empirische Anwendung bzgl. der Validierung von makroökonomischer Wachstumtheorie. Aus neo-klassischen Ansätzen wie dem Solow-Swan-Modell kann die Hypothese, dass Volkswirtschaften zu einem gemeinsamen Wachstumspfad hin konvergieren, abgeleitet werden. Diese Konvergenzhypothese impliziert die Existenz von Aufholeffekten: Ärmere Volkswirtschaften müssen im mittel schneller Wachsen als die Wirtschaft wohlhabender Länder. Die grundlegende Spezifikation eines entsprechenden Regressionsmodells lautet \\[\\begin{align}\n  \\text{WR}_{i} = \\alpha_0 \\text{BIP0}_i + u_i, \\label{eq:growthmodel1}\n\\end{align}\\] wobei \\(\\text{WR}_{i}\\) die Wachstumsrate des Pro-Kopf-BIP in Land \\(i\\) über einen Zeitraum (typischerweise berechnet als Log-Differenz zwischen zwei Perioden) und \\(\\text{BIP0}_i\\) das (logarithmierte) Pro-Kopf-BIP zu beginn der Referenzperiode ist. Gemäß der Konvergenzhypothese muss \\(\\alpha_0&lt;0\\) sein: Je wohlhabender eine Volkswirtschaft ist, desto geringer ist das erwartete Wirtschaftswachstum.\nUm eine Verzerrung durch ausgelassene Kovariablen zu vermeiden, sollte das Modell \\(\\eqref{eq:growthmodel1}\\) um länder-spezifische Regressoren \\(x_{i,j}\\), die sowohl das Ausgangsniveau \\(\\text{BIP0}\\) als auch die Wachtumsrate beeinflussen, erweitert werden. Zu der großen Menge potentieller Kovariablen gehören makro- und sozio-ökonomische Maße wie bspw. die Investitionstätigkeit des Staates, die Offenheit der Volkswirtschaft, das politische Umfeld, das Bildungsniveau, die Demographie, usw. Eine bevorzugte Spezifikation ist daher \\[\\begin{align}\n  \\text{WR}_{i} = \\alpha_0 \\text{BIP0}_i + \\sum_{j=1}^k \\beta_j x_{i,j} + u_i,\\label{eq:growthmodel2}\n\\end{align}\\] wobei \\(\\alpha_0\\) als Behandlungseffekt interpretiert werden kann. Beachte, dass \\(\\eqref{eq:growthmodel2}\\) eine Regression in der Form von \\(\\eqref{eq:lassotmt}\\) ist.\nWir illustrieren die Schätzung von und Inferenz bzgl. \\(\\alpha_0\\) in \\(\\eqref{eq:growthmodel2}\\) mit Post-Double-Selektion für einen 90 Länder umfassenden Auszug aus dem Datensatz von Barro und Lee (2013), der als Objekt GrowthData im R-Paket hdm verfügbar ist.25\n25 Eine ausführliche Beschreibung der Variablen ist hier einsehbar.\n13.4.1.1 Analyse mit R\n\n# Datensatz in Arbeitsumgebung verfügbar machen\nlibrary(hdm)\ndata(GrowthData)\n\n# Anzahl Beobachtungen und Variablen\ndim(GrowthData)\n\n[1] 90 63\n\n\nDie Spalte Outcome ist die jeweilige Wachstumsrate des BIP zwischen den Perioden 1965-1975 und 1975-1985 und gdpsh465 ist das reale Pro-Kopf-BIP im Jahr 1965 zu Preisen von 1980.\nWir führen zunächst eine grafische Analyse hinsichtlich des einfachen Modells \\(\\eqref{eq:growthmodel1}\\) durch, indem wir gdpsh465 gegen Outcome plotten und die geschätzte Regressionsgerade einzeichnen.\n\n# Einfache grafische Analyse mit ggplot2\nGrowthData %&gt;%\n  ggplot(\n    mapping = aes(\n      x = gdpsh465, \n      y = Outcome\n    )\n  ) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F) +\n  labs(\n    title = \"BIP-Wachstum: Einfache Regression\"\n  ) +\n  theme_cowplot()\n\n\n\n\n\n\n\nDie Grafik zeigt einen geringen positiven geschätzten Effekt \\(\\widehat{\\alpha}_0\\). Eine Auswertung mit lm() ergibt, dass der Effekt \\(\\alpha_0\\) nicht signifikant von \\(0\\) verschieden ist.\n\n# Einfache Regression durchführen, \n# Inferenz für gdpsh465 erhalten\nlm(Outcome ~ gdpsh465, data = GrowthData) %&gt;%\n  summary() %&gt;%\n  coefficients() %&gt;% \n  .[2, ]\n\n   Estimate  Std. Error     t value    Pr(&gt;|t|) \n0.001316713 0.006102200 0.215776701 0.829661165 \n\n\nDer positive Effekt aus der einfachen Schätzung widerspricht der Konvergenzhypothese. Dieses Ergebnis könnte allerdings durch Auslassen relevanter Kovariablen ungültig sein. Beispielsweise ist es plausibel, dass das Bildungsniveau einer Volkswirtschaft sowohl mit dem BIP korreliert ist als auch die Wachstumsrate beeinflusst. Dann wäre das Bildungsniveau eine relevante Kovariable, deren Auslassen zu einer verzerrten Schätzung von \\(\\alpha_0\\) führt.\nEine “lange” Regression mit allen Kovariablen ist zwar möglich, aber problematisch: Das Verhältnis von Beobachtungen (90) zu Regressoren (62) bedeutet eine hohe Unsicherheit der Schätzung.\n\n# Inferenz für alpha_0 in langer Regression\nsummary(\n  lm(Outcome ~ . - 1 , data = GrowthData)\n  ) %&gt;% \n  coefficients() %&gt;% \n  .[2, ]\n\n    Estimate   Std. Error      t value     Pr(&gt;|t|) \n-0.009377989  0.029887726 -0.313773911  0.756018518 \n\n\nDer geschätzte Koeffizient \\(\\widehat{\\alpha}_0\\) ist nun zwar negativ, liefert jedoch weiterhin keine Evidenz, dass \\(\\alpha_0\\) von 0 verschieden ist. Ein Vergleich der Standardfehler zeigt aber, dass die KQ-Schätzung aufgrund Berücksichtigung aller potentiellen Kovariablen mit deutlich größerer Varianz behaftet ist als in der einfachen KQ-Regression \\(\\eqref{eq:growthmodel1}\\)\nPost-Double-Selection erlaubt gültige Inferenz bzgl. \\(\\alpha_0\\) nach Schätzung der Menge relevanter Kovariablen. Wir weisen die entsprechenden Variablen R-Objekten zu und berechnen den Schätzer.\n\n# Variablen für Post-Double-Selection vorbereiten\n\n# abh. Variable\ny &lt;- GrowthData %&gt;% \n  pull(Outcome)\n\n# \"Treatment\"\nd &lt;- GrowthData %&gt;% \n  pull(gdpsh465)\n\n# potentielle Regressoren\nX &lt;- GrowthData %&gt;% \n  dplyr::select(\n    -Outcome, -intercept, -gdpsh465\n  )\n\n\n# Post-Double-Selection-Schätzer berechnen\nGrowth_DS &lt;- \n  rlassoEffect(\n    x = X %&gt;% \n      as.matrix(), \n    y = y, \n    d = d, \n    method = \"double selection\"\n)\n\nPost-Double-Selection wählt aus der Menge potentieller Kovariablen lediglich sieben Regressoren aus.\n\n# Selektierte Variablen einsehen\n# ID\nSelektion &lt;- Growth_DS$selection.index\n\n# Namen auslesen\nnames(\n  which(Selektion == T)\n)\n\n[1] \"bmp1l\"    \"freetar\"  \"hm65\"     \"sf65\"     \"lifee065\" \"humanf65\" \"pop6565\" \n\n\nTabelle 13.3 zeigt die Definitionen der ausgewählten Variablen.\n\n\n\n\n\n\n\n\nVariable\nBeschreibung\n\n\n\nbmp1l\nSchwarzmarktprämie d. Währung\n\n\nfreetar\nMaß für Zollbeschränkungen\n\n\nhm65\nEinschreibungsquote Uni (Männer)\n\n\nsf65\nBeschulungsquote Sekundarstufe (Frauen)\n\n\nlifee065\nLebenserwartung bei Geburt\n\n\nhumanf65\nDurchschn. Bildung im Alter 25 (Frauen)\n\n\npop6565\nAnteil Bevölkerung ü. 65 Jahre\n\n\n\n\n\n\n\nTabelle 13.3: Mit PDS selektierte Variablen aus GrowthData. Referenzjahr 1965.\n\n\n\n\n# Gültige Inferenz mit dem Post-Double-Selection-Schätzer\nsummary(Growth_DS)\n\n[1] \"Estimates and significance testing of the effect of target variables\"\n   Estimate. Std. Error t value Pr(&gt;|t|)   \nd1  -0.05001    0.01579  -3.167  0.00154 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDas Ergebnis der Post-Double-Selection-Schätzung unterstützt die (bedingte) Konvergenzhypothese mit einer signifikanten negativen Schätzung.",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regularisierte Regression</span>"
    ]
  },
  {
    "objectID": "RegReg.html#zusammenfassung",
    "href": "RegReg.html#zusammenfassung",
    "title": "13  Regularisierte Regression",
    "section": "\n13.5 Zusammenfassung",
    "text": "13.5 Zusammenfassung\nRegularisierte Regression erweitert klassische KQ-Schätzung durch Hinzufügen von Straftermen zur Verlustfunktion, um Schätzungen auch in Situationen mit stark korrelierten Regressoren sowie in hoch-dimensionalen Settings zu ermöglichen. Die zwei wichtigsten Varianten sind Ridge- und Lasso-Regression. Der methodische Kern hierbei ist die Regulierung der Koeffizientenschätzung durch einen Tuning-Parameter, der einen Kompromiss zwischen Verzerrung und Varianz der Schätzung steuert. Ridge-Regression führt zu einer proportionalen Schrumpfung der Koeffizienten (Shrinkage), während Lasso-Regression zusätzlich Variablenselektion durch exakte Null-Schätzungen einzelner Koeffizienten ermöglicht (Soft Thresholding). Regularisierte Regression eignet sich besonders für Prognoseaufgaben, wo eine gewisse Verzerrung zugunsten geringerer Varianz in Kauf genommen werden kann. Die Anwendung dieser Schätzer in R haben wir mit den Paketen glmnet und lars demonstriert.\nFür Schätzung von Behandlungseffekten bei vielen potentiellen Kontrollvariablen wurde der Post-Double-Selection-Schätzer vorgestellt, der Lasso zur Variablenselektion nutzt und anschließend unverzerrte Schätzungen mit klassischen Standardfehlern ermöglicht. Diese Methode kann in R mit dem Paket hdm berechnet werden.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBarro, Robert J., und Jong Wha Lee. 2013. „A new data set of educational attainment in the world, 1950–2010“. Journal of Development Economics 104: 184–98. https://doi.org/https://doi.org/10.1016/j.jdeveco.2012.10.001.\n\n\nBelloni, Alexandre, Daniel Chen, Victor Chernozhukov, und Christian Hansen. 2012. „Sparse models and methods for optimal instruments with an application to eminent domain“. Econometrica 80 (6): 2369–429.\n\n\nBelloni, Alexandre, und Victor Chernozhukov. 2013. „Least squares after model selection in high-dimensional sparse models“. Bernoulli, 521–47.\n\n\nBelloni, Alexandre, Victor Chernozhukov, und Christian Hansen. 2014. „High-dimensional methods and inference on structural and treatment effects“. Journal of Economic Perspectives 28 (2): 29–50.\n\n\nCortez, Paulo, und Alice Maria Gonçalves Silva. 2008. „Using data mining to predict secondary school student performance“.\n\n\nEfron, Bradley, Trevor Hastie, Iain Johnstone, und Robert Tibshirani. 2004. „Least angle regression“.\n\n\nHahn, P Richard, Carlos M Carvalho, David Puelz, und Jingyu He. 2018. „Regularization and confounding in linear regression for treatment effect estimation“.\n\n\nHoerl, Arthur E, und Robert W Kennard. 1970. „Ridge regression: Biased estimation for nonorthogonal problems“. Technometrics 12 (1): 55–67.\n\n\nTibshirani, Robert. 1996. „Regression shrinkage and selection via the lasso“. Journal of the Royal Statistical Society Series B: Statistical Methodology 58 (1): 267–88.",
    "crumbs": [
      "Machine Learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regularisierte Regression</span>"
    ]
  }
]