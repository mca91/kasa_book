[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kausalanalyse und Machine Learning in R",
    "section": "",
    "text": "Einleitung\n\n\n\nIn den letzten Jahren hat sich die datengetriebene Forschung in vielen Fachgebieten, insbesondere in der Ökonometrie und den empirischen Wirtschaftswissenschaften, grundlegend verändert. Haupttreiber dieses Wandels ist die zunehmende Verfügbarkeit von big data – hochdimensionale Datenmengen die regelmäßig in Unternehmen und öffentlichen Institutionen anfallen und die Entwicklung sowie den Einsatz neuer statistischer Verfahren im Gebiet machine learning prominent gemacht haben. Mit diesen Verfahren können große Datenmengen schnell und effizient verarbeitet und analysiert werden, was ihre zunehmende Relevanz für die evidenzbasierte Entscheidungsfindung in Politik und Wirtschaft begründet.\nEin weiterer Treiber der empirischen wirtschaftswissenschaftlichen Forschung ist die11 Bekannst als the credibility revolution in empirical economics (Angrist und Pischke 2010).\n\nData Science / Varian zitieren: der hat recht behalten\nReproducibility\nProgrammierung / Relevanz von Coding\nkanonischer Unterrichtskatalog in Ökonometrie aufbrechen\nAlles zusammenlegen als ein wichtiger Block für Wirtschaftswissenschaftler und solche die es werden wollen. Und es wird noch wichtiger werden.\n\n(Angrist und Pischke 2010)\n\n\n\n\n\n\nAngrist, Joshua D, und Jörn-Steffen Pischke. 2010. „The credibility revolution in empirical economics: How better research design is taking the con out of econometrics“. Journal of economic perspectives 24 (2): 3–30."
  },
  {
    "objectID": "R_Einfuehrung.html",
    "href": "R_Einfuehrung.html",
    "title": "\n1  Statistische Programmierung mit R\n",
    "section": "",
    "text": "Dieses Kapitel ist nicht als umfassende Einführung in R gedacht, sondern behandelt Kernkonzepte und soll der Selbsteinschätzung dienen. Wenngleich die Inhalte deutlich über ein Hallo-Welt-Beispiel1 hinausgehen, betrachten wir hier absolutes Basiswissen. Dieses ist Vorraussetzung für das Verständnis fortgeschrittener Konzepte in späteren Kapitel. Falls Sie bereits über solide Grundkenntnisse im Umgang mit R verfügen, können Sie problemlos zu Kapitel XYZ springen. Sollten Sie nicht oder nur teilweise mit den hier gezeigten Befehlen vertraut sein, empfiehlt sich eine Erarbeitung bzw. Wiederholung der Grundlagen. Nachstehede Ressourcen finden wir hilfreich:1 https://de.wikipedia.org/wiki/Hallo-Welt-Programm\n\nFeedbackgestütze interaktive Übungsaufgaben bei DataCamp, bspw. Einführung in R2\nOpen-source-Literatur wie der Umfangreiche Leitfaden von Ellis und Mayer (2023).\n\n2 Ein Teil des hier angebotenen Katalogs (exlusive Einführung in R) ist kostenpflichtig.\nR lädt, etwas Geduld bitte...\n\n\n\n\n\n\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. \n\nLade Pakete, etwas Geduld bitte...  \n\n\n\n\n\n1.0.0.1 Pinguine und Pipes"
  },
  {
    "objectID": "RDD.html#sharp-regression-discontinuity-design",
    "href": "RDD.html#sharp-regression-discontinuity-design",
    "title": "\n2  Regression Discontiniuty Designs\n",
    "section": "\n2.1 Sharp Regression Discontinuity Design",
    "text": "2.1 Sharp Regression Discontinuity Design\nModell und funktionale Form\nDie korrekte Spezifikation der funktionalen Form für RDD ist wichtig, um eine unverzerrte Schätzung des Effekts zu vermeiden. Die einfachste Form eines SRDD kann anhand der linearen Regression \\[\\begin{align}\nY_i = \\beta_0 + \\beta_1 B_i + \\beta_2 X_i + u_i\\label{eq-simpleSRDD}\n\\end{align}\\] geschätzt werden, wobei \\(B_i\\) eine Dummy-Variable für das Überschreiten des Schwellenwertes \\(c\\)ist, d.h. \\[\\begin{align*}\n  B_i=\\begin{cases}\n    0 & X_i &lt; C\\\\\n    1 & X_i \\geq C.\n  \\end{cases}\n\\end{align*}\\] Damit ist \\(B_i\\) eine deterministische Funktion der Laufvariable \\(X_i\\) und zeigt die Zugehörigkeit zur Behandlungs- oder Treatmentgruppe an. \\(\\beta_1\\) ist der Behandlungseffekt.\nModell \\(\\eqref{eq-simpleSRDD}\\) unterstellt, dass \\(X\\) links- und rechtsseitig von \\(c\\)denselben Effekt auf \\(Y\\) hat. Diese Annahme ist restriktiv. Eine Alternative ist ein lineares Interaktionsmodell \\[\\begin{align}\nY_i = \\beta_0 + \\beta_1 B_i + \\beta_2 (X_i - C) + \\beta_3(X_i-C)\\times B_i + u_i.\\label{eq:linearSRDD}\n\\end{align}\\] Das Modell \\(\\eqref{eq:linearSRDD}\\) kann unterschiedliche lineare Effekte von \\(X\\) auf \\(Y\\) unterhalb (\\(\\beta_2\\)) und oberhalb (\\(\\beta_2 + \\beta_3\\)) von \\(c\\)abgebilden. Beachte, dass \\((X_i - C)\\) die um den Schwellenwert zentrierte Laufvariable ist, sodass \\(\\beta_1\\) wie in \\(\\eqref{eq-simpleSRDD}\\) den Unterschied des Effekts von \\(X\\) auf \\(Y\\) für Beoabachtungen am Schwellenwert erfasst.\nUm unterschiedliche nicht-lineare Zusammenhänge von \\(X\\) und \\(Y\\) unterhalb und oberhalb von \\(c\\)abzubilden, können (interargierte) Polynom-Terme in \\(X\\) verwendet werden, bspw. eine quadratische Regressionsfunktion \\[\\begin{align*}\n  Y_i =&\\, \\beta_0 + \\beta_1 B_i + \\beta_2 (X_i - C) + \\beta_3 (X_i - C)^2\\\\\n       &+\\, \\beta_4(X_i-C)\\times B_i + \\beta_5(X_i-C)\\times B_i + u_i.\\label{eq:quadSRDD}\n\\end{align*}\\] Gelman und Imbens (2019) zeigen, dass Polynome höherer Ordnung zu verzerrten Schätzern und hoher Varianz führen können.2 Die Authoren empfehlen die Schätzung mit lokaler Regression.2 Ursachen sind Überanpassung an die Daten sowie instabiles Verhalten der Schätzung nahe des Schwellenwertes.\nNicht-parametrische Schätzung und Bandweite\nAktuelle Studien nutzen nicht-parametrische Schätzer, die den Behandlungseffekt als Differenz der geschätzten Regressionsfunktionen am Schwellenwert \\(c\\) berechnen. Um auch nicht-lineare Regressionsfunktionen abzubilden zu können, wird häufig lokale Regression verwendet. Dieses Verfahren liefert eine “lokale” Schätzung der Regressionsfunktionen am Schwellenwert, bei der nur Beobachtungen nahe bei \\(X = c\\) für die Schätzung berücksichtigt werden. Hinreichende Nähe wird durch eine sogenannte Bandweite \\(h\\) festgelegt, wobei \\[\\begin{align}\n  \\lvert(X_i-C)\\rvert\\leq h \\label{eq:bwc}\n\\end{align}\\] das Kriterium für eine Berücksichtigung von Beobachtung \\(i\\) bei der Schätzung ist.\nUnter Verwendung einer Bandweite \\(h\\) wird der Regressionsansatz \\(\\eqref{eq:linearSRDD}\\) als lokale lineare Regression mit Uniform-Kernelfunktion bezeichnet. Der Uniform-Kernel gibt allen Beobachtungen, innerhalb der Bandweite \\(h\\) dasselbe Gewicht. Ist \\(h\\) so groß, dass der gesamte Datensatz in die Schätzung einbezogen wird, entspricht der lokale lineare Regressions-Schätzer mit Uniform-Kernel dem globalen KQ-Schätzer. Neben dem Uniform-Kernel ist der Triangular-Kernel eine in der Praxis häufig genutzte lineare Kernelfunktion. Der nachstehende Code plottet die Uniform- (grün) sowie die Triangular-Kernelfunktion (blau), siehe Abbildung 2.2.\n\nCodelibrary(ggplot2)\nlibrary(cowplot)\nggplot() + \n    geom_function(\n      fun = ~ ifelse(abs(.) &lt;= 1, 1/2, 0), \n      col = \"green\", \n      n = 1000\n      ) + \n    geom_function(\n      fun = ~ ifelse(abs(.) &lt;= 1, 1-abs(.), 0), \n      col = \"blue\", \n      n = 100\n      ) + \n    scale_x_continuous(\"x\", limits = c(-1.5, 1.5), \n                       breaks = c(-1, 0, 1)) +\n    scale_y_continuous(\"K(x)\", \n                       breaks = c(0, 1), \n                       limits = c(0, 1.25)) +\n    theme_cowplot()\n\n\n\nAbbildung 2.2: Kernelfunktionen auf [-1, 1]\n\n\n\nIn Studien wird oftmals zunächst lokale lineare Regression anhand von \\(\\eqref{eq:linearSRDD}\\) mit einer linearen Kernelfunktionen und geringer bandweite \\(h\\) genutzt. Anschließend wird die Robustheit der Ergebnisse anhand flexiblerer Spezifikationen, die eine Nicht-Linearitäten in der Regressionsfunktion besser abbilden können, geprüft.\nDie nachstehende Visualisierung zeigt die Schätzung des kausalen Effektes der Behandlung \\(B_i\\) anhand lokaler linearer Regression mit einem Uniform-Kernel für wiefolgt simulierte Daten:\n\\[\\begin{align*}\n  Y_i =&\\, \\beta_1 X_i + \\beta_2 B + \\beta_3 X_i^2 \\times B_i + u_i,\\\\\n  \\\\\n  u_i \\sim&\\, N(0, 0.5), \\quad X_i \\sim U(0, 10), \\quad B = \\mathbb{I}(X_i \\geq c = 5)\\\\\n  \\beta_1 =&\\, .5, \\quad \\beta_2 = 1.5, \\quad \\beta_3 = -0.15\n\\end{align*}\\]\n\nset.seed(1234)\nn &lt;- 750\n\nc &lt;- 5\nbeta_1 &lt;- .5\nbeta_2 &lt;- 1.5\nbeta_3 &lt;- -.15\n\nf &lt;- function(X) {\n  beta_1 * (X-c) + beta_2 * B + beta_3 * B * (X-c)^2\n}\n\nX &lt;- runif(n, 0, 11)\nB &lt;- ifelse(X - c &gt;= 0, 1, 0)\nY &lt;- f(X) + rnorm(n, sd = .5)\n\ndat &lt;- data.frame(\n  Y = Y, X = X - c, B = B\n)\n\n\nhtml`\n&lt;style&gt;\n.regression {\n  fill: none;\n  stroke: #000;\n  stroke-width: 1.5px;\n}\n.axis line {\n  stroke: #ddd;\n}\n.axis .baseline line {\n  stroke: #555;\n}\n.axis .domain {\n  display: none;\n} \n&lt;/style&gt;\n&lt;link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css\"&gt;\n`\n\n\n\n\n\n\n\nd3 = require(\"d3-array@3\", \"d3-axis@3\", \"d3-regression@1\", \"d3-scale@4\", \"d3-shape@3\", \"d3-selection@3\", \"d3-format\")\n\nmargin = ({left: 55, right: 8, top: 13, bottom: 24});\nbase = Math.min(width, 500);\ninnerWidth = base - margin.left - margin.right;\ninnerHeight = base-100 - margin.top - margin.bottom;\n\n\nviewof bw_daten_LLRU = Inputs.range([.1, 6], {\n  label: \"Bandweite (h)\",\n  step: .1,\n  value: 1.3\n});\n\nxScaleLLRU = d3.scaleLinear()\n   .domain([-6, 6])\n   .range([0, innerWidth]);\n   \nyScaleLLRU = d3.scaleLinear()\n  .domain([-4, 6])\n  .range([innerHeight, 0]);\n\nlineLLRU = d3.line()\n  .x(d =&gt; xScaleLLRU(d[0]))\n  .y(d =&gt; yScaleLLRU(d[1]));\n  \nxAxisLLRU = d3.axisBottom(xScaleLLRU)\n  .tickSize(innerHeight + 10)\n  .tickValues([-6, -4, -2, 0, 2, 4, 6])\n  .tickFormat(d =&gt; d);\n\nyAxisLLRU = d3.axisLeft(yScaleLLRU)\n  .tickSize(innerWidth + 10)\n  .tickFormat(d =&gt; d);\n\nLLRURegression = d3.regressionLinear()\n  .x(d =&gt; d.X)\n  .y(d =&gt; d.Y);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  const svg = d3.select(DOM.svg(innerWidth + margin.left + margin.right + 20, innerHeight + margin.top + margin.bottom + 20))\n  \n  const g = svg.append(\"g\")\n      .attr(\"transform\", `translate(${margin.left}, ${margin.top})`);\n\n  g.append(\"g\")\n      .attr(\"class\", \"axis\")\n      .call(xAxisLLRU);\n\n  g.append(\"g\")\n    .attr(\"class\", \"axis\")\n    .attr(\"transform\", `translate(${innerWidth})`)\n    .call(yAxisLLRU);\n\n  // Add X axis label:\n  g.append(\"text\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"font-size\", 13)\n    .attr(\"x\", innerWidth)\n    .attr(\"y\", innerHeight + margin.top + 25)\n    .text(\"X - c\");\n\n  // Y axis label:\n  g.append(\"text\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"transform\", \"rotate(-90)\")\n    .attr(\"font-size\", 13)\n    .attr(\"y\", -margin.left+10)\n    .attr(\"x\", -margin.top+10)\n    .text(\"Y\");\n\n  g.selectAll(\"circle\")\n    .data(transpose(SRDD))\n    .enter().append(\"circle\")\n    .attr(\"r\", 2)\n    .attr(\"cx\", d =&gt; xScaleLLRU(d.X))\n    .attr(\"cy\", d =&gt; yScaleLLRU(d.Y));\n\ng.selectAll(\"circle\")\n .filter( function(d){ return Math.abs(d.X) &lt;= bw_daten_LLRU } )\n .attr(\"fill\", \"orange\")\n .attr(\"stroke\", \"none\");\n \n  &lt;!-- trf --&gt;\nvar  line = d3.line()\n           .x(function(d) { return xScaleLLRU(d.X); }) \n           .y(function(d) { return yScaleLLRU(d.Y_true); }) \n           .curve(d3.curveLinear); \n\n  g.append(\"path\")\n    .datum(transpose(SRDD))\n    .attr(\"d\", line)\n    .attr(\"fill\", \"none\")\n    .attr(\"stroke\", \"red\")\n    .attr(\"stroke-width\", 2);\n\n\nfunction b(d) { return LLRURegression(\n        transpose(SRDD).filter(function(d){ return d.X &lt;= 0 & d.X &gt;= -bw_daten_LLRU })\n    ); }\n\nfunction a(d) { return LLRURegression(\n      transpose(SRDD).filter(function(d){ return d.X &gt; 0 & d.X &lt;= bw_daten_LLRU })\n    ); }\n\n  g.append(\"path\")\n      .attr(\"class\", \"regression\")\n      .datum(b)\n      .attr(\"d\", lineLLRU)\n      .attr(\"stroke-width\", 2)\n      .style(\"stroke\", \"#39FF14\");\n\n  g.append(\"path\")\n      .attr(\"class\", \"regression\")\n      .datum(a)\n      .attr(\"d\", lineLLRU)\n      .attr(\"stroke-width\", 2)\n      .style(\"stroke\", \"#39FF14\");\n  \n  g.append(\"line\")\n  .attr(\"x1\", xScaleLLRU(0))\n  .attr(\"y1\", yScaleLLRU((b().slice(-1))[0][1]))\n  .attr(\"x2\", xScaleLLRU(0))\n  .attr(\"y2\", yScaleLLRU((a().slice(0))[0][1]))\n  .attr(\"stroke\", \"#39FF14\")\n  .attr(\"stroke-width\", 2);\n  \n   g.append(\"text\")\n    .attr(\"x\", d =&gt; xScaleLLRU(-2.75))\n    .attr(\"y\", d =&gt; yScaleLLRU(4.5))\n    .attr(\"dy\", \".35em\")\n    .attr(\"fill\", \"#39FF14\")\n    .text(\n    d3.format(\",.2f\")( (a().slice(0))[0][1] - (b().slice(-1))[0][1] ) \n    );\n  \n  /* dashed line data bw upper */\n  g.append(\"line\")\n  .attr(\"x1\", xScaleLLRU(bw_daten_LLRU))\n  .attr(\"y1\", 0)\n  .attr(\"x2\", xScaleLLRU(bw_daten_LLRU))\n  .attr(\"y2\", innerHeight)\n  .style(\"stroke\", \"blue\")\n  .style(\"stroke-dasharray\", \"4\")\n  .style(\"stroke-width\", \"1\");\n  \n  /* dashed line data bw lower */\n  g.append(\"line\")\n  .attr(\"x1\", xScaleLLRU(-bw_daten_LLRU))\n  .attr(\"y1\", 0)\n  .attr(\"x2\", xScaleLLRU(-bw_daten_LLRU))\n  .attr(\"y2\", innerHeight)\n  .style(\"stroke\", \"blue\")\n  .style(\"stroke-dasharray\", \"4\")\n  .style(\"stroke-width\", \"1\");\n\n  return svg.node();\n}\n\n\n\n\nAbbildung 2.3: Nicht-parametrische Regression auf beiden Seiten des Cut-offs\n\n\nDer interssierende Effekt am Schwellenwert \\(c=5\\) beträgt \\(\\beta_2 = 1.5\\). Beachte, dass aufgrund des Terms \\(\\beta_3 X_i^2 \\times B_i\\) ein quadratischer Zusammenhang von \\(Y\\) und \\(X\\) oberhalb von \\(X_i = c\\) vorliegt. Abbildung 2.3 Es können folgende Eigenschaften der Schätzung in Abhängigkeit von der Bandweite \\(h\\) beobachtet werden:\n\nFür die voreingestellte Bandweite \\(h = 1.3\\) liefert die lokale lineare Regression eine gute Approximation des Regressionszusammenhangs auf beiden Seiten des Schwellenwertes und die Schätzung des Behandlungseffekts liegt nahe beim wahren Wert \\(\\beta_2 = 1.5\\).\nFür kleinere Bandweiten verringern sich Datenbasis der Schätzung. Die Varianz der Schätzung nimmt zu und die Approximation der Regressionsfunktion verschlechtert sich. Wir erhalten eine mit \\(h\\to0\\) zunehmend verzerrte Schätzung des Behandlungseffekts.\nGrößere Bandweiten \\(h\\) erhöhen die Datenbasis der Schätzung, führen aber zu einer Annäherung der lokalen Schätzung an die globale KQ-Schätzung. Linksseitig des Schwellenwertes erzielen wir damit eine Schätzung mit hoher Güte. Rechsseitig von \\(X_i = c\\) verschlechtert sich die lokale Anpassung am Schwellenwert deutlich, weil die lineare Schätzung den tatsächlichen nicht-linearen Zusammenhang nicht adäquait abbildet. Die Schätzung des Behandlungseffekts ist deutlich verzerrt.\n\nDie Wahl der Bandweite ist also eine wichtige Komponenten der RDD-Schätzung: Kleine Bandweiten erlauben eine Schätzung der Regressionsfunktion nahe des Schwellenwertes mit wenig Verzerrung. Allerdings kann diese Schätzung unpräzise sein, wenn nur wenige Beobachtungen \\(\\eqref{eq:bwc}\\) erfüllen. In der Praxis wird \\(h\\) daher mit einem analytischen Schätzer (vgl. G. Imbens und Kalyanaraman 2012) oder anhand von Cross Validation (bspw. G. W. Imbens und Lemieux 2008) bestimmt. Die später in diesem Kapitel betrachteten R-Pakete halten diese Methoden bereit."
  },
  {
    "objectID": "RDD.html#fuzzy-regression-discontinuity-design",
    "href": "RDD.html#fuzzy-regression-discontinuity-design",
    "title": "\n2  Regression Discontiniuty Designs\n",
    "section": "\n2.3 Fuzzy Regression Discontinuity Design",
    "text": "2.3 Fuzzy Regression Discontinuity Design\n\n\n\n\n\noberhalb causal Diagramm RDD\n\n\nX\n\nX\nY\n\nY\nX-&gt;Y\n\n\noberhalb c\n\noberhalb c\nX-&gt;oberhalb c\n\n\nBehandlung\n\nBehandlung\nX-&gt;Behandlung\n\n\noberhalb c-&gt;Behandlung\n\n\nZ\n\nZ\nZ-&gt;X\n\n\nZ-&gt;Y\n\n\nZ-&gt;Behandlung\n\n\nBehandlung-&gt;Y\n\n\n\nAbbildung 2.8: Kausales Diagram für FRDD\n\n\n\nEin FRDD liegt vor, wenn die Laufvariable \\(X\\) (und möglicherweise weitere Variablen \\(Z\\)) die Zuweisung der Behandlung \\(B\\) beeinflusst. Im Vergleich zum SRDD ist die Behandlung dann nicht ausschließlich durch Überschreiten des Schwellenwerts \\(X = c\\) bestimmt. Abbildung Abbildung 2.8 zeig den Zusammenhang. Es genügt weiterhin, für \\(X\\) (und ggf. \\(Z\\)) zu kontrollieren, um den Pfad oberhalb \\(C\\) → Behandlung \\(B\\) → \\(Y\\) zu isolieren. Der so für Behandlung \\(B\\) ermittelte Effekt auf \\(Y\\) entspricht jedoch nicht dem “vollständigen” Behandlungseffekt, da bei \\(c\\) die Zuweisung der Behandlung nicht von 0 auf 100% springt. Die Schätzung des FRDD berücksichtigt dies und skaliert den Effekt entsprechend.\nWir betrachten zunächst den Zusammenhang \\[\\begin{align}\n  Y_i = \\beta_0 + \\beta_1 B_i + \\beta_2 (X_i - c) + u_i.\\label{eq-simpleFRDD}\n\\end{align}\\] In einem FRDD springt die Behandlungswahrscheinlichkeit am Schwellenwert \\(c\\) um \\(\\Delta p&lt;1\\). Wir können \\(B_i\\) also nicht als deterministische Funktion von \\(X\\) definieren, die Zuweisung zu Behandlungs- bzw. Kontrollgruppe am Schwellenwert \\(c\\) anzeigt (wie im SRDD). Stattdessen betrachten wir \\[\\begin{align}\n  P(B_i=1\\vert X_i) =\n  \\begin{cases}\n    g_{X_i&lt;c}(X_i), & X_i &lt; c \\\\\n    g_{X_i\\geq c}(X_i) & X_i \\geq c\n  \\end{cases}\\,. \\label{eq-BFRDD}\n\\end{align}\\] Die Funktionen \\(g_{X_i&lt;c}\\) und \\(g_{X_i\\geq c}\\) können verschieden sein, jedoch muss \\[g_{X_i&lt;c}(X_i = c) \\neq g_{X_i\\geq c}(X_i = c)\\] gelten. Die Behandlungsvariable \\(B_i\\) ist also eine (binäre) Zufallsvariable, deren bedingte Wahrscheinlichkeitsfunktion \\(P(B_i=1\\vert X_i)\\) am Schwellenwert \\(c\\) eine Diskontinuität aufweist. Abbildung 2.9 zeigt ein Beispiel für eine nicht-lineare Wahrscheinlichkeitsfunktion mit Diskontinuität bei \\(X_i = c\\).\n\nCodelibrary(ggplot2)\nlibrary(cowplot)\nggplot() + \n  geom_function(\n    fun = ~ ifelse(\n      . &lt; 0, \n      -.1 * .^2 + .25, \n      -.1 * (.-1.5)^2 + 1\n    ), \n    n = 1000\n  ) + \n    geom_function(\n    fun = ~ ifelse(\n      . &lt; 0, \n     .35, \n     .65\n    ),\n    n = 1000, lty = 2, col = \"red\"\n  ) + \n  scale_x_continuous(\"Laufvariable X\", limits = c(-1.5, 1.5),\n                     labels = NULL,\n                     breaks = NULL) +\n  scale_y_continuous(\"P(D=1|X)\", \n                     breaks = c(0, 1), \n                     limits = c(0, 1)) +\n  theme_cowplot()\n\n\n\nAbbildung 2.9: Bedingte Behandlungswahrscheinlichkeiten im FRDD\n\n\n\nDefinition \\(\\eqref{eq-BFRDD}\\) bedeutet, dass eine KQ-Schätzung von \\(\\beta_1\\) anhand \\(\\eqref{eq-simpleFRDD}\\) eine verzerrte Schätzung des Behandlungseffekts ist: Der in \\(\\widehat{\\beta}_1\\) erfasste Effekt auf \\(Y\\) ist auf einen Sprung der Behandlungswahrscheinlichkeit bei \\(X_i = c\\) um weniger als 100% zurückzuführen. Der Behandlungseffekt wird unterschätzt. Daher muss \\(\\widehat{\\beta}_1\\) skaliert werden, sodass die Schätzung als Effekt einer Änderung der Behandlungswahrscheinlichkei um 100% interpretiert werden kann – der zu erwartende Effekt, wenn ausschließlich Subjekte mit \\(X_i\\geq c\\) behandelt würden. Diese skalierte Schätzung erhalten wir mit IV-Regression (vgl. Kapitel XYZ). Hierfür nutzen wir für \\(B_i\\) die Instrumentvariable \\[\\begin{align*}\n  D_i = \\begin{cases}\n    0, & X_i &lt; c \\\\\n    1, & X_i \\geq c.\n  \\end{cases} \\label{eq-instFRDD}\n\\end{align*}\\] Angenommen \\(g_{X_i\\geq c}(X_i) = \\alpha_0\\) und \\(g_{X_i&lt;c}(X_i) = \\alpha_0 + \\alpha_1\\) mit \\(\\alpha_0 + \\alpha_1 &lt; 1\\) (vgl. rote Funktion in Abbildung 2.8). Der FRDD-Schätzer des Behandlungseffekts ist dann \\(\\widehat{\\gamma}_\\textup{FRDD}\\) im 2SLS-Verfahren mit den Regressionen \\[\\begin{align}\n  \\begin{split}\n  (\\mathrm{I})\\qquad B_i =&\\, \\alpha_0 + \\alpha_1 D_i + \\alpha_2 (X_i - c) + e_i,\\\\\n  (\\mathrm{II})\\qquad Y_i =&\\, \\gamma_0 + \\gamma_1 \\widehat{B}_i + \\gamma_2 (X_i - c) + \\epsilon_i,\n  \\end{split}\\label{eq:FRDD_simpleIV}\n\\end{align}\\] wobei \\(\\widehat{B}_i\\) die angepassten Werte aus Stufe \\((\\mathrm I)\\) und \\(e_i\\) sowie \\(\\epsilon_i\\) Fehlterterme sind.\nAnalog zum SRDD müssen in Anwendungen geeignete Spezifikationen für die Regressionsfunktionen \\(\\eqref{eq-simpleFRDD}\\) und \\(\\eqref{eq-BFRDD}\\) gewählt und der 2SLS-Schätzer \\(\\eqref{eq:FRDD_simpleIV}\\) entsprechend angepasst werden. Ein einfaches Interaktionsmodell wäre \\[\\begin{align}\n  \\begin{split}\n  (\\mathrm{I})\\qquad B_i =&\\, \\alpha_0 + \\alpha_1 D_i + \\alpha_2 (X_i - c)\\\\\n  +&\\, \\alpha_3 (X_i - c) \\times D_i + e_i,\\\\\n  \\\\\n  (\\mathrm{II})\\qquad Y_i =&\\, \\gamma_0 + \\gamma_1 \\widehat{B}_i\\\\\n  +&\\, \\gamma_2 (X_i - c) + \\gamma_3 (X_i-c)\\times\\widehat{B}_i, \\epsilon_i\n  \\end{split}\\label{eq:FRDD_lintIV}\n\\end{align}\\] d.h. wir instrumentieren \\(B_i\\) mit \\(D_i\\) und dem Interaktionsterm \\((X_i-c)\\times D_i\\).\nWie im SRDD werden die IV-Ansätze für das FRDD \\(\\eqref{eq:FRDD_simpleIV}\\) und in empirischen Studien unter Berücksichtigung einer Bandweite (i.d.R. dieselbe Bandweite für beide Stufen) angewendet."
  },
  {
    "objectID": "RDD.html#case-study-protestantische-arbeitsethik",
    "href": "RDD.html#case-study-protestantische-arbeitsethik",
    "title": "\n2  Regression Discontiniuty Designs\n",
    "section": "\n2.4 Case Study: Protestantische Arbeitsethik",
    "text": "2.4 Case Study: Protestantische Arbeitsethik\n\n\n\nDie Studie Beyond Work Ethic: Religion, Individual, and Political Preferences (Basten und Betz 2013) untersucht den Zusammenhang zwischen Religion, individuellen Merkmalen und politischen Präferenzen. Das Hauptaugenmerk ist die Rolle von Religiosität als Einflussfaktor auf politische Einstellungen. Die Hypothese ist, das Religiosität eines Individuums über den traditionellen Rahmen von Moralvorstellungen und sozialen Normen hinaus auch politische Präferenzen beeinflusst. Diese Theorie wurde zu Beginn des 20. Jahrhunderts entwickelt und prominent von Max Weber (vgl. Weber 2004) vertreten. Weber argumentiert, dass die protestantische Arbeitsethik einen entscheidenden Einfluss auf die Entwicklung des Kapitalismus hatte. Laut Weber führte der protestantische Glaube an harte Arbeit, ein sparsames Leben und ethisches Verhalten zur einer verbreiteten “Geisteshaltung”, die den wirtschaftlichen Erfolg förderte und den Aufstieg des Kapitalismus begünstigte.\nBasten und Betz (2013) nutzen Wahlergebnisse sowie geo- und soziodemographische Datensätze für schweizer Gemeinden, um den Zusammenhang zwischen Religiosität und politischen Präferenzen wie links-rechts-Ausrichtung, Einstellungen zur Umverteilung und Einwanderung zu untersuchen. Hierfür verwenden die Autoren ein FRDD, dass auf einer historisch bedingte Diskontinuität der geographischen Verteilung von evanglischer bzw. katholischer Religionszugehörigkeit zwischen den Kantonen Freiburg (überwiegend dunkelrote Region, frz. Fribourg) und Waadt (kleinere hellrote Region, frz. Vaud) basiert, vgl. Abbildung 2.10.\n\n\n\n\nAbbildung 2.10: Historische Verteilung von Religionszugehörigkeit in Schweizer Gemeinden. Quelle: Basten und Betz (2013).\n\n\n\nDie Ergebnisse der Studie zeigen einen signifikanten Einfluss von Protestantismus auf politische Präferenzen, die über traditionelle Moralvorstellungen hinausgehen: Die Autoren finden Hinweise, dass Einwohner evangelisch geprägter Gemeinden eher konservative soziale und politische Ansichten vertreten. Eine mögliche Erklärung für diesen Effekt ist, dass religiöse Institutionen auch eine soziale und politische Agenda verfolgen, die von den Gläubigen internalisiert wird.\n\n2.4.1 Aufbereitung der Daten\nIn diesem Kapitel zeigen wir, wie die Kernergebnisse der Studie mit R reproduziert werden können. Hierfür werden folgende Pakete benötigt.\n\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(vtable)\nlibrary(rdrobust)\n\nDas Papier sowie der Datensatz BastenBetz.dta sind auf der Übersichtsseite der AEA verfügbar und liegt im STATA-Format .dta vor.44 Siehe alternativ das working paper, falls kein Abbonement für AEA-Journals vorliegt.\n\n# Datensatz einlesen\nBastenBetz &lt;- read_dta('BastenBetz.dta')\n\nDer Datensatz BastenBetz enthält Beobachtungen zu 509 schweizer Gemeinden. Eine Vielzahl an Variablen ist lediglich für Robustheits-Checks relevant. Für die Reproduktion der Kernergebnisse erstellen wir zunächst einen reduzierten Datensatz und transformieren einige Variablen.\n\n# Reduzierten Datensatz erstellen\nBastenBetz &lt;- BastenBetz %&gt;%\n  transmute(\n    gini = Ecoplan_gini,\n    prot = prot1980s,\n    bord = borderdis, \n    vaud,\n    pfl, \n    pfr, \n    pfi\n  )\n\nDie Definitionen der Variablen sind in Tabelle 2.2 gegeben. Die Präferenzen pfl, pfr und pfi basieren auf Wahlergebnissen auf Gemeindeebene zu Volksentscheiden.\n\n\n\n\n\n\n\n\nVariable\nDefinition\n\n\n\nprot\nAnteil Prothestanten im Jahr 1980 (%)\n\n\ngini\nGini-Koeffizient\n\n\nbord\nLaufdistanz zur Kantonsgrenze (Km)\n\n\nvaud\nDummyvariable: Gemeine im Kanton Waadt\n\n\npfl\nPräferenz für Freizeit (%)\n\n\npfr\nPräferenz für Umverteilung (%)\n\n\npfi\nPräferenz für wirtschaftliche Intervention des Staats (%)\n\n\n\nTabelle 2.2: BastenBetz – Variablen und Definitionen\nFür die Berechnung der optimalen Bandweite des FRDD verwenden wir einen MSE-optimalen Schätzer, der in der Funktion rdrobust::rdbwselect() implementiert ist.55 Basten und Betz (2013) setzen BW = 5.01, den Durchschnitt von IK-Schätzungen über Modelle sämtlicher betrachteter Outcome-Variablen. Diese Bandweite liegt nahe des Ergebnisses von rdbwselect. Wir verwenden nachfolgend die Schätzung OB.\n\n# Bandweite schätzen (Bsp. für Freizeitpräferenz)\nbw_selection &lt;- rdbwselect(\n  y = BastenBetz$pfl,\n  x = BastenBetz$bord,\n  fuzzy = BastenBetz$prot, \n  bwselect = \"mserd\", \n  kernel = \"uniform\"\n) \n\n# summary(bw_selection)\n\n# Bandweite auslesen und zuweisen\n(OB &lt;- bw_selection$bws[1])\n\n[1] 5.078001\n\n\n\n2.4.2 Deskriptive Statistiken\nZur Reproduktion von Tabelle 1 aus Basten und Betz (2013) erzeugen wir eine nach Kantonen gruppierte Zusammenfassung der Daten und berechnen deskriptive Statistiken. Wie im Paper berücksichtigen wir hierbei nur Gemeinden innerhalb der geschätzten optimalen Bandweite OB.\n\n# Datensatz für Reproduktion von Table 1 formatieren\nT1 &lt;- BastenBetz %&gt;%\n    filter(abs(bord) &lt; OB) %&gt;%\n    mutate(\n        vaud = ifelse(vaud == 1, \"Waadt\", \"Freiburg\"),\n        prot = prot * 100\n    ) %&gt;%\n    group_by(vaud) %&gt;%\n    summarise(\n      across(everything(), list(Mean = mean, SD = sd, N = length))\n      ) %&gt;%\n    pivot_longer(\n      -vaud,\n      names_to = c(\"variable\", \"statistic\"), \n      names_sep = \"_\"\n    )\n\nFür die tabellarische Darstellung transformieren wir in ein weites Format, sodass die Tabelle die deskriptive Statistiken spaltenweise für die Kantone zeigt.\n\n# weites Format\nT1_wider &lt;- T1 %&gt;% \n    pivot_wider(\n        names_from = c(\"vaud\", \"statistic\")\n    )\n\nDie Tabelle erzeugen wir mit gt::gt().\n\n# Tabelle mit gt() erzeugen\nT1_wider %&gt;%\n  gt(rowname_col = \"Variable\") %&gt;% \n  tab_spanner_delim(\n    delim = \"_\",\n  ) %&gt;%\n tabopts\n\n\n\n\n\n\n\n  \n\nvariable\n      \n        Freiburg\n      \n      \n        Waadt\n      \n    \n\nMean\n      SD\n      N\n      Mean\n      SD\n      N\n    \n\n\n\ngini\n0.302\n0.029\n49\n0.367\n0.052\n84\n\n\nprot\n9.428\n5.695\n49\n83.245\n11.411\n84\n\n\nbord\n−2.327\n1.274\n49\n2.493\n1.201\n84\n\n\npfl\n48.239\n4.774\n49\n39.508\n5.723\n84\n\n\npfr\n43.049\n2.634\n49\n39.19\n5.025\n84\n\n\npfi\n52.642\n2.94\n49\n47.086\n3.368\n84\n\n\n\nTabelle 2.3:  Datensatz BastenBetz – tusammenfassende Statistiken \n\n\n\nDie Statistiken in Tabelle 2.3 scheinen konsistent mit der (historischen) Verteilung der Religionszugehörigkeit und politischen Einstellung gemäß der Hypothese: Im überwiegend katholischen Freiburg finden wir eine größere Einkommensungleichkeit und höhere aus Wahlergebnissen abgeleitete Präferenzen für Freizeit, Umverteilung sowie staatliche Interventionen.\n\n2.4.3 Modellspezifikation und First-Stage-Ergebnisse\nDie Kantone Waadt und Freiburg haben bis heute mehrheitlich protestantische bzw. katholische Gemeinden. Die Verteilung von Protestantismus ist also, u.a. aufgrund von Bevölkerungsbewegungen, nicht mehr deterministisch. An der Kantonsgrenze besteht jedoch eine deutliche Diskontinuität im Anteil protestantischer Einwohner, die auf die historische Verteilung der Religionszugehörigkeit zurückzuführen ist. Damit kann ein FRDD implementiert werden, bei dem die Distanz zur Grenze (bord) die zentrierte Laufvariable ist und die Zugehörigkeit zum Kanton Waadt (vaud) ein Instrument für die Behandlungsvariable (prot) ist.\nWir nutzen die Funktion rdrobust::rdplot um diesen Zusammenhang für verschiedene Bandweiten anhand des linearen Interaktionsmodells \\[\\begin{align}\n  \\begin{split}\n  prot_i =&\\, \\alpha_0 + \\alpha_1 vaud_i + \\alpha_2 bord_i \\\\\n  +&\\, \\alpha_3 bord_i \\times vaud_i + u_i\n  \\end{split}\\label{eq:BBFSR}\n\\end{align}\\] grafisch darzustellen. Dies ist die First-Stage-Regression für die 2SLS-Schätzung der Behandlungseffekte.\n\n# Reproduktion von Abbildung 3 in Basten und Betz (2013)\n\nplots_BB &lt;- list(\n  # gesch. optimale Bandweite\n  p_OB = rdplot(y = BastenBetz$prot, \n                x = BastenBetz$bord, \n                h = c(OB, OB), \n                x.label = \"Distanz zur Grenze (bord)\",\n                y.label = \"Anteil Protestanten (prot)\", \n                title = \"Gesch. Bandweite\",\n                p = 1, \n                nbins = c(6, 14), \n                masspoints = \"off\"),\n  \n  # Bandweite 10\n  p_BW10 = rdplot(y = BastenBetz$prot, \n                  x = BastenBetz$bord, \n                  h = c(10, 10), \n                  x.label = \"Distanz zur Grenze (bord)\",\n                  y.label = \"Anteil Protestanten  (prot)\", \n                  title = \"Bandweite = 10\",\n                  p = 1, \n                  nbins = c(6, 14),\n                  masspoints = \"off\"),\n  \n  # Bandweite 20\n  p_BW20 = rdplot(y = BastenBetz$prot, \n                  x = BastenBetz$bord, \n                  h = c(20, 20), \n                  x.label = \"Distanz zur Grenze (bord)\",\n                  y.label = \"Anteil Protestanten  (prot)\", \n                  title = \"Bandweite = 20\",\n                  p = 1, \n                  nbins = c(6, 14),\n                  masspoints = \"off\"),\n  \n  # Gesamter Datensatz\n  p_G = rdplot(y = BastenBetz$prot, \n               x = BastenBetz$bord,\n               x.label = \"Distanz zur Grenze (bord)\",\n               y.label = \"Anteil Protestanten\", \n               title = \"Ges. Datensatz\",\n               p = 1, \n               nbins = c(6, 14),\n               masspoints = \"off\")\n)\n\nWir sammeln die Ergebnisse in einem Plot-Gitter mit cowplot::plot_grid().\n\n# Reproduktion von Abbildung 3 in Basten und Betz (2013)\nplot_grid(\n  plotlist = map(plots_BB, ~ .$rdplot), ncol = 2\n)\n\n\n\nAbbildung 2.11: First-Stage-Regressionen\n\n\n\nDie Grafiken in Abbildung 2.11 zeigen deutliche Hinweise auf die Diskontinuität in prot nahe der Kantonsgrenze. Die Größe des geschätzten Sprungs scheint nur wenig sensitiv gegenüber der gewählten Bandweite zu sein. Die Signifikanz des Effekts können wir anhand der jeweiligen KQ-Regressionen beurteilen.66 Wir nutzen update() um die Regression mit weniger Code für verschiedene Bandweiten zu schätzen.\n\n# Reproduktion der First-Stage-Regressionen\n# s. Tabelle 2 in Basten und Betz (2013)\n\n# (1) BW = OB\nFS1 &lt;- lm(\n  formula = prot ~ vaud + bord + vaud * bord, \n  data = BastenBetz %&gt;% filter(abs(bord) &lt;= OB)\n)\n\n# (2) BW = 10\nFS2 &lt;- update(\n  FS1,\n  data = BastenBetz %&gt;% filter(abs(bord) &lt;= 10)\n)\n\n# (3) BW = 20\nFS3 &lt;- update(\n  FS1,\n  data = BastenBetz %&gt;% filter(abs(bord) &lt;= 20)\n)\n\n# (4) Ges. Datensatz\nFS4 &lt;- update(\n  FS1,\n  data = BastenBetz\n)\n\n\n# Tabellarische Darstellung\nmodelsummary::modelsummary(\n  list(\"BW = OB\"= FS1, \n       \"BW = 10\" = FS2, \n       \"BW=20\" = FS3, \n       \"Ges. Datensatz\" = FS4), \n  vcov = \"HC1\", \n  stars = T, \n  gof_map = \"nobs\", \n  output = \"gt\"\n) %&gt;%\n  tabopts()\n\n\n\n\n\n\n\n  \n \n      BW = OB\n      BW = 10\n      BW=20\n      Ges. Datensatz\n    \n\n\n(Intercept)\n0.134***\n0.100***\n0.103***\n0.109***\n\n\n\n(0.017)\n(0.013)\n(0.010)\n(0.009)\n\n\nvaud\n0.671***\n0.726***\n0.756***\n0.710***\n\n\n\n(0.034)\n(0.022)\n(0.018)\n(0.014)\n\n\nbord\n0.017**\n0.001\n0.001\n0.002*\n\n\n\n(0.006)\n(0.003)\n(0.001)\n(0.001)\n\n\nvaud × bord\n-0.006\n-0.001\n-0.009***\n-0.004***\n\n\n\n(0.012)\n(0.005)\n(0.003)\n(0.001)\n\n\nNum.Obs.\n133\n207\n312\n509\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n    \n\nTabelle 2.4:  First-Stage Regressionen \n\n\n\nFür die geschätze Bandweite schätzen wir einen hochsignifikanten Sprung in prot von etwa 67% an der Kantonsgrenze. Auch für größere Bandweiten von 10km und 20km sowie für den gesamten Datensatz finden wir vergleichbare signifikante Effekte, was eine bei zunehmender Distanz zur Grenze persistente Diskrepanz der Religionszugehörigkeit bestätigt.\n\n2.4.4 Second-Stage-Ergebnisse\nWir schätzen nun den LATE von Protestantismus für die Outcome-Variablen gini, pfl, pfi und pfr, vgl. Tabelle 2.2. Die Spezifikation für die Second-Stage-Regression der FRDD-Schätzung ist \\[\\begin{align}\n  \\begin{split}\n    Y_i = \\gamma_0 + \\gamma_1 \\widehat{prot}_i +  \\gamma_2 bord_i + \\gamma_3 bord_i  \\times vaud_i + e_i\n  \\end{split},\n\\end{align}\\] wobei \\(\\widehat{prot}_i\\) angepasste Werte aus der KQ-Schätzung von \\(\\eqref{eq:BBFSR}\\) mit Bandweite OB sind. Dazu erzeugen wir zunächst eine angepasste Version des Objekts BastenBetz, welche nur Gemeinden innerhalb der Bandweite enthält.\n\nBastenBetz_OB &lt;- BastenBetz %&gt;% \n  filter(\n    abs(bord) &lt;= OB\n  )\n\nZur Illustration schätzen wir nun die Second-Stage-Regression für \\(Y = pfl\\).\n\nBastenBetz_OB %&gt;% \n  mutate(prot_fitted = fitted(FS1)) %&gt;%\n  \nlm(pfl ~ prot_fitted + bord + vaud:bord, data = .) %&gt;% \n  summary()\n\n\nCall:\nlm(formula = pfl ~ prot_fitted + bord + vaud:bord, data = .)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.8870  -3.8621  -0.0423   3.4993  12.1636 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  50.5275     1.9721  25.621  &lt; 2e-16 ***\nprot_fitted -13.4600     3.1749  -4.240 4.24e-05 ***\nbord          0.4380     0.6528   0.671    0.503    \nbord:vaud    -0.3636     0.7939  -0.458    0.648    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.433 on 129 degrees of freedom\nMultiple R-squared:  0.383, Adjusted R-squared:  0.3686 \nF-statistic: 26.69 on 3 and 129 DF,  p-value: 1.704e-13\n\n\nDer Koeffizient prot_fitted ist der gesuchte Behandlungseffekt. Beachte, dass die von summary() berechneten Standardfehler ungültig sind, weil diese die zusätzliche Unsicherheit durch die Berechnung von \\(\\widehat{prot}\\) über die First-Stage-Regression nicht berücksichtigen. Nachfolgend nutzen wir AER::ivreg(), um komfortabel gültige (heteroskedastie-robuste) Inferenz betreiben zu können.77 Die Autoren geben an, robuste SEs zu nutzen. Das scheint nicht der Fall zu sein, denn vcov = \"HC0\" liefert die Ergebinsse im Paper. Die von Stata berechneten HC1-SEs weichen ab. Dies ändert allerdings nichts an der Signifikanz der Koeffizienten. Wir nutzen vcov = \"HC1\".\n\n# Schätzung mit 2SlS\n# s. Tabelle 4 in Basten und Betz (2013)\n#\n# Wir instrumentieren Treatment (`prot1980s`) mit dem Schwellenindikator (`vaud`)\n# ivreg: exogene Variablen instrumentieren sich selbst, daher\n# ' | vaud * borderdis '\nlibrary(AER)\n# (1) Präferenz für Freizeit\nSS_pfl &lt;- ivreg(\n  formula = pfl ~ prot + bord:vaud + bord | vaud * bord,\n  data = BastenBetz_OB\n)\n\n# (2) Präferenz für Umverteilung\nSS_pfr &lt;- update(\n  SS_pfl,\n  formula = pfr ~ prot + bord:vaud + bord | vaud * bord,\n)\n\n# (3) Präferenz für Intervention\nSS_pfi &lt;- update(\n  SS_pfl,\n  formula = pfi ~ prot + bord:vaud + bord | vaud * bord,\n)\n\n# (4) Einkommensungleichheit\nSS_gini &lt;- update(\n  SS_pfl,\n  formula = pfi ~ prot + bord:vaud + bord | vaud * bord,\n)\n\n\n# Tabellarische Darstellung\nmodelsummary::modelsummary(\n  list(\"(1) Freizeit\"= SS_pfl, \n       \"(2) Umverteilung\" = SS_pfr, \n       \"(3) Intervention\" = SS_pfi, \n       \"(4) Ungleichheit\" = SS_gini), \n  vcov = \"HC1\", \n  stars = T, \n  gof_map = \"nobs\", \n  output = \"gt\"\n) %&gt;%\n  tabopts()\n\n\n\n\n\n\n\n  \n \n      (1) Freizeit\n      (2) Umverteilung\n      (3) Intervention\n      (4) Ungleichheit\n    \n\n\n(Intercept)\n50.528***\n44.560***\n52.871***\n52.871***\n\n\n\n(1.918)\n(0.950)\n(1.063)\n(1.063)\n\n\nprot\n-13.460***\n-5.061*\n-6.487***\n-6.487***\n\n\n\n(3.161)\n(2.161)\n(1.738)\n(1.738)\n\n\nbord\n0.438\n0.444\n-0.165\n-0.165\n\n\n\n(0.639)\n(0.357)\n(0.332)\n(0.332)\n\n\nbord × vaud\n-0.364\n-0.909\n0.011\n0.011\n\n\n\n(0.811)\n(0.561)\n(0.432)\n(0.432)\n\n\nNum.Obs.\n133\n133\n133\n133\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n    \n\nTabelle 2.5:  Ergebnisse der Second-Stage-Regressionen \n\n\n\nDie Koeffizienten von prot in Tabelle 2.5 sind die mit 2SLS ermittelten erwarteten Behandlungseffekte einer 100%-Reformation (d.h. von 100% katholisch zu 100% protestantisch) für eine durchschnittliche Gemeine nahe der Kantonsgrnze. Es handelt sich jeweils um einen lokalen durchschnittlichen Behandlungseffekt (LATE). Gem. der Definition der abhängigen Variablen, interpretieren wir die Koeffizienten von prot in de Regressionen (1), (2) und (3) als erwartete Prozentänderung durch Reformation. Der Koeffizient in Regression (4) gibt die erwartete Änderung des Gini-Index an. Sämtliche geschätzte Effekte sind signifikant und haben ein mit der Hypothese der Autoren konsistentes negatives Vorzeichen.\nDie Ergebnisse sind Evidenz, dass Protestantismus zu verringerter Präferenz für Freizeit, Umverteilung sowie wirtschaftspolitische Intervention seitens des Staats führt. Auch die ökonomische Ungleichheit ist signifikant geringer, als in einer durchschnittlichen vollständig katholischen Gemeinde.\n\n2.4.5 Addendum: FRDD-Schätzung mit rdrobust()\n\nDie Funktion rdrobust::rdrobust() erlaubt die Schätzung von SRDD und FRDD mit einer Vielzahl von Optionen, s. ?rdrobust. Dies erleichtert die Schätzung mehrerer Modellspezifikationenen und Bandweiten. Mit dem nachstehenden Befehl schätzen wir den LATE von Reformation auf die Präferenz für Umverteilung anhand lokaler quadratischer Regression. Der Output gibt einen Überblick der Bandweitenschätzung sowie der 2 Stufen des 2SLS-Schätzers, inkl. robuster Inferenzstatistiken.\n\npfr_rdr &lt;- rdrobust(\n  y = BastenBetz$pfr,\n  x = BastenBetz$bord,\n  fuzzy = BastenBetz$prot, \n  p = 2,\n  kernel = \"uniform\",\n  vce = \"HC1\"\n) \n\npfr_rdr %&gt;% \n  summary()\n\nFuzzy RD estimates using local polynomial regression.\n\nNumber of Obs.                  509\nBW type                       mserd\nKernel                      Uniform\nVCE method                      HC1\n\nNumber of Obs.                  127          382\nEff. Number of Obs.              85          131\nOrder est. (p)                    2            2\nOrder bias  (q)                   3            3\nBW est. (h)                  10.796       10.796\nBW bias (b)                  22.271       22.271\nrho (h/b)                     0.485        0.485\nUnique Obs.                      97          261\n\nFirst-stage estimates.\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     0.701     0.039    17.782     0.000     [0.624 , 0.778]     \n        Robust         -         -    15.837     0.000     [0.599 , 0.768]     \n=============================================================================\n\nTreatment effect estimates.\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional    -5.047     2.254    -2.239     0.025    [-9.464 , -0.629]    \n        Robust         -         -    -2.210     0.027   [-10.114 , -0.607]    \n=============================================================================\n\n\nAuch für die quadratische Spezifikation erhalten wir mit -5.047 ein vergleichbares signifikantes Ergebnis für den LATE von Protestantismus auf Umverteilung, vgl. Spalte (2) in Tabelle 2.5.\nMit der Option bwselect = \"msetwo\" kann die Bandweite jeweils für die lokale Regression links- und rechtssetig des Schwellenwerts geschätzt werden.\n\npfr_rdr %&gt;% \n  update(bwselect = \"msetwo\") %&gt;%\n  summary()\n\nFuzzy RD estimates using local polynomial regression.\n\nNumber of Obs.                  509\nBW type                      msetwo\nKernel                      Uniform\nVCE method                      HC1\n\nNumber of Obs.                  127          382\nEff. Number of Obs.              51          134\nOrder est. (p)                    2            2\nOrder bias  (q)                   3            3\nBW est. (h)                   5.340       11.387\nBW bias (b)                  13.917       22.330\nrho (h/b)                     0.384        0.510\nUnique Obs.                      97          261\n\nFirst-stage estimates.\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     0.649     0.046    14.216     0.000     [0.560 , 0.739]     \n        Robust         -         -    11.970     0.000     [0.534 , 0.743]     \n=============================================================================\n\nTreatment effect estimates.\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional    -7.487     3.378    -2.216     0.027   [-14.109 , -0.866]    \n        Robust         -         -    -2.156     0.031   [-14.750 , -0.704]    \n=============================================================================\n\n\nTrotz Diskrepanz der geschätzten Bandweiten erhalten wir eine größere aber vergleichbare Schätzung für einen negativen Effekt.\n\n\n\n\n\n\nBasten, Christoph, und Frank Betz. 2013. „Beyond work ethic: Religion, individual, and political preferences“. American Economic Journal: Economic Policy 5 (3): 67–91.\n\n\nGelman, Andrew, und Guido Imbens. 2019. „Why high-order polynomials should not be used in regression discontinuity designs“. Journal of Business & Economic Statistics 37 (3): 447–56.\n\n\nImbens, G. W., und Thomas Lemieux. 2008. „Regression discontinuity designs: A guide to practice“. Journal of econometrics 142 (2): 615–35.\n\n\nImbens, Guido, und Karthik Kalyanaraman. 2012. „Optimal bandwidth choice for the regression discontinuity estimator“. The Review of economic studies 79 (3): 933–59.\n\n\nLee, David S. 2008. „Randomized experiments from non-random selection in US House elections“. Journal of Econometrics 142 (2): 675–97.\n\n\nWeber, Max. 2004. Die protestantische Ethik und der Geist des Kapitalismus. Bd. 1614. CH Beck."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "\n3  Summary\n",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2\n\n\n \n            # What is the capital of Berlin? (**SC**)\n            \n            In this question you are asked a **very** difficult question. \n            \n            &gt; Do some research! \n            \n            - [x] Berlin\n                &gt; This is the correct answer. \n            - [ ] Stuttgart \n            - [ ] Cologne \n                &gt; Cologne is the fourth largest city. \n            - [ ] Düsseldorf \n            \n            # Please bring the following into order! \n            \n            Below you find the steps of the machine learning workflow. \n            Do you find the **correct order**? \n            \n            &gt; The model selection happens before the `final model evaluation`!\n            \n            1. Get the data \n            2. Explore the data \n            3. Train test split with `train_test_split()` \n            4. Feature engineering \n            5. Model selection \n            6. Model evaluation \n            7. Deployment \n            \n            # Welchen Wert hat `y`? \n            \n            ```r\n            y \n\n\n\n\n\n \n\n      \n         2  Regression Discontiniuty Designs\n                \n  \n  \n      \n        4  Demo"
  },
  {
    "objectID": "webrworking.html#background",
    "href": "webrworking.html#background",
    "title": "\n4  Demo\n",
    "section": "\n4.1 Background",
    "text": "4.1 Background\nThe purpose of this document is to explore how WebR can be embedded in a Quarto Document for the purposes of teaching R.\n\nWebR Website: https://docs.r-wasm.org/webr/latest/\n\nWebR GitHub: https://github.com/r-wasm/webr/"
  },
  {
    "objectID": "webrworking.html#setup",
    "href": "webrworking.html#setup",
    "title": "\n4  Demo\n",
    "section": "\n4.2 Setup",
    "text": "4.2 Setup\nSee the https://github.com/coatless-r-n-d/webR-quarto-demos for source."
  },
  {
    "objectID": "webrworking.html#exploration",
    "href": "webrworking.html#exploration",
    "title": "\n4  Demo\n",
    "section": "\n4.3 Exploration",
    "text": "4.3 Exploration\nNext, let’s look at a few features of the language\n\n4.3.1 Linear Regression\nWe’ll first start with the WebR team’s demo example or the statistician way of saying, “Hello world!”… Aka linear regression:\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n4.3.2 Retrieving prior objects\nEach WebR cell appears to be connected to each other. Thus, we can access the fit outcome:\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n4.3.3 Mixing active and non-active R code\nFor if-else statements, we have:\nif (...) {\n  # Statements for TRUE\n} else {\n  # Statements for FALSE\n}\n\n\n... denotes a condition (either TRUE or FALSE)\nIf TRUE, then run the statements inside {}\n\nElse, FALSE, carry on with your day.\n\nHow could we modify temperature to have the if statement print \"Hot!\"?\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n4.3.4 Summarize Data\nGlancing at data frames yields:\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n4.3.5 Errors and Warnings\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n4.3.6 Base graphics\nGraphing with base R\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\nMore advanced base R graphing…\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n4.3.7 ggplot2 Graphics\nNext, we look at using ggplot2 graphics. By default, the ggplot2 package is not available as it is dependency heavy.\n\n\nPackage installation for `ggplot2` given by `webr::install(\"ggplot2\")`\n\nDownloading webR package: cli\nDownloading webR package: glue\nDownloading webR package: gtable\nDownloading webR package: isoband\nDownloading webR package: rlang\nDownloading webR package: lifecycle\nDownloading webR package: MASS\nDownloading webR package: lattice\nDownloading webR package: nlme\nDownloading webR package: Matrix\nDownloading webR package: mgcv\nDownloading webR package: farver\nDownloading webR package: labeling\nDownloading webR package: colorspace\nDownloading webR package: munsell\nDownloading webR package: R6\nDownloading webR package: RColorBrewer\nDownloading webR package: viridisLite\nDownloading webR package: scales\nDownloading webR package: fansi\nDownloading webR package: magrittr\nDownloading webR package: utf8\nDownloading webR package: vctrs\nDownloading webR package: pillar\nDownloading webR package: pkgconfig\nDownloading webR package: tibble\nDownloading webR package: withr\nDownloading webR package: ggplot2\n\n\nR lädt. Etwas Geduld bitte…"
  },
  {
    "objectID": "webrworking_2.html#background",
    "href": "webrworking_2.html#background",
    "title": "\n5  Demo\n",
    "section": "\n5.1 Background",
    "text": "5.1 Background\nThe purpose of this document is to explore how WebR can be embedded in a Quarto Document for the purposes of teaching R.\n\nWebR Website: https://docs.r-wasm.org/webr/latest/\n\nWebR GitHub: https://github.com/r-wasm/webr/"
  },
  {
    "objectID": "webrworking_2.html#setup",
    "href": "webrworking_2.html#setup",
    "title": "\n5  Demo\n",
    "section": "\n5.2 Setup",
    "text": "5.2 Setup\nSee the https://github.com/coatless-r-n-d/webR-quarto-demos for source."
  },
  {
    "objectID": "webrworking_2.html#exploration",
    "href": "webrworking_2.html#exploration",
    "title": "\n5  Demo\n",
    "section": "\n5.3 Exploration",
    "text": "5.3 Exploration\nNext, let’s look at a few features of the language\n\n5.3.1 Linear Regression\nWe’ll first start with the WebR team’s demo example or the statistician way of saying, “Hello world!”… Aka linear regression:\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n5.3.2 Retrieving prior objects\nEach WebR cell appears to be connected to each other. Thus, we can access the fit outcome:\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n5.3.3 Mixing active and non-active R code\nFor if-else statements, we have:\nif (...) {\n  # Statements for TRUE\n} else {\n  # Statements for FALSE\n}\n\n\n... denotes a condition (either TRUE or FALSE)\nIf TRUE, then run the statements inside {}\n\nElse, FALSE, carry on with your day.\n\nHow could we modify temperature to have the if statement print \"Hot!\"?\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n5.3.4 Summarize Data\nGlancing at data frames yields:\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n5.3.5 Errors and Warnings\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n5.3.6 Base graphics\nGraphing with base R\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\nMore advanced base R graphing…\n\n\nR lädt. Etwas Geduld bitte…\n\n\n\n\n\n\n\n\n\n\n5.3.7 ggplot2 Graphics\nNext, we look at using ggplot2 graphics. By default, the ggplot2 package is not available as it is dependency heavy.\n\n\nPackage installation for `ggplot2` given by `webr::install(\"ggplot2\")`\n\nDownloading webR package: cli\nDownloading webR package: glue\nDownloading webR package: gtable\nDownloading webR package: isoband\nDownloading webR package: rlang\nDownloading webR package: lifecycle\nDownloading webR package: MASS\nDownloading webR package: lattice\nDownloading webR package: nlme\nDownloading webR package: Matrix\nDownloading webR package: mgcv\nDownloading webR package: farver\nDownloading webR package: labeling\nDownloading webR package: colorspace\nDownloading webR package: munsell\nDownloading webR package: R6\nDownloading webR package: RColorBrewer\nDownloading webR package: viridisLite\nDownloading webR package: scales\nDownloading webR package: fansi\nDownloading webR package: magrittr\nDownloading webR package: utf8\nDownloading webR package: vctrs\nDownloading webR package: pillar\nDownloading webR package: pkgconfig\nDownloading webR package: tibble\nDownloading webR package: withr\nDownloading webR package: ggplot2\n\n\nR lädt. Etwas Geduld bitte…"
  },
  {
    "objectID": "Literatur.html",
    "href": "Literatur.html",
    "title": "References",
    "section": "",
    "text": "Angrist, Joshua D, and Jörn-Steffen Pischke. 2010. “The\nCredibility Revolution in Empirical Economics: How Better Research\nDesign Is Taking the Con Out of Econometrics.” Journal of\nEconomic Perspectives 24 (2): 3–30.\n\n\nBasten, Christoph, and Frank Betz. 2013. “Beyond Work Ethic:\nReligion, Individual, and Political Preferences.” American\nEconomic Journal: Economic Policy 5 (3): 67–91.\n\n\nGelman, Andrew, and Guido Imbens. 2019. “Why High-Order\nPolynomials Should Not Be Used in Regression Discontinuity\nDesigns.” Journal of Business & Economic Statistics\n37 (3): 447–56.\n\n\nImbens, G. W., and Thomas Lemieux. 2008. “Regression Discontinuity\nDesigns: A Guide to Practice.” Journal of Econometrics\n142 (2): 615–35.\n\n\nImbens, Guido, and Karthik Kalyanaraman. 2012. “Optimal Bandwidth\nChoice for the Regression Discontinuity Estimator.” The\nReview of Economic Studies 79 (3): 933–59.\n\n\nLee, David S. 2008. “Randomized Experiments from Non-Random\nSelection in US House Elections.” Journal of\nEconometrics 142 (2): 675–97.\n\n\nWeber, Max. 2004. Die Protestantische Ethik Und Der Geist Des\nKapitalismus. Vol. 1614. CH Beck."
  },
  {
    "objectID": "RDD.html#manipulation-am-schwellenwert",
    "href": "RDD.html#manipulation-am-schwellenwert",
    "title": "\n2  Regression Discontiniuty Designs\n",
    "section": "\n2.2 Manipulation am Schwellenwert",
    "text": "2.2 Manipulation am Schwellenwert\nEine wichtige Annahmen für die Gültigkeit der RDD-Schätzung ist, dass keine Manipulation der Gruppenzugehörigkeit am Schwellenwert vorliegt. Wenn für Subjekte nahe des Schwellenwertes \\(c\\) – d.h. in Abhängigkeit der Laufvariable \\(X\\) – sich systematisch in den Confoundern \\(Z\\) unterscheiden, können wir den Backdoor-Pfad Oberhalb C → Behandlung B → Y nicht isolieren. Wir erhalten wir eine verzerrte Schätzung des Behandlungseffekts.\nBspw. kann in empirischen Studien mit Individuen Selbstselektion auftreten: Menschen mit \\(X&lt;c\\) aber nahe \\(c\\) (Kontrollgruppe) könnten aufgrund unbeobachtbarer Eigenschaften \\(Z\\) die Ausprägung ihrer Laufvariable zu \\(X&gt;c\\) (Behandlungsgruppe) manipulieren. Wenn \\(Z\\) die Outcome-Variable beeinflusst, bleibt der Backdoor-Pfad Oberhalb C → Behandlung B → Y dann bestehen.\nManipulation resultiert in Häufung von Beobachtungen am Schwellenwert. Dei Verteilung der Laufvariable kann auf diese Diese Unregelmäßigkeit hin untersucht werden. (McCrary2008?) schlägt hierfür einen Verfahren vor, das auf die Kontinuität der Dichtefunktion von \\(X\\) am Schwellenwert testet.\nDer Test von (McCrary2008?) ist in rdd::DCdensity() implementiert. wir Zeigen die Anwendung anhand der weiter oben simulierten Daten. Beachte, dass \\(X_i\\sim U(0, 10)\\), d.h. die Laufvariable ist bei \\(X_i = c\\) kontinuierlich verteilt: die Nullhypothese trifft für die simulierten Daten zu.\n\n# McCrary-Test durchführen\np_mccrary &lt;- rdd::DCdensity(\n  runvar = X, \n  cutpoint = c, \n  plot = F\n)\n\n# p-Wert\np_mccrary\n\n[1] 0.5013939\n\n\nDer p-Wert 0.5 ist größer als jedes übliche Signifikanzniveau und ist damit starke Evidenz für die Nullhypothese (keine Diskontinuität) und damit gegen Manipulation am Schwellenwert.\n(CJM2020?) (CMJ) schlagen eine Weiterentwicklung des McCrary-Tests vor, die höhere statistische Power gegenüber Diskontinuitäten hat. Der CJM-Test ist im Paket rddensity implementiert.\n\nlibrary(rddensity)\n# CJm Schätzer berechnen\nCJM &lt;- rddensity(X, c = 5)\n\nMit der Funktion rdplotdensity() erzeugen wir Abbildung 2.4.\n\n# plot erstellen\nplot &lt;- rdplotdensity(\n  CJM, \n  X = X, \n  type = \"both\" # Punkte- und Linienplots\n)\n\n\n\nAbbildung 2.4: CJM-Test – geschätzte Dichtefunktionen der Laufvariable\n\n\n\nDie Abbildung zeigt die geschätzten Dichtefunktionen. Erwartungsgemäß finden wir eine große Überlappung der zugehörigen Konfidenzbänder (schattierte Flächen) am Schwellenwert \\(c=5\\).\nMit summary() erhalten wir eine detalierte Zusammenfassung des Tests.\n\nsummary(CJM)\n\n\nManipulation testing using local polynomial density estimation.\n\nNumber of obs =       750\nModel =               unrestricted\nKernel =              triangular\nBW method =           estimated\nVCE method =          jackknife\n\nc = 5                 Left of c           Right of c          \nNumber of obs         329                 421                 \nEff. Number of obs    133                 154                 \nOrder est. (p)        2                   2                   \nOrder bias (q)        3                   3                   \nBW est. (h)           1.918               2.124               \n\nMethod                T                   P &gt; |T|             \nRobust                -0.3338             0.7385              \n\n\nP-values of binomial tests (H0: p=0.5).\n\nWindow Length              &lt;c     &gt;=c    P&gt;|T|\n0.346     + 0.346          20      21    1.0000\n0.521     + 0.544          34      37    0.8126\n0.696     + 0.742          44      57    0.2323\n0.870     + 0.939          54      64    0.4075\n1.045     + 1.137          62      77    0.2349\n1.220     + 1.334          73      98    0.0661\n1.394     + 1.532          86     106    0.1701\n1.569     + 1.729          96     124    0.0685\n1.743     + 1.927         119     140    0.2139\n1.918     + 2.124         133     154    0.2377\n\n\nGemäß des p-Werts (P &gt; |T|) von 0.7385 spricht der CJM-Test noch deutlicher gegen eine Diskontinuität als der McCrary-Test.\n\n2.2.1 Beispiel: Amtsinhaber-Vorteil (Lee 2008)\n\nLee (2008) untersucht den Einfluss des Amtsinhaber-Vorteils auf die Wahl von Mitgliedern des US-Repräsentantenhauses. In den meisten Wahlkreisen entfallen große Anteile der Stimmen (wenn nicht sogar ausschließlich) auf demokratische und repuplikanische Kanditat*innen, sodass sich die Studie auf diese Parteien beschränkt. Entfällt die Mehrheit der Stimmen auf eine*n Kandiat*in, gewinnt diese*r den Sitz für den Wahlkreis. Durch die Analyse der 6558 Wahlen im Zeitraum 1946-1998 mit einem SRDD kommt die Studie zu dem Ergebnis, dass Amtsinhabende im Durchschnitt einen Vorteil von etwa 8%-10% bei der Wahl haben. Dieses Ergebnis kann verschiedene Ursachen haben, bspw. dass die amtierende Partei höhere finanzielle Ressourcen besitzt und von einer besseren Organisation als die Opposition profitiert.\nAnhand der Datensätze house und house_binned illustrieren wir nachfolgend die Schätzung von SRDD-Modellen für den Wahlerfolg der demokratischen Partei, wenn diese Amtsinhaber ist. Wir lesen zunächst die Datensätze house und house_binned ein und verschaffen uns einen Überblick.\n\nlibrary(tidyverse)\nlibrary(modelsummary)\n\nhouse &lt;- read_csv(\"datasets/house.csv\")\nhouse_binned &lt;- read_csv(\"datasets/house_binned.csv\")\n\nglimpse(house)\n\nRows: 6,558\nColumns: 2\n$ StimmenTm1 &lt;dbl&gt; 0.1049, 0.1393, -0.0736, 0.0868, 0.3994, 0.1681, 0.2516, 0.…\n$ StimmenT   &lt;dbl&gt; 0.5810, 0.4611, 0.5434, 0.5846, 0.5803, 0.6244, 0.4873, 0.5…\n\nglimpse(house_binned)\n\nRows: 100\nColumns: 2\n$ StimmenT   &lt;dbl&gt; 0.5995600, 0.5657000, 0.4272554, 0.5637456, 0.6868627, 0.60…\n$ StimmenTm1 &lt;dbl&gt; 0.104764444, 0.135005263, -0.075690769, 0.084570886, 0.3951…\n\n\nDer Datensatz house enthält Stimmenanteile demokratischer Kandidat*innen bei der Wahl zum Zeitpunkt \\(T\\) (\\(StimmenT\\)) sowie die Differenz zwischen demokratischen und republikanischen Stimmenanteile bei der vorherigen Wahl, d.h. zum Zeitpunkt \\(T-1\\) (\\(StimmenTm1\\)). Der Schwellenwert für einen Wahlgewinn liegt bei Stimmengleichheit, d.h. \\(StimmenTm1 = 0\\).\nhouse_binned ist eine aggregierte Version von house mit Mittelwerten von jeweils 50 gleichgroßen Intervallen oberhalb und unterhalb der Schwelle von 0. Dieser Datensatz eignet sich, um einen ersten Eindruck des funktionalen Zusammenhangs auf beiden Seiten zu gewinnen. Wir stellen diese klassierten Daten mit ggplot2 graphisch dar.\n\nhouse_binned %&gt;%\n  ggplot(aes(x = StimmenTm1, y = StimmenT)) +\n  geom_point() +\n  geom_vline(xintercept = 0, lty = 2)\n\n\n\nAbbildung 2.5: Klassierte Daten aus Lee (2008)\n\n\n\nDie Grafik zeigt eindeutig einen Sprung von \\(StimmenT\\) bei \\(StimmenTm1 = 0\\). Weiterhin erkennen wir, dass der Zusammenhang nahe 0 vermutlich jeweils gut durch eine lineare Funktion approximiert werden kann. Eine Modell-Spezifikation mit gleicher Steigung auf beiden Seiten des Schwellenwertes könnte hingegen weniger gut geeignet sein. Wir vergleichen diese Spezifikationen nachfolgend.\nZunächst fügen wir dem Datensatz eine Dummyvariable B hinzu. Diese dient als Indikator für den Wahlgewinn in der letzten Wahl und zeigt Amtsinhaberschaft (“Behandlung”) an.\n\nhouse &lt;- house %&gt;% \n  mutate(B = StimmenTm1 &gt; 0)\n\nglimpse(house)\n\nRows: 6,558\nColumns: 3\n$ StimmenTm1 &lt;dbl&gt; 0.1049, 0.1393, -0.0736, 0.0868, 0.3994, 0.1681, 0.2516, 0.…\n$ StimmenT   &lt;dbl&gt; 0.5810, 0.4611, 0.5434, 0.5846, 0.5803, 0.6244, 0.4873, 0.5…\n$ B          &lt;lgl&gt; TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE…\n\n\nWir überprüfen die Laufvariable auf Manipulation am Schwellenwert \\(c=0\\).\n\n# CJM-Test\nCJM_Lee &lt;- rddensity(X = house$StimmenTm1)\nsummary(CJM_Lee)\n\n\nManipulation testing using local polynomial density estimation.\n\nNumber of obs =       6558\nModel =               unrestricted\nKernel =              triangular\nBW method =           estimated\nVCE method =          jackknife\n\nc = 0                 Left of c           Right of c          \nNumber of obs         2740                3818                \nEff. Number of obs    1297                1360                \nOrder est. (p)        2                   2                   \nOrder bias (q)        3                   3                   \nBW est. (h)           0.236               0.243               \n\nMethod                T                   P &gt; |T|             \nRobust                1.4346              0.1514              \n\n\nP-values of binomial tests (H0: p=0.5).\n\nWindow Length / 2          &lt;c     &gt;=c    P&gt;|T|\n0.004                      21      24    0.7660\n0.007                      38      46    0.4452\n0.011                      50      60    0.3909\n0.014                      73      77    0.8066\n0.018                      91     104    0.3902\n0.022                     124     132    0.6618\n0.025                     149     149    1.0000\n0.029                     163     174    0.5860\n0.032                     176     202    0.1984\n0.036                     197     223    0.2225\n\n\n\n# CJM-Plot\nplot &lt;- rdplotdensity(\n  CJM_Lee,\n  X = house$StimmenTm1, \n  type = \"both\", \n)\n\n\n\nAbbildung 2.6: CJM-Test – geschätzte Dichtefunktionen der Laufvariable\n\n\n\nAbbildung 2.6 und der p-Wert von \\(0.15\\) liefern Evidenz gegen Manipulation am Schwellenwert.\nUm den Behandlungseffekt im SRDD zu ermitteln, schätzen wir das Interaktionsmodell \\[\\begin{align*}\n  \\text{StimmenT}_i =&\\, \\beta_0 + \\beta_1 B_i + \\beta_2 (\\text{StimmenTm1}_i - 50)\\\\\n  +&\\, \\beta_3(\\text{StimmenTm1}_i - 50)\\times B_i + u_i\n\\end{align*}\\] zunächst bei einer Bandweite von \\(h = 0.5\\). Aufgrund der Skalierung der Daten bedeutet dies die Verwendung des gesamten Datensatzes für die Schätzung.\n\nhouse_llr1 &lt;- lm(\n  formula = StimmenT ~ B * StimmenTm1, \n  data = house\n)\n  \nmodelsummary(house_llr1, \n             vcov = \"HC1\", \n             stars = T, \n             gof_map = \"nobs\", \n             output = \"gt\") %&gt;% \n  tabopts\n\n\n\n\n\n\n \n      (1)\n    \n\n\n(Intercept)\n0.433***\n\n\n\n(0.004)\n\n\nBTRUE\n0.118***\n\n\n\n(0.006)\n\n\nStimmenTm1\n0.297***\n\n\n\n(0.016)\n\n\nBTRUE × StimmenTm1\n0.046*\n\n\n\n(0.018)\n\n\nNum.Obs.\n6558\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n    \n\n\n\n\nDer geschätzte Koeffizient von \\(B\\) (BTRUE) beträgt etwa 0.12 und ist hochsignifikant. Übereinstimmend mit Abbildung Abbildung 2.5 erhalten wir also eine positive Schätzung des Treatment-Effekts. Die Interpretation ist, dass die amtierende Demokraten bei der Wahl von einem Amtsinhabervorteil profitieren, der sich als Stimmenbonus von geschätzten 12% niederschlägt. Diese Schätzung könnte jedoch verzerrt sein:\n\nDie (implizite) Wahl von \\(h=0.5\\) in unserer Schätzung macht die Isolation des relevanten Frontdoor-Paths (\\(c=0\\) → Treatment → StimmenT) wenig plausibel. \\(h\\) sollte mit einer datengetriebenen Methode gewählt werden.\nWeiterhin könnte die lineare funktionale Form der Regression inadäquat sein: Die lineare Approximation nahe beim Schwellenwert 0 könnte nicht hinreichend gut sein und in einer verzerrten Schätzung des Effekts resultieren. Zur Überprüfung der Robustheit der Ergebnisse sollte mit Schätzungen nicht-linearer Spezifikationen verglichen werden.\n\nUm diesen Gefahren für die Validität der Studie zu begegnen, schätzen wir nun weitere Spezifikationen. Im Folgenden verwenden wir eine Bandweitenschätzung gemäß G. Imbens und Kalyanaraman (2012).\n\n# Bandweite mit Schätzer von IK (2012) berechnen\n(\nIK_BW &lt;- \n  rdd::IKbandwidth(\n    X = house$StimmenTm1, \n    Y = house$StimmenT\n  )\n)\n\n[1] 0.2685123\n\n\nWir schätzen zunächst erneut das lineare Interaktionsmodell, diesmal jedoch mit Bandweite IK_BW.\n\n# Lineares Interaktionsmodelle mit IK-Bandweite\nhouse_llin_IK &lt;- lm(\n  formula = StimmenT ~ B * StimmenTm1, \n  data = house %&gt;% \n    filter(abs(StimmenTm1) &lt;= IK_BW)\n)\n\nFür den Vergleich mit einer nicht-linearen Spezifikation schätzen wir auch ein quadratisches Interaktionsmodel.\n\n# Quadratisches Interaktionsmodell mit IK-Bandweite\nhouse_poly_IK &lt;- update(\n  house_llin_IK,\n  formula = StimmenT ~ B * poly(StimmenTm1, degree = 2, raw = T)\n)\n\nFür eine Gegenüberstellung der Modelle verwenden wir modelsummary::modelsummary().\n\n# Tabellarischer Modellvergleich\nmodelsummary(\n  list(\n    \"Linear int.\" = house_llin_IK, \n    \"Quadratisch int.\" = house_poly_IK\n  ),  \n  vcov = \"HC1\", \n  stars = T,\n  gof_map = \"nobs\", \n  output = \"gt\") %&gt;% \n    tabopts\n\n\n\n\n\n\n\n  \n \n      Linear int.\n      Quadratisch int.\n    \n\n\n(Intercept)\n0.450***\n0.460***\n\n\n\n(0.005)\n(0.008)\n\n\nBTRUE\n0.085***\n0.068***\n\n\n\n(0.008)\n(0.012)\n\n\nStimmenTm1\n0.360***\n\n\n\n\n(0.036)\n\n\n\nBTRUE × StimmenTm1\n0.055\n\n\n\n\n(0.059)\n\n\n\npoly(StimmenTm1, degree = 2, raw = T)1\n\n0.573***\n\n\n\n\n(0.138)\n\n\npoly(StimmenTm1, degree = 2, raw = T)2\n\n0.798\n\n\n\n\n(0.493)\n\n\nBTRUE × poly(StimmenTm1, degree = 2, raw = T)1\n\n0.036\n\n\n\n\n(0.219)\n\n\nBTRUE × poly(StimmenTm1, degree = 2, raw = T)2\n\n-1.529+\n\n\n\n\n(0.834)\n\n\nNum.Obs.\n2956\n2956\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n    \n\nTabelle 2.1:  Vergleich von SRDD-Interaktionsmodellen für Lee (2008) \n\n\n\nDie Spalte (1) in Tabelle 2.1 zeigt die lokale Schätzung mit einem linearen Interaktionsmodell. Wir erhalten damit einen Behandlungseffekt von etwa 8.5%. Der Schätzwert fällt also etwas geringer aus, als für die globale KQ-Schätzung des linearen Interaktionsmodells. Für das Modell (2) mit quadratischer Spezifikation liegt der Schätzwert in der gleichen Größenordnung, fällt jedoch mit 6.8% etwas geringer aus. Beide Schätzungen des Effekts sind signifikant von 0 verschieden. Weiterhin fällt auf, dass in beiden Modellen keine Evidenz verschiedene Spezifikationen der Regressionsfunktionen auf beiden Seiten des Schwellenwerts vorliegen: sämtliche Koeffizientenschätzwerte der Interaktionsterme haben hohe Standardfehler und sind nicht signifikant. Im quadratischen Modell hat auch der Term \\(StimmenTm1^2\\) keinen signifikanten Effekt. Diese Ergebnisse deuten darauf hin, dass eine lineare Spezifikation ausreichend ist.\nSRDD-Schätzung mit LOESS\nWir illustrieren nachfolgend die Schätzung des Behandlungseffekts mit einer flexiblen und in der Praxis häufig verwendeten Methode für lokale Regression. Die interaktive Grafik zeigt die klassierten Daten aus Lee (2008) auf dem Intervall \\([-0.5,0.5]\\) gemeinsam mit einer nicht-parametrischen Schätzung des Zusammenhangs von StimmenT und StimmenTm1 mittels LOESS.3 Diese Implementierung von lokaler Regression nutzt einen tricube kernel. Über den Input kann eine Bandweite \\(l\\in(0,1]\\) für den LOESS-Schätzer auf beiden Seiten des Schwellenwerts 0 gewählt werden. Die Bandweite ist hier der Anteil der Beobachtungen an der gesamten Anzahl an Beobachtungen, die in die Schätzung einbezogen werden sollen. Für die Schätzung am Schwellenwert berücksichtigte Daten werden orange kenntlich gemacht. Die rote linie zeigt die geschätzte Regressionsfunktion über gleichmäßig verteilte Werte von StimmenTm1 auf \\([-0.5,0.5]\\). Die Grafik verdeutlicht, das die LOESS-Methode flexibel genug ist, lineare und nicht-lineare Zusammenhänge abbilden zu können. Wie zuvor ist eine adäquate Wahl der Bandweite wichtig:3 LOESS ist eine Variante von lokaler Polynom-Regression.\n\nDer mit LOESS geschätzte Zusammenhang auf beiden Seiten des Schwellenwerts ist etwa linear für den voreingestellten Parameter (\\(l = 0.28\\)).\nFür größere Werte von \\(l\\) nähert sich die Schätzung weiter einem linearen Verlauf an. Die Schätzung des Effekts bleibt vergleichbar mit den Ergebnissen des linearen Interaktionsmodell (s. oben).\nFür kleinere \\(l\\) erhalten wir eine stärkere Anpassung der Schätzung an die Daten. Zu kleine Werte führen zu einer Überanpassung (overfitting). Insbesondere tendiert die geschätzte Funktion zu extremer Steigung nahe des Schwellenwerts → stark verzerrte Schätzung des Effekts!\n\n\nhtml`\n&lt;style&gt;\n.regression {\n  fill: none;\n  stroke: #000;\n  stroke-width: 1.5px;\n}\n.axis line {\n  stroke: #ddd;\n}\n.axis .baseline line {\n  stroke: #555;\n}\n.axis .domain {\n  display: none;\n} \n&lt;/style&gt;\n&lt;link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css\"&gt;\n`\n\n\n\n\n\n\n\nviewof bandwidth = Inputs.range([.01, 1], {\n  label: \"Bandweite LOESS (l)\",\n  step: .01,\n  value: .28\n});\n\nxScaleLoess = d3.scaleLinear()\n   .domain([-.55, .55])\n   .range([0, innerWidth]);\n   \nyScaleLoess = d3.scaleLinear()\n  .domain([.2, .8])\n  .range([innerHeight, 0]);\n\nlineLoess = d3.line()\n  .x(d =&gt; xScaleLoess(d[0]))\n  .y(d =&gt; yScaleLoess(d[1]));\n  \nxAxisLoess = d3.axisBottom(xScaleLoess)\n  .tickSize(innerHeight + 10)\n  .tickValues([-.5, -.25, 0, .25, .5])\n  .tickFormat(d =&gt; d);\n\nyAxisLoess = d3.axisLeft(yScaleLoess)\n  .tickSize(innerWidth + 10)\n  .tickValues([.2, .35, .5, .65, .8])\n  .tickFormat(d =&gt; d);\n\nloessRegression = d3.regressionLoess()\n  .x(d =&gt; d.StimmenTm1)\n  .y(d =&gt; d.StimmenT)\n  .bandwidth(bandwidth);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  const svg = d3.select(DOM.svg(innerWidth + margin.left + margin.right + 20, innerHeight + margin.top + margin.bottom + 20))\n  \n  const g = svg.append(\"g\")\n      .attr(\"transform\", `translate(${margin.left}, ${margin.top})`);\n\n  g.append(\"g\")\n      .attr(\"class\", \"axis\")\n      .call(xAxisLoess);\n\n  g.append(\"g\")\n    .attr(\"class\", \"axis\")\n    .attr(\"transform\", `translate(${innerWidth})`)\n    .call(yAxisLoess);\n\n  // Add X axis label:\n  g.append(\"text\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"font-size\", 13)\n    .attr(\"x\", innerWidth)\n    .attr(\"y\", innerHeight + margin.top + 25)\n    .text(\"Differenz Stimmenanteil Demokraten letzte Wahl zur 50%-Schwelle\");\n\n  // Y axis label:\n  g.append(\"text\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"transform\", \"rotate(-90)\")\n    .attr(\"font-size\", 13)\n    .attr(\"y\", -margin.left+10)\n    .attr(\"x\", -margin.top+10)\n    .text(\"Stimmenanteil Demokraten\");\n\n  g.selectAll(\"circle\")\n    .data(transpose(house_binned))\n    .enter().append(\"circle\")\n    .attr(\"r\", 2)\n    .attr(\"cx\", d =&gt; xScaleLoess(d.StimmenTm1))\n    .attr(\"cy\", d =&gt; yScaleLoess(d.StimmenT));\n\n  g.selectAll(\"circle\")\n   .filter( function(d){ return Math.abs(d.StimmenTm1) &lt;= bandwidth/2 } )\n   .attr(\"fill\", \"orange\")\n   .attr(\"stroke\", \"none\");\n\nfunction b(d) { return loessRegression(\n        transpose(house).filter(function(d){ return d.StimmenTm1 &lt;= 0 & d.StimmenTm1 &gt;= -.5 })\n    ); }\n\nfunction a(d) { return loessRegression(\n      transpose(house).filter(function(d){ return d.StimmenTm1 &gt; 0 & d.StimmenTm1 &lt;= .5  })\n    ); }\n\n  g.append(\"path\")\n      .attr(\"class\", \"regression\")\n      .datum(b)\n      .attr(\"d\", lineLoess)\n      .style(\"stroke\", \"red\");\n\n  g.append(\"path\")\n      .attr(\"class\", \"regression\")\n      .datum(a)\n      .attr(\"d\", lineLoess)\n      .style(\"stroke\", \"red\");\n  \n  g.append(\"text\")\n    .attr(\"x\", d =&gt; xScaleLoess(-.24))\n    .attr(\"y\", d =&gt; yScaleLoess(.55))\n    .attr(\"dy\", \".35em\")\n    .attr(\"fill\", \"#39FF14\")\n    .text(d3.format(\",.2f\")((a().slice(0))[0][1] - (b().slice(-1))[0][1]));\n  \n  g.append(\"line\")\n  .attr(\"x1\", xScaleLoess(0))\n  .attr(\"y1\", yScaleLoess((b().slice(-1))[0][1]))\n  .attr(\"x2\", xScaleLoess(0))\n  .attr(\"y2\", yScaleLoess((a().slice(0))[0][1]))\n  .attr(\"stroke\", \"#39FF14\")\n  .attr(\"stroke-width\", 2);\n  \n  /* dashed line at cutoff */\n  g.append(\"line\")\n  .attr(\"x1\", xScaleLoess(0))\n  .attr(\"y1\", 0)\n  .attr(\"x2\", xScaleLoess(0))\n  .attr(\"y2\", innerHeight)\n  .style(\"stroke\", \"black\")\n  .style(\"stroke-dasharray\", \"1\")\n  .style(\"stroke-width\", \"1\");\n  \n  /* dashed line data bw upper */\n  g.append(\"line\")\n  .attr(\"x1\", xScaleLoess(bandwidth/2))\n  .attr(\"y1\", 0)\n  .attr(\"x2\", xScaleLoess(bandwidth/2))\n  .attr(\"y2\", innerHeight)\n  .style(\"stroke\", \"blue\")\n  .style(\"stroke-dasharray\", \"4\")\n  .style(\"stroke-width\", \"1\");\n  \n  /* dashed line data bw lower */\n  g.append(\"line\")\n  .attr(\"x1\", xScaleLoess(-bandwidth/2))\n  .attr(\"y1\", 0)\n  .attr(\"x2\", xScaleLoess(-bandwidth/2))\n  .attr(\"y2\", innerHeight)\n  .style(\"stroke\", \"blue\")\n  .style(\"stroke-dasharray\", \"4\")\n  .style(\"stroke-width\", \"1\");\n\n  return svg.node();\n}\n\n\n\n\nAbbildung 2.7: Nicht-parametrische Regression auf beiden Seiten des Cut-offs."
  }
]