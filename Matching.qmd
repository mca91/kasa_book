---
webr: 
  show-startup-message: true
  packages: [
            'boot', 
            'cobalt', 
            'dplyr',
            'ggplot2',
            'marginaleffects', 
            'MatchIt', 
            'sandwich',
            'tidyr'
            ]
---

```{=html}
<style>
.qwebr-code-output-stdout {background-color: powderblue;}

.qwebr-button-run, .qwebr-button-reset, .qwebr-button-copy {
  background-color:  rgba(0, 0, 0, 0);
  border-style: none;
  font-weight: 400;
  color: white; 
  transition: none;
}

.qwebr-editor-toolbar {
  width: 100%;
  display: flex;
  justify-content: space-between;
  box-sizing: border-box;
  border-radius: 0 0 6px 6px;
  background-color: darkgreen;
  border-color: darkgreen;
  border-width: 1px;
  border-style: solid;
  padding: 0 0; 
  transition: color .1s ease-in-out, background-color .1s ease-in-out,border-color .1s ease-in-out,box-shadow .1s ease-in-out;
}

.qwebr-editor-toolbar:hover {
  background-color: white;
  border-color: darkgreen;
  border-width: 1px;
}

.qwebr-editor-toolbar:hover * {
  color: darkgreen;
}

.overflow-guard, .qwebr-editor, .monaco-editor {
  border-radius: 6px 6px 0 0;
  border-width: 1px 1px 0 1px;
  border-color: darkgreen;
}

</style>
```

# Matching

```{r, echo=F, message=FALSE}
library(gt)
library(tidyverse)
# Formatierung von gt-Tabellen
tabopts <- function(x) {
    fmt_number(x, decimals = 3, drop_trailing_zeros = T) %>%
  tab_options(table_body.hlines.color = "white", 
              column_labels.border.bottom.color = "black", 
             column_labels.border.top.color = "black",
             table_body.border.bottom.color = "black", 
             table.border.bottom.color = "black",
             column_labels.font.weight = "bold", 
             table.font.color = "black", 
             table.font.size = 16)
}
```

```{webr-r}
#| context: setup
# create dataset directory
dir.create("datasets")
# Download the dataset
download.file(
    "https://raw.githubusercontent.com/mca91/kausal_data/main/darkmode.csv",
    'datasets/darkmode.csv',
)
```

```{webr-r}
#| context: setup
library(dplyr)
# make darkmode available using read.csv for now
# because there's some issue with readr::read_csv
# I can't fix right now
darkmode <- read.csv(
    file = "datasets/darkmode.csv", 
    colClasses = c("numeric", "logical", "numeric", "numeric", "numeric") 
)

options(pillar.bold = TRUE, pillar.subtle = FALSE)
```

In randomisierten kontrollierten Studien stellt eine randomisierte Behandlung sicher, dass die Individuen beider Gruppen im Mittel vergleichbar sind, dass heißt es gibt keine systematischen Unterschiede der Studiensubjekte hinsichtlich der Verteilung von Charakteristika zwischen den Gruppen. Dann ist es plausibel eine beobachtete mittlere Differenz in der Outcome-Variable alleine auf die Behandlung zurückzuführen.

In der Praxis, insbesondere in ökonomischen Studien, sind randomisierte kontrollierte Studien aus ethischen und/oder finanziellen Gründen nicht durchführbar. Stattdessen werden nicht-experimentelle Daten genutzt, die jedoch nur sehr selten eine Vergleichbarkeit von Behandlungs- und Kontrollgruppe gewährleisten.

In diesem Kapitel betrachten wir Methoden, die in solchen Forschungsdesigns -- bei hinreichenden Informationen über die Studiensubjekte -- eine Schätzung kausaler Effekte ermöglichen, indem eine statistische Vergleichbarkeit von Behandlungs- und Kontrollgruppe hergestellt wird. Dies kann durch eine gezielte Gewichtung von Beobachtungen anhand invididueller Merkmale bei der Schätzung des Behandlungseffekts erfolgen. Andere etablierte Methoden schätzen den kausalen Effekt nach Selektion von vergleichbaren Teilmengen von Subjekten beider Gruppen aus der ursprünglichen Stichprobe, sogenanntes *Matching*.

Da *Matching* ähnliche Beobachtungen basierend auf beobachtbaren Merkmalen vergleicht, kann die Wahrscheinlichkeit einer verzerrten Schätzung des kausalen Effekt durch falsche Modellspezifikationen geringer sein als für eine Schätzung des Effekts anhand multipler Regression. Weiterhin basieren Matching-Methoden nicht auf der Annahme eines linearen Zusammenhangs zwischen Kovariablen und der erklärenden Variable und können für die Schätzung unterschiedlicher Spezifikationen von Behandlungseffekten herangezogen werden.

Für die Gültigkeit eines Schätzers basierend auf *Matching* sind zwei Annahmen erforderlich.

1.  ***Bedingte Unabhängigkeit.*** Seien $Y^{(0)}_i$ und $Y^{(1)}_i$ potentielle Ergebnisse der Outcome-Variable $Y$ für ein Subjekt $i$ mit $B_i=0$ (keine Zuweisung zur Behandlung) beziehungsweise $B_i=1$ (Behandlung) und $X_i$ die beobachteten Kovariablen. Wir nehmen an, dass \begin{align}
      \left\{Y^{(0)}_i, Y^{(1)}_i\right\} \perp B_i\vert X_i, \label{eq:cia}
    \end{align} d.h. die Behandlungszuweisung/-selektion ist unanabhängig von den potentielle Ergebnissen $Y^{(0)}_i$ und $Y^{(1)}_i$, wenn wir für die Kovariablen $X$ kontrollieren.

2.  ***Überlappung.*** Für jede mögliche Kombination von Kovariablen $X_i$ gibt es eine positive Wahrscheinlichkeit $<1$, sowohl zur Behandlungsgruppe ($B_i = 1$) als auch zur Kontrollgruppe ($B_i = 0$) zugewiesen zu werden, \begin{align}
      0 < \text{P}(B_i=1\lvert X_i) < 1, \label{eq:overlap}
    \end{align} d.h. keine Beobachtung hat eine Behandlungswahrscheinlichkeit von exakt $0$ oder $1$.

Annahme 1 stellt sicher, dass die Zuweisung zur Behandlungsgruppe nach Kontrolle für die Kovariablen $X$ als zufällig betracht werden kann. Somit ist es möglich den kausalen Effekt der Behandlung zu identifizieren, indem wir hinsichtlich der Kovariablen $X$ ähnliche Subjekte (vgl. Annahme 2) aus Kontroll- und Behandlungsgruppe vergleichen.

Annahme 2 setzt vorraus, dass es eine ausreichende Überlappung in den Verteilungen der Kovariablen zwischen Behandlungs- und Kontrollgruppe gibt. Dann ist sichergestellt, dass für jedes Subjekt in einer Gruppe ein hinsichtlich seiner Charakteristika vergleichbares Subjekt in der anderen Gruppe geben kann, sodass ein Vergleich möglich ist.

## *Balance*: Vergleichbarkeit von Behandlungs- und Kontrollgruppe {#sec-balance}

Der Lehrstuhl für Ökonometrie an der Universität Duisburg-Essen betreibt einen Ökonometrie-Blog und interessiert sich für den kausalen Effekt der Einführung eines [darkmode](https://en.wikipedia.org/wiki/Wikipedia:Dark_mode) auf die Verweildauer der User auf der Webseite. Die Webseite ist zwar nicht-kommerziell, hat sich allerdings insb. für die Aquise internationaler Studierender für den Studiengang MSc. Econometrics als wichtiges Marketing-Instrument erwiesen. Ein anprechendes Design wird daher als hoch-relevant erachtet.

Idealerweise sollte der Effekt des Design-Relaunches auf die Nutzungsintensität in einem kontrollierten randomisierten Experiment untersucht werden. Hierbei würden wir Nutzern zufällig das neue oder das alte Design zuweisen und den Effekt als Differnz des durchschnittlichen Verweildauer für die Gruppen bestimmen. Eine solche Studie ist jedoch aus technischen und finanziellen Gründen nicht realisierbar, sodass die Auswirkungen des darkmode mit vorliegenden nicht-experimenellen Nutzungsstatistiken für die Webseite geschätzt werden sollen.

Die Nutzungsstatistiken sind im Datensatz [*darkmode.csv*](https://raw.githubusercontent.com/mca91/kasa_data/main/darkmode.csv) enthalten und sollen der Analyse des Effekts des darkmode (`dark_mode`) auf die Verweildauer der Leser auf der Webseite (`read_time`) dienen.

@tbl-darkmode zeigt die Definitionen der Variablen in *darkmode.csv*.

```{r, echo = F}
#| tbl-cap: "Variablen im Datensatz *darkmode*"
#| label: tbl-darkmode
tibble(
  Variable = c(
    "read_time", 
    "dark_mode", 
    "male", 
    "age", 
    "hours"
    ),
  Beschreibung = c(
    "Lesezeit (Minuten/Woche)",
    "Indikator: Beobachtung nach Einführung darkmode",
    "Indikator: Individuum männlich",
    "Alter (in Jahren)",
    "Bisherige Verweildauer auf der Seite"
  )
) %>%
  gt() %>%
  tabopts
```

Für die Analyse lesen wir zunächst den Datensatz *darkmode.csv* mit `readr::read_csv()` ein und verschaffen uns einen Überblick über die verfügbaren Variablen.

```{r, message=FALSE}
# Paket `tidyverse` laden
library(tidyverse)

# Datensatz 'darkmode' einlesen
darkmode <- read_csv(
  file = "datasets/darkmode.csv"
)
```

`dark_mode` hat den Typ `logical`. Mit `dplyr::mutate_all()` können wir komfortabel alle Spalten in den Typ `numeric` transformieren.

```{r}
# Alle Variablen zu typ 'numeric' formatieren...
darkmode <- darkmode %>% 
  mutate_all(.funs = as.numeric)

# ... und überprüfen
glimpse(darkmode)
```

Eine naive Schätzung des durchschnittlichen Behandlungseffekts (ATE) $\widehat{\tau}^{\text{naiv}}$ erhalten wir als Mittelwertdifferenz von `read_time` für die Behandlungsgruppe (`dark_mode == 1`) und die Kontrollgruppe (`dark_mode == 0`) \begin{align}
  \widehat{\tau}^{\text{naiv}} = \overline{\text{read\_time}}_{\text{Behandlung}} - \overline{\text{read\_time}}_{\text{Kontrolle}}.\label{eq:naivATEdarkmode}
\end{align}

Diese Berechnung ist schnell mit R durchgeführt.

```{r}
# Naiver Schätzer für ATE: 
# Differenz der Gruppen-Durchschnitte

# Outcome in Behandlungsgruppe
read_time_mTG <- darkmode %>% 
  filter(dark_mode == 1) %>% 
  pull("read_time")

# Outcome in Kontrollgruppe
read_time_mKG <- darkmode %>% 
  filter(dark_mode == 0) %>% 
  pull("read_time")

# Mittelwert-Differenz
mean(read_time_mTG) - mean(read_time_mKG)
```

Die Schätzung ergibt einen negativen Behandlungseffekt, mit der Interpreation, dass das neue Design zu einer Reduktion der Lesezeit um etwa 0.44 Minuten pro Woche führt. Dieses Ergebnis ist allerdings zweifelhaft, weil eine Isolierung des Behandlungseffekts aufgrund von Backdoor-Pfaden im DGP vermutlich nicht gewähleistet ist. Ein Indikator hierfür sind systematische Unterschiede hinsichtlich von (möglicherweise unbeobachtbaren) Charakteristika von Kontrollgruppe und Behandlungsgruppe.

Da die User sich beim Aufrufen der Seite aktiv für oder gegen den das neue Design entscheiden müssen (und somit selektieren, ob Sie in der Behandlungs- oder Kontrollgruppe landen), liegt wahrscheinlich *Confounding* vor: Unsere Hypothese ist zunächst, dass männliche User eine durchschnittlich längere Lesezeit aufweisen *und* mit größerer Wahrscheinlichkeit auf das neue Design wechseln als nicht-männliche Leser. Dann ist `male` eine Backdoor-Variable. Diese Situation ist unter der Annahme, dass nur diese Faktoren den DGP bestimmen, in @fig-maleCDdarkmode dargestellt.

```{dot}
//| fig-width: 4
//| fig-height: 3
//| fig-align: 'center'
//| fig-cap: "Backdoor durch 'male' im Website-Design-Bespiel"
//| label: "fig-maleCDdarkmode" 
digraph {
  layout=neato
  fontname="Helvetica,Arial,sans-serif"
  node [fontname="Helvetica,Arial,sans-serif"]
  edge [fontname="Helvetica,Arial,sans-serif"]
  node [shape=none];
  "read_time" [pos="4,0.5!"]
  "dark_mode" [pos="0,0.5!"]
  "male" [pos="2,-1!"]
  "dark_mode" -> "read_time" [color="green"]
  "male" -> "dark_mode" [color="red"]
  "male" -> "read_time" [color="red"]
}
```

Der DGP in @fig-maleCDdarkmode führt zu einer verzerrten Schätzung des kausalen Effekts von `dark_mode` auf `read_time` mit \eqref{eq:naivATEdarkmode}, wenn das Verhältnis von männlichen und nicht-männlichen Usern in Bahandlungs- und Kontrollgruppe nicht ausgeglichen ist. Wir überprüfen dies mit R.

```{r}
# Anteile männlicher und nicht-männlicher User
(
  anteile <- darkmode %>% 
  group_by(dark_mode) %>% 
  summarise(
    gesamt = n(),
    ant_m = mean(male),
    ant_nm = 1 - ant_m,
    anz_m = sum(male),
    anz_nm = gesamt - anz_m
    )
)
```

Die Zusammenfassung `anteile_m` zeigt, dass der Anteil männlicher User in der Behandlungsgruppe deutlich höher ist als in der Kontrollgruppe.

### Matching durch Gewichtung

Matching eliminiert die Variation von `male` zwischen den Gruppen. Eine Möglichkeit hierfür ist die Gewichtung der Beobachtungen in der Kontrollgruppe entsprechend der Anteile von Männern und Nicht-Männern in der Behandlungsgruppe, sodass die Vergleichbarkeit mit der Behandlungsgruppe hinsichtlich des Geschlechts gewährleistet ist. Dies wird in der Literatur als *Balance* bezeichnet. Der Behandlungseffekt wird dann analog zu \eqref{eq:naivATEdarkmode} geschätzt.

Die Gewichte für Beobachtungen in der Kontrollgruppe $w_i$ werden berechnet als \begin{align}
  w_i = 
  \begin{cases}
    \text{ant\_m}_B/\text{anz\_m}_{K}, & \text{falls } \text{male}_i = 1\\
        \text{ant\_nm}_B/\text{anz\_nm}_{K}, & \text{sonst.}\\
  \end{cases}\label{eq:darkmodeweights}
\end{align} Anhand der Formel für einen gewichteten Durchschnitt, \begin{align}
  \overline{X}_w = \frac{\sum_i w_i \cdot X_i}{\sum_i w_i},
\end{align} berechnen wir die gewichteten Mittelwerte für `male` und `read_time` in der Kontrollgruppe.

```{r}
# Anteile und Anzahlen aus `anteile` auslesen
anz_m_K <- anteile %>% 
  filter(dark_mode == 0) %>% pull(anz_m)

anz_nm_K <- anteile %>% 
  filter(dark_mode == 0) %>% pull(anz_nm)

ant_m_B <- anteile %>% 
  filter(dark_mode == 1) %>% pull(ant_m)

ant_nm_B <- anteile %>% 
  filter(dark_mode == 1) %>% pull(ant_nm)
```

```{r}
# Gewichtete Mittel für Kontrollgruppe berechnen
(
gew_K <- darkmode %>% 
  filter(dark_mode == 0) %>% 
  select(read_time, male) %>%
  mutate(w = ifelse(
    male == 1, 
    ant_m_B/anz_m_K, 
    ant_nm_B/anz_nm_K)
    ) %>%
  summarise(
    male_k = sum(male * w) / sum(w),
    mean_read_time_wK = sum(read_time * w) / sum(w)
  )
)
```

Ein Vergleich des gewichteten Mittelwertes von `male` in der Kontrollgruppe mit dem Mittelwert in der Behandlungsgruppe (`male_k`) zeigt, dass die Gewichte die Variation in `male` zwischen beiden Gruppen eliminieren, sodass die Backdoor durch `male` geschlossen ist. Mit `wmean_read_time_K` haben wir einen entsprechend gewichteten Mittelwert der Verweildauer für die Kontrollgruppe berechnet. Wir schätzen den Behandlungseffekt nun als \begin{align}
  \widehat{\tau}^{\text{w}} = \overline{\text{read\_time}}_{B} - \overline{\text{read\_time}}_{w,K}.\label{eq:weightedATEdarkmode}
\end{align}

```{r}
mean(read_time_mTG)  - gew_K$mean_read_time_wK
```

Entgegen der naiven Schätzung andhand von \eqref{eq:naivATEdarkmode} erhalten wir nach Matching für `male` eine positive Schätzung des Behandlungseffekts von etwa $`r round(mean(read_time_mTG) - gew_K$mean_read_time_wK, 2)`$.

Die Schätzung des Behandlungseffekts anhand von \eqref{eq:weightedATEdarkmode} entspricht dem geschätzten Koeffizienten $\widehat{\beta}_1$ aus einer gewichteten KQ-Regression im Modell \begin{align*}
  \text{read\_time} = \beta_0 + \beta_1 \text{dark\_mode} + u,
\end{align*} 
wobei die Beobachtungen der Kontrollgruppe wie in \eqref{eq:darkmodeweights} gewichtet werden und $w_i=1$ für Beobachtungen der Behandlungsgruppe ist. Wir überprüfen dies mit R.

```{r}
darkmode_w <- darkmode %>% 
  mutate(
    w = case_when(
      male == 1 & dark_mode == 0 ~ ant_m_B/anz_m_K,
      male == 0 & dark_mode == 0 ~ ant_nm_B/anz_nm_K,
      T ~ 1
    )
  ) 

lm(read_time ~ dark_mode, weights = w, data = darkmode_w) %>%
  summary()
```

Der geschätzte Koeffizient von `dark_mode` entspricht $\widehat{\tau}^w$.

Da `male` eine binäre Variable ist, reduziert sich eine Beurteilung der Vergleichbarkeit der Verteilungen von `male` in Behandlungs- und Kontrollgruppe auf einen simplen Vergleich des Männeranteils beider Gruppen. In der Praxis gibt es meist eine Vielzahl potentieller Backdoor-Variablen, die zudem kontinuierlich verteilt sind. Es scheint plausibel, dass das Alter der Nutzer sowohl die Akzeptanz des Design-Updates als auch die Lesezeit beeinflusst. Die bisherige Verweildauer ist mindestens eine plausible Determinante der Lesezeit.

Der erweiterte DGP ist in Abbildung @fig-CDdarkmode dargestellt, wobei der zusätzliche Backdoor-Pfad durch `age` ebenfalls mit roten Pfeilen gekennzeichnet sind.

```{dot}
//| fig-width: 4
//| fig-height: 3
//| fig-align: 'center'
//| fig-cap: "Erweiterter DGP im Website-Design-Beispiel"
//| label: "fig-CDdarkmode" 
digraph {
  layout=neato
  fontname="Helvetica,Arial,sans-serif"
  node [fontname="Helvetica,Arial,sans-serif"]
  edge [fontname="Helvetica,Arial,sans-serif"]
  node [shape=none];
  "read_time" [pos="4,0.5!"]
  "dark_mode" [pos="0,0.5!"]
  "male" [pos="2,-1!"]
  "age" [pos="2,2!"]
  "hours" [pos="4,2!"]
  "hours" -> "read_time"
  "age" -> "dark_mode" [color="red"]
  "age" -> "read_time" [color="red"]
  "dark_mode" -> "read_time" [color="green"]
  "male" -> "dark_mode" [color="red"]
  "male" -> "read_time" [color="red"]
}
```

Die Beurteilung der *Balance* von Kontrollgruppe und Behandlungsgruppe kann durch eine grafische Gegenüberstellung der empirischen Verteilungen der Kovariablen beider Gruppen erfolgen. Wir visualisieren die empirischen Verteilungen mit `ggplot2`. Hierzu standardisieren wir `age` und `hours` zunächst mit `scale()`.

```{r}
# Datensatz für graphische Darstellung formatieren
darkmode_p <- darkmode %>% 
  # Standardisierung mit 'scale()'
  mutate(
    dark_mode = as_factor(dark_mode),
    age = scale(age), 
    hours = scale(hours)
  )

head(darkmode_p)
```

Für `age` und `hours` eignen sich die geschätzten Dichtefunktionen für einen Vergleich der Verteilungen in Behandlungs- und Kontrollgruppe.

```{r}
# Vergleich mit Dichteschätzungen
darkmode_p %>%
  select(dark_mode, hours, age) %>%
  # in langes Format überführen
  pivot_longer(cols = c(-dark_mode)) %>%
  
  ggplot(
    aes(x = value, fill = dark_mode)
    ) +
  geom_density(alpha = .5) + 
  facet_wrap(
    facets = ~ name, 
    scales = "free", 
    nrow = 2
    )
```

Die graphische Analyse zeigt deutliche Unterschiede in den Verteilungen von `age` zwischen Kontroll- und Behandlungsgruppe. Für einen Beurteilung mit deskriptiven Statistiken wird häufig eine sogenannte *Balance Table* herangezogen. Wir berechnen diese für `age`, `hours` und `male` mit `cobalt::bal.tab()`

```{r}
library(cobalt)

# Balance table mit 'cobalt::bal.tab()'
bal.tab(
  x = darkmode %>% 
    select(age, hours, male), 
  treat = darkmode$dark_mode, 
   # berechne SMD für KG und TG:
  disp = "m", 
  s.d.denom = "pooled"
)
```

Die Einträge `M.0.Un` und `M.1.Un` zeigen die jeweiligen Stichprobenmittelwerte der Variablen für Kontroll- und Behandlungsgruppe. `Diff.Un` gibt eine standardisierte Mittelwertdifferenz $SMD$ an, wobei \begin{align*}
  SMD_j := \left(\overline{X}_{j,B} - \overline{X}_{j,K}\right) \bigg/ \sqrt{\frac{1}{2}\left(\widehat{\text{Var}}(X_{j,B}) + \widehat{\text{Var}}(X_{j,K})\right)},
\end{align*} mit Stichprobenmitteln $\overline{X}_{j,B}$ und $\overline{X}_{j,K}$ und Stichprobenvarianzen $\widehat{\text{Var}}(X_{j,B})$ und $\widehat{\text{Var}}(X_{j,K})$ für eine kontinuierliche Kovariable $j$.[^matching-1] Obwohl es keinen einheitlichen Schwellenwert für die standardisierte Differenz gibt, der ein erhebliches Ungleichgewicht anzeigt, gilt für kontinuierliche Variablen eine standardisierte (absolute) Differenz von weniger als $0.1$ als Hinweis auf einen vernachlässigbaren Unterschied zwischen den Gruppen.

[^matching-1]: Siehe @Austin2011 für einen Überblick zu Balance-Statistiken.

Die Balance Table weist also auf einen vernachlässigbaren Unterschied für `hours` hin und bestätigt den aus den Grafiken abgeleiteten Eindruck einer relevanten Differenzen für `age`.

### Entropy Balancing

*Entropy Balancing* [@Hainmueller2012] ist eine weitere Methode zur Gewährleistung der Vergleichbarkeit von Behandlungs- und Kontrollgruppe anhand von Gewichten. Das Verfahren nutzt Konzepte aus der [Informationstheorie](https://de.wikipedia.org/wiki/Informationstheorie) um die Gewichte für Subjekte in der Kontrollgruppe so anzupassen, dass die Verteilung der Matchingvariablen in der Kontrollgruppe die Verteilung in der Behandlungsgruppe möglichst gut approximiert. Dies geschieht unter der Restriktion, dass bestimmte empirische Momente (meist Mittelwerte und Varianzen) der Matchingvariablen exakt übereinstimmen. Mathematisch werden die Gewichte für Kontrollgruppenbeobachtungen durch Minimierung der [Kullback-Leibler-Divergenz](https://de.wikipedia.org/wiki/Kullback-Leibler-Divergenz) zwischen den Verteilungen gefunden, wobei die Divergenz ein Maß für den Unterschied von Wahrscheinlichkeitsverteilungen ist.

Entropy Balancing ist im R-Paket `WeightIt` implementiert. Wir zeigen, wie die benötigten Gewichte für eine Schätzungen des ATT im Website-Beispiel mit `WeightIt::wightit()` bestimmt werden können. Über das Argument `moments` legen wir fest, dass die Gewichte unter der Restriktion übereinstimmender Mittelwerte aller Matching-Variablen zwischen Behandlungs- und Kontrollgruppe erfolgen soll. 

```{r}
library(WeightIt)

# Gewichte für Entropy Balancing
(
  W1 <- weightit(
  dark_mode ~ age + male + hours,
  data = darkmode,
  method = "ebal", 
  estimand = "ATT",
  moments = 1
  )
 )
```

Wir schätzen den Behandlungseffekt nach Entropy Balancing mit gewichteter Regression.

```{r}
# Mittelwert-Vergleich mit lm()
fit <- lm(
  formula = read_time ~ dark_mode, 
  data = darkmode, 
  weights = W1$weights
)
summary(fit)
```

Beachte, dass die von `summary()` berechneten Standardfehler bei Entropy Balancing ungültig sind. In Abschnitt @sec-bootmatching erläutern wir die Berechnung von Standardfehlern für Matching-Schätzer mit dem Bootstrap.

### Mehrere Matching-Variablen und der Propensity Score {#sec-PSM}

Bei mehreren Backdoor-Variablen kann eine Gewichtung anhand der Behandlungswahrscheinlichkeit (*Treatment Propensity*) erfolgen. Die Idee hierbei ist, dass der DGP wie in @fig-propCDdarkmode dargestellt werden kann.

```{dot}
//| fig-width: 4
//| fig-height: 3
//| fig-align: 'center'
//| fig-cap: "Propensity im Website-Design-Beispiel"
//| label: "fig-propCDdarkmode" 
digraph {
  layout=neato
  fontname="Helvetica,Arial,sans-serif"
  node [fontname="Helvetica,Arial,sans-serif"]
  edge [fontname="Helvetica,Arial,sans-serif"]
  node [shape=none];
  "read_time" [pos="4,0.5!"]
  "dark_mode" [pos="0,0.5!"]
  "TreatmentPropensity" [pos="0,2!"]
  "male" [pos="2,-1!"]
  "age" [pos="2,2!"]
  "hours" [pos="4,2!"]
  "hours" -> "read_time"
  "age" -> "TreatmentPropensity" [color="red"]
  "age" -> "read_time" [color="red"]
  "dark_mode" -> "read_time" [color="green"]
  "male" -> "TreatmentPropensity" [color="red"]
  "male" -> "read_time" [color="red"]
  "TreatmentPropensity" -> "dark_mode" [color="red"]
}
```

Hierbei beeinflussen die Backdoor-Variablen *age* und *male* die Behandlungsvariable *dark_mode* lediglich durch die Behandlungswahrscheinlichkeit *Treatment Propensity*. Diese Darstellung zeigt, das die mehrdimensionale Information bzgl. der Ähnlichkeit von Subjekten hinsichtlich der beobachteten Kovariablen in einer einzigen Variable zusammengefasst werden kann. Die Backdoor-Pfade können daher geschlossen werden, indem wir Subjekte anhand von *Treatment Propensity* derart gewichten, dass beide Gruppen hinsichtlich der Verteilung der Behandlungswahrscheinlichkeit vergleichbar sind. Betrachte erneut \eqref{eq:cia} und beachte, dass \begin{align}
  Y_i = Y_i^{(1)} D_i + Y_i^{(0)} (1-D_i).
\end{align} @RosenbaumRubin1983 zeigen, dass es hinsichtlich \eqref{eq:cia} äquivalent ist für die *Treatment Propensity* $P_i(X_i):=P(B_i=1\vert X_i = x)$ zu kontrollieren, d.h. \begin{align}
  \left\{Y_i^{(1)},Y_i^{(0)}\right\} \perp B_i\vert X_i \quad\Leftrightarrow\quad \left\{Y_i^{(1)},Y_i^{(0)}\right\} \perp B_i\vert P_i(X_i).
\end{align}

Der Behandlungseffekt kann so als Differenz von gewichteten Gruppenmittelwerten berechnet werden, mit inversem Wahrscheinlichkeitsgewicht (IPW) $w_{i,B} = 1/P_i(X_i)$ für Beobachtungen in der Behandlungsgruppe und $w_{i,K} = 1/(1-P_i(X_i))$ für Beobachtungen in der Kontrollgruppe, \begin{align}
  \tau^{\text{IPW}} = \frac{1}{n}\sum_{i=1}^n \left[\frac{B_i Y_i}{P_i(X_i)} - \frac{(1-B_i)Y_i}{1-P_i(X_i)} \right].\label{eq:tauipw}
\end{align}

Grundsätzlich ist *TreatmentPropensity* eine nicht beobachtbare Variable und muss daher aus den Daten geschätzt werden. Eine geschätzte Behandlungswahrscheinlichkeiten $\widehat{P}_i(X_i)$ wird als *Propensity Score* bezeichnet. In der Praxis erfolgt die Schätzung von *Propensity Scores* meist mit logistischer Regression. Ein erwartungstreuer Schätzer des ATE ist \begin{align}
  \widehat{\tau}^{\text{IPW}} = \frac{1}{n}\sum_{i=1}^n \left[\frac{B_i Y_i}{\widehat{P}_i(X_i)} - \frac{(1-B_i)Y_i}{1-\widehat{P}_i(X_i)} \right].\label{eq:hattauipw}
\end{align} @Hiranoetal2003 diskutieren Alternativen zu \eqref{eq:hattauipw} für die Schätzung anderer Typen von Behandlungseffekten.

Wir schätzen nachfolgend die *Propensity Scores* für unser Anwendungsbeispiel, erläutern die Berechnung der Gewichte sowie die Schätzung von Behandlungseffekten mit gewichteter Regression. Hierbei betrachten wir eine Variante von \eqref{eq:hattauipw} mit normalisierten Gewichten $\tilde{w}_{i,B} = w_{i,B}/\sum_i w_{i,B}$ und $\tilde{w}_{i,K} = w_{i,K}/\sum_i w_{i,K}$ die sich jeweils zu 1 summieren.[^matching-2] Dies ergibt den Hájek-Schätzer[^matching-3] \begin{align}
    \widehat{\tau}_N^{\text{IPW}} = \frac{\sum_i\tilde{w}_{i,B}Y_i}{\sum_i\tilde{w}_{i,B}} -  \frac{\sum_i\tilde{w}_{i,K}Y_i}{\sum_i\tilde{w}_{i,K}}.\label{eq:hattauhajek}
\end{align}

[^matching-2]: Eine Normalisierung der Gewichte reduziert die Varianz des Schätzers, vgl. @Hiranoetal2003

[^matching-3]: Siehe @Hajek1971.

Zunächst Schätzen wir ein logistisches Regressionsmodell mit `age`, `male` und `hours` als erklärende Variablen für `dark_mode`.

```{r}
# Logit-Modell mit 'glm()' schätzen
(
  darkmode_ps_logit <- glm(
    formula = dark_mode ~ age + male + hours,
    data = darkmode,
    family = binomial
  )
)
```

Die *Propensity Scores* erhalten wir als angepasste Werte aus der Regression `darkmode_ps_logit` mit `fitted()`. Wir erweitern den Datensatz mit den Ergebnissen.

```{r}
# Datensatz um Propensity Scores erweitern
(
  darkmode_probs <- 
    darkmode %>%
    mutate(
      PS = fitted(darkmode_ps_logit)
    )
)
```

Zur Beurteilung der Überlappung (vgl. Annahme \eqref{eq:overlap} können wir die Verteilung der *Propensity Scores* nach Behandlungs-Indikator mit Histogrammen visualisieren.

```{r}
# Überlappung prüfen:
# Histogramme der PS nach Treatment-Indikator
darkmode_probs %>%
  ggplot(
    mapping = aes(
      x = PS, 
      fill = factor(dark_mode)
    )
  ) + 
  geom_histogram(
    alpha = .5, 
    bins = 25, 
    position = "identity"
  )
```

Ein Vergleich der Histogramme zeigt, dass die Überlappung der *Propensity Scores* in der linken Flanken der Verteilungen der Kontrollgruppe und in der rechten Flanke der Behandlungsgruppe schlechter wird. Wir entfernen zunächst Beobachtungen aus der Stichprobe deren *Propensity Scores* wenig bzw. keine Überlappung aufweisen.

```{r}
# Datensatz nach PS trimmen
darkmode_probs <- darkmode_probs %>% 
  filter(
    between(
      x = PS,
      left = .25,
      right = .75
    )
  )
```

```{r}
# Überlappung nach trimming prüfen:
# Dichteschätzung der PS nach Treatment-Indikator
darkmode_probs %>%
ggplot(
  mapping = aes(
    x = PS, 
    fill = factor(dark_mode))
  ) + 
  geom_histogram(
    alpha = .5, 
    bins = 25, 
    position = "identity"
  )
```

IPWs anhand der *Propensity Scores* können schnell mit der Vorschrift \begin{align}
  \text{IPW} = \frac{\text{dark\_mode}}{\text{PS}} + \frac{1 - \text{dark\_mode}}{1 - \text{PS}},
\end{align} berechnet werden.

```{r}
# Datensatz um IPWs erweitern
darkmode_IPW <- darkmode_probs %>%
  mutate(
    IPW = dark_mode / PS + (1 - dark_mode) / (1 - PS)
  )

darkmode_IPW %>% 
  select(IPW)
```

Eine Schätzung des durchschnittlichen Behandlungseffekts gemäß \eqref{eq:hattauhajek} implementieren wir mit `dplyr`.

```{r}
darkmode_IPW %>%
  group_by(dark_mode) %>%
  mutate(w = IPW / sum(IPW)) %>%
  summarise(weighted_mean = sum(read_time * w)) %>%
  summarise(diff = diff(weighted_mean))
```

Diese Schätzung des Behandlungseffekts ist äquivalent zur gewichteten KQ-Schätzung anhand eines einfachen linearen Regressionsmodells.

```{r}
# Mit IPWs gewichteter KQ-Schaetzer berechnet den ATE
model_ipw <- lm(
  formula = read_time ~ dark_mode, 
  data = darkmode_IPW,
  weights = IPW
)

summary(model_ipw)
```

Unsere Schätzung des ATE ist der geschätzte Koeffizient von `dark_mode`. Die ausgegebenen Standardfehler und Inferenzstatistiken sind jedoch *ungültig* aufgrund der Gewichtung mit IPWs, den inversen *geschätzten* Wahrscheinlichkeiten für eine Behandlung. Der Grund hierfür ist, dass die Berechnung der Standardfehler in `summary()` die zusätzliche Unsicherheit durch die geschätzen *Propensity Scores* nicht berücksichtigt! Später im Kapitel erläutern wir die Berechnung gültiger Standardfehler für IPW-Schätzer basierend auf *Propensity Scores* mit dem Bootstrap.

## Selektierende Matching-Verfahren

Das grundsätzliche Konzept von selektierendem Matching wird in der nachstehenden interaktiven Grafik veranschaulicht. Hier betrachten wir beobachtete Ausprägungen von zwei (unabhängig und identisch verteilten) Matching-Variablen für Subjekte in der Behandlungsgruppe (blau) sowie Kontrollgruppe (rot). Als Matches qualifizieren sich sämtliche Beobachtungen der anderen Gruppe, deren [Euklidische Distanz](https://de.wikipedia.org/wiki/Euklidischer_Abstand) zu dem ausgewählten Punkt das über den Slider eingestellte Maximum *Caliper* nicht überschreitet.^[Es handelt sich hierbei um einen Spezialfall von Matching anhand der Mahalanobis-Distanz.] Diese Region wird durch den gestrichelten Kreis gekennzeichnet und kann über den zugehörigen Slider angepasst werden. Per Klick auf eine Beobachtung werden Matches aus der anderen Gruppe durch eine verbindende Linie und farbliches Hervorheben kenntlich gemacht. Mit dem Slider für k wird festgelegt, dass nur die nächsten k qualifizierten Beobachtungen als Matches behandelt werden. Die Grafik illustriert inbesondere, dass Beobachtungen in Abhängigkeit von k und Caliper falls gewünscht mehrfach (s.g. Matching mit Zurücklegen) oder gar nicht gematcht werden können.

<iframe width="100%" height="678" frameborder="0"
  src="https://observablehq.com/embed/62067a02a72c9f90@464?cells=theplot%2Cviewof+k%2Cviewof+caliper%2Cstyles"></iframe>

Für die nachfolgenden Code-Beispiele verwenden wir das R-Paket `MatchIt`. `MatchIt::matchit()` nutzt standardmäßig Eins-zu-Eins-Matching (ohne Zurücklegen) von Beobachtungen der Treatment-Gruppe mit Beobachtungen der Kontrollgruppe.^[Dieses Schema zielt auf eine Schätzung des ATT ab.] Die für das Matching zu verwendenden Variablen werden über das Argument `formula` als Funktion des Behandlungsindikators definiert. `matchit()` bereitet das Objekt für eine Schätzung des ATT mit einer geeigneten Funktionen, s. `?matchit` und hier insb. die Erläuterungen der Argumente `replace = F`, `ratio = 1` und `estimand = "ATT"` für Details. Mit `cobalt::balt.tab()` erhalten wir eine *balance table* für den gematchten Datensatz.

Wir zeigen als nächstes, wie `MatchIt::matchit()` für Matching anhand der Regressoren `age`, `hours`, und `male` in unserem Website-Beispiel für unterschiedliche Varianten durchgeführt werden kann.

### Exaktes Matching 

Exaktes Matching ordnet einem Subjekt aus der Behandlungsgruppe ein oder mehrere Subjekte aus der Kontrollgruppe zu, wenn die boebachteten Ausprägung der Matching-Variablen *exakt* übereinstimmen. Hierbei muss die 'Distanz' zwischen den Ausprägung der Matching-Variablen folglich $0$ sein. Dieses Verfahren findet meist bei ausschließlich diskret verteilten Merkmalen Anwendung. Bei kontinuierlich verteilten Merkmalen (vgl. die obige interaktive Grafik) sind exakte Matches zwar theoretisch unmöglich, ergeben sich jedoch in der Praxis aus der Datenerfassung, bspw. durch Rundungsfehler. In `matchit()` erhalten wir exaktes Ein-zu-eins-Matching mit `method = "exact"`.

```{r, error=TRUE}
library(MatchIt)

# Exaktes Eins-zu-Eins-Matching durchführen
res_em <- matchit(
  formula = dark_mode ~ age + male + hours, 
  data = darkmode,
  estimand = "ATT",
  method = "exact"
)
res_em
```

Aufgrund der kontinulierliche Verteilten Variable `hours` gibt es in unserem Website-Beispiel keine exakten Matches. Dieses Verfahren ist hier folglich ungeeignet.

### Coarsened Exact Matching

Bei dieser Methode werden kontinuierliche Matching-Variablen grob (Engl. *coarse*) klassiert, ähnlich wie bei einem Histogram. Diese Diskretisierung ermöglicht es exakte Übereinstimmungen zwischen Behandlungs- und Kontrollgruppenbeobachtungen hinsichtlich ihrer klassierten Ausprägungen zu finden. Sowohl Behandlungs- als auch Kontrollbeobachtungen die mindestents einen exakten Match haben, werden Teil des gematchten Datensatzes. In `matchit()` wird Coarsened Exact Matching mit `method = "cem"` durchgeführt. Über das Argument `cutpoints` geben wir an, dass `hours` in 6 Klassen und `age` in 4 Klassen eingeteilt werden soll.^[Diese Werte wurden ad-hoc gewählt da sie zu einem guten Ergebnis führen.] Mit `k1k = TRUE` erfolgt Eins-zu-eins-Matching: Bei mehreren exakten Matches wird die Beobachtung mit der geringsten Mahalanobis-Distanz (für die unklassierten Matching-Variablen) gewählt.

```{r}
# Coarsened Exact Matching
res_CEM <- matchit(
  formula = dark_mode ~ age + male + hours, 
  data = darkmode, 
  estimand = "ATT",
  method = "cem", 
  k2k = TRUE,
  cutpoints = list(
    "hours" = 6, 
    "age" = 4
  ) 
)
res_CEM
```

```{r}
# Balance-Table Coarsened Exact Matching
bal.tab(res_CEM)
```

Mit Coarsened Exact Matching erhalten wir einen Datensatz mit 82 Beobachtungen und guter Balance.

### Matching mit der Mahalanobis-Distanz

Die Euklidische Distanz misst den direkten Abstand zwischen zwei Punkten und ist nicht invariant gegenüber Transformationen, insbesondere bei unterschiedlichen Skalierungen und bei Korrelation der Matching-Variablen. Die Mahalanobis-Distanz hingegen ist ein standardisiertes Distanzmaß, das unter Berücksichtigung der Varianz-Kovarianz-Struktur der Daten angibt, wie viele Standardabweichungen zwei Datenpunkte voneinander entfernt sind. Die Mahalanobis-Distanz ist invariant gegenüber linearen Transformationen (Skalierung, Translation und Rotation) der Daten und bietet ein genaueres Maß für die Unähnlichkeit zweier Beobachtungen hinsichtlich ihrer Ausprägungen der Matching-Variablen. 

Betrachte die Datenpunkte $P_1=(X_1,Y_1)'$ und $P_2=(X_2,Y_2)'$ für die Matching-Variablen $X$ und $Y$. Die Mahalanobis-Distanz zwischen $P_1$ und $P_2$ ist definiert als
\begin{align*}
  d_M(P_1,\,P_2) = \sqrt{(P_1 - P_2)'\boldsymbol{S}^{-1} (P_1 - P_2)},
\end{align*}
wobei $\boldsymbol{S}$ die Varianz-Kovarianz-Matrix von $X$ und $Y$ ist. Die Mahalanobis-Distanz $d_M(P_1,\,P_2)$ ist also die Euklidische Distanz zwischen den standardisierten Datenpunkten.

In empirischen Anwendungen ersetzen wir die (unbekannten) Komponenten der Varianz-Kovarianz-Matrix durch Stichprobenvarianten. Dies ergibt die Formel

\begin{align*}
  \widehat{d}_M(P_1,\,P_2) = \sqrt{
  \begin{pmatrix}
    X_1 - X_2\\
    Y_1 - Y_2
  \end{pmatrix}'
  \begin{pmatrix}
    \widehat{\text{Var}}(X^2) & \widehat{\text{Cov}}(X, Y) \\
     \widehat{\text{Cov}}(X, Y) & \widehat{\text{Var}}(Y^2) 
  \end{pmatrix}^{-1}
    \begin{pmatrix}
    X_1 - X_2\\
    Y_1 - Y_2
  \end{pmatrix}
}.
\end{align*}

Die nachstehende interaktive Grafik zeigt Beobachtungen zweier Matching-Variablen, die aus einer bivariaten Normalverteilung mit positiver Korrelation generiert wurden. Diese bivariate Verteilung ist identisch für Beobachtungen aus der Kontrollgruppe (rot) und Beobachtungen aus der Behandlungsgruppe (blau). Für die ausgewählte Beobachtung aus der Behandlungsgruppe (schwarzer Rand) werden potentielle Matches in der Kontrollgruppe innerhalb der vorgegebenen Mahalanobis-Distanz in Cyan kenntlich gemacht. Beachte, dass die Mahalanobis-Distanz Varianzen und Kovarianzen der Daten berücksichtigt, sodass die gematchten Beobachtungen in einem elliptischen Bereich um die betrachtete behandelte Beobachtung liegen. Eine Euklidische Distanz hingegen (gestrichelte Linie) ignoriert die Skalierung der Daten.


<iframe width="100%" height="648" frameborder="0"
  src="https://observablehq.com/embed/1338355035acc056@687?cells=theplot%2Cviewof+caliper%2Cstyles"></iframe>
::: {.column-margin}
```{r}
#| cache: true
#| echo: false
library(rsvg)
library(qrcode)
code <- qr_code("https://observablehq.com/d/62067a02a72c9f90")
path <- "docs/img/EDM_qr.svg"
qrcode::generate_svg(
  qrcode = code, 
  filename =  "docs/img/EDM_qr.svg"
  )
rsvg::rsvg_png(
  "docs/img/EDM_qr.svg", "docs/img/EDM_qr.png",
  width = 200, height = 200
)
```
::: {.centered-caption}
![Link zum Observable-Notebook](docs/img/EDM_qr.png){fig-alt="Link zu Observable" fig-align="center" width=20% class="cfigcaption"}
:::
:::


Für Eins-zu-Eins-Matching im Website-Beispiel anhand der Mahalanobis-Distanz mit `matchit()` setzen wir `distance = "mahalanobis"` und wählen `method = "nearest"`. Mit diesen Parametern wird jeder Behandlung aus der Behandlungsgruppe die gemäß $d_M$ am ehesten vergleichbarste Beobachtung aus der Kontrollgruppe zugewiesen, wobei keine mehrfachen Matches zulässig sind. 

```{r}
# 1:1 Mahalanobis-Distanz-Matching
res_maha <- matchit(
  formula = dark_mode ~ age + male + hours, 
  data = darkmode, 
  estimand = "ATT",
  distance = "mahalanobis", 
  method = "nearest"
)
res_maha
```

```{r}
# Balance-Table für 1:1 Mahalanobis-Matching
bal.tab(res_maha)
```

Die Ergebnisse zeigen, dass für sämtliche $149$ Beobachtungen aus der Behandlungsgruppe ein individueller Match in der Kontrollgruppe gefunden werden konnte. Es werden lediglich $2$ Beobachtungen der $151$ Beobachtungen in der Kontrollgruppe nicht gematcht.

Entsprechend zeigt die Balance-Table eine ähnliche Diskrepanz beider Gruppen hinsichtlich der Matching-Variablen an.

**Mahalanobis-Distanz mit Caliper .25 für Propensity Scores basierend auf logistischer Regression**

Für eine strengeres Matching-Kriterium kann ein *Caliper*, d.h. eine maximal zulässige Distanz, herangezogen werden. Die Mahalanobis-Distanz hat jedoch keine einheitliche Skala: Ob eine Distanz als groß oder klein betrachten werden kann, hängt von der Anzahl der Matching-Variablen und dem Überlappungsgrad zwischen den Gruppen ab. Daher wird die Beschränkung durch einen Caliper nicht auf $\widehat{d}_M$ sondern auf Propensity Scores angewendet.

Im nächsten Code-Beispiel spezifizieren wir mit `distance = "glm"`, dass Propensity Scores gemäß der Vorschrift in `formula` geschätzt werden. Mit `mahvars = ~ age + male + hours` legen wir die Matching-Variablen für die Berechnung von $\widehat{d}_M$ fest. `caliper = .25` legt fest, dass lediglich Beobachtungen der Kontrollgruppe bei einer absoluten Differenz der Propensity Scores von höchstens $0.25$ Standardabweichungen als Match für eine Beobachtung in der Behandlungsgruppe qualifiziert sind.

```{webr-r}
#| context: setup
# Logit-Modell mit 'glm()' schätzen
(
  darkmode_ps_logit <- glm(
    formula = dark_mode ~ age + male + hours,
    data = darkmode,
    family = binomial
  )
)
```
```{r}
# Mahalanobis-Matchig mit PS-Caliper
res_mahaC <- matchit(
  formula = dark_mode ~ age + male + hours, 
  data = darkmode, 
  distance = "glm",
  estimand = "ATT",
  method = "nearest",
  mahvars = ~ age + male + hours,
  caliper = .25
)
res_mahaC
```

```{r}
# Balance Table
bal.tab(res_mahaC)
```

Die Balance-Table zeigt einen deutlichen Effekt der Beschränkung qualifizierter Beobachtungen durch `caliper = .25`: Aufgrund der oberen Grenze für die Propensity-Score-Differenz von $`r round(.25 * sd(fitted(darkmode_ps_logit)), 3)`$ wird für lediglich $104$ Beobachtungen aus der Behandlungsgruppe ein individueller Match in der Kontrollgruppe gefunden.^[Die durch `caliper` implizierte Obergrenze ergibt sich als `.25 * sd(fitted(darkmode_ps_logit)))`.] Weiterhin finden wir eine verbesserte Balance für den gematchten Datensatz.

:::{.column-margin}
```{webr-r}
.25 * sd(
  fitted(darkmode_ps_logit)
  )
```
:::

### Propensity Score Matching

Eine gängige Variante ist Matching ausschließlich anhand von Propensity Scores innerhalb eines Calipers. 

```{r}
# 1:1 Matching mit PS und Caliper
res_PSC <- matchit(
  formula = dark_mode ~ age + male + hours, 
  data = darkmode, 
  estimand = "ATT",
  distance = "glm", 
  method = "nearest", 
  caliper = .25
)
res_PSC
```

```{r}
# Balance Table
bal.tab(res_PSC)
```

Laut Balance-Table führt Eins-zu-Eins-Matching basierend auf Propensity Scores zu einem Datensatz mit $104$ gematchten Beobachtungen in der Behandlungsgruppe. Hinsichtlich der standardisierten Mittelwertdifferenz (`Diff.Adj`) erzielt diese Methode die beste Balance unter den betrachteten Ansätzen.

**Vergleich der Balance verschiedener Verfahren mit Love-Plot**

Standardisierte Mittelwertdifferenzen für verschiedene Matching-Verfahren können grafisch mit einem Love-Plot [@Love2004] veranschaulicht werden. Hierzu nutzen wir `cobalt::love.plot()` und übergeben die mit `matchit()` generierten Objekte im Argument `weights`.

```{r}
# Love-Plot für
love.plot(
  x = dark_mode ~ age + male + hours, 
  weights = list(
    CEM = res_CEM,
    Mahalanobis = res_maha,
    Mahalanobis_Cal = res_mahaC,
    PSC = res_PSC
  ),
  data = darkmode, 
  line = T,
  # absolute Mittelwertdifferenz plotten
  abs = T
)
```

Die Grafik zeigt, dass Coarsened Exact Matching (CEM) unter allen betrachteten Verfahren die Stichprobe mit der besten Balance ergibt. Diesen gematchten Datensatz erhalten wir mit `MatchIt::match.data()`.

```{r}
# gematchten Datensatz zuweisen
darkmode_matched_CEM <- match.data(res_CEM)
head(darkmode_matched_CEM)
```

`darkmode_matched` enthält Gewichte (`weights`) für die jeweilige Gruppe zu denen gemachte Beobachtungen gehören (`subclass`). Dies ist relevant, falls Beobachtungen mehrfach gematcht werden. Wegen Eins-zu-eins-Matching _ohne_ Zurücklegen gibt es in unserem Beispiel `r length(unique(darkmode_matched_CEM$subclass))` Beobachtungspaare und sämtliche Gewichte sind 1. Die Berücksichtigung der Gewicht in den nachfolgenden Aufrufen von Schätzfunktionen (bspw.`lm()`) ist daher nicht nötig und erfolgt lediglich zur Illustration der grundsätzlichen Vorgehensweise.

Eine Wiederholung der grafischen Analyse in @sec-balance zeigt eine deutlich verbesserte Vergleichbarkeit hinsichtlich der Verteilung der Matching-Variablen in `darkmode_matched`.

```{r, warning=FALSE, message = F}
darkmode_matched_CEM %>%
  group_by(dark_mode) %>%
  select(age, hours) %>%
  mutate_all(scale) %>%
  pivot_longer(cols = c(-dark_mode)) %>%
  
  ggplot(
    aes(x = value, fill = as.factor(dark_mode))
  ) +
  geom_density( alpha = .5) + 
  facet_wrap(
    facets = ~ name, 
    scales = "free", 
    nrow = 3
  )

darkmode_matched_CEM %>% 
  group_by(dark_mode) %>%
  mutate(
    male = as.factor(male), 
    dark_mode = as.factor(dark_mode)
  ) %>%
  
  ggplot(
    aes(x = dark_mode, fill = male)
  ) +
  geom_bar(position = "fill") +
  ylab("Anteil")
```

Wir beobachten eine bessere Balance bei `age` und `hours`. Inbesondere ist `male` für Kontroll- und Behandlungsgruppe ausgeglichen.


## Schätzung und Inferenz für den Behandlungseffekt nach Matching {#sec-regadj}

Wir schätzen nun den Behandlungseffekt von `dark_mode` auf `read_time` für die mit CEM und Propensity Score Matching ermittelten Datensätzen und vergleichen die Ergebniss anschließend mit einer Regressionsschätzung ohne Matching. 

Wir kombinieren die Matching-Verfahren mit linearer Regression, d.h. wir Schätzen den Behandlungseffekt anhand es gematchten Datensatzes als Mittelwertdifferenz nach zusätzlicher Kontrolle für die Matching-Variablen. Diese Kombination von Matching mit Regression wird in der Literatur als *Regression Adjustment* bezeichnet und ist insbesondere hilfreich, wenn Backdoors mit Matching geschlossen werden sollen, der kausale Effekt jedoch nur unter Verwendung einer nicht-trivialen Regressionsfunktion ermittelt werden kann. Zum Beispiel kann bei einer kontinuierlichen Behandlungsvariable und einem nicht-linearen Zusammenhang mit $Y$ der kausale Effekt nicht durch einen bloßen Mittelwertvergleich erfasst werden, sondern erfordert eine adäquate Modellierung dieses Zusammenhangs in der Regressionsfunktion. Die zusätzliche Kontrolle für Matching-Variablen kann die Varianz der Schätzung verringern und das Risiko einer verzerrten Schätzung abmildern, falls nach Matching noch Unterschiede in der Balance von Behandlungs- und Kontrollgruppe vorliegen.

```{r}
# ATT mit linearem Modell schätzen: CEM Datensatz
ATT_mod_CEM <- lm(
  formula = read_time ~ age + male + hours + dark_mode,
  data = darkmode_matched_CEM, 
  weights = weights 
)

summary(ATT_mod_CEM)
```

```{r}
# Datensatz für Propensity Score Matching zuweisen
darkmode_matched_PSC <- match.data(res_PSC)

# ATT mit linearem Modell schätzen: PSM Datensatz
ATT_mod_PSC <- lm(
  formula = read_time ~ age + male + hours + dark_mode,
  data = darkmode_matched_PSC, 
  weights = weights 
)

summary(ATT_mod_PSC)
```

```{r}
# ATT mit linearem Modell ohne Matching
ATT_mod_org <- lm(
  formula = read_time ~ age + male + hours + dark_mode,
  data = darkmode
)

summary(ATT_mod_org)
```

Beachte, dass für die gematchten Datensätze jeweils ein durchschnittlicher Behandlungseffekt für die Beobachtungen _mit_ erfolgter Behandlung ermittelt wird: In sämtlichen oben gezeigten Matchibg-Verfahren werden mit `estimand = "ATT"` vergleichbarere Kontrollbeobachtungen für die behandelten Beobachtungen ermittelt. Wir schätzen den Effekt der Behandlung, indem wir die Ergebnisse von behandelten Personen mit denen von gematchten Personen vergleichen, die keine Behandlung erhalten haben. Diese Vergleichsgruppe dient als Ersatz für den hypothetischen Zustand der Behandlungsgruppe, wenn keine Behandlung erfolgt wäre. Dies entspricht der Definition eines ATT --- ein average treatment effect *on the treated*.

### Cluster-robuste Standardfehler

Für Matching-Verfahren sind die mit `summary()` berechneten Standardfehler (und damit auch Konfidenzintervalle, t-Statistiken und p-Werte) für den Behandlungseffekt *grundsätzlich ungültig*. Je nach Matching-Verfahren liegen unterschiedliche Quellen von Schätzunsicherheit vor, die bei der Berechnung von Standardfehlern zusätzlich zu der "üblichen" Stichproben-Variabilität berücksichtig werden müssen. Gründe hierfür sind der Matching-Prozess ansich oder weitere Unsicherheit durch die Schätzung zusätzlicher Parameter, etwa bei der Berechnung von Propensity Scores mit logistischer Regression. Eine weiterere Ursache zusätzlicher Variation durch den Matching-Prozess, die wir bisher nicht näher betrachtet haben ensteht durch Zurücklegen, d.h. wenn Beobachtungen mehrfach gematcht werden können. Auch dieser Faktor wird in der von `summary()` verwendeten Formel für den Standardfehler des Effekt-Schätzers nicht berücksichtigt.

Die Standardfehlerberechnung für Matching-Schätzer von Behandlungseffekten ist ein Gegenstand aktueller methodischer Forschung. @AustinSmall2014 und @AbadieSpiess2022 belegen die Gültigkeit von cluster-robusten Standardfehlern mit Clustering auf Ebene der Beobachtungsgruppen (`subclass` im output von `match.data()`) bei Matching ohne Zurücklegen. Für Matching anhand von Propensity Scores (auch mit Zurücklegen) zeigt @AbadieImbens2016, dass ignorieren der zusätzlichen Unsicherheit durch die Schätzung der Propensity Scores zu konservativer Inferenz für den ATE anhand eines cluster-robusten Standardfehlerschätzers führt, jedoch ungültige Inferenz für die Schätzung des ATT bedeuten kann. Ähnlich zu @AustinSmall2014 deuten die Ergebnisse der Simulationsstudie von @Bodoryetal2020 jedoch auf grundsätzlich bessere Eigenschaften der Schätzung hin, wenn die Standardfehler *nicht* für die Schätzung der Propensity Scores adjustiert werden.

Weiterhin ist die Kontrolle für Kovariablen mit Erklärungskraft für die Outcome-Variable und für die Matching-Variablen mit *Regression Adjustment* (vgl. @sec-regadj) für die Schätzung des Behandlungseffekts nach Matching eine etablierte Strategie, vgl. @HillReiter2006 und @AbadieSpiess2022. So können die Varianz der Schätzung und das Risiko einer Verzerrung der Standardfehler aufgrund verbleibender Imbalance von Behandlungs- und Kontrollgruppe nach Matching verringert werden.

Zur Demonstration von (cluster)-robuster Inferenz und für eine  tabellarische Zusammenfassung der Ergebnisse nutzen wir die Pakete `marginaleffects` und `modelsummary`. Mit `marginaleffects::avg_comparisons()` können p-Werte und Kofindenzintervalle unter Berücksichtigung von robuster Standardfehlern und der Gewichte aus dem Matching-Verfahren berechnet werden.

```{r}
library(marginaleffects)

# Inferenz: Multiple Regression, ungematchter Datensatz
(
  sum_orig <- avg_comparisons(
    model = ATT_mod_org,
    variables = "dark_mode",
    # Heteroskedastie-robuste SE:
    vcov = "HC3", 
    # Identifizierung der Kontrollgruppe:
    newdata = subset(darkmode, dark_mode == 1) 
  )
) 
```
```{r}
# Inferenz: Multiple Regression bei CEM
(
  sum_CEM <- avg_comparisons(
  model = ATT_mod_CEM ,
  variables = "dark_mode",
  # Cluster-robuste SE
  vcov = ~ subclass, 
  newdata = subset(darkmode_matched_CEM, dark_mode == 1),
  wts = "weights"
  )
)
```
```{r}
# Inferenz: Multiple Regression bei PSM
(
  sum_PSC <- avg_comparisons(
    model = ATT_mod_PSC ,
    variables = "dark_mode",
    vcov = ~ subclass, 
    newdata = subset(darkmode_matched_PSC, dark_mode == 1),
    wts = "weights"
  )
)
```

Wir fassen die Ergebnisse mit `modelsummary::modelsummary()` tabellarisch zusammen.

```{r}
library(modelsummary)

# Tabellarische Zusammenfassung erzeugen
modelsummary(
  models = list(
   "Kein Matching" = sum_orig, 
   "Coarsened Exact" = sum_CEM, 
   "Propensity Scores" = sum_PSC
  ),
  stars = T, 
  gof_map = "nobs", 
  output = "gt"
) %>%
  tabopts()
```


## Bootstrap-Schätzung kausaler Effekte bei Matching {#sec-bootmatching}

Ein Bootstrap-Verfahren generiert mit Resampling (wiederholtes Ziehen mit Zurücklegen) aus dem Original-Datensatz (viele) künstliche Datensätze, für die der Schätzer (d.h. das gesamte Verfahren inkl. Matching!) jeweils berechnet wird. Die Verteilung der so gewonnenen Bootstrap-Schätzwerte approximiert die wahre, unbekannte Stichprobenverteilung des Schätzers des Behandlungseffekts. Mit dieser simulierten Verteilung können wir Inferenz betreiben: Wir können einen Bootstrap-Punktschätzer des Behandlungseffekts (Stichprobenmittel der Bootstrap-Schätzungen) sowie Standardfehler (Standardabweichung der der Bootstrap-Schätzungen) und p-Werte berechnen.

Der Bootstrap kann hilfreich sein, wenn unklar ist, wie Standardfehler für die Unsicherheit des Matching-Prozesses zu adjustieren sind, um gültige Inferenzsstatistiken zu erhalten. @AbadieImbens2008 zeigen analytisch, dass der Standard-Bootstrap  die Stichprobenverteilung für Schätzer kausaler Effekte anhand von gematchten Datensätzen (d.h. bei Zuordnung/Selektion von Beobachtungen mit Matching) nicht korrekt abbilden kann. Grundsätzlich problematisch hierbei ist, wenn der Bootstrap eine verzerrte Schätzung produziert und/oder zu kleine Standardfehler liefert. @AbadieImbens2008 belegen die Tendenz des Bootstraps zu *konservative* (d.h. zu große) Standardfehler zu produzieren. Simulationsnachweise [@Bodoryetal2020; @HillReiter2006; @AustinSmall2014;@AustinStuart2017] finden, dass Bootstrap-Standardfehler u.a. bei Propensity Score Matching mit Zurücklegen leicht konservativ sind somit das gewünschte nominale Signifikanzniveau eines Bootstrap-Hypothesentests nicht überschritten wird, weshalb der Standard-Bootstrap trotz seiner Schwächen in der empirischen Forschung oft angewendet wird.


Wir betrachen als nächstes einen Bootstrap-Algorithmus für Inferenz bezüglich eines kausalen Effekts nach Matching und demonstrieren die Schätzung anhand unseres Website-Beispiels für den ATT nach Propensity-Score-Matching.

::: {.callout-tip title="**Algorithmus: Bootstrap-Schätzer für Matching mit Regression Adjustment**" icon=false}

1. Generiere eine Bootstrap-Stichprobe durch $N$ Züge *mit Zurücklegen* aus der $N$-elementigen originalen Stichprobe.

2. Wende das Matching-Verfahren für die Bootstrap-Stichprobe an. Schätze den Behandlungseffekt $\beta$ anhand der gematchten Stichprobe mit Regression. Speichere den Punktschätzer des Behandlungseffekts $\widehat{\beta}_b^*$.

3. Fürhre die Schritte 1 und 2 für $b=1,\dots,B$ aus, wobei $B$ eine hinreichend große Anzahl von Bootstrap-Replikationen ist.

4. Berechne den Bootstrap-Schätzer des Behandlungseffekts $\overline{\beta}^* = \frac{1}{B}\sum_{b=1} \widehat{\beta}_b^*$ und den Standardfehler $\text{SE}(\overline{\beta}^*) = \sqrt{\frac{1}{B-1}\sum_{b=1}^B(\widehat{\beta}_b^*-\overline{\beta}^*)^2}$. Berechne Inferenz-Statistiken mit den üblichen Formeln.

:::

Wir Implementieren nun einen Bootstrap-Schätzer des ATT im Website-Beispiel für Propensity-Score-Matching. Hierzu definieren wir eine `R`-Funktion `boot_fun()` für die Schritte 1 und 2 im obigen Algorithmus.

```{r}
# Bootstrap-Funktion für Schritte 1 und 2
boot_fun <- function(
    data, # originale Stichprobe
    i     # Indexmenge f. Bootstrap-Stichprobe
) {
  
  # Bootstrap-Stichprobe
  boot_data <- data[i, ]
  
  # 1:1 PS Matching
  match_res <- matchit(
    dark_mode ~ age + hours + male,
    estimand = "ATT",
    distance = "glm", 
    method = "nearest", 
    caliper = .25,
    data = boot_data
  ) 
  
  # Gematchten Datensatz zuweisen
  darkmode_matched <- match.data(
    object = match_res, 
    data = boot_data
  )
  
  # Outcome-Modell schätzen
  ATT_mod <- lm(
    formula = read_time ~ age + male + hours + dark_mode,
    data = darkmode_matched, 
    weights = weights 
  )
  
  #  ATT-Schätzung zurückgeben
  return(
    ATT_mod$coefficients["dark_mode"]  
  )
}
```

Wir berechnen nun eine Bootstrap-Schätzung des ATT von `dark_mode` auf `readingtime` nach Propensity Score Matching mit einem caliper von 0.25 sowie den zugehörigen Standardfehler und ein 95%-KI mit der zuvor definierten Funktion `boot_fun`.

```{r, cache = F}
library("boot")
set.seed(4321)

# Anz. Bootstrap-Replikationen
B <- 999

# Bootstrap durchführen
(
  boot_out <- boot(darkmode, boot_fun, R = B)
)
```

Den Bootstrap-Schätzer des ATT sowie den Bootstrap-Standardfehler berechnen wir mit `mean()` und `sd()` anhand der `r B` Bootstrap-Replikationen in `boot_out$t`.

Beachte, dass der Bootstrap-Schätzer des Behandlungseffekts nicht unmittelbar von `boot()` ausgegeben wird. `original` ist die Schätzung anhand der gesamten Stichprobe (d.h. ohne Bootstrap) und `bias` ist die Differenz zwischen dieser Schätzung und dem Mittelwert der Bootstrap-Schätzungen.

```{r}
# Bootstrap-Schätzer für den Treatment-Effekt
mean(boot_out$t) 

# bootstrap - original = bias
mean(boot_out$t) - boot_out$t0
```

Wir können prüfen, dass die Berechnung des Standardfehlers dem Stichprobenstandardabweichung der Bootstrap-Schätzungen entspricht.

```{r}
# Bootstrap-Standardfehler
sd(boot_out$t)
```

Ein 95\%-Konfidenzintervall für den kausalen Effekt erhalten wir mit `boot::boot.ci()`.^[`type = "bca"` (bias-corrected accelerated) ist eine gängige Implementierung für die Berechnung des Konfidenz-Intervalls.]

```{r}
# 95% Bootstrap-KI für den Treatment-Effekt
boot.ci(
  boot.out = boot_out, 
  type = "bca", 
  conf = .95
)
```

Beachte, dass der Bootstrap-Standardfehler sowie das Bootstrap-Konfidenzintervall nahe der mit `avg_comarisons` berechneten Werte für `sum_PSC` sind.

**Bootstrap-Standardfehler für IPW-Schätzer des ATE berechnen**

Die Bootstrap-Funktion `boot_fun` kann leicht für eine Schätzung des Standardfehlers für den IPW-Schätzer des ATE aus @sec-PSM angepasst werden. Statt einer Matching-Prozedur berechnen wir hierzu für $B$ Bootstrap-Stichproben den Schätzer $\widehat{\tau}^\text{IPW}$ mit Trimming der Propensity Scores.

```{r}
# IPW estimation with regression adjustment
IPW_boot <- function(
    data, 
    i
) {
  
  # Bootstrap-Stichprobe erstellen
  data_boot  <- data %>% 
    slice(i)
  
  # Logistischee Regression
  glm_fit <- glm(
    formula = dark_mode ~ age + hours + male,
    data = data_boot, 
    family = binomial
  )
  
  # Propensity Scores berechnen
  data_boot <- data_boot %>%
    mutate(
      ps = predict(glm_fit, type = 'response')
    )
  
  # Beobachtungen anhand Propensity Scores trimmen
  data_boot <- data_boot %>%
    filter(
      between(
        x = ps,
        left = .2,
        right = .7
      )
    )
  
  # IPW berechnen
  data_boot <- data_boot %>%
    mutate(
      ipw = case_when(
        dark_mode == 1 ~ 1 / ps,
        dark_mode == 0 ~ 1 / (1 - ps))
    )
  
  # Gewichtete Mittelwerte der Gruppen   
  w_means <- data_boot %>%
    group_by(dark_mode) %>%
    summarize(m = weighted.mean(read_time, w = ipw)) %>%
    arrange(dark_mode)
  
  # ATT-Schätzwert
  return(w_means$m[2] - w_means$m[1])
}
```

```{r}
set.seed(1234)
# Bootstrap für IPW durchführen
(
  b_IPW <- boot(
    data = darkmode,
    statistic = IPW_boot, 
    R = 999
  )
)
```

```{r}
# Bootstrap-Schätzer und Standardfehler berechnen
mean(b_IPW$t)
sd(b_IPW$t)
```

In diesem Fall ist der Bootstrap-Standardfehler von ca. `r round(sd(b_IPW$t), 2)` gut mit dem anhand von `summary(model_ipw)` berechneten Standardfehler vergleichbar. Ein 95\%-Konfidenzintervall für den ATE erhalten wir wie zuvor mit `boot.ci()`.

```{r}
# 95% Bootstrap-KI für den ATE
boot.ci(b_IPW, type = "bca")
```

## Regression, Matching und Doubly-Robust-Schätzung

Als *Doubly-Robust-Schätzer* bezeichnet man Methoden, die bei Fehlspezifikationen im Matching-Verfahrens *oder* der funktionalen Form der Regressionsfunktion für die Outcome-Variable eine zuverlässige Schätzungen des kausalen Effekts ermöglichen.^[Bspw. kann eine falsche funktionale Form bei logistischer Regression eine verzerrte Schätzung von Propensity Scores und damit eine unzureichende Balance bedeuten.] Unter der Vorraussetzung, dass die verwendeten Matching-Variablen sämliche Backdoors schließen, ist so mit Doubly-Robust-Schätzung eine konsistente Schätzung des Behandlungseffekts unter abgeschwächten Annahmen gewähtleistet. Dies macht Doubly-Robust-Schätzer besonders nützlich in Forschungskontexten, in denen präzise Modellspezifikationen herausfordernd sind.

Der von @Wooldrige2010 vorgeschlagene Doubly-Robust-Schätzer (IPWRA) für den ATE erreicht seine vorteilhaften Eigenschaften durch eine geschickte Kombination von IPW und Regression Adjustment.

::: {.callout-tip title="**Algorithmus: IPWRA-Schätzer des ATE**" icon=false}

Vgl. @Wooldrige2010.

1. Berechne IPW anhand von Propensity Score mit logistischer Regression unter Verwendung der Matching-Variablen.

2. Regression Adjustment:

    (a) Schätze lediglich für die *Behandlungsgruppe* eine mit den IPW gewichtete Regressionspezifikation der Outcome-Variable mit Kontrolle für die Matching-Variablen.
  
    (b) Wiederhole Schritt A für *Kontrollgruppe*.

3. Berechne Vorhersagen der Outcome-Variable für die angepassten Modelle aus 2 (a) und 2 (b) anhand des *gesamten* Datensatzes.

4. Schätze den ATE als Mittelwert-Differenz der Vorhersagen aus Schritt 3.

:::




Wir implementieren den Doubly-Robust-Schätzer des ATE von @Wooldrige2010 für das Website-Beispiel in der Funktion `IPWRA()` under Adaption des Schemas von `IPW_boot()`.

```{r}
# IPW estimation with regression adjustment
IPWRA <- function(
    data, 
    i = i) {
  
    # Bootstrap-Stichprobe zuweisen
    b_data <- data %>% 
      slice(i)
    
    # Logistische Regression
    glm_fit <- glm(
      formula = dark_mode ~ age + hours + male,
      data = b_data, 
      family = binomial(link = 'logit')
    )
    
    # Propensity Scores berechnen
    b_data <- b_data %>%
        mutate(ps = predict(glm_fit, type = 'response'))
    
    # Propensity Scores trimmen
    b_data <- b_data %>%
      filter(
        between(
          x = ps,
          left = .2,
          right = .7
          )
    )
    
    # IPW berechnen
    b_data <- b_data %>%
      mutate(
        IPW = case_when(
          dark_mode == 1 ~ 1 / ps,
          dark_mode == 0 ~ 1 / (1 - ps))
      )
    
    # Regression Adjustment:
    
    # Schätzung des Behandlungseffekts für die ges. Stichprobe
    # mit Modell für Behandlungsgruppe
    mtreat <- b_data %>%
      filter(dark_mode == 1) %>%
      lm(read_time ~ age + hours + male, data = ., weights = .$IPW) %>%
      predict(newdata = b_data) %>%
      mean()

    # Schätzung des Behandlungseffekts für die ges. Stichprobe
    # mit Modell für Kontrollgruppe   
    mcont <- b_data %>%
      filter(dark_mode == 0) %>%
      lm(read_time ~ age + hours + male, data = ., weights = .$ipw) %>%
      predict(newdata = b_data) %>%
      mean()
    
    # Regression adjusted ATE-Schätzer
    return(mtreat - mcont)
}
```

Schätzung des ATE mit `IPWRA()`:

```{r}
IPWRA(data = darkmode, i = 1:nrow(darkmode))
```

Wie bei $\widehat{\tau}^\text{IPW}$ gibt es keine formale Darstellung des Standardfehlers für den IPWRA-Schätzer, sodass auch hier der Bootstrap genutzt werden sollte.

```{r}
set.seed(1234)

# Bootrstrap für IPWRA durchführen
(
  b_IPWRA <- boot(
  data = darkmode,
  statistic = IPWRA,
  R = B
  )
)
```

Wir berechnen die interessierenden Statistiken analog zu der Vorgehensweise in @sec-bootmatching.

```{r}
# Bootstrap-IPWRA-Schätzer des ATE
mean(b_IPWRA$t)

# Bootstrap-Standardfehler
sd(b_IPWRA$t)
```

```{r}
# 95%-Bootstrap-KI für den ATE
boot.ci(b_IPWRA, type = "bca")
```

Die Bootstrap-Schätzung des ATE mit IPWRA ist mit den Ergebnissen für die Bootstrap-Variante von $\widehat{\tau}^\text{IPW}$ vergleichbar, hat allerdings einen etwas kleineren Standardfehler und ist somit genauer.
