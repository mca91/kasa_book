---
webr: 
  show-startup-message: true
  packages: [
            'boot', 
            'cobalt', 
            'marginaleffects', 
            'MatchIt', 
            'sandwich',
            'ggplot2'
            ]
---

# Matching

```{r, echo=F, message=FALSE}
library(gt)
library(tidyverse)
# Formatierung von gt-Tabellen
tabopts <- function(x) {
    fmt_number(x, decimals = 3, drop_trailing_zeros = T) %>%
  tab_options(table_body.hlines.color = "white", 
              column_labels.border.bottom.color = "black", 
             column_labels.border.top.color = "black",
             table_body.border.bottom.color = "black", 
             table.border.bottom.color = "black",
             column_labels.font.weight = "bold", 
             table.font.color = "black", 
             table.font.size = 16)
}
```

```{webr-r}
#| context: setup
webr::install("dplyr")

# create dataset directory
dir.create("datasets")
# Download the dataset
download.file(
    "https://raw.githubusercontent.com/mca91/kausal_data/main/darkmode.csv",
    'datasets/darkmode.csv',
)
```

```{webr-r}
#| context: setup
library(dplyr)
# make darkmode available using read.csv for now
# because there's some issue with readr::read_csv
# I can't fix right now
darkmode <- read.csv(
    file = "datasets/darkmode.csv", 
    colClasses = c("numeric", "logical", "numeric", "numeric", "numeric") 
)

options(pillar.bold = TRUE, pillar.subtle = FALSE)
```

In randomisierten kontrollierten Studien stellt eine randomisierte Behandlung sicher, dass die Individuen beider Gruppen im Mittel vergleichbar sind, dass heißt es gibt keine systematischen Unterschiede der Studiensubjekte hinsichtlich der Verteilung von Charakteristika zwischen den Gruppen. Dann ist es plausibel eine beobachtete mittlere Differenz in der Outcome-Variable alleine auf die Behandlung zurückzuführen.

In der Praxis, insbesondere in ökonomischen Studien, sind randomisierte kontrollierte Studien aus ethischen und/oder finanziellen Gründen nicht durchführbar. Stattdessen werden nicht-experimentelle Daten genutzt, die jedoch nur sehr selten eine Vergleichbarkeit von Behandlungs- und Kontrollgruppe gewährleisten.

In diesem Kapitel betrachten wir Methoden, die in solchen Forschungsdesigns -- bei hinreichenden Informationen über die Studiensubjekte -- eine Schätzung kausaler Effekte ermöglichen, indem eine Vergleichbarkeit von Behandlungs- und Kontrollgruppe hergestellt wird. Dies kann über eine gezielte Gewichtung von Beobachtungen anhand invididueller Merkmale erfolgen. Eine etablierte Methode ist die Schätzung des kausalen Effekts nach Selektion von vergleichbaren Teilmengen von Subjekten beider Gruppen aus der ursprünglichen Stichprobe, sogenanntes *Matching*.

## Gewichtete Mittelwerte und Matching

Der Lehrstuhl für Ökonometrie an der Universität Duisburg-Essen verwaltet betreibt einen Ökonometrie-Blog und interessiert sich für den kausalen Effekt der Einführung eines [darkmode](https://en.wikipedia.org/wiki/Wikipedia:Dark_mode) auf die Verweildauer der User auf der Webseite. Die Webseite ist zwar nicht-kommerziell, hat sich allerdings insb. für die Aquise internationaler Studierender für den Studiengang MSc. Econometrics als wichtiges Marketing-Instrument erwiesen. Ein anprechendes Design wird daher als hoch-relevant erachtet. 

Idealerweise sollte der Effekt des Design-Relaunches auf die Nutzungsintensität in einem kontrollierten randomisierten Experiment untersucht werden. Hierbei würden wir Nutzern zufällig das neue oder das alte Design zuweisen und den Effekt als Differnz des durchschnittlichen Verweildauer für die Gruppen bestimmen. Eine solche Studie ist jedoch aus technischen und finanziellen Gründen nicht realisierbar, sodass die Auswirkungen des darkmode mit vorliegenden nicht-experimenellen Nutzungsstatistiken für die Webseite geschätzt werden sollen. 

Die Nutzungsstatistiken sind im Datensatz [*darkmode.csv*](https://raw.githubusercontent.com/mca91/kasa_data/main/darkmode.csv) enthalten und sollen der Analyse des Effekts des darkmode (`dark_mode`) auf die Verweildauer der Leser auf der Webseite (`read_time`) dienen.

@tbl-darkmode zeigt die Definitionen der Variablen in *darkmode.csv*.

```{r, echo = F}
#| tbl-cap: "Variablen im Datensatz *darkmode*"
#| label: tbl-darkmode
tibble(
  Variable = c(
    "read_time", 
    "dark_mode", 
    "male", 
    "age", 
    "hours"
    ),
  Beschreibung = c(
    "Lesezeit (Minuten/Woche)",
    "Indikator: Beobachtung nach Einführung darkmode",
    "Indikator: Individuum männlich",
    "Alter (in Jahren)",
    "Bisherige Verweildauer auf der Seite"
  )
) %>%
  gt() %>%
  tabopts
```

Für die Analyse lesen wir zunächst den Datensatz *darkmode.csv* mit `readr::read_csv()` ein und verschaffen uns einen Überblick über die verfügbaren Variablen. 

```{r, message=FALSE}
# Paket `tidyverse` laden
library(tidyverse)

# Datensatz 'darkmode' einlesen
darkmode <- read_csv(
  file = "datasets/darkmode.csv"
)
```

`dark_mode` hat den Typ `logical`. Mit `dplyr::mutate_all()` können wir komfortabel alle Spalten in den Typ `numeric` transformieren.

```{r}
# Alle Variablen zu typ 'numeric' formatieren...
darkmode <- darkmode %>% 
  mutate_all(.funs = as.numeric)

# ... und überprüfen
glimpse(darkmode)
```

Eine naive Schätzung des durchschnittlichen Behandlungseffekts (ATE) $\widehat{\tau}^{\text{naiv}}$ erhalten wir als Mittelwertdifferenz von `read_time` für die Behandlungsgruppe (`dark_mode == 1`) und die Kontrollgruppe (`dark_mode == 0`)
\begin{align}
  \widehat{\tau}^{\text{naiv}} = \overline{\text{read\_time}}_{\text{Behandlung}} - \overline{\text{read\_time}}_{\text{Kontrolle}}.\label{eq:naivATEdarkmode}
\end{align}

Diese Berechnung ist schnell mit R durchgeführt.

```{r}
# Naiver Schätzer für ATE: 
# Differenz der Gruppen-Durchschnitte

# Outcome in Behandlungsgruppe
read_time_mTG <- darkmode %>% 
  filter(dark_mode == 1) %>% 
  pull("read_time")

# Outcome in Kontrollgruppe
read_time_mKG <- darkmode %>% 
  filter(dark_mode == 0) %>% 
  pull("read_time")

# Mittelwert-Differenz
mean(read_time_mTG) - mean(read_time_mKG)
```

Die Schätzung ergibt einen negativen Behandlungseffekt, mit der Interpreation, dass das neue Design zu einer Reduktion der Lesezeit um etwa 0.44 Minuten pro Woche führt. Dieses Ergebnis ist allerdings zweifelhaft, weil eine Isolierung des Behandlungseffekts aufgrund von Backdoor-Pfaden im DGP vermutlich nicht gewähleistet ist. Ein Indikator hierfür sind systematische Unterschiede hinsichtlich von (möglicherweise unbeobachtbaren) Charakteristika von Kontrollgruppe und Behandlungsgruppe.

Da die User sich beim Aufrufen der Seite aktiv für oder gegen den das neue Design entscheiden müssen (und somit selektieren, ob Sie in der Behandlungs- oder Kontrollgruppe landen), liegt wahrscheinlich *Confounding* vor: Unsere Hypothese ist zunächst, dass männliche User eine durchschnittlich längere Lesezeit aufweisen *und* mit größerer Wahrscheinlichkeit auf das neue Design wechseln als nicht-männliche Leser. Dann ist `male` eine Backdoor-Variable. Diese Situation ist unter der Annahme, dass nur diese Faktoren den DGP bestimmen, in @fig-maleCDdarkmode dargestellt.

```{dot}
//| fig-width: 4
//| fig-height: 3
//| fig-align: 'center'
//| fig-cap: "Backdoor durch 'male' im Website-Design-Bespiel"
//| label: "fig-maleCDdarkmode" 
digraph {
  layout=neato
  fontname="Helvetica,Arial,sans-serif"
  node [fontname="Helvetica,Arial,sans-serif"]
  edge [fontname="Helvetica,Arial,sans-serif"]
  node [shape=none];
  "read_time" [pos="4,0.5!"]
  "dark_mode" [pos="0,0.5!"]
  "male" [pos="2,-1!"]
  "dark_mode" -> "read_time" [color="green"]
  "male" -> "dark_mode" [color="red"]
  "male" -> "read_time" [color="red"]
}
```

Der DGP in @fig-maleCDdarkmode führt zu einer verzerrten Schätzung des kausalen Effekts von `dark_mode` auf `read_time` mit \eqref{eq:naivATEdarkmode}, wenn das Verhältnis von männlichen und nicht-männlichen Usern in Bahandlungs- und Kontrollgruppe sich systematisch unterscheided. Wir überprüfen dies mit R.

```{r}
# Anteile männlicher und nicht-männlicher User
(
  anteile <- darkmode %>% 
  group_by(dark_mode) %>% 
  summarise(
    gesamt = n(),
    ant_m = mean(male),
    ant_nm = 1 - ant_m,
    anz_m = sum(male),
    anz_nm = gesamt - anz_m
    )
)
```

Die Zusammenfassung `anteile_m` zeigt, dass der Anteil männlicher User in der Behandlungsgruppe deutlich höher ist als in der Kontrollgruppe.

Ein Schätzer basierend auf einem Matching eliminiert die Variation von `male` zwischen den Gruppen. Eine Möglichkeit hierfür ist die Gewichtung der Beobachtungen in der Kontrollgruppe entsprechend der Anteile von Mönnern und Nicht-Männern in der Behandlungsgruppe, sodass die Vergleichbarkeit hinsichtlich des Geschlechts gewährleistet ist. Hierzu berechnen wir zunächst die Gewichte als
\begin{align}
  w_i = 
  \begin{cases}
    \text{ant\_m}_B/\text{anz\_m}_{K}, & \text{falls } \text{male}_i = 1\\
        \text{ant\_nm}_B/\text{anz\_nm}_{K}, & \text{sonst.}\\
  \end{cases}
\end{align}
Anhand der Formel
\begin{align}
  \overline{X}_w = \frac{\sum_i w_i \cdot X_i}{\sum_i w_i}
\end{align}
berechnen wir die gewichteten Mittelwerte für `male` und `read_time` in der Kontrollgruppe.

```{r}
# Anteile und Anzahlen auslesen
anz_m_K <- anteile %>% 
  filter(dark_mode == 0) %>% pull(anz_m)
anz_nm_K <- anteile %>% 
  filter(dark_mode == 0) %>% pull(anz_nm)
ant_m_B <- anteile %>% 
  filter(dark_mode == 1) %>% pull(ant_m)
ant_nm_B <- anteile %>% 
  filter(dark_mode == 1) %>% pull(ant_nm)
```

```{r}
# Gewichtete Mittelwerte für Kontrollgruppe
(
gew_K <- darkmode %>% 
  filter(dark_mode == 0) %>% 
  select(read_time, male) %>%
  mutate(w = ifelse(
    male == 1, 
    ant_m_B/anz_m_K, 
    ant_nm_B/anz_nm_K)
    ) %>%
  summarise(
    male_k = sum(male * w) / sum(w),
    mean_read_time_wK = sum(read_time * w) / sum(w)
  )
)
```

Ein Vergleich des gewichteten Mittelwertes von `male` in der Kontrollgruppe mit dem Mittelwert in der Behandlungsgruppe (`male_k`) zeigt, dass die Gewichte die Variation in `male` zwischen beiden Gruppen eliminieren. Mit `wmean_read_time_K` haben wir einen entsprechend gewichteten Mittelwert der Verweildauer für die Kontrollgruppe berechnet. Wir schätzen den Behandlungseffekt nun als
\begin{align}
  \widehat{\tau}^{\text{w}} = \overline{\text{read\_time}}_{B} - \overline{\text{read\_time}}_{w,K}.
\end{align}

```{r}
mean(read_time_mTG)  - gew_K$mean_read_time_wK
```



### *Balance*: Vergleichbarkeit von Behandlungs- und Kontrollgruppe









Weiterhin scheint plausibel, dass das Alter der Nutzer sowohl die Akzeptanz des Design-Updates als auch die Lesezeit beeinflusst. Die bisherige Verweildauer ist ebenfalls eine plausible Determinante der Lesezeit.

Der angenommene DGP ist in Abbildung @fig-CDdarkmode dargestellt, wobei Backdoor-Pfade mit roten Pfeilen gekennzeichnet sind.

```{dot}
//| fig-width: 4
//| fig-height: 3
//| fig-align: 'center'
//| fig-cap: "Vermuteter DGP im Website-Design-Bespiel"
//| label: "fig-CDdarkmode" 
digraph {
  layout=neato
  fontname="Helvetica,Arial,sans-serif"
  node [fontname="Helvetica,Arial,sans-serif"]
  edge [fontname="Helvetica,Arial,sans-serif"]
  node [shape=none];
  "read_time" [pos="4,0.5!"]
  "dark_mode" [pos="0,0.5!"]
  "male" [pos="2,-1!"]
  "age" [pos="2,2!"]
  "hours" [pos="4,2!"]
  "hours" -> "read_time"
  "age" -> "dark_mode" [color="red"]
  "age" -> "read_time" [color="red"]
  "dark_mode" -> "read_time" [color="green"]
  "male" -> "dark_mode" [color="red"]
  "male" -> "read_time" [color="red"]
}
```

Zur Beurteilung der Vergleichbarkeit von Kontrollgruppe und Behandlungsgruppe empfiehlt sich eine Gegenüberstellung der empirischen Verteilungen der Kovariablen beider Gruppen. Wir visualisieren die empirischen Verteilungen zunächst mit `ggplot2`. Hierzu transformieren wir `male` und `dark_mode` in den Typ `factor` und standardisieren `age` und `hours` mit `scale()`.

```{webr-r}
# Datensatz für graphische Darstellung formatieren
darkmode_p <- darkmode %>% 
  # Standardisierung mit 'scale()'
  mutate(
    male = as.factor(male), 
    dark_mode = as.factor(dark_mode),
    age = scale(age), 
    hours = scale(hours)
  )

head(darkmode_p)
```

Für `age` und `hours` eignen sich die geschätzten Dichtefunktionen für einen Vergleich der Verteilungen in Behandlungs- und Kontrollgruppe.

```{webr-r}
# Vergleich mit Dichteschätzungen
darkmode_p %>%
  select(dark_mode, hours, age) %>%
  # in langes Format überführen
  pivot_longer(cols = c(-dark_mode)) %>%
  
  ggplot(
    aes(x = value, fill = dark_mode)
    ) +
  geom_density(alpha = .5) + 
  facet_wrap(
    facets = ~ name, 
    scales = "free", 
    nrow = 2
    )
```

Für `male` vergleichen wir die relativen Häufigkeiten mit Balkendiagrammen.

```{webr-r}
# Relative Hfkt. für 'male' als barplot
darkmode_p %>%
  ggplot(
    aes(x = dark_mode, fill = male)
    ) +
  geom_bar(position = "fill") +
  ylab("Anteil")
```

Die graphische Analyse zeigt deutliche Unterschiede in den Verteilungen von `age` und `male` zwischen Kontroll- und Behandlungsgruppe. Für einen Beurteilung mit deskriptiven Statistiken wird häufig eine sogenannte *Balance Table* herangezogen. Wir berechnen diese für `age`, `hours` und `male` mit `cobalt::bal.tab()`

```{webr-r}
library(cobalt)

# Balance table mit 'cobalt::bal.tab()'
bal.tab(
  x = darkmode %>% 
    select(age, hours, male), 
  treat = darkmode$dark_mode, 
   # berechne SMD für KG und TG:
  disp = "m", 
  s.d.denom = "pooled"
)
```

Die Einträge `M.0.Un` und `M.1.Un` zeigen die jeweiligen Stichprobenmittelwerte der Variablen für Kontroll- und Behandlungsgruppe. `Diff.U` gibt eine standardisierte Mittelwertdifferenz $SMD$ an, wobei
\begin{align*}
  SMD_j := \left(\overline{X}_{j,B} - \overline{X}_{j,K}\right) \bigg/ \sqrt{\frac{1}{2}\left(\widehat{\text{Var}}(X_{j,B}) + \widehat{\text{Var}}(X_{j,K})\right)},
\end{align*}
mit Stichprobenmitteln $\overline{X}_{j,B}$ und $\overline{X}_{j,K}$ und Stichprobenvarianzen $\widehat{\text{Var}}(X_{j,B})$ und $\widehat{\text{Var}}(X_{j,K})$ für eine kontinuierliche Kovariable $j$.^[Siehe @Austin2011 für einen Überblick zu Balance-Statistiken.] Obwohl es keinen einheitlichen Schwellenwert für die standardisierte Differenz gibt, der ein erhebliches Ungleichgewicht anzeigt, gilt für kontinuierliche Variablen eine standardisierte (absolute) Differenz von weniger als $0.1$ als Hinweis auf einen vernachlässigbaren Unterschied zwischen den Gruppen.

Die Balance Table weist also auf einen vernachlässigbaren Unterschied für `hours` und bestätigt die aus den Grafiken abgeleiteten Hinweise auf relevante Differenzen für `age` und `male`. 

###

### Inverse Probability Weighting

### Propensity score

```{webr-r}
lm(
   formula = read_time ~ dark_mode + age + male + hours,
   data = darkmode
 ) %>%
   summary()
```


```{webr-r}
# Logit-Modell mit 'glm()' schätzen
(
  darkmode_ps_logit <- glm(
    formula = dark_mode ~ age + male + hours,
    data = darkmode,
    family = binomial
  )
)
```

```{webr-r}
# Datensatz um propensity scores erweitern
(
  darkmode_probabilities <- 
    darkmode %>%
    mutate(
      propensity = fitted(darkmode_ps_logit)
    )
)
```

Inverse probability weights (IPWs) anhand der PS können schnell anhand der Vorschrift $$\texttt{ipw} = \texttt{dark\_mode} / \texttt{propensity} + (1 - \texttt{dark\_mode}) / (1 - \texttt{propensity}), \quad \texttt{dark\_mode} \in\{0,1\}$$
berechnet werden.

```{webr-r}
# Datensatz um IPWs erweitern
darkmode_ipw <- darkmode_probabilities %>%
  mutate(
    ipw = dark_mode / propensity + (1 - dark_mode) / (1 - propensity)
  )

darkmode_ipw %>% 
  select(ipw)
```

Verteilung der Propensity Scores nach Behandlungs-Indikator:

```{webr-r}
# Dichteschätzung der PS nach Treatment-Indikator
darkmode_ipw %>%
ggplot(
  mapping = aes(
    x = propensity, 
    fill = factor(dark_mode))
  ) + 
  lims(x = c(0, 1)) +
  geom_density(alpha = .5, )
```

Beobachtungen aus der Kontroll-Gruppe entfernen, die außerhalb des Supports der Treatment-Gruppe liegen.

```{webr-r}
# Propensity scores auslesen
darkmode_ipws <- darkmode_ipw %>% 
  filter(dark_mode == 1) %>% 
  pull(propensity)

# Support sicherstellen 
# (entfernt 13 Beobachtungen aus der Kontrollgruppe)
darkmode_ipw <- darkmode_ipw %>% 
  filter(
    between(
      propensity,
      darkmode_ipws %>% 
        min(),
      darkmode_ipws %>% 
        max()
    )
  )
```

Die Abdeckung können wir erneut mit einer Grafik geschätzter Dichtefunktionen vergleichen.

```{webr-r}
# Dichteschätzung der PS per Treatment-Indikator nach Anpassung
darkmode_ipw %>%
  ggplot(
    mapping = aes(
      x = propensity, 
      fill = factor(dark_mode)
    )
  ) + 
  lims(x = c(0, 1)) +
  geom_density(alpha = .5)
```

Wir finden etwas weniger Wahrscheinlichkeits-Masse nahe 0 für die Kontroll-Gruppe nach filtern von (Kontroll-)Beobachtungen mit PS in der Spannweite der PS in der Behandlungs-Gruppe. Als nächstes schätzen wir den ATE mit linearer Regression.

```{webr-r}
# Mit IPWs gewichteter KQ-Schaetzer berechnet einen ATE
model_ipw <- lm(
  formula = read_time ~ dark_mode, 
  data = darkmode_ipw,
  weights = ipw
)

summary(model_ipw)
```

Unsere Schätzung des ATE ist der geschätzte Koeffizient von `dark_mode`. Die ausgegebenen Standardfehler und Inferenzstatistiken sind *ungültig* aufgrund der Gewichtung mit IPWs, inversen *geschätzten*  Wahrscheinlichkeiten für eine Behandlung. Der Grund hierfür ist, dass die Standardformel in `summary()`  die zusätzliche Unsicherheit durch die IPW-Schätzung nicht berücksichtigt!

Die Vergleichbarkeit der Nutzer in Kontroll- und Behandlungsgruppe-Gruppe für die Variablen `age`, `hours` und `male` können wir graphisch und anhand einer *balance table* vergleichen.

```{webr-r}
# Dichteschätzungen
darkmode %>% 
  group_by(dark_mode) %>%
  select(age, hours) %>%
  mutate_all(scale) %>% # Standardisierung mit 'scale()'
  pivot_longer(cols = c(-dark_mode)) %>% # langes Format
  
  ggplot(aes(x = value, fill = as.factor(dark_mode))) +
  geom_density( alpha = .5) + 
  facet_wrap(~ name, scales = "free", nrow = 3) # Facetting nach 'name'

# Relative Hfkt. für 'male' als barplot
darkmode %>% 
  group_by(dark_mode) %>%
  mutate(
    male = as.factor(male), 
    dark_mode = as.factor(dark_mode)
  ) %>%
  
  ggplot(aes(x = dark_mode, fill = male)) +
  geom_bar(position = "fill") +
  ylab("Anteil")

# Balance table mit 'cobalt::bal.tab()'
bal.tab(
  x = darkmode %>% 
    select(age, hours, male), 
  treat = darkmode$dark_mode, 
  disp = "m", # zeige zusätzlich Mittelwerte für C und T
)
```

Wir zeigen als nächstes, wie `MatchIt::matchit()` für Nearest-neighbor-Matching anhand der Regressoren `age`, `hours`, und `male` in unterschiedlichen Varianten durchgeführt werden kann. 

`MatchIt::matchit()` führt standardmäßig 1:1-Matching (ohne Zurücklegen) von Beobachtungen der Treatment-Gruppe mit Beobachtungen der Kontrollgruppe druch. Das Objekt wird für eine Schätzung des ATT mit einer geeigneten Funktionen vorbereitet, s. `?matchit`, und hier insb. die Argumente `replace = F`, `ratio = 1` und `estimand = "ATT"` für Details. 

Mit `cobalt::balt.tab()` erhalten wir eine *balance table* für den gematchten Datensatz.

**Exaktes Matching**
    
```{webr-r}
res <- matchit(
  formula = dark_mode ~ age + male + hours, 
  data = darkmode, 
  method = "exact"
)
bal.tab(res)
```

**Eins-zu-Eins-Matching: Mahalanobis-Distanz**
    
```{webr-r}
res <- matchit(
  formula = dark_mode ~ age + male + hours, 
  data = darkmode, 
  distance = "mahalanobis", 
  method = "nearest"
)
bal.tab(res)
```

**Eins-zu-Eins-Matching: Mahalanobis-Distanz mit Caliper 0.25 für propensity scores basierend auf logistischer Regression**

```{webr-r}
res <- matchit(
  formula = dark_mode ~ age + male + hours, 
  data = darkmode, 
  distance = "glm", 
  caliper = .25,
  mahvars = ~ age + male + hours
)
# (Nur K-Beobachtungen mit PS bei Caliper .25 kommen für MHD-Matching in betracht.)
bal.tab(res)
```

**4. Eins-zu-Eins-Matching: Propensity scores basierend auf logistischer Regression mit Caliper 0.25**
        
```{webr-r}
res <- matchit(
  formula = dark_mode ~ age + male + hours, 
  data = darkmode, 
  method = "nearest", 
  distance = "glm", 
  caliper = .25
)
bal.tab(res)
```
    
Die Vergleichbarkeit der Nutzer in Kontroll- und Treatment-Gruppe hinsichtlich der Variablen `age`, `hours` und `male` können wir graphisch und anhand einer *balance table* vergleichen. Wir berechnen die balance table mit `cobalt::bal.tab()` für den anhand von Variante 4 gematchten Datensatz.

```{webr-r}
bal.tab(res, un = T, disp = "m")

# Der gematchte Datensatz enthält Gewichte für die jeweilige 
# Subklasse zu denen die Beobachtungen gehören.
#
# Hier 1:1 matching _ohne_ Zurücklegen, d.h. sämtliche
# Gewichte sind 1 und wird müssten diese nicht für nachfolgende 
# Aufrufe von avg comparisons berücksichtigen.
darkmode_matched <- match.data(res)

darkmode_matched %>%
  group_by(dark_mode) %>%
  select(age, hours) %>%
  mutate_all(scale) %>%
  pivot_longer(cols = c(-dark_mode)) %>%
  
  ggplot(aes(x = value, fill = as.factor(dark_mode))) +
  geom_density( alpha = .5) + 
  facet_wrap(~ name, scales = "free", nrow = 3)

darkmode_matched %>% 
  group_by(dark_mode) %>%
  mutate(
    male = as.factor(male), 
    dark_mode = as.factor(dark_mode)
  ) %>%
  
  ggplot(aes(x = dark_mode, fill = male)) +
  geom_bar(position = "fill") +
  ylab("Anteil")
```

Wir beobachten eine bessere Balance bei `age` und `hours`. Am wichtigsten: `gender` (`male`) ist nahezu ausgeglichen für Kontroll- und Treatment-Gruppe!

Wir schätzen nun den ATT von `dark_mode` auf `read_time` mit linearer Regression für den gematchten Datensatz aus sowie für den ursprünglichen Datensatz und berechnen jeweils ein robustes 95%-Konfidenzintervall für den ATT.

```{webr-r}
# ATT mit linearem Modell für ungematchten Datensatz schätzen
ATT_mod_org <- lm(
  formula = read_time ~ age + male + hours + dark_mode,
  data = darkmode
)
summary(ATT_mod_org)

# ATT mit linearem Modell für gematchten Datensatz schätzen
ATT_mod <- lm(
  formula = read_time ~ age + male + hours + dark_mode,
  data = darkmode_matched, 
  weights = weights 
)
# (weights = 1 für alle Beobachtungen weil wg. 1:1-Matching
# nur 2er-Paare von Beobachtungen. Hier also vernachlässigbar.
# Andere Gewichtung bei k:1-Matching!)
summary(ATT_mod)
```

**Achtung**: Für Matching-Verfahren (`ATT_mod`) sind die von `summary()` berechneten Standardfehler (und damit KI, t-Statistiken und p-Werte) für den ATT *grundsätzlich ungültig* Wir haben 3 Quellen von Schätzunsicherheit, die bei der Berechnung von Standardfehlern berücksichtigt werden müssen: Die Schätzung der PS, der Matching-Prozess und die "übliche" Stichproben-Variabilität. Wir nutzen daher nachfolgende Funktionen gem. Empfehlungen aus der aktuellen Forschung für Standardfehlerberechnung. S. auch Aufgabe 5 (a).

```{webr-r}
library(marginaleffects)

# Inferenz Multiple Regression bei ungematchten Beobachtungen
# identisch zu 'coeftest(ATT_mod_org, vcovHC, type = "HC3")'
avg_comparisons(
  model = ATT_mod_org,
  variables = "dark_mode",
  vcov = "HC3", # Heteroskedastie-robuster SE
  newdata = subset(darkmode, dark_mode == 1) # Identifiziert Kontrollgruppe
) 

# Inferenz Multiple Regression bei _gematchten_ Beobachtungen
avg_comparisons(
  model = ATT_mod,
  variables = "dark_mode",
  vcov = ~subclass, # cluster robust SE > als oben => mehr Unsicherheit
  newdata = subset(darkmode_matched, dark_mode == 1),
  wts = "weights"  # = 1
)
# ( Weights = 1 wg. 1:1-Matching.
# Anzahl subclasses = Anzahl gematchter treatment/control units )
```



## Inferenz für ATT/ATE: Propensity-Score-Matching mit Bootstrap

Bei Matching mit Zurücklegen besteht zusätzliche Unsicherheit durch Zurücklegen, d.h. Beobachtungen aus der Kontroll-Gruppe können mehrfach als Match für Beobachtungen aus der Treatment-Gruppe genutzt werden. Mit `summary()` berechnete Standardfehler berücksichtigen dies nicht!

Ein Bootstrap-Verfahren generiert mit Resampling (wiederholtes Ziehen mit Zurücklegen) aus dem Original-Datensatz (viele) künstliche Datensätze, für die der Schätzer (d.h. das gesamte Verfahren inkl. Matching!) jeweils berechnet wird. Die Verteilung der so gewonnenen Bootstrap-Schätzwerte approximiert die wahre, unbekannte Stichprobenverteilung des Schätzers des Behandlungseffekts. Mit dieser simulierten Verteilung können wir Inferenz betreiben: Wir können einen Bootstrap-Punktschätzer des Behandlungseffekts (Stichprobenmittel der Bootstrap-Schätzungen) sowie Standardfehler (Standardabweichung der der Bootstrap-Schätzungen) und p-Werte berechnen.

Wir Implementieren nun einen Bootstrap-Schätzer des ATT als `R`-Funktion `boot_fun()`.

```{webr-r}
boot_fun <- function(data, i) {
  
  boot_data <- data[i, ]
  
  # 1:1 PS Matching _mit_ Zurücklegen
  match_res <- matchit(dark_mode ~ age + hours + male,
                       data = boot_data,
                       caliper = .25,
                       replace = TRUE) # Zurücklegen
  
  # Gematchten Datensatz zuweisen
  darkmode_matched <- match.data(match_res, data = boot_data)
  
  # Outcome-Modell schätzen
  ATT_mod <- lm(
    formula = read_time ~ age + male + hours + dark_mode,
    data = darkmode_matched, 
    weights = weights # hier teilweise > 1 wg. Matching mit Zurücklegen!
  )
  
  #  ATT-Schätzer auslesen
  return(
    ATT_mod$coefficients["dark_mode"]  
  )
}
```


Abadie & Imbens (2008) zeigen analytisch, dass ein Standard-Bootstrap bei Matching grundsätzlich ungültig ist: Die unbekannte Varianz der Stichprobenverteilung des Matching-Schätzers (und damit der Standardfehler des Schätzers) kann durch den Bootstrap nicht repliziert werden. Problematisch hierbei sind grundsätzlich zu liberale (d.h. zu große) mit dem Bootstrap berechnete Standardfehler. Es gibt jedoch Simulationsnachweise die zeigen, dass Bootstrap-Standardfehler bei Matching mit Zurücklegen konservativ sind (Bodory et al., 2020), also tendentiell zu kleine Standardfehler produzieren und damit das gewünschte nominale Signifikanzniveau eines Bootstrap-Hypothesentests nicht überschritten wird.

Wir berechnen nun eine Bootstrap-Schätzung des ATT von `dark_mode` auf `readingtime` sowie den zugehörigen Standardfehler und ein 95%-KI mit der zuvor definierten Funktion `boot_fun`.

```{webr-r}
library("boot")
set.seed(4321)
boot_out <- boot(darkmode, boot_fun, R = 999)

boot_out
```

```{webr-r}
# Bootstrap-Schätzer für den Treatment-Effekt
mean(boot_out$t) 
# = mean(t0) + bias = mean(Bootstrap_samples)
# vgl. 't0 = boot_fun(darkmode, i = 1:1e3)'

# Bootstrap-Standardfehler
sd(boot_out$t)

# 95% Bootstrap-KI für den Treatment-Effekt
boot.ci(boot_out, type = "perc")
```


## Doubly-Robust-Schätzer für ATT/ATE

Implementieren und berechnen Sie einen Doubly-Robust-Schätzer des ATT (vgl. Wooldridge, 2010) für den kausalen Effekt in Aufgabe 5. Vergleichen Sie mit den Ergebnissen der Aufgaben 1 (d), 4 (f) und 5 (d).

```{webr-r}
# IPW estimation with regression adjustment
ipwra <- function(br, index = 1:nrow(br)) {
    # slice bootstrapped observations
    br <- br %>% slice(index)
    
    # estimate and predict propensity score
    m <- glm(formula = dark_mode ~ age + hours + male,
             data = br, 
             family = binomial(link = 'logit'))
    
    br <- br %>%
        mutate(ps = predict(m, type = 'response'))
    
    # trim control observations outside of treated PS range
    minps <- br %>%
        filter(dark_mode == 1) %>%
        pull(ps) %>%
        min(na.rm = TRUE)
    
    maxps <- br %>%
        filter(dark_mode == 1) %>%
        pull(ps) %>%
        max(na.rm = TRUE)
    
    # do the trimming
    br <- br %>%
        filter(ps >= minps & ps <= maxps)
    
    # compute IPWs
    br <- br %>%
      mutate(
        ipw = case_when(
          dark_mode == 1 ~ 1 / ps,
          dark_mode == 0 ~ 1 / (1 - ps))
      )
    
    # Simple _ATT_ estimate:
    # w_means <- br %>%
    #     group_by(dark_mode) %>%
    #     summarize(m = weighted.mean(read_time, w = ipw)) %>% 
    #     arrange(dark_mode)
    # 
    # # simple diff-in-means _ATT_ estimate
    #  return(w_means$m[2] - w_means$m[1]) 
    
    # Do regression adjustment for _ATE_ estimate
    # TE prediction for whole sample based on TG model
    mtreat <- br %>%
      filter(dark_mode == 1) %>%
      lm(read_time ~ 1 + age + hours + male, data = ., weights = .$ipw) %>%
      predict(newdata = br) %>%
      mean()
    
    # TE prediction for whole sample based on CG model
    mcont <- br %>%
      filter(dark_mode == 0) %>%
      lm(read_time ~ 1 + age + hours + male, data = ., weights = .$ipw) %>%
      predict(newdata = br) %>%
      mean()

    return(mtreat - mcont) # Regression adjusted _ATE_ estimate
}
```

```{webr-r}
b <- boot(data = darkmode, ipwra, R = 999)
# Bootstrap estimate and standard error
mean(b$t)
sd(b$t)
```

\vfill
# Literatur

Abadie, Alberto, and Guido W. Imbens. (2008). *On the Failure of the Bootstrap for Matching Estimators.*Econometrica 76 (**6**): 1537–57.

Bodory, H., Camponovo, L., Huber, M., & Lechner, M. (2020). *The Finite Sample Performance of Inference Methods for Propensity Score Matching and Weighting Estimators*. Journal of Business & Economic Statistics, 38(**1**), 183–200.

Wooldridge, J. M. (2010). *Econometric analysis of cross section and panel data*. MIT press.



