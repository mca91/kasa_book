---
webr: 
  show-startup-message: true
  packages: [
            'boot', 
            'cobalt', 
            'marginaleffects', 
            'MatchIt', 
            'sandwich',
            'ggplot2'
            ]
---

# Matching

```{r, echo=F, message=FALSE}
library(gt)
library(tidyverse)
# Formatierung von gt-Tabellen
tabopts <- function(x) {
    fmt_number(x, decimals = 3, drop_trailing_zeros = T) %>%
  tab_options(table_body.hlines.color = "white", 
              column_labels.border.bottom.color = "black", 
             column_labels.border.top.color = "black",
             table_body.border.bottom.color = "black", 
             table.border.bottom.color = "black",
             column_labels.font.weight = "bold", 
             table.font.color = "black", 
             table.font.size = 16)
}
```

```{webr-r}
#| context: setup
webr::install("dplyr")
webr::install("tidyr")

# create dataset directory
dir.create("datasets")
# Download the dataset
download.file(
    "https://raw.githubusercontent.com/mca91/kausal_data/main/darkmode.csv",
    'datasets/darkmode.csv',
)
```

```{webr-r}
#| context: setup
library(dplyr)
# make darkmode available using read.csv for now
# because there's some issue with readr::read_csv
# I can't fix right now
darkmode <- read.csv(
    file = "datasets/darkmode.csv", 
    colClasses = c("numeric", "logical", "numeric", "numeric", "numeric") 
)

options(pillar.bold = TRUE, pillar.subtle = FALSE)
```

In randomisierten kontrollierten Studien stellt eine randomisierte Behandlung sicher, dass die Individuen beider Gruppen im Mittel vergleichbar sind, dass heißt es gibt keine systematischen Unterschiede der Studiensubjekte hinsichtlich der Verteilung von Charakteristika zwischen den Gruppen. Dann ist es plausibel eine beobachtete mittlere Differenz in der Outcome-Variable alleine auf die Behandlung zurückzuführen.

In der Praxis, insbesondere in ökonomischen Studien, sind randomisierte kontrollierte Studien aus ethischen und/oder finanziellen Gründen nicht durchführbar. Stattdessen werden nicht-experimentelle Daten genutzt, die jedoch nur sehr selten eine Vergleichbarkeit von Behandlungs- und Kontrollgruppe gewährleisten.

In diesem Kapitel betrachten wir Methoden, die in solchen Forschungsdesigns -- bei hinreichenden Informationen über die Studiensubjekte -- eine Schätzung kausaler Effekte ermöglichen, indem eine Vergleichbarkeit von Behandlungs- und Kontrollgruppe hergestellt wird. Dies kann durch eine gezielte Gewichtung von Beobachtungen anhand invididueller Merkmale bei der Schätzung des Behandlungseffekts erfolgen. Andere etablierte Methoden schätzen den kausalen Effekt nach Selektion von vergleichbaren Teilmengen von Subjekten beider Gruppen aus der ursprünglichen Stichprobe, sogenanntes *Matching*.

Da *Matching* ähnliche Beobachtungen basierend auf beobachtbaren Merkmalen vergleicht, kann die Wahrscheinlichkeit einer verzerrten Schätzung des kausalen Effekt durch falsche Modellspezifikationen geringer sein als für eine Schätzung des Effekts anhand multipler Regression. Weiterhin basieren Matching-Methoden nicht auf der Annahme eines linearen Zusammenhangs zwischen Kovariablen und der erklärenden Variable und können für die Schätzung unterschiedlicher Spezifikationen von Behandlungseffekten herangezogen werden.

Für die Gültigkeit eines Schätzers basierend auf *Matching* sind zwei Annahmen erforderlich.

1.  ***Bedingte Unabhängigkeit.*** Seien $Y^{(0)}_i$ und $Y^{(1)}_i$ potentielle Ergebnisse der Outcome-Variable $Y$ für ein Subjekt $i$ mit $B_i=0$ (keine Zuweisung zur Behandlung) beziehungsweise $B_i=1$ (Behandlung) und $X_i$ die beobachteten Kovariablen. Wir nehmen an, dass \begin{align}
      \left\{Y^{(0)}_i, Y^{(1)}_i\right\} \perp B_i\vert X_i, \label{eq:cia}
    \end{align} d.h. die Behandlungszuweisung/-selektion ist unanabhängig von den potentielle Ergebnissen $Y^{(0)}_i$ und $Y^{(1)}_i$, wenn wir für die Kovariablen $X$ kontrollieren.

2.  ***Überlappung.*** Für jede mögliche Kombination von Kovariablen $X_i$ gibt es eine positive Wahrscheinlichkeit $<1$, sowohl zur Behandlungsgruppe ($B_i = 1$) als auch zur Kontrollgruppe ($B_i = 0$) zugewiesen zu werden, \begin{align}
      0 < \text{P}(B_i=1\lvert X_i) < 1, \label{eq:overlap}
    \end{align} d.h. keine Beobachtung hat eine Behandlungswahrscheinlichkeit von exakt $0$ oder $1$.

Annahme 1 stellt sicher, dass die Zuweisung zur Behandlungsgruppe nach Kontrolle für die Kovariablen $X$ als zufällig betracht werden kann. Somit ist es möglich den kausalen Effekt der Behandlung zu identifizieren, indem wir hinsichtlich der Kovariablen $X$ ähnliche Subjekte (vgl. Annahme 2) aus Kontroll- und Behandlungsgruppe vergleichen.

Annahme 2 setzt vorraus, dass es eine ausreichende Überlappung in den Verteilungen der Kovariablen zwischen Behandlungs- und Kontrollgruppe gibt. Dann ist sichergestellt, dass für jedes Subjekt in einer Gruppe ein hinsichtlich seiner Charakteristika vergleichbares Subjekt in der anderen Gruppe geben kann, sodass ein Vergleich möglich ist.

## *Balance*: Vergleichbarkeit von Behandlungs- und Kontrollgruppe {#sec-balance}

Der Lehrstuhl für Ökonometrie an der Universität Duisburg-Essen betreibt einen Ökonometrie-Blog und interessiert sich für den kausalen Effekt der Einführung eines [darkmode](https://en.wikipedia.org/wiki/Wikipedia:Dark_mode) auf die Verweildauer der User auf der Webseite. Die Webseite ist zwar nicht-kommerziell, hat sich allerdings insb. für die Aquise internationaler Studierender für den Studiengang MSc. Econometrics als wichtiges Marketing-Instrument erwiesen. Ein anprechendes Design wird daher als hoch-relevant erachtet.

Idealerweise sollte der Effekt des Design-Relaunches auf die Nutzungsintensität in einem kontrollierten randomisierten Experiment untersucht werden. Hierbei würden wir Nutzern zufällig das neue oder das alte Design zuweisen und den Effekt als Differnz des durchschnittlichen Verweildauer für die Gruppen bestimmen. Eine solche Studie ist jedoch aus technischen und finanziellen Gründen nicht realisierbar, sodass die Auswirkungen des darkmode mit vorliegenden nicht-experimenellen Nutzungsstatistiken für die Webseite geschätzt werden sollen.

Die Nutzungsstatistiken sind im Datensatz [*darkmode.csv*](https://raw.githubusercontent.com/mca91/kasa_data/main/darkmode.csv) enthalten und sollen der Analyse des Effekts des darkmode (`dark_mode`) auf die Verweildauer der Leser auf der Webseite (`read_time`) dienen.

@tbl-darkmode zeigt die Definitionen der Variablen in *darkmode.csv*.

```{r, echo = F}
#| tbl-cap: "Variablen im Datensatz *darkmode*"
#| label: tbl-darkmode
tibble(
  Variable = c(
    "read_time", 
    "dark_mode", 
    "male", 
    "age", 
    "hours"
    ),
  Beschreibung = c(
    "Lesezeit (Minuten/Woche)",
    "Indikator: Beobachtung nach Einführung darkmode",
    "Indikator: Individuum männlich",
    "Alter (in Jahren)",
    "Bisherige Verweildauer auf der Seite"
  )
) %>%
  gt() %>%
  tabopts
```

Für die Analyse lesen wir zunächst den Datensatz *darkmode.csv* mit `readr::read_csv()` ein und verschaffen uns einen Überblick über die verfügbaren Variablen.

```{r, message=FALSE}
# Paket `tidyverse` laden
library(tidyverse)

# Datensatz 'darkmode' einlesen
darkmode <- read_csv(
  file = "datasets/darkmode.csv"
)
```

`dark_mode` hat den Typ `logical`. Mit `dplyr::mutate_all()` können wir komfortabel alle Spalten in den Typ `numeric` transformieren.

```{r}
# Alle Variablen zu typ 'numeric' formatieren...
darkmode <- darkmode %>% 
  mutate_all(.funs = as.numeric)

# ... und überprüfen
glimpse(darkmode)
```

Eine naive Schätzung des durchschnittlichen Behandlungseffekts (ATE) $\widehat{\tau}^{\text{naiv}}$ erhalten wir als Mittelwertdifferenz von `read_time` für die Behandlungsgruppe (`dark_mode == 1`) und die Kontrollgruppe (`dark_mode == 0`) \begin{align}
  \widehat{\tau}^{\text{naiv}} = \overline{\text{read\_time}}_{\text{Behandlung}} - \overline{\text{read\_time}}_{\text{Kontrolle}}.\label{eq:naivATEdarkmode}
\end{align}

Diese Berechnung ist schnell mit R durchgeführt.

```{r}
# Naiver Schätzer für ATE: 
# Differenz der Gruppen-Durchschnitte

# Outcome in Behandlungsgruppe
read_time_mTG <- darkmode %>% 
  filter(dark_mode == 1) %>% 
  pull("read_time")

# Outcome in Kontrollgruppe
read_time_mKG <- darkmode %>% 
  filter(dark_mode == 0) %>% 
  pull("read_time")

# Mittelwert-Differenz
mean(read_time_mTG) - mean(read_time_mKG)
```

Die Schätzung ergibt einen negativen Behandlungseffekt, mit der Interpreation, dass das neue Design zu einer Reduktion der Lesezeit um etwa 0.44 Minuten pro Woche führt. Dieses Ergebnis ist allerdings zweifelhaft, weil eine Isolierung des Behandlungseffekts aufgrund von Backdoor-Pfaden im DGP vermutlich nicht gewähleistet ist. Ein Indikator hierfür sind systematische Unterschiede hinsichtlich von (möglicherweise unbeobachtbaren) Charakteristika von Kontrollgruppe und Behandlungsgruppe.

Da die User sich beim Aufrufen der Seite aktiv für oder gegen den das neue Design entscheiden müssen (und somit selektieren, ob Sie in der Behandlungs- oder Kontrollgruppe landen), liegt wahrscheinlich *Confounding* vor: Unsere Hypothese ist zunächst, dass männliche User eine durchschnittlich längere Lesezeit aufweisen *und* mit größerer Wahrscheinlichkeit auf das neue Design wechseln als nicht-männliche Leser. Dann ist `male` eine Backdoor-Variable. Diese Situation ist unter der Annahme, dass nur diese Faktoren den DGP bestimmen, in @fig-maleCDdarkmode dargestellt.

```{dot}
//| fig-width: 4
//| fig-height: 3
//| fig-align: 'center'
//| fig-cap: "Backdoor durch 'male' im Website-Design-Bespiel"
//| label: "fig-maleCDdarkmode" 
digraph {
  layout=neato
  fontname="Helvetica,Arial,sans-serif"
  node [fontname="Helvetica,Arial,sans-serif"]
  edge [fontname="Helvetica,Arial,sans-serif"]
  node [shape=none];
  "read_time" [pos="4,0.5!"]
  "dark_mode" [pos="0,0.5!"]
  "male" [pos="2,-1!"]
  "dark_mode" -> "read_time" [color="green"]
  "male" -> "dark_mode" [color="red"]
  "male" -> "read_time" [color="red"]
}
```

Der DGP in @fig-maleCDdarkmode führt zu einer verzerrten Schätzung des kausalen Effekts von `dark_mode` auf `read_time` mit \eqref{eq:naivATEdarkmode}, wenn das Verhältnis von männlichen und nicht-männlichen Usern in Bahandlungs- und Kontrollgruppe nicht ausgeglichen ist. Wir überprüfen dies mit R.

```{r}
# Anteile männlicher und nicht-männlicher User
(
  anteile <- darkmode %>% 
  group_by(dark_mode) %>% 
  summarise(
    gesamt = n(),
    ant_m = mean(male),
    ant_nm = 1 - ant_m,
    anz_m = sum(male),
    anz_nm = gesamt - anz_m
    )
)
```

Die Zusammenfassung `anteile_m` zeigt, dass der Anteil männlicher User in der Behandlungsgruppe deutlich höher ist als in der Kontrollgruppe.

Matching eliminiert die Variation von `male` zwischen den Gruppen. Eine Möglichkeit hierfür ist die Gewichtung der Beobachtungen in der Kontrollgruppe entsprechend der Anteile von Männern und Nicht-Männern in der Behandlungsgruppe, sodass die Vergleichbarkeit mit der Behandlungsgruppe hinsichtlich des Geschlechts gewährleistet ist. Dies wird in der Literatur als *Balance* bezeichnet. Der Behandlungseffekt wird dann analog zu \eqref{eq:naivATEdarkmode} geschätzt.

Die Gewichte für Beobachtungen in der Kontrollgruppe $w_i$ werden berechnet als \begin{align}
  w_i = 
  \begin{cases}
    \text{ant\_m}_B/\text{anz\_m}_{K}, & \text{falls } \text{male}_i = 1\\
        \text{ant\_nm}_B/\text{anz\_nm}_{K}, & \text{sonst.}\\
  \end{cases}\label{eq:darkmodeweights}
\end{align} Anhand der Formel für einen gewichteten Durchschnitt, \begin{align}
  \overline{X}_w = \frac{\sum_i w_i \cdot X_i}{\sum_i w_i},
\end{align} berechnen wir die gewichteten Mittelwerte für `male` und `read_time` in der Kontrollgruppe.

```{r}
# Anteile und Anzahlen aus `anteile` auslesen
anz_m_K <- anteile %>% 
  filter(dark_mode == 0) %>% pull(anz_m)

anz_nm_K <- anteile %>% 
  filter(dark_mode == 0) %>% pull(anz_nm)

ant_m_B <- anteile %>% 
  filter(dark_mode == 1) %>% pull(ant_m)

ant_nm_B <- anteile %>% 
  filter(dark_mode == 1) %>% pull(ant_nm)
```

```{r}
# Gewichtete Mittel für Kontrollgruppe berechnen
(
gew_K <- darkmode %>% 
  filter(dark_mode == 0) %>% 
  select(read_time, male) %>%
  mutate(w = ifelse(
    male == 1, 
    ant_m_B/anz_m_K, 
    ant_nm_B/anz_nm_K)
    ) %>%
  summarise(
    male_k = sum(male * w) / sum(w),
    mean_read_time_wK = sum(read_time * w) / sum(w)
  )
)
```

Ein Vergleich des gewichteten Mittelwertes von `male` in der Kontrollgruppe mit dem Mittelwert in der Behandlungsgruppe (`male_k`) zeigt, dass die Gewichte die Variation in `male` zwischen beiden Gruppen eliminieren, sodass die Backdoor durch `male` geschlossen ist. Mit `wmean_read_time_K` haben wir einen entsprechend gewichteten Mittelwert der Verweildauer für die Kontrollgruppe berechnet. Wir schätzen den Behandlungseffekt nun als \begin{align}
  \widehat{\tau}^{\text{w}} = \overline{\text{read\_time}}_{B} - \overline{\text{read\_time}}_{w,K}.\label{eq:weightedATEdarkmode}
\end{align}

```{r}
mean(read_time_mTG)  - gew_K$mean_read_time_wK
```

Entgegen der naiven Schätzung andhand von \eqref{eq:naivATEdarkmode} erhalten wir nach Matching für `male` eine positive Schätzung des Behandlungseffekts von etwa $`r round(mean(read_time_mTG) - gew_K$mean_read_time_wK, 2)`$.

Die Schätzung des Behandlungseffekts anhand von \eqref{eq:weightedATEdarkmode} entspricht dem geschätzten Koeffizienten $\widehat{\beta}_1$ aus einer gewichteten KQ-Regression im Modell \begin{align*}
  \text{read\_time} = \beta_0 + \beta_1 \text{dark\_mode} + u,
\end{align*} 
wobei die Beobachtungen der Kontrollgruppe wie in \eqref{eq:darkmodeweights} gewichtet werden und $w_i=1$ für Beobachtungen der Behandlungsgruppe ist. Wir überprüfen dies mit R.

```{r}
darkmode_w <- darkmode %>% 
  mutate(
    w = case_when(
      male == 1 & dark_mode == 0 ~ ant_m_B/anz_m_K,
      male == 0 & dark_mode == 0 ~ ant_nm_B/anz_nm_K,
      T ~ 1
    )
  ) 

lm(read_time ~ dark_mode, weights = w, data = darkmode_w) %>%
  summary()
```

Der geschätzte Koeffizient von `dark_mode` entspricht $\widehat{\tau}^w$.

Da `male` eine binäre Variable ist, reduziert sich eine Beurteilung der Vergleichbarkeit der Verteilungen von `male` in Behandlungs- und Kontrollgruppe auf einen simplen Vergleich des Männeranteils beider Gruppen. In der Praxis gibt es meist eine Vielzahl potentieller Backdoor-Variablen, die zudem kontinuierlich verteilt sind. Es scheint plausibel, dass das Alter der Nutzer sowohl die Akzeptanz des Design-Updates als auch die Lesezeit beeinflusst. Die bisherige Verweildauer ist mindestens eine plausible Determinante der Lesezeit.

Der erweiterte DGP ist in Abbildung @fig-CDdarkmode dargestellt, wobei der zusätzliche Backdoor-Pfad durch `age` ebenfalls mit roten Pfeilen gekennzeichnet sind.

```{dot}
//| fig-width: 4
//| fig-height: 3
//| fig-align: 'center'
//| fig-cap: "Erweiterter DGP im Website-Design-Beispiel"
//| label: "fig-CDdarkmode" 
digraph {
  layout=neato
  fontname="Helvetica,Arial,sans-serif"
  node [fontname="Helvetica,Arial,sans-serif"]
  edge [fontname="Helvetica,Arial,sans-serif"]
  node [shape=none];
  "read_time" [pos="4,0.5!"]
  "dark_mode" [pos="0,0.5!"]
  "male" [pos="2,-1!"]
  "age" [pos="2,2!"]
  "hours" [pos="4,2!"]
  "hours" -> "read_time"
  "age" -> "dark_mode" [color="red"]
  "age" -> "read_time" [color="red"]
  "dark_mode" -> "read_time" [color="green"]
  "male" -> "dark_mode" [color="red"]
  "male" -> "read_time" [color="red"]
}
```

Die Beurteilung der *Balance* von Kontrollgruppe und Behandlungsgruppe kann durch eine grafische Gegenüberstellung der empirischen Verteilungen der Kovariablen beider Gruppen erfolgen. Wir visualisieren die empirischen Verteilungen mit `ggplot2`. Hierzu standardisieren wir `age` und `hours` zunächst mit `scale()`.

```{r}
# Datensatz für graphische Darstellung formatieren
darkmode_p <- darkmode %>% 
  # Standardisierung mit 'scale()'
  mutate(
    dark_mode = as_factor(dark_mode),
    age = scale(age), 
    hours = scale(hours)
  )

head(darkmode_p)
```

Für `age` und `hours` eignen sich die geschätzten Dichtefunktionen für einen Vergleich der Verteilungen in Behandlungs- und Kontrollgruppe.

```{r}
# Vergleich mit Dichteschätzungen
darkmode_p %>%
  select(dark_mode, hours, age) %>%
  # in langes Format überführen
  pivot_longer(cols = c(-dark_mode)) %>%
  
  ggplot(
    aes(x = value, fill = dark_mode)
    ) +
  geom_density(alpha = .5) + 
  facet_wrap(
    facets = ~ name, 
    scales = "free", 
    nrow = 2
    )
```

Die graphische Analyse zeigt deutliche Unterschiede in den Verteilungen von `age` zwischen Kontroll- und Behandlungsgruppe. Für einen Beurteilung mit deskriptiven Statistiken wird häufig eine sogenannte *Balance Table* herangezogen. Wir berechnen diese für `age`, `hours` und `male` mit `cobalt::bal.tab()`

```{r}
library(cobalt)

# Balance table mit 'cobalt::bal.tab()'
bal.tab(
  x = darkmode %>% 
    select(age, hours, male), 
  treat = darkmode$dark_mode, 
   # berechne SMD für KG und TG:
  disp = "m", 
  s.d.denom = "pooled"
)
```

Die Einträge `M.0.Un` und `M.1.Un` zeigen die jeweiligen Stichprobenmittelwerte der Variablen für Kontroll- und Behandlungsgruppe. `Diff.Un` gibt eine standardisierte Mittelwertdifferenz $SMD$ an, wobei \begin{align*}
  SMD_j := \left(\overline{X}_{j,B} - \overline{X}_{j,K}\right) \bigg/ \sqrt{\frac{1}{2}\left(\widehat{\text{Var}}(X_{j,B}) + \widehat{\text{Var}}(X_{j,K})\right)},
\end{align*} mit Stichprobenmitteln $\overline{X}_{j,B}$ und $\overline{X}_{j,K}$ und Stichprobenvarianzen $\widehat{\text{Var}}(X_{j,B})$ und $\widehat{\text{Var}}(X_{j,K})$ für eine kontinuierliche Kovariable $j$.[^matching-1] Obwohl es keinen einheitlichen Schwellenwert für die standardisierte Differenz gibt, der ein erhebliches Ungleichgewicht anzeigt, gilt für kontinuierliche Variablen eine standardisierte (absolute) Differenz von weniger als $0.1$ als Hinweis auf einen vernachlässigbaren Unterschied zwischen den Gruppen.

[^matching-1]: Siehe @Austin2011 für einen Überblick zu Balance-Statistiken.

Die Balance Table weist also auf einen vernachlässigbaren Unterschied für `hours` hin und bestätigt den aus den Grafiken abgeleiteten Eindruck einer relevanten Differenzen für `age`.

### Mehrere Matching-Variablen und der Propensity Score

Bei mehreren Backdoor-Variablen kann eine Gewichtung anhand der Behandlungswahrscheinlichkeit (*Treatment Propensity*) erfolgen. Die Idee hierbei ist, dass der DGP wie in @fig-propCDdarkmode dargestellt werden kann.

```{dot}
//| fig-width: 4
//| fig-height: 3
//| fig-align: 'center'
//| fig-cap: "Propensity im Website-Design-Beispiel"
//| label: "fig-propCDdarkmode" 
digraph {
  layout=neato
  fontname="Helvetica,Arial,sans-serif"
  node [fontname="Helvetica,Arial,sans-serif"]
  edge [fontname="Helvetica,Arial,sans-serif"]
  node [shape=none];
  "read_time" [pos="4,0.5!"]
  "dark_mode" [pos="0,0.5!"]
  "TreatmentPropensity" [pos="0,2!"]
  "male" [pos="2,-1!"]
  "age" [pos="2,2!"]
  "hours" [pos="4,2!"]
  "hours" -> "read_time"
  "age" -> "TreatmentPropensity" [color="red"]
  "age" -> "read_time" [color="red"]
  "dark_mode" -> "read_time" [color="green"]
  "male" -> "TreatmentPropensity" [color="red"]
  "male" -> "read_time" [color="red"]
  "TreatmentPropensity" -> "dark_mode" [color="red"]
}
```

Hierbei beeinflussen die Backdoor-Variablen *age* und *male* die Behandlungsvariable *dark_mode* lediglich durch die Behandlungswahrscheinlichkeit *Treatment Propensity*. Diese Darstellung zeigt, das die mehrdimensionale Information bzgl. der Ähnlichkeit von Subjekten hinsichtlich der beobachteten Kovariablen in einer einzigen Variable zusammengefasst werden kann. Die Backdoor-Pfade können daher geschlossen werden, indem wir Subjekte anhand von *Treatment Propensity* derart gewichten, dass beide Gruppen hinsichtlich der Verteilung der Behandlungswahrscheinlichkeit vergleichbar sind. Betrachte erneut \eqref{eq:cia} und beachte, dass \begin{align}
  Y_i = Y_i^{(1)} D_i + Y_i^{(0)} (1-D_i).
\end{align} @RosenbaumRubin1983 zeigen, dass es hinsichtlich \eqref{eq:cia} äquivalent ist für die *Treatment Propensity* $P_i(X_i):=P(B_i=1\vert X_i = x)$ zu kontrollieren, d.h. \begin{align}
  \left\{Y_i^{(1)},Y_i^{(0)}\right\} \perp B_i\vert X_i \quad\Leftrightarrow\quad \left\{Y_i^{(1)},Y_i^{(0)}\right\} \perp B_i\vert P_i(X_i).
\end{align}

Der Behandlungseffekt kann so als Differenz von gewichteten Gruppenmittelwerten berechnet werden, mit inversem Wahrscheinlichkeitsgewicht (IPW) $w_{i,B} = 1/P_i(X_i)$ für Beobachtungen in der Behandlungsgruppe und $w_{i,K} = 1/(1-P_i(X_i))$ für Beobachtungen in der Kontrollgruppe, \begin{align}
  \tau^{\text{IPW}} = \frac{1}{n}\sum_{i=1}^n \left[\frac{B_i Y_i}{P_i(X_i)} - \frac{(1-B_i)Y_i}{1-P_i(X_i)} \right].\label{eq:tauipw}
\end{align}

Grundsätzlich ist *TreatmentPropensity* eine nicht beobachtbare Variable und muss daher aus den Daten geschätzt werden. Eine geschätzte Behandlungswahrscheinlichkeiten $\widehat{P}_i(X_i)$ wird als *Propensity Score* bezeichnet. In der Praxis erfolgt die Schätzung von *Propensity Scores* meist mit logistischer Regression. Ein erwartungstreuer Schätzer des ATE ist \begin{align}
  \widehat{\tau}^{\text{IPW}} = \frac{1}{n}\sum_{i=1}^n \left[\frac{B_i Y_i}{\widehat{P}_i(X_i)} - \frac{(1-B_i)Y_i}{1-\widehat{P}_i(X_i)} \right].\label{eq:hattauipw}
\end{align} @Hiranoetal2003 diskutieren Alternativen zu \eqref{eq:hattauipw} für die Schätzung anderer Typen von Behandlungseffekten.

Wir schätzen nachfolgend die *Propensity Scores* für unser Anwendungsbeispiel, erläutern die Berechnung der Gewichte sowie die Schätzung von Behandlungseffekten mit gewichteter Regression. Hierbei betrachten wir eine Variante von \eqref{eq:hattauipw} mit normalisierten Gewichten $\tilde{w}_{i,B} = w_{i,B}/\sum_i w_{i,B}$ und $\tilde{w}_{i,K} = w_{i,K}/\sum_i w_{i,K}$ die sich jeweils zu 1 summieren.[^matching-2] Dies ergibt den Hájek-Schätzer[^matching-3] \begin{align}
    \widehat{\tau}_N^{\text{IPW}} = \frac{\sum_i\tilde{w}_{i,B}Y_i}{\sum_i\tilde{w}_{i,B}} -  \frac{\sum_i\tilde{w}_{i,K}Y_i}{\sum_i\tilde{w}_{i,K}}.\label{eq:hattauhajek}
\end{align}

[^matching-2]: Eine Normalisierung der Gewichte reduziert die Varianz des Schätzers, vgl. @Hiranoetal2003

[^matching-3]: Siehe @Hajek1971.

Zunächst Schätzen wir ein logistisches Regressionsmodell mit `age`, `male` und `hours` als erklärende Variablen für `dark_mode`.

```{r}
# Logit-Modell mit 'glm()' schätzen
(
  darkmode_ps_logit <- glm(
    formula = dark_mode ~ age + male + hours,
    data = darkmode,
    family = binomial
  )
)
```

Die *Propensity Scores* erhalten wir als angepasste Werte aus der Regression `darkmode_ps_logit` mit `fitted()`. Wir erweitern den Datensatz mit den Ergebnissen.

```{r}
# Datensatz um Propensity Scores erweitern
(
  darkmode_probs <- 
    darkmode %>%
    mutate(
      PS = fitted(darkmode_ps_logit)
    )
)
```

Zur Beurteilung der Überlappung (vgl. Annahme \eqref{eq:overlap} können wir die Verteilung der *Propensity Scores* nach Behandlungs-Indikator mit Histogrammen visualisieren.

```{r}
# Überlappung prüfen:
# Histogramme der PS nach Treatment-Indikator
darkmode_probs %>%
  ggplot(
    mapping = aes(
      x = PS, 
      fill = factor(dark_mode)
    )
  ) + 
  geom_histogram(
    alpha = .5, 
    bins = 25, 
    position = "identity"
  )
```

Ein Vergleich der Histogramme zeigt, dass die Überlappung der *Propensity Scores* in der linken Flanken der Verteilungen der Kontrollgruppe und in der rechten Flanke der Behandlungsgruppe schlechter wird. Wir entfernen zunächst Beobachtungen aus der Stichprobe deren *Propensity Scores* wenig bzw. keine Überlappung aufweisen.

```{r}
# Datensatz nach PS trimmen
darkmode_probs <- darkmode_probs %>% 
  filter(
    between(
      x = PS,
      left = .25,
      right = .75
    )
  )
```

```{r}
# Überlappung nach trimming prüfen:
# Dichteschätzung der PS nach Treatment-Indikator
darkmode_probs %>%
ggplot(
  mapping = aes(
    x = PS, 
    fill = factor(dark_mode))
  ) + 
  geom_histogram(
    alpha = .5, 
    bins = 25, 
    position = "identity"
  )
```

IPWs anhand der *Propensity Scores* können schnell mit der Vorschrift \begin{align}
  \text{IPW} = \frac{\text{dark\_mode}}{\text{PS}} + \frac{1 - \text{dark\_mode}}{1 - \text{PS}},
\end{align} berechnet werden.

```{r}
# Datensatz um IPWs erweitern
darkmode_IPW <- darkmode_probs %>%
  mutate(
    IPW = dark_mode / PS + (1 - dark_mode) / (1 - PS)
  )

darkmode_IPW %>% 
  select(IPW)
```

Eine Schätzung des durchschnittlichen Behandlungseffekts gemäß \eqref{eq:hattauhajek} implementieren wir mit `dplyr`.

```{r}
darkmode_IPW %>%
  group_by(dark_mode) %>%
  mutate(w = IPW / sum(IPW)) %>%
  summarise(weighted_mean = sum(read_time * w)) %>%
  summarise(diff = diff(weighted_mean))
```

Diese Schätzung des Behandlungseffekts ist äquivalent zur gewichteten KQ-Schätzung anhand eines einfachen linearen Regressionsmodells.

```{r}
# Mit IPWs gewichteter KQ-Schaetzer berechnet den ATE
model_ipw <- lm(
  formula = read_time ~ dark_mode, 
  data = darkmode_IPW,
  weights = IPW
)

summary(model_ipw)
```

Unsere Schätzung des ATE ist der geschätzte Koeffizient von `dark_mode`. Die ausgegebenen Standardfehler und Inferenzstatistiken sind jedoch *ungültig* aufgrund der Gewichtung mit IPWs, den inversen *geschätzten* Wahrscheinlichkeiten für eine Behandlung. Der Grund hierfür ist, dass die Berechnung der Standardfehler in `summary()` die zusätzliche Unsicherheit durch die geschätzen *Propensity Scores* nicht berücksichtigt! Später im Kapitel erläutern wir die Berechnung gültiger Standardfehler für IPW-Schätzer basierend auf *Propensity Scores* mit dem Bootstrap.

## Matching-Verfahren

Das grundsätzliche Konzept von Matching wird in der nachstehenden interaktiven Grafik veranschaulicht. Hier betrachten wir beobachtete Ausprägungen von zwei (unabhängig und identisch verteilten) Matching-Variablen für Subjekte in der Behandlungsgruppe (blau) sowie Kontrollgruppe (rot). Per Klick auf eine Beobachtung werden Matches aus der anderen Gruppe in grün kenntlich gemacht. Als Matches zählen sämtliche Beobachtungen der anderen Gruppe, deren [Euklidische Distanz](https://de.wikipedia.org/wiki/Euklidischer_Abstand) zu dem ausgewählten Punkt das über den Slider eingestellte Maximum *Caliper* nicht überschreitet.^[Es handelt sich hierbei um einen Spezialfall von Matching anhand der Mahalanobis-Distanz.] Diese Region wird durch den gestrichelten Kreis gekennzeichnet. Die Grafik illustriert inbesondere, dass Beobachtungen mehrfach (s.g. Matching mit zurücklegen) oder gar nicht gematcht werden können.

<iframe width="100%" height="629" frameborder="0" src="https://observablehq.com/embed/62067a02a72c9f90?cells=theplot%2Cviewof+caliper%2Cstyles">
</iframe>

`MatchIt::matchit()` nutzt standardmäßig Eins-zu-Eins-Matching (ohne Zurücklegen) von Beobachtungen der Treatment-Gruppe mit Beobachtungen der Kontrollgruppe. Die für das Matching zu verwendenden Variablen werden über das Argument `formula` als Funktion des Behandlungsindikators definiert. `matchit()` bereitet das Objekt für eine Schätzung des ATT mit einer geeigneten Funktionen, s. `?matchit` und hier insb. die Erläuterungen der Argumente `replace = F`, `ratio = 1` und `estimand = "ATT"` für Details. Mit `cobalt::balt.tab()` erhalten wir eine *balance table* für den gematchten Datensatz.

Wir zeigen als nächstes, wie `MatchIt::matchit()` für Matching anhand der Regressoren `age`, `hours`, und `male` in unserem Website-Beispiel für unterschiedliche Varianten durchgeführt werden kann.

**Exaktes Matching**

Exaktes Matching ordnet einem Subjekt aus der Behandlungsgruppe ein oder mehrere Subjekte aus der Kontrollgruppe zu, wenn die boebachteten Ausprägung der Matching-Variablen *exakt* übereinstimmen. Hierbei muss die 'Distanz' zwischen den Ausprägung der Matching-Variablen folglich $0$ sein. Dieses Verfahren findet meist bei ausschließlich diskret verteilten Merkmalen Anwendung. Bei kontinuierlich verteilten Merkmalen (vgl. die obige interaktive Grafik) sind exakte Matches zwar theoretisch unmöglich, ergeben sich jedoch in der Praxis aus der Datenerfassung, bspw. durch Rundungsfehler. In `matchit()` erhalten wir exaktes Ein-zu-eins-Matching mit `method = "exact"`.

```{r, error=TRUE}
library(MatchIt)

# Exaktes Eins-zu-Eins-Matching durchführen
res_em <- matchit(
  formula = dark_mode ~ age + male + hours, 
  data = darkmode,
  estimand = "ATT",
  method = "exact"
)
res_em
```

Aufgrund der kontinulierliche Verteilten Variable `hours` gibt es in unserem Website-Beispiel keine exakten Matches. Dieses Verfahren ist hier folglich ungeeignet.

**Coarsened Exact Matching**

Bei dieser Methode werden kontinuierliche Matching-Variablen grob (Engl. *coarse*) klassiert, ähnlich wie bei einem Histogram. Diese Diskretisierung ermöglicht es exakte Übereinstimmungen zwischen Behandlungs- und Kontrollgruppenbeobachtungen hinsichtlich ihrer klassierten Ausprägungen zu finden. Sowohl Behandlungs- als auch Kontrollbeobachtungen die mindestents einen exakten Match haben, werden Teil des gematchten Datensatzes. In `matchit()` wird Coarsened Exact Matching mit `method = "cem"` durchgeführt. Über das Argument `cutpoints` geben wir an, dass `hours` in 6 Klassen und `age` in 4 Klassen eingeteilt werden soll.^[Diese Werte wurden ad-hoc gewählt da sie zu einem guten Ergebnis führen.] Mit `k1k = TRUE` erfolgt Eins-zu-eins-Matching: Bei mehreren exakten Matches wird die Beobachtung mit der geringsten Mahalanobis-Distanz (für die unklassierten Matching-Variablen) gewählt.

```{r}
# Coarsened Exact Matching
res_CEM <- matchit(
  formula = dark_mode ~ age + male + hours, 
  data = darkmode, 
  estimand = "ATT",
  method = "cem", 
  k2k = TRUE,
  cutpoints = list(
    "hours" = 6, 
    "age" = 4
  ) 
)
res_CEM
```

```{r}
# Balance-Table Coarsened Exact Matching
bal.tab(res_CEM)
```

Mit Coarsened Exact Matching erhalten wir einen Datensatz mit 82 Beobachtungen und guter Balance.

**Matching anhand der Mahalanobis-Distanz**

Die Euklidische Distanz misst den direkten Abstand zwischen zwei Punkten und ist nicht invariant gegenüber Transformationen, insbesondere bei unterschiedlichen Skalierungen und bei Korrelation der Matching-Variablen. Die Mahalanobis-Distanz hingegen ist ein standardisiertes Distanzmaß, das unter Berücksichtigung der Varianz-Kovarianz-Struktur der Daten angibt, wie viele Standardabweichungen zwei Datenpunkte voneinander entfernt sind. Die Mahalanobis-Distanz ist invariant gegenüber linearen Transformationen (Skalierung, Translation und Rotation) der Daten und bietet ein genaueres Maß für die Unähnlichkeit zweier Beobachtungen hinsichtlich ihrer Ausprägungen der Matching-Variablen. 

Betrachte die Datenpunkte $P_1=(X_1,Y_1)'$ und $P_2=(X_2,Y_2)'$ für die Matching-Variablen $X$ und $Y$. Die Mahalanobis-Distanz zwischen $P_1$ und $P_2$ ist definiert als
\begin{align*}
  d_M(P_1,\,P_2) = \sqrt{(P_1 - P_2)'\boldsymbol{S}^{-1} (P_1 - P_2)},
\end{align*}
wobei $\boldsymbol{S}$ die Varianz-Kovarianz-Matrix von $X$ und $Y$ ist. Die Mahalanobis-Distanz $d_M(\cdot,\cdot)$ ist also die Euklidische Distanz zwischen den standardisierten Datenpunkten.

Für beobachtete Daten ersetzen wir die Komponenten der Varianz-Kovarianz-Matrix durch  Stichprobenmaße. Dies ergibt die Formel

\begin{align*}
  \widehat{d}_M(P_1,\,P_2) = \sqrt{
  \begin{pmatrix}
    X_1 - X_2\\
    \tilde  Y_1 - \tilde Y_2
  \end{pmatrix}'
  \begin{pmatrix}
    \widehat{\text{Var}}(X^2) & \widehat{\text{Cov}}(X, Y) \\
     \widehat{\text{Cov}}(X, Y) & \widehat{\text{Var}}(X^2) 
  \end{pmatrix}^{-1}
    \begin{pmatrix}
    X_1 - X_2\\
    \tilde Y_1 - \tilde Y_2
  \end{pmatrix}
}.
\end{align*}

Die nachstehende interaktive Grafik zeigt Beobachtungen zweier Matching-Variablen, die aus einer bivariaten Normalverteilung mit positiver Korrelation generiert wurden. Diese bivariate Verteilung ist identisch für Beobachtungen aus der Kontrollgruppe (rot) und Beobachtungen aus der Behandlungsgruppe (blau). Für die ausgewählte Beobachtung aus der Behandlungsgruppe (schwarzer Rand) werden potentielle Matches in der Kontrollgruppe innerhalb der vorgegebenen Mahalanobis-Distanz in Cyan kenntlich gemacht. Beachte, dass die Mahalanobis-Distanz Varianzen und Kovarianzen der Daten berücksichtigt, sodass die gematchten Beobachtungen in einem elliptischen Bereich um die betrachtete behandelte Beobachtung liegen. Eine Euklidische Distanz hingegen (gestrichelte Linie) ignoriert die Skalierung der Daten.

<iframe width="100%" height="648" frameborder="0"
  src="https://observablehq.com/embed/1338355035acc056@687?cells=theplot%2Cviewof+caliper%2Cstyles"></iframe>

Für Eins-zu-Eins-Matching im Website-Beispiel anhand der Mahalanobis-Distanz mit `matchit()` setzen wir `distance = "mahalanobis"` und wählen `method = "nearest"`. Mit diesen Parametern wird jeder Behandlung aus der Behandlungsgruppe die gemäß $d_M$ am ehesten vergleichbarste Beobachtung aus der Kontrollgruppe zugewiesen, wobei keine mehrfachen Matches zulässig sind. 

```{r}
# 1:1 Mahalanobis-Distanz-Matching
res_maha <- matchit(
  formula = dark_mode ~ age + male + hours, 
  data = darkmode, 
  estimand = "ATT",
  distance = "mahalanobis", 
  method = "nearest"
)
res_maha
```

```{r}
# Balance-Table für 1:1 Mahalanobis-Matching
bal.tab(res_maha)
```

Die Ergebnisse zeigen, dass für sämtliche $149$ Beobachtungen aus der Behandlungsgruppe ein individueller Match in der Kontrollgruppe gefunden werden konnte. Es werden lediglich $2$ Beobachtungen der $151$ Beobachtungen in der Kontrollgruppe nicht gematcht.

Entsprechend zeigt die Balance-Table eine ähnliche Diskrepanz beider Gruppen hinsichtlich der Matching-Variablen an.

**Mahalanobis-Distanz mit Caliper .25 für Propensity Scores basierend auf logistischer Regression**

Für eine strengeres Matching-Kriterium kann ein *Caliper*, d.h. eine maximal zulässige Distanz, herangezogen werden. Die Mahalanobis-Distanz hat jedoch keine einheitliche Skala: Ob eine Distanz als groß oder klein betrachten werden kann, hängt von der Anzahl der Matching-Variablen und dem Überlappungsgrad zwischen den Gruppen ab. Daher wird die Beschränkung durch einen Caliper nicht auf $\widehat{d}_M$ sondern auf Propensity Scores angewendet.

Im nächsten Code-Beispiel spezifizieren wir mit `distance = "glm"`, dass Propensity Scores gemäß der Vorschrift in `formula` geschätzt werden. Mit `mahvars = ~ age + male + hours` legen wir die Matching-Variablen für die Berechnung von $\widehat{d}_M$ fest. `caliper = .25` legt fest, dass lediglich Beobachtungen der Kontrollgruppe bei einer absoluten Differenz der Propensity Scores von höchstens $0.25$ Standardabweichungen als Match für eine Beobachtung in der Behandlungsgruppe qualifiziert sind.

```{r}
# Mahalanobis-Matchig mit PS-Caliper
res_mahaC <- matchit(
  formula = dark_mode ~ age + male + hours, 
  data = darkmode, 
  distance = "glm",
  estimand = "ATT",
  method = "nearest",
  mahvars = ~ age + male + hours,
  caliper = .25
)
res_mahaC
```

```{r}
# Balance Table
bal.tab(res_mahaC)
```

Die Balance-Table zeigt einen deutlichen Effekt der Beschränkung qualifizierter Beobachtungen durch `caliper = .25`: Aufgrund der oberen Grenze für die Propensity-Score-Differenz von $`r round(.25 * sd(fitted(darkmode_ps_logit)), 3)`$ wird für lediglich $104$ Beobachtungen aus der Behandlungsgruppe ein individueller Match in der Kontrollgruppe gefunden.^[Die durch `caliper` implizierte Obergrenze ergibt sich als `.25 * sd(fitted(darkmode_ps_logit)))`.] Weiterhin finden wir eine verbesserte Balance für den gematchten Datensatz.

**Matching mit Propensity Scores und Caliper**

Eine gängige Variante ist Matching ausschließlich anhand von Propensity Scores innerhalb eines Calipers. 

```{r}
# 1:1 Matching mit PS und Caliper
res_PSC <- matchit(
  formula = dark_mode ~ age + male + hours, 
  data = darkmode, 
  estimand = "ATT",
  distance = "glm", 
  method = "nearest", 
  caliper = .25
)
res_PSC
```

```{r}
# Balance Table
bal.tab(res_PSC)
```

Laut Balance-Table führt Eins-zu-Eins-Matching basierend auf Propensity Scores zu einem Datensatz mit $104$ gematchten Beobachtungen in der Behandlungsgruppe. Hinsichtlich der standardisierten Mittelwertdifferenz (`Diff.Adj`) erzielt diese Methode die beste Balance unter den betrachteten Ansätzen.

**Vergleich der Balance verschiedener Verfahren mit Love-Plot**

Standardisierte Mittelwertdifferenzen für verschiedene Matching-Verfahren können grafisch mit einem Love-Plot [@Love2004] veranschaulicht werden. Hierzu nutzen wir `cobalt::love.plot()` und übergeben die mit `matchit()` generierten Objekte im Argument `weights`.

```{r}
# Love-Plot für
love.plot(
  x = dark_mode ~ age + male + hours, 
  weights = list(
    CEM = res_CEM,
    Mahalanobis = res_maha,
    Mahalanobis_Cal = res_mahaC,
    PSC = res_PSC
  ),
  data = darkmode, 
  line = T,
  # absolute Mittelwertdifferenz plotten
  abs = T
)
```

Die Grafik zeigt, dass Coarsened Exact Matching (CEM) unter allen betrachteten Verfahren die Stichprobe mit der besten Balance ergibt. Diesen gematchten Datensatz erhalten wir mit `MatchIt::match.data()`.

```{r}
# gematchten Datensatz zuweisen
darkmode_matched_CEM <- match.data(res_CEM)
head(darkmode_matched_CEM)
```

`darkmode_matched` enthält Gewichte (`weights`) für die jeweilige Gruppe zu denen gemachte Beobachtungen gehören (`subclass`). Dies ist relevant, falls Beobachtungen mehrfach gematcht werden. Wegen Eins-zu-eins-Matching _ohne_ Zurücklegen gibt es in unserem Beispiel `r length(unique(darkmode_matched_CEM$subclass))` Beobachtungspaare und sämtliche Gewichte sind 1. Die Berücksichtigung der Gewicht in den nachfolgenden Aufrufen von Schätzfunktionen (bspw.`lm()`) ist daher nicht nötig und erfolgt lediglich zur Illustration der grundsätzlichen Vorgehensweise.

Eine Wiederholung der grafischen Analyse in @sec-balance zeigt eine deutlich verbesserte Vergleichbarkeit hinsichtlich der Verteilung der Matching-Variablen in `darkmode_matched`.

```{r, warning=FALSE, message = F}
darkmode_matched_CEM %>%
  group_by(dark_mode) %>%
  select(age, hours) %>%
  mutate_all(scale) %>%
  pivot_longer(cols = c(-dark_mode)) %>%
  
  ggplot(
    aes(x = value, fill = as.factor(dark_mode))
  ) +
  geom_density( alpha = .5) + 
  facet_wrap(
    facets = ~ name, 
    scales = "free", 
    nrow = 3
  )

darkmode_matched_CEM %>% 
  group_by(dark_mode) %>%
  mutate(
    male = as.factor(male), 
    dark_mode = as.factor(dark_mode)
  ) %>%
  
  ggplot(
    aes(x = dark_mode, fill = male)
  ) +
  geom_bar(position = "fill") +
  ylab("Anteil")
```

Wir beobachten eine bessere Balance bei `age` und `hours`. Inbesondere ist `male` für Kontroll- und Behandlungsgruppe ausgeglichen!

## Schätzung und Inferenz für den Behandlungseffekts nach Matching

Wir schätzen nun den Behandlungseffekt von `dark_mode` auf `read_time` für die mit CEM und Propensity Score Matching ermittelten Datensätze mittels linearer Regression und vergleichen mit einer Regression anhand des ursprünglichen Datensatzes. 


```{r}
# ATT mit linearem Modell schätzen: CEM Datensatz
ATT_mod_CEM <- lm(
  formula = read_time ~ age + male + hours + dark_mode,
  data = darkmode_matched_CEM, 
  weights = weights 
)
summary(ATT_mod_CEM)
```

```{r}
# Datensatz für Propensity Score Matching zuweisen
darkmode_matched_PSC <- match.data(res_PSC)

# ATT mit linearem Modell schätzen: PSM Datensatz
ATT_mod_PSC <- lm(
  formula = read_time ~ age + male + hours + dark_mode,
  data = darkmode_matched_PSC, 
  weights = weights 
)
summary(ATT_mod_PSC)
```

```{r}
# ATT mit linearem Modell für vollständigen Datensatz schätzen
ATT_mod_org <- lm(
  formula = read_time ~ age + male + hours + dark_mode,
  data = darkmode
)
summary(ATT_mod_org)
```

Beachte, dass für die gematchten Datensätze jeweils ein durchschnittlicher Behandlungseffekt für die Beobachtungen _mit_ erfolgter Behandlung ermittelt wird: In sämtlichen oben gezeigten Verfahren werden mit `estimand = "ATT"` vergleichbarere Kontrollbeobachtungen für die behandelten Beobachtungen ermittelt. Wir schätzen den Effekt der Behandlung, indem wir die Ergebnisse von behandelten Personen mit denen von  gematchten (d.h.ähnlichen) Personen vergleichen, die keine Behandlung erhalten haben. Diese Vergleichsgruppe dient als Ersatz für den hypothetischen Zustand der Behandlungsgruppe, wenn keine Behandlung erfolgt wäre. Dies ist die Definition eines ATT --- ein average treatment effect *on the treated*.

Für Matching-Verfahren (`ATT_mod`) sind die von `summary()` berechneten Standardfehler (und damit Konfidenzintervalle, t-Statistiken und p-Werte) für den Behandlungseffekt *grundsätzlich ungültig*. Je nach Matching-Verfahren liegen unterschiedliche Quellen von Schätzunsicherheit vor, die bei der Berechnung von Standardfehlern zusätzlich zu der "üblichen" Stichproben-Variabilität berücksichtig werden müssen, bspw. aufgrund der Schätzung von Propensity Scores und der Matching-Prozess ansich. Wir nutzen daher nachfolgende Funktionen gem. Empfehlungen aus der aktuellen Forschung für Standardfehlerberechnung.

```{r}
library(marginaleffects)

# Inferenz: Multiple Regression bei ungematchten Beobachtungen
(
  sum_orig <- avg_comparisons(
    model = ATT_mod_org,
    variables = "dark_mode",
    # Heteroskedastie-robuste SE:
    vcov = "HC3", 
    # Identifizierung der Kontrollgruppe:
    newdata = subset(darkmode, dark_mode == 1) 
  )
) 

# Inferenz: Multiple Regression bei CEM
(
  sum_CEM <- avg_comparisons(
  model = ATT_mod_CEM ,
  variables = "dark_mode",
  # Cluster-robuster SE
  vcov = ~ subclass, 
  newdata = subset(darkmode_matched_CEM, dark_mode == 1),
  wts = "weights"  # = 1
  )
)

# Inferenz: Multiple Regression bei PSM
(
  sum_PSC <- avg_comparisons(
    model = ATT_mod_PSC ,
    variables = "dark_mode",
    vcov = ~ subclass, 
    newdata = subset(darkmode_matched_PSC, dark_mode == 1),
    wts = "weights"  # = 1
  )
)
```

```{r}
library(modelsummary)
modelsummary(
  models = list(sum_orig, sum_CEM, sum_PSC)
)
```


## Inferenz für ATT/ATE: Propensity-Score-Matching mit Bootstrap

Bei Matching mit Zurücklegen besteht zusätzliche Unsicherheit durch Zurücklegen, d.h. Beobachtungen aus der Kontroll-Gruppe können mehrfach als Match für Beobachtungen aus der Treatment-Gruppe genutzt werden. Mit `summary()` berechnete Standardfehler berücksichtigen dies nicht!

Ein Bootstrap-Verfahren generiert mit Resampling (wiederholtes Ziehen mit Zurücklegen) aus dem Original-Datensatz (viele) künstliche Datensätze, für die der Schätzer (d.h. das gesamte Verfahren inkl. Matching!) jeweils berechnet wird. Die Verteilung der so gewonnenen Bootstrap-Schätzwerte approximiert die wahre, unbekannte Stichprobenverteilung des Schätzers des Behandlungseffekts. Mit dieser simulierten Verteilung können wir Inferenz betreiben: Wir können einen Bootstrap-Punktschätzer des Behandlungseffekts (Stichprobenmittel der Bootstrap-Schätzungen) sowie Standardfehler (Standardabweichung der der Bootstrap-Schätzungen) und p-Werte berechnen.

Wir Implementieren nun einen Bootstrap-Schätzer des ATT als `R`-Funktion `boot_fun()`.

```{r}
boot_fun <- function(data, i) {
  
  boot_data <- data[i, ]
  
  # 1:1 PS Matching _mit_ Zurücklegen
  match_res <- matchit(
    dark_mode ~ age + hours + male,
    estimand = "ATT",
    distance = "glm", 
    method = "nearest", 
    caliper = .3,
    data = boot_data,
    # mit Zurücklegen:
    replace = TRUE
  ) 
  
  # Gematchten Datensatz zuweisen
  darkmode_matched <- match.data(match_res, data = boot_data)
  
  # Outcome-Modell schätzen
  ATT_mod <- lm(
    formula = read_time ~ age + male + hours + dark_mode,
    data = darkmode_matched, 
    weights = weights # hier teilweise > 1 wg. Matching mit Zurücklegen!
  )
  
  #  ATT-Schätzer auslesen
  return(
    ATT_mod$coefficients["dark_mode"]  
  )
}
```

Abadie & Imbens (2008) zeigen analytisch, dass ein Standard-Bootstrap bei Matching grundsätzlich ungültig ist: Die unbekannte Varianz der Stichprobenverteilung des Matching-Schätzers (und damit der Standardfehler des Schätzers) kann durch den Bootstrap nicht repliziert werden. Problematisch hierbei sind grundsätzlich zu liberale (d.h. zu große) mit dem Bootstrap berechnete Standardfehler. Es gibt jedoch Simulationsnachweise die zeigen, dass Bootstrap-Standardfehler bei Matching mit Zurücklegen konservativ sind (Bodory et al., 2020), also tendentiell zu kleine Standardfehler produzieren und damit das gewünschte nominale Signifikanzniveau eines Bootstrap-Hypothesentests nicht überschritten wird.

Wir berechnen nun eine Bootstrap-Schätzung des ATT von `dark_mode` auf `readingtime` sowie den zugehörigen Standardfehler und ein 95%-KI mit der zuvor definierten Funktion `boot_fun`.

```{r}
library("boot")
set.seed(4321)
boot_out <- boot(darkmode, boot_fun, R = 999)

boot_out
```

```{r}
# Bootstrap-Schätzer für den Treatment-Effekt
mean(boot_out$t) 
# = mean(t0) + bias = mean(Bootstrap_samples)
# vgl. 't0 = boot_fun(darkmode, i = 1:1e3)'

# Bootstrap-Standardfehler
sd(boot_out$t)

# 95% Bootstrap-KI für den Treatment-Effekt
boot.ci(boot_out, type = "perc")
```

## Doubly-Robust-Schätzer für ATT/ATE

Implementieren und berechnen Sie einen Doubly-Robust-Schätzer des ATT (vgl. Wooldridge, 2010) für den kausalen Effekt in Aufgabe 5. Vergleichen Sie mit den Ergebnissen der Aufgaben 1 (d), 4 (f) und 5 (d).

```{r}
# IPW estimation with regression adjustment
ipwra <- function(br, index = 1:nrow(br)) {
    # slice bootstrapped observations
    br <- br %>% slice(index)
    
    # estimate and predict propensity score
    m <- glm(formula = dark_mode ~ age + hours + male,
             data = br, 
             family = binomial(link = 'logit'))
    
    br <- br %>%
        mutate(ps = predict(m, type = 'response'))
    
    # trim control observations outside of treated PS range
    # minps <- br %>%
    #     filter(dark_mode == 1) %>%
    #     pull(ps) %>%
    #     min(na.rm = TRUE)
    # 
    # maxps <- br %>%
    #     filter(dark_mode == 1) %>%
    #     pull(ps) %>%
    #     max(na.rm = TRUE)
    # 
    # # do the trimming
    # br <- br %>%
    #     filter(ps >= minps & ps <= maxps)
   
    br <- br %>%
      filter(
        between(
          x = ps,
          left = .2,
          right = .7
          )
    )
    
    # compute IPWs
    br <- br %>%
      mutate(
        ipw = case_when(
          dark_mode == 1 ~ 1 / ps,
          dark_mode == 0 ~ 1 / (1 - ps))
      )
    
    # Simple _ATT_ estimate:
    # w_means <- br %>%
    #     group_by(dark_mode) %>%
    #     summarize(m = weighted.mean(read_time, w = ipw)) %>% 
    #     arrange(dark_mode)
    # 
    # # simple diff-in-means _ATT_ estimate
    #  return(w_means$m[2] - w_means$m[1]) 
    
    # Do regression adjustment for _ATE_ estimate
    # TE prediction for whole sample based on TG model
    mtreat <- br %>%
      filter(dark_mode == 1) %>%
      lm(read_time ~ 1 + age + hours + male, data = ., weights = .$ipw) %>%
      predict(newdata = br) %>%
      mean()
    
    # TE prediction for whole sample based on CG model
    mcont <- br %>%
      filter(dark_mode == 0) %>%
      lm(read_time ~ 1 + age + hours + male, data = ., weights = .$ipw) %>%
      predict(newdata = br) %>%
      mean()

    return(mtreat - mcont) # Regression adjusted _ATE_ estimate
}
```

```{r}
b <- boot(data = darkmode, ipwra, R = 999)
# Bootstrap estimate and standard error
mean(b$t)
sd(b$t)
# 95% Bootstrap-KI für den Treatment-Effekt
boot.ci(b, type = "perc")
```



\vfill

# Literatur

Abadie, Alberto, and Guido W. Imbens. (2008). *On the Failure of the Bootstrap for Matching Estimators.*Econometrica 76 (**6**): 1537–57.

Bodory, H., Camponovo, L., Huber, M., & Lechner, M. (2020). *The Finite Sample Performance of Inference Methods for Propensity Score Matching and Weighting Estimators*. Journal of Business & Economic Statistics, 38(**1**), 183–200.

Wooldridge, J. M. (2010). *Econometric analysis of cross section and panel data*. MIT press.
