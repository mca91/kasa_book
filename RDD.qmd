---
webr: 
  packages: [
            'AER',
            'cowplot',
            'dplyr',
            'ggplot2',
            'gt',
            'haven',
            'modelsummary',
            'rdd',
            'rddensity',
            'rdrobust',
            'readr',
            'tidyr',
            'vtable'
            ]
  cell-options:
    warning: false
    message: false           
  repos:
    - https://rstudio.r-universe.dev
---

{{< include ./_extensions/r-wasm/live/_knitr.qmd >}}

# Regression Discontinuity Designs {#sec-RDD}

```{webr}
#| echo: false
#| output: false
#| edit: false
#| message: false
#| warning: false

# create dataset directory
dir.create("datasets")
# Download the datasets
download.file(
    "https://raw.githubusercontent.com/mca91/kausal_data/refs/heads/main/house.csv",
    "datasets/house.csv"
)
download.file(
    "https://raw.githubusercontent.com/mca91/kausal_data/refs/heads/main/house_binned.csv",
    "datasets/house_binned.csv"
)
download.file(
    "https://raw.githubusercontent.com/mca91/kausal_data/refs/heads/main/BastenBetz.dta",
    "datasets/BastenBetz.dta"
)


# Formatierung von gt-Tabellen
tabopts <- function(x) {
  fmt_number(x, decimals = 3, drop_trailing_zeros = T) %>%
    tab_options(
      # general
      table.width = "80%",
      # fonts
      table.font.color = "black", 
      table.font.size = 16,
      column_labels.font.weight = "bold", 
      # table header  
      column_labels.padding = 15,
      column_labels.border.bottom.color = "black", 
      column_labels.border.bottom.width = "1px", 
      column_labels.border.top.color = "black",
      # group labels
      row_group.border.top.width = 0,
      row_group.border.bottom.width = 0,
      row_group.font.weight = "bold",
      row_group.padding = 20,
      # body
      
      table_body.hlines.width = 0, 
      table_body.border.bottom.color = "black",
      table_body.border.bottom.width = "1px",
      table_body.border.top.width = "0px",
      table.border.bottom.color = "black"
    )
}
```

```{r, echo=F, message=FALSE}
library(gt)
library(tidyverse)
# Formatierung von gt-Tabellen
tabopts <- function(x) {
    fmt_number(x, decimals = 3, drop_trailing_zeros = T) %>%
  tab_options(table_body.hlines.color = "white", 
              column_labels.border.bottom.color = "black", 
             column_labels.border.top.color = "black",
             table_body.border.bottom.color = "black", 
             table.border.bottom.color = "black",
             column_labels.font.weight = "bold", 
             table.font.color = "black", 
             table.font.size = 16)
}

house <- read_csv("datasets/house.csv")
```

Regression Discontinuity Design (RDD) ist ein Ansatz für die Schätzung von Behandlungseffekten mit Regression, wenn durch einen experimentell oder natürlich gegebenen Umstand die Behandlung an einem Schwellenwert ($c$) einer *Laufvariable* ($X$) sprunghaft beeinflusst wird. Ein RDD-Schätzer wird so implementiert, dass lediglich Beobachtungen mit Ausprägungen von $X$, die knapp ober- oder knapp unterhalb von $c$ liegen, berücksichtigt werden. Die zentrale Idee hierbei ist, dass Individuen nahe bei $c$ im Durchschnitt ähnliche Merkmale aufweisen. Beobachtungen nahe $c$ sind dann insbesondere hinsichtlich potentieller Backdoor-Variablen vergleichbar, sodass deren problematische Pfade geschlossen sind. Das kausale Diagram in @fig-CDRDD zeigt den grundsätzlichen Zusammenhang.

```{dot}
//| fig-width: 5
//| fig-height: 3
//| fig-align: 'center'
//| fig-cap: "Kausales Diagramm für Sharp RDD"
//| label: "fig-CDRDD" 
digraph "Causal Diagramm RDD" {
  layout=neato
  fontname="Helvetica,Arial,sans-serif"
  node [fontname="Helvetica,Arial,sans-serif",shape=ellipse]
  edge [fontname="Helvetica,Arial,sans-serif"]
  "X" [pos="0,1!"]
  "Y" [pos="4,-1!"]
  "Oberhalb c" [pos="0,-1!"]
  "Z" [pos="4,1!"]
  "Behandlung B" [pos="2,-1!"]
  "X" -> "Y"
  "Z" -> "X"
  "Z" -> "Y"
  "X" -> "Oberhalb c"
  "Oberhalb c" -> "Behandlung B"
  "Behandlung B" -> "Y"
}
```

RDD isoliert Variation auf dem Pfad *Oberhalb C &rarr; Behandlung B &rarr; Y*. Somit können Backdoor-Pfade über $X$ oder weitere (möglichweise unbeobachtbare) Confounder ($Z$) vermieden werden, siehe @fig-CDRDD. Der kausale Effekt wird dabei als (lokaler) durchschnittlicher Behandlungseffekt der Diskontinuität auf die Outcome-Variable ($Y$) anhand von Beobachtungen *nahe bei c* ermittelt. 

Hinsichtlich der Beeinflussung der Behandlung unterscheiden wir zwischen *Sharp* und *Fuzzy* Regression Discontinuity Designs (SRDD/FRDD). Bei einem SRDD ist die Zuweisung der Behandlung *deterministisch*, d.h. der Schwellenwert in der Laufvariable ist eine harte Grenze für die Gruppenzugehörigkeit: Die *Wahrscheinlichkeit* der Behandlung $p$ springt bei $X=c$ von $p=0$ um $\Delta p = 1$ auf $p=1$.

Bei einem FRDD ist die Zuordnung in Behandlungs- und Kontrollgruppe nicht perfekt durch den Schwellenwert $c$ bestimmt: Die Behandlungswahrscheinlichkeit $p$ springt bei $X=c$ um $\Delta p<1$. Im FRDD können grundsätzlich also sowohl behandelte Subjekte als auch Kontroll-Beobachtungen auf beiden Seiten der Diskontinuität vorliegen -- die Trennung der Gruppen ist "unscharf"^[Engl. *fuzzy*.]. Dieser Umstand ist oft in empirischen Studien mit nicht-experimentellen Daten gegeben, wenn es neben der Überschreitung von $c$ weitere Determinanten der Behandlung gibt (für die wir nicht kontrollieren können). Die Wahl zwischen SRDD und FRDD hängt grundsätzlich vom datenerzeugenden Prozess und der Forschungsfrage ab.


## Sharp Regression Discontinuity Design

**Modell und funktionale Form**

Die korrekte Spezifikation der funktionalen Form für ein RDD ist wichtig, um eine verzerrte Schätzung des Effekts zu vermeiden. Die einfachste Form eines SRDD kann anhand der linearen Regression 
\begin{align}
Y_i = \beta_0 + \beta_1 B_i + \beta_2 X_i + u_i\label{eq-simpleSRDD}
\end{align} geschätzt werden, wobei $B_i$ eine Dummy-Variable für das Überschreiten des Schwellenwertes $c$ ist, d.h.
\begin{align*}
  B_i=\begin{cases}
    0 & X_i < c\\
    1 & X_i \geq c.
  \end{cases}
\end{align*}
Damit ist $B_i$ eine *deterministische* Funktion der Laufvariable $X_i$ und zeigt die Zugehörigkeit zur Behandlungs- oder Treatmentgruppe an. Der Koeffizient $\beta_1$ misst den Behandlungseffekt.

Das Modell \eqref{eq-simpleSRDD} unterstellt, dass $X$ links- und rechtsseitig von $c$ denselben Effekt auf $Y$ hat. Diese Annahme ist restriktiv. Eine Alternative ist ein lineares Interaktionsmodell
\begin{align}
Y_i = \beta_0 + \beta_1 B_i + \beta_2 (X_i - c) + \beta_3(X_i - c)\times B_i + u_i.\label{eq:linearSRDD}
\end{align}
Das Modell \eqref{eq:linearSRDD} kann unterschiedliche lineare Effekte von $X$ auf $Y$ unterhalb ($\beta_2$) und oberhalb ($\beta_2 + \beta_3$) von $c$ abbilden. Beachte, dass $(X_i - c)$ die um den Schwellenwert zentrierte Laufvariable ist, sodass $\beta_1$ wie in \eqref{eq-simpleSRDD} den Unterschied des Effekts von $X$ auf $Y$ für Beobachtungen am Schwellenwert erfasst. 

Um unterschiedliche nicht-lineare Zusammenhänge von $X$ und $Y$ unterhalb und oberhalb von $c$ abzubilden, können (interagierte) Polynom-Terme in $X$ verwendet werden. Häufig wird eine quadratische Regressionsfunktion genutzt,
\begin{align}
  \begin{split}
  Y_i =&\, \beta_0 + \beta_1 B_i + \beta_2 (X_i - c) + \beta_3 (X_i - c)^2\\ 
       &+\, \beta_4(X_i - c)\times B_i + \beta_5(X_i - c)\times B_i + u_i.
  \end{split}\label{eq:quadSRDD}
\end{align}
@GelmanImbens2019 zeigen, dass Polynome höherer Ordnung zu verzerrten Schätzern und hoher Varianz führen können.^[Ursachen sind Überanpassung an die Daten sowie instabiles Verhalten der Schätzung nahe des Schwellenwertes.] Diese Autoren empfehlen stattdessen die Schätzung mit lokaler Regression.

**Nicht-parametrische Schätzung und Bandweite**

Aktuelle Studien mit RDD nutzen nicht-parametrische Schätzer, die den Behandlungseffekt als Differenz der geschätzten Regressionsfunktionen am Schwellenwert $c$ berechnen. Um auch nicht-lineare Regressionsfunktionen abzubilden zu können, wird häufig lokale Regression verwendet. Dieses Verfahren liefert eine "lokale" Schätzung der Regressionsfunktionen am Schwellenwert, bei der nur Beobachtungen nahe $X = c$ für die Schätzung berücksichtigt werden. Hinreichende Nähe wird hierbei durch eine sogenannte Bandweite $h$ festgelegt, wobei 
\begin{align}
  \lvert(X_i-c)\rvert\leq h \label{eq:bwc}
\end{align}
das Kriterium für eine Berücksichtigung von Beobachtung $i$ bei der Schätzung ist. 

Unter Verwendung einer Bandweite $h$ wird der Regressionsansatz \eqref{eq:linearSRDD} als *lokale lineare Regression* mit Uniform-Kernelfunktion bezeichnet. Der Uniform-Kernel gibt allen Beobachtungen, innerhalb der Bandweite $h$ dasselbe Gewicht. Ist $h$ so groß, dass der gesamte Datensatz in die Schätzung einbezogen wird, entspricht der lokale lineare Regressions-Schätzer mit Uniform-Kernel dem (globalen) KQ-Schätzer in einem linearen Interaktionsmodell anhand aller Beobachtungen. Neben dem Uniform-Kernel ist der Triangular-Kernel eine in der Praxis häufig genutzte lineare Kernelfunktion. Der nachstehende Code plottet die Uniform- (grün) sowie die Triangular-Kernelfunktion (blau).

```{webr}
library(ggplot2)
library(cowplot)

# Kernelfunktionen zeichnen
ggplot() + 
    geom_function(
      fun = ~ ifelse(
        test = abs(.) <= 1,
        yes =  1/2, 
        no = 0
      ), 
      col = "green", 
      n = 1000
      ) + 
    geom_function(
      fun = ~ ifelse(
        test = abs(.) <= 1, 
        yes = 1 - abs(.), 
        no = 0
      ), 
      col = "blue", 
      n = 100
      ) + 
    scale_x_continuous(
      name = "x", 
      limits = c(-1.5, 1.5), 
      breaks = c(-1, 0, 1)
    ) +
    scale_y_continuous(
      name = "K(x)", 
      breaks = c(0, 1), 
      limits = c(0, 1.25)
    ) +
    labs(
      title = "Kernelfunktionen auf [-1, 1]"
    ) +
    theme_cowplot()
```

In empirischen Studien wird als Basis-Spezifikation oft eine lokale lineare Regression anhand von \eqref{eq:linearSRDD} mit einer linearen Kernelfunktionen und geringer Bandweite $h$ genutzt. Anschließend wird die Robustheit der Ergebnisse anhand flexiblerer Spezifikationen, die Nicht-Linearitäten in der Regressionsfunktion besser abbilden können, geprüft.

Die nachstehende Visualisierung zeigt die Schätzung des kausalen Effektes der Behandlung $B_i$ anhand lokaler linearer Regression mit einem Uniform-Kernel für wie folgt simulierte Daten:
\begin{align*}
  Y_i =&\, \beta_1 X_i + \beta_2 B + \beta_3 X_i^2 \times B_i + u_i,\\
  \\
  u_i \sim&\, N(0, 0.5), \quad X_i \sim U(0, 10), \quad B = \mathbb{I}(X_i \geq c = 5)\\
  \beta_1 =&\, .5, \quad \beta_2 = 1.5, \quad \beta_3 = -0.15
\end{align*}

Diese Vorschrift ist schnell mit R implementiert:

```{webr}
set.seed(1234)
# Anz.Beobachtungen
n <- 750

# Parameter definieren
c <- 5
beta_1 <- .5
beta_2 <- 1.5
beta_3 <- -.15

# Regressionsfunktion definieren
f <- function(X) {
  beta_1 * (X - c) + beta_2 * B 
  + beta_3 * B * (X - c)^2
}

# Daten erzeugen
X <- runif(n, 0, 11)
B <- ifelse(X - c >= 0, 1, 0)
Y <- f(X) + rnorm(n, sd = .5)

# Beobachtungen sammeln
dat <- data.frame(
  Y = Y, X = X - c, B = B
)
```

In der interaktiven Grafik können der tatsächliche funktionale Zusammenhang (mit einer Diskontinuität von 1.5 an Schwellenwert) und die mit lokaler Regression geschätzte Funktion ein- und ausgeblendet werden. Über Radio-Buttons und Slider können sowohl die Bandweite als auch die Polynomiale-Ordnung der Regressionsmodells auf beiden Seites des Schwellenwerts separat eingestellt werden.

<iframe width="100%" height="818" frameborder="0" class="box-shadow"
  src="https://observablehq.com/embed/74f688f1119258d6?cells=svg%2Cviewof+est%2Cviewof+showTruth%2Cviewof+lowerPoly%2Cviewof+upperPoly%2Cviewof+bw_left%2Cviewof+bw_right%2Cstyles"></iframe>

Der interessierende Effekt am Schwellenwert $c=5$ beträgt $\beta_2 = 1.5$. Beachte, dass aufgrund des Terms $\beta_3 X_i^2 \times B_i$ im DGP ein quadratischer Zusammenhang von $Y$ und $X$ *oberhalb* von $X_i = c$ vorliegt. Es können folgende Eigenschaften des Schätzers untersucht werden:

- Die Spezifikation der Regressionsfunktion (lineare oder lokale quadratische Regression) und die Bandweite können auf beiden Seiten des Schwellenwerts separat gewählt werden.

- Für die Bandweiten von $1.8$ links und $1.4$ rechts vom Schwellenwert liefert eine lokale lineare Regression eine gute Approximation des wahren Zusammenhangs nahe des Schwellenwertes.^[Zur Beurteilung der Anpassungsgüte kann der wahre Zusammenhang über die Check-Box "Zeige Zusammenhang" eingeblendet werden.] Die Schätzung des lokalen Behandlungseffekts liegt nahe beim wahren Wert $\beta_2 = 1.5$.

- Für kleinere Bandweiten verringert sich die Datenbasis der Schätzung. Die Varianz der Schätzung des lokalen Behandlungseffekts nimmt dann grundsätzlich zu.

- Eine *quadratische* Regression kann den nicht-linearen Zusammenhang rechts des Schwellenwerts besser abbilden als eine *lineare* Regression. Die zusätzliche Flexibilität kann jedoch schnell zu einer Überanpassung bei einer zu kleinen Bandweite rechts des Schwellenwerts führen. 

- Größere Bandweiten erhöhen die Datenbasis der Schätzung, führen aber zu einer Annäherung der lokalen Schätzung an die globale Schätzung.^["Globale Schätzung" meint hier die Schätzung eines Interaktionsmodells mit dem gesamten Datensatz.] Linksseitig des Schwellenwertes erzielen wir mit lokaler linearer Regression eine Schätzung mit hoher Güte. Für $X_i - c\geq0$ verschlechtert sich die lokale lineare Anpassung am Schwellenwert deutlich, weil die lineare Schätzung den tatsächlichen (nicht-linearen) Zusammenhang nicht adäquat abbilden kann. Eine quadratische Spezifikation ist besser geeignet.

Die Wahl der Bandweite und die funktionale Flexibilität sind also wichtige Komponenten der RDD-Schätzung: 

Kleine Bandweiten erlauben bei auch bei nicht-linearen Zusammenhängen eine hinreichend gute Approximation durch lokale lineare Regression nahe des Schwellenwertes und damit eine Schätzung des lokalen Behandlungseffekts mit wenig Verzerrung. Allerdings kann die Schätzung unpräzise sein, wenn nur wenige Beobachtungen \eqref{eq:bwc} erfüllen. In der Praxis wird die Bandweite daher mit einem analytischen Schätzer [vgl. @ImbensKalyanaraman2012] oder anhand von *Cross Validation* [bspw. @ImbensLemieux2008] bestimmt. Die später in diesem Kapitel betrachteten R-Pakete halten diese Methoden bereit. 
Deutliche Nicht-Linearitäten könnten unzureichend durch lokale lineare Regression abgebildet werden. Zum Vergleich werden in der Praxis oft zusätzliche quadratische Spezifikationen geschätzt. Ein höherer Polynomgrad ist meist nicht zu empfehlen, weil die resultierende größere Flexibilität das Risiko einer Überanpassung an die Daten erhöht.

## Manipulation am Schwellenwert

Eine wichtige Annahmen für die Gültigkeit einer RDD-Schätzung ist, dass keine Manipulation der Gruppenzugehörigkeit am Schwellenwert vorliegt. Wenn sich Subjekte nahe des Schwellenwertes $c$ --- d.h. in Abhängigkeit der Laufvariable $X$ --- systematisch in den Confoundern $Z$ unterscheiden, können wir den Backdoor-Pfad *Oberhalb C &rarr; Behandlung B &rarr; Y* nicht isolieren. Wir erhalten dann eine verzerrte Schätzung des Behandlungseffekts.

In empirischen Studien mit -- insbesondere mit Individuen -- kann Selbstselektion auftreten: Menschen mit $X<c$ aber nahe $c$ (hier Kontrollgruppe) könnten aufgrund unbeobachtbarer Eigenschaften $Z$ die Ausprägung ihrer Laufvariable zu $X>c$ (hier Behandlungsgruppe) manipulieren. Wenn $Z$ die Outcome-Variable beeinflusst, bleibt der Backdoor-Pfad *Oberhalb C &rarr; Behandlung B &rarr; Y* so bestehen.  

Manipulation resultiert in Häufung von Beobachtungen am Schwellenwert. Die Verteilung der Laufvariable kann auf diese Unregelmäßigkeit hin untersucht werden. @McCrary2008 schlägt hierfür einen Verfahren vor, das die Kontinuität der Dichtefunktion von $X$ am Schwellenwert testet.

Der Test von @McCrary2008 ist in `rdd::DCdensity()` implementiert. Wir zeigen die Anwendung des Tests anhand der oben simulierten Daten. Beachte, dass $X_i\sim U(0, 10)$, d.h. die Laufvariable ist bei $X_i = c$ kontinuierlich verteilt. Die Nullhypothese (keine Manipulation) gilt für die simulierten Daten.

```{webr}
# McCrary-Test durchführen
p_mccrary <- rdd::DCdensity(
  runvar = X, 
  cutpoint = c, 
  plot = F
)

# p-Wert
p_mccrary
```

Der p-Wert ist größer als jedes übliche Signifikanzniveau. Damit liegt starke Evidenz für die Nullhypothese (keine Diskontinuität) und gegen Manipulation am Schwellenwert vor.

@CJM2020 (CMJ) schlagen eine Weiterentwicklung des McCrary-Tests vor, die höhere statistische Macht gegenüber Diskontinuitäten hat am Schwellenwert hat. Der CJM-Test ist im Paket `rddensity` implementiert.

```{webr}
library(rddensity)

# CJM Schätzer berechnen
CJM <- rddensity(X, c = 5)
```

Mit der Funktion `rddensity::rdplotdensity()` erzeugen wir eine grafische Auswertung.

```{webr}
#| fig-cap: "CJM-Test -- geschätzte Dichtefunktionen der Laufvariable auf beiden Seiten des Schwellenwerts c = 5"
#| label: fig-cjmtsim
# Plot für Dichtefunktion erstellen
plot <- rdplotdensity(
  rdd = CJM, 
  X = X, 
  # für Punkte- und Linienplots:
  type = "both" 
)
```
Die obige Abbildung zeigt die geschätzten Dichtefunktionen. Erwartungsgemäß finden wir eine große Überlappung der zugehörigen Konfidenzbänder (schattierte Flächen) am Schwellenwert $c=5$.

Mit `summary()` erhalten wir eine detaillierte Zusammenfassung des Tests. 

```{webr}
# Statistische Zusammenfassung des CJM-Tests
summary(CJM)
```

Gemäß des p-Werts (`P > |T|`) von 0.74 spricht der CJM-Test noch deutlicher gegen eine Diskontinuität als der McCrary-Test.

### Case Study: Amtsinhaber-Vorteil [@Lee2008]

@Lee2008 untersucht den Einfluss des Amtsinhaber-Vorteils auf die Wahl von Mitgliedern des US-Repräsentantenhaus. In den meisten Wahlkreisen entfallen große Anteile der Stimmen (oder gar ausschließlich) auf demokratische und republikanische Kanditat\*innen, sodass sich die Studie auf diese Parteien beschränkt. Entfällt die Mehrheit der Stimmen auf eine\*n Kandidat\*in, gewinnt diese\*r den Sitz für den Wahlkreis. Durch die Analyse der 6558 Wahlen im Zeitraum 1946-1998 mit einem SRDD kommt die Studie zu dem Ergebnis, dass Amtsinhabende im Durchschnitt einen Vorteil von etwa 8% bis 10% bei der Wahl haben. Dieses Ergebnis kann verschiedene Ursachen haben, bspw. dass die amtierende Partei höhere finanzielle Ressourcen besitzt und von einer besseren Organisation und durch Instrumentalisierung staatlicher Strukturen für die eigenen Zwecke profitiert.

Anhand der Datensätze `house` und `house_binned` illustrieren wir nachfolgend die Schätzung von SRDD-Modellen für den Wahlerfolg der demokratischen Partei, wenn diese Amtsinhaber ist. Wir lesen hierfür zunächst die Datensätze `house` und `house_binned` ein und verschaffen uns einen Überblick.

```{webr}
library(readr)

# Daten einlesen:
# Ungruppierter Datensatz
house <- read_csv("datasets/house.csv")
# Gruppierter Datensatz
house_binned <- read_csv("datasets/house_binned.csv")

# Überblick verschaffen
glimpse(house)
glimpse(house_binned)
```

Der Datensatz `house` enthält die Stimmenanteile demokratischer Kandidat\*innen bei der Wahl zum Zeitpunkt $t$ ($\textup{Stimmen}_t$) sowie die Differenz zwischen demokratischen und republikanischen Stimmenanteilen bei der vorherigen Wahl, d.h. zum Zeitpunkt $t-1$ ($\textup{Stimmen}_{t-1}$). Der Schwellenwert für einen Wahlsieg liegt bei Stimmengleichheit, d.h. $\textup{Stimmen}_{t-1} = 0$.

`house_binned` ist eine aggregierte Version von `house` mit Mittelwerten von jeweils 50 gleichgroßen Intervallen oberhalb und unterhalb der Schwelle von $\textup{Stimmen}_{t-1} = 0$. Dieser Datensatz eignet sich, um einen ersten Eindruck des funktionalen Zusammenhangs auf beiden Seiten zu erhalten. Wir stellen zunächst diese klassierten Daten mit `ggplot2` graphisch dar.

```{webr}
# Klassierte Daten plotten
house_binned %>%
  ggplot(
    aes(x = StimmenTm1, y = StimmenT)
    ) +
  geom_point() +
  geom_vline(xintercept = 0, lty = 2) +
  labs(
    title = "Klassierte Daten aus Lee (2008)",
  ) +
  theme_cowplot()
```

Die Grafik zeigt eindeutig einen Sprung von $\textup{Stimmen}_t$ bei $\textup{Stimmen}_{t-1} = 0$. Weiterhin erkennen wir, dass der Zusammenhang nahe $0$ vermutlich jeweils gut durch eine lineare Funktion approximiert werden kann. Eine Modell-Spezifikation mit gleicher Steigung auf beiden Seiten des Schwellenwertes scheint hingegen weniger gut geeignet. Wir vergleichen diese Spezifikationen nachfolgend. 

Zunächst fügen wir dem Datensatz eine Dummyvariable `B` hinzu. Diese dient als Indikator für den Wahlgewinn in der letzten Wahl und zeigt die Amtsinhaberschaft (Behandlung) an.

```{webr}
# Behandlungsindikator B hinzufügen
house <- house %>% 
  mutate(B = StimmenTm1 > 0)

glimpse(house)
```

Wir überprüfen die Laufvariable mit dem CJM-Test auf Manipulation am Schwellenwert $c=0$.

```{webr}
library(rdd)
library(rddensity)
# CJM-Test durchführen
CJM_Lee <- rddensity(X = house$StimmenTm1)

# Zusammenfassung anzeigen
summary(CJM_Lee)
```

```{webr}
# CJM-Plot
plot <- rdplotdensity(
  rdd = CJM_Lee,
  X = house$StimmenTm1, 
  type = "both",
  title = "CJM-Test: Geschätzte Dichtefunktionen der Laufvariable"
)
```
Die Abbildung der geschätzten Dichtefunktionen der Laufvariable und der p-Wert von $0.15$ sind Evidenz für keine Manipulation am Schwellenwert. 

Um den Behandlungseffekt anhand eines SRDDs zu ermitteln, schätzen wir das Interaktionsmodell 
\begin{align*}
  \text{Stimmen}_{t,i} =&\, \beta_0 + \beta_1 B_i + \beta_2 (\text{Stimmen}_{t-1,i} - 50)\\ 
  +&\, \beta_3(\text{Stimmen}_{t-1,i} - 50)\times B_i + u_i
\end{align*}
zunächst für eine Bandweite von $h = 0.5$. Aufgrund der Skalierung der Daten (Wahlergebnisse in \%) bedeutet dies die Verwendung des *gesamten* Datensatzes für die Schätzung.

```{webr}
# Interaktionsmodell schätzen
house_llr1 <- lm(
  formula = StimmenT ~ B * StimmenTm1, 
  data = house
)

library(modelsummary)

# Tabellarische Zusammenfassung erstellen  
modelsummary(
  models = house_llr1, 
  vcov = "HC1", # robuste Standardfehler
  stars = T, 
  gof_map = "nobs", 
  title = "SRDD Interaktionsmodell, Lee (2008)",
  output = "gt"
) %>% 
  tabopts()
```

Der geschätzte Koeffizient von $B$ (BTRUE) beträgt etwa $0.12$ und ist hochsignifikant. Übereinstimmend mit der grafischen Darstellung der klassierten Daten erhalten wir also eine positive Schätzung des Behandlungseffekts. Die Interpretation ist, dass die amtierenden Demokraten bei der Wahl von einem Amtsinhabervorteil profitieren. Dieser Effekt schlägt sich als Stimmenbonus von geschätzten 12\% nieder. Diese Schätzung des Behandlungseffekts könnte jedoch verzerrt sein: 

- Die (implizite) Wahl von $h=0.5$ in unserer Schätzung macht die Isolation des relevanten Frontdoor-Paths ($c=0$ &rarr; Treatment &rarr; $\textup{Stimmen}_t$) wenig plausibel. $h$ sollte mit einer datengetriebenen Methode gewählt werden.

- Weiterhin könnte die lineare funktionale Form der Regression inadäquat sein: Die lineare Approximation der wahren Regressionsfunktion nahe des Schwellenwerts $0$ könnte unzureichend sein und in einer verzerrten Schätzung des Effekts resultieren. Zur Überprüfung der Robustheit der Ergebnisse sollte mit Schätzungen anhand nicht-linearer Spezifikationen verglichen werden.

Um diesen Gefahren für die Validität der Studie zu begegnen, schätzen wir nun weitere Spezifikationen. Im Folgenden verwenden wir eine Bandweitenschätzung gemäß @ImbensKalyanaraman2012.

```{webr}
# Bandweite mit Schätzer von IK (2012) berechnen
(
IK_BW <- 
  rdd::IKbandwidth(
    X = house$StimmenTm1, 
    Y = house$StimmenT
  )
)
```

Wir schätzen zunächst erneut das lineare Interaktionsmodell, diesmal jedoch mit der Bandweite `IK_BW`.

```{webr}
# Lineares Interaktionsmodelle mit IK-Bandweite
house_llin_IK <- lm(
  formula = StimmenT ~ B * StimmenTm1, 
  data = house %>% 
    filter(
      abs(StimmenTm1) <= IK_BW
    )
)
```

Für den Vergleich mit einer nicht-linearen Spezifikation schätzen wir auch ein quadratisches Interaktionsmodell.

```{webr}
# Quadratisches Interaktionsmodell mit IK-Bandweite
house_poly_IK <- update(
  object = house_llin_IK,
  formula = StimmenT ~ B * poly(
    StimmenTm1, 
    degree = 2, 
    raw = T
  )
)
```

Für eine Gegenüberstellung der Ergebnisse verwenden wir `modelsummary()`.

```{webr}
# Tabellarischer Modellvergleich
modelsummary(
  models = list(
    "Linear int." = house_llin_IK, 
    "Quadratisch int." = house_poly_IK
  ),  
  vcov = "HC1", 
  stars = T,
  gof_map = "nobs", 
  output = "gt",
  title = "Vergleich von SRDD-Interaktionsmodellen in Lee (2008)"
) %>% 
  tabopts()
```

Die Spalte (1) in der obigen Tabelle zeigt die lokale Schätzung mit einem linearen Interaktionsmodell. Wir erhalten damit einen Behandlungseffekt von etwa $8.5\%$. Der Schätzwert fällt also etwas geringer aus als für die globale KQ-Schätzung des linearen Interaktionsmodells. Für das Modell (2) mit quadratischer Spezifikation liegt der Schätzwert mit $6.8\%$ in der selben Größenordnung. Beide Schätzungen ergeben einen signifikant von $0$ verschieden Effekt. Weiterhin fällt auf, dass in beiden Modellen keine Evidenz für unterschiedliche Formen der Regressionsfunktionen auf beiden Seiten des Schwellenwerts vorliegen: sämtliche Koeffizientenschätzwerte der Interaktionsterme haben hohe Standardfehler und sind nicht signifikant. Im quadratischen Modell hat auch der Term $\textup{Stimmen}_{t-1}^2$ keinen signifikanten Effekt. Diese Ergebnisse deuten darauf hin, dass eine lineare Spezifikation ausreichend ist.

**SRDD-Schätzung mit LOESS**

Wir illustrieren nachfolgend die Schätzung des Behandlungseffekts mit einer flexiblen und in der Praxis häufig verwendeten Methode für lokale Regression. Die nachfolgende interaktive Grafik zeigt die klassierten Daten aus @Lee2008 auf dem Intervall $[-0.5,0.5]$ gemeinsam mit einer nicht-parametrischen Schätzung des Zusammenhangs von `StimmenT` und `StimmenTm1` mittels LOESS.^[[LOESS](https://en.wikipedia.org/wiki/Local_regression) ist eine Variante von lokaler Polynom-Regression. @sec-loess erläutert nicht-parametrische Regression mit LOESS im Detail.] Diese Implementierung von lokaler Regression nutzt einen [tricube kernel](https://en.wikipedia.org/wiki/Kernel_(statistics)). Über den Input kann eine Bandweite $l\in(0,1]$ für den LOESS-Schätzer auf beiden Seiten des Schwellenwerts $0$ gewählt werden. Die Bandweite ist hier der *Anteil der Beobachtungen an der gesamten Anzahl an Beobachtungen*, die in die Schätzung einbezogen werden sollen. 

Für die Schätzung am Schwellenwert berücksichtigte Daten sind in orange kenntlich gemacht. Die rote Linie zeigt die geschätzte Regressionsfunktion über gleichmäßig verteilte Werte von `StimmenTm1` auf $[-0.5,0.5]$. Die Grafik verdeutlicht, dass die LOESS-Methode flexibel genug ist, um lineare und nicht-lineare Zusammenhänge abbilden zu können. Wie zuvor ist eine adäquate Wahl der Bandweite wichtig: 

- Der mit LOESS geschätzte Zusammenhang auf beiden Seiten des Schwellenwerts ist etwa linear für den voreingestellten Parameter ($l = 0.28$).

- Für größere Werte von $l$ nähert sich die Schätzung weiter einem linearen Verlauf an. Die Schätzung des Effekts bleibt vergleichbar mit den Ergebnissen des linearen Interaktionsmodell (s. oben).

- Für kleinere $l$ erhalten wir eine stärkere Anpassung der Schätzung an die Daten. Zu kleine Werte führen zu einer Überanpassung (*overfitting*). Insbesondere tendiert die geschätzte Funktion zu extremer Steigung nahe des Schwellenwerts &rarr; stark verzerrte Schätzung des Effekts!

<iframe width="100%" height="698" frameborder="0" class="box-shadow"
  src="https://observablehq.com/embed/@mca91/add_lee2008?cells=svg%2Cviewof+binning%2Cviewof+bandwidth%2Cstyles"></iframe>


## Fuzzy Regression Discontinuity Design

```{dot}
//| fig-width: 5
//| fig-height: 3
//| fig-align: 'center'
//| fig-cap: "Kausales Diagram für FRDD"
//| label: "fig-CDFRDD" 
digraph {
  layout=neato
  fontname="Helvetica,Arial,sans-serif"
  node [fontname="Helvetica,Arial,sans-serif", shape=ellipse]
  edge [fontname="Helvetica,Arial,sans-serif"]
  "X" [pos="0,1!"]
  "Y" [pos="4,-1!"]
  "oberhalb c" [pos="0,-1!"]
  "Z" [pos="4,1!"]
  "Behandlung" [pos="2,-1!"]
  "Z" -> "Behandlung"
  "X" -> "Y"
  "X" -> "Behandlung"
  "Z" -> "X"
  "Z" -> "Y"
  "X" -> "oberhalb c"
  "oberhalb c" -> "Behandlung"
  "Behandlung" -> "Y"
}
```

Ein FRDD liegt vor, wenn die Zuweisung der Behandlung $B$ durch die Laufvariable $X$ (und möglicherweise weitere Variablen $Z$) beeinflusst wird. Im Vergleich zum SRDD ist die Behandlung dann also *nicht* ausschließlich durch Überschreiten des Schwellenwerts $X = c$ bestimmt. 

@fig-CDFRDD zeigt den grundsätzlichen Zusammenhang. Hier genügt es weiterhin für $X$ (und ggf. $Z$) zu kontrollieren, um den Pfad *oberhalb $C$ &rarr; Behandlung $B$ &rarr; $Y$* zu isolieren. Der so für *Behandlung $B$* ermittelte Effekt auf $Y$ entspricht jedoch *nicht* dem "vollständigen" Behandlungseffekt, da bei $c$ die Zuweisung der Behandlung nicht von $0$ auf $100\%$ springt. Die Schätzung des FRDD berücksichtigt dies und skaliert den geschätzten Effekt entsprechend.

Wir betrachten zunächst den Zusammenhang
\begin{align}
  Y_i = \beta_0 + \beta_1 B_i + \beta_2 (X_i - c) + u_i.\label{eq-simpleFRDD}
\end{align}
In einem FRDD springt die Behandlungswahrscheinlichkeit am Schwellenwert $c$ um $\Delta p<1$. Wir können $B$ also nicht als deterministische Funktion von $X$, welche die Zuweisung zu Behandlungs- bzw. Kontrollgruppe am Schwellenwert $c$ anzeigt (wie im SRDD), definieren. Stattdessen betrachten wir
\begin{align}
  P(B_i=1\vert X_i) = 
  \begin{cases}
    g_{X_i<c}(X_i), & X_i < c \\ 
    g_{X_i\geq c}(X_i) & X_i \geq c
  \end{cases}\,. \label{eq-BFRDD}
\end{align}
Die Funktionen $g_{X_i<c}$ und $g_{X_i\geq c}$ können verschieden sein. Es muss jedoch $$g_{X_i<c}(X_i = c) \neq g_{X_i\geq c}(X_i = c)$$ gelten. Die Behandlungsvariable $B_i$ ist im FRDD also eine (binäre) Zufallsvariable, deren bedingte Wahrscheinlichkeitsfunktion $P(B_i=1\vert X_i)$ am Schwellenwert $c$ eine Diskontinuität aufweist. Die nächste Grafik zeigt heispielhafte Verläufe nicht-linearer bedingter Wahrscheinlichkeitsfunktion für die Behandlung mit einer Diskontinuität bei $X_i = c$.

```{webr}
library(ggplot2)
library(cowplot)

# Bedingte Behandlungswahrscheinlichkeit im FRDD illustrieren
ggplot() + 
  geom_function(
    fun = ~ ifelse(
      . < 0, 
      -.1 * .^2 + .25, 
      -.1 * (.-1.5)^2 + 1
    ), 
    n = 1000
  ) + 
    geom_function(
    fun = ~ ifelse(
      . < 0, 
     .35, 
     .65
    ),
    n = 1000, 
    lty = 2, 
    col = "red"
  ) + 
  scale_x_continuous(
    name = "Laufvariable X", 
    limits = c(-1.5, 1.5)
  ) +
  scale_y_continuous(
    name = "P(D=1|X)", 
    breaks = c(0, 1), 
    limits = c(0, 1)
  ) +
  labs(
    title = "Bedingte Behandlungswahrscheinlichkeiten im FRDD"
  ) +
  theme_cowplot()
```

Definition \eqref{eq-BFRDD} bedeutet, dass eine KQ-Schätzung von $\beta_1$ anhand \eqref{eq-simpleFRDD} eine *verzerrte* Schätzung des Behandlungseffekts ist: Der in $\widehat{\beta}_1$ erfasste Effekt auf $Y$ ist auf einen Sprung der Behandlungswahrscheinlichkeit bei $X_i = c$ um *weniger* als $100\%$ zurückzuführen. Der wahre Behandlungseffekt wird also *unterschätzt*. Daher muss $\widehat{\beta}_1$ skaliert werden, sodass die Schätzung als Effekt einer Änderung der Behandlungswahrscheinlichkei um $100\%$ interpretiert werden kann --- der erwartete Effekt, wenn ausschließlich Subjekte mit $X_i\geq c$ behandelt würden. Diese skalierte Schätzung erhalten wir mit IV-Regression (vgl. Kapitel XYZ). Hierfür nutzen wir für $B_i$ die Instrumentvariable 
\begin{align*}
  D_i = \begin{cases}
    0, & X_i < c \\ 
    1, & X_i \geq c.
  \end{cases}
\end{align*}

Angenommen $g_{X_i\geq c}(X_i) = \alpha_0$ und $g_{X_i<c}(X_i) = \alpha_0 + \alpha_1$ mit $\alpha_0 + \alpha_1 < 1$ (vgl. rote Funktion in @fig-CDFRDD). Der FRDD-Schätzer des Behandlungseffekts ist dann $\widehat{\gamma}_\textup{FRDD}$ im 2SLS-Verfahren mit den Regressionen
\begin{align}
  \begin{split}
  (\mathrm{I})\qquad B_i =&\, \alpha_0 + \alpha_1 D_i + \alpha_2 (X_i - c) + e_i,\\
  (\mathrm{II})\qquad Y_i =&\, \gamma_0 + \gamma_1 \widehat{B}_i + \gamma_2 (X_i - c) + \epsilon_i,
  \end{split}\label{eq:FRDD_simpleIV}
\end{align}
wobei $\widehat{B}_i$ die angepassten Werte aus Stufe $(\mathrm I)$ und $e_i$ sowie $\epsilon_i$ Fehlterterme sind.

Analog zum SRDD müssen in empirischen Anwendungen geeignete Spezifikationen für die Regressionsfunktionen \eqref{eq-simpleFRDD} und \eqref{eq-BFRDD} gewählt und der 2SLS-Schätzer \eqref{eq:FRDD_simpleIV} entsprechend angepasst werden. Ein einfaches Interaktionsmodell wäre
\begin{align}
  \begin{split}
  (\mathrm{I})\qquad B_i =&\, \alpha_0 + \alpha_1 D_i + \alpha_2 (X_i - c)\\ 
  +&\, \alpha_3 (X_i - c) \times D_i + e_i,\\
  \\
  (\mathrm{II})\qquad Y_i =&\, \gamma_0 + \gamma_1 \widehat{B}_i\\
  +&\, \gamma_2 (X_i - c) + \gamma_3 (X_i-c)\times\widehat{B}_i, \epsilon_i
  \end{split},\label{eq:FRDD_lintIV}
\end{align}
d.h. wir instrumentieren $B_i$ mit $D_i$ und dem Interaktionsterm $(X_i-c)\times D_i$.

Wie im SRDD werden die IV-Ansätze für das FRDD \eqref{eq:FRDD_simpleIV} und \eqref{eq:FRDD_lintIV} in empirischen Studien unter Berücksichtigung einer Bandweite (i.d.R. dieselbe Bandweite für beide Stufen) angewendet.


## Case Study: Protestantische Arbeitsethik

```{r, echo=F}
library(rddensity)
library(cowplot)
library(modelsummary)
knitr::opts_chunk$set(fig.align = 'center', warning = F, message = F)
```

Die Studie *Beyond Work Ethic: Religion, Individual, and Political Preferences* [@BastenBetz2013] untersucht den Zusammenhang zwischen Religion, individuellen Merkmalen und politischen Präferenzen. Das Hauptaugenmerk ist die Rolle von Religiosität als Einflussfaktor auf politische Einstellungen. Die Hypothese der Autoren ist, dass Religiosität eines Individuums über den traditionellen Rahmen von Moralvorstellungen und sozialen Normen hinaus auch die politischen Präferenzen beeinflusst. Eine entsprechende Theorie wurde zu Beginn des 20. Jahrhunderts entwickelt und prominent von Max Weber [vgl. @Weber2004] vertreten. Weber argumentiert, dass die protestantische Arbeitsethik einen entscheidenden Einfluss auf die Entwicklung des Kapitalismus hatte. Laut Weber führte der protestantische Glaube an harte Arbeit, ein sparsames Leben und ethisches Verhalten zur einer in den damaligen Gesellschaften weit verbreiteten Geisteshaltung, die wirtschaftliches Wachstum förderte und den Aufstieg des Kapitalismus begünstigte.

@BastenBetz2013 nutzen Wahlergebnisse sowie geo- und soziodemographische Datensätze für schweizer Gemeinden, um den Zusammenhang zwischen Religiosität und politischen Präferenzen wie links-rechts-Ausrichtung, Einstellungen zur Umverteilung und Einwanderung zu untersuchen. Hierfür verwenden die Autoren ein FRDD, dass eine historisch bedingte Diskontinuität der geographischen Verteilung von evangelischer bzw. katholischer Religionszugehörigkeit zwischen den Kantonen Freiburg (überwiegend dunkelrote Region, frz. *Fribourg*) und Waadt (kleinere hellrote Region, frz. *Vaud*) ausnutzt. Die historische Verteilung der Konfessionen in der betrachteten Region im 16. Jahrhundert durch Abspaltung des Kantons Freiburg ist in @fig-vaudfb dargestellt.

Aufgrund von Bevölkerungsbewegungen ist die Verteilung der Konfessionen zwar nicht mehr eindeutig durch die Kantonsgrenze bestimmt, jedoch sind die Gemeinden der betrachteten Kantone auch heute noch mehrheitlich protestantisch bzw. katholisch. Es ist plausibel, dass eine Prägung gemäß Webers Theorie vorliegt, sich die Gemeinden nahe der Grenze aber hinsichtlich anderer Charakteristika (insb. der Bevölkerungsstruktur) nicht systematisch unterscheiden.

```{r, out.width = "500px"}
#| echo: false
#| fig-cap: "Historische Verteilung von Religionszugehörigkeit in Schweizer Gemeinden im 16. Jahrhundert. Quelle: Basten und Betz (2013)."
#| cap-location: margin
#| label: fig-vaudfb
knitr::include_graphics(path = "img/WaadtFribourg.png")
```

Die Ergebnisse der Studie zeigen einen signifikanten Einfluss von Protestantismus auf politische Präferenzen, die über traditionelle Moralvorstellungen hinausgehen: Die Autoren finden Hinweise, dass Einwohner evangelisch geprägter Gemeinden eher konservative soziale und politische Ansichten vertreten. Eine mögliche Erklärung für diesen Effekt ist, dass religiöse Institutionen auch eine soziale und politische Agenda verfolgen, die von den Gläubigen internalisiert wird.

### Aufbereitung der Daten

In diesem Kapitel zeigen wir, wie die Kernergebnisse der Studie mit R reproduziert werden können. Hierfür werden folgende Pakete benötigt.

```{webr, eval=TRUE, warning=FALSE}
library(haven)
library(vtable)
library(rdrobust)
```

Das Papier sowie der Datensatz `BastenBetz.dta` sind auf der [Übersichtsseite der AEA](https://www.aeaweb.org/articles?id=10.1257/pol.5.3.67) verfügbar. Die Daten liegen im STATA-Format `.dta` vor.^[Siehe alternativ das [working paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2133848), falls kein Abbonement für AEA-Journals vorliegt.]

```{webr}
# Datensatz einlesen
BastenBetz <- read_dta('datasets/BastenBetz.dta')
```

Der Datensatz `BastenBetz` enthält Beobachtungen zu 509 schweizer Gemeinden. Eine Vielzahl an Variablen ist lediglich für Robustheits-Checks relevant. Für die Reproduktion der Kernergebnisse erstellen wir zunächst einen reduzierten Datensatz und transformieren einige Variablen. 

```{webr}
# Reduzierten Datensatz erstellen
BastenBetz <- BastenBetz %>%
  transmute(
    gini = Ecoplan_gini,
    prot = prot1980s,
    bord = borderdis, 
    vaud,
    pfl, 
    pfr, 
    pfi
  )
```

Die Definitionen der Variablen sind in @tbl-BastenBetzRed gegeben. Die Präferenzen `pfl`, `pfr` und `pfi` basieren auf Wahlergebnissen auf Gemeindeebene zu Volksentscheiden.

| Variable    | Definition                                                |
|-------------|-----------------------------------------------------------|
| `prot`      | Anteil Prothestanten im Jahr 1980 (%)                     |
| `gini`      | Gini-Koeffizient                                          |
| `bord`      | Laufdistanz zur Kantonsgrenze (Km)                     |
| `vaud`      | Dummyvariable: Gemeinde im Kanton Waadt                    |
| `pfl`       | Präferenz für Freizeit (%)                                |
| `pfr`       | Präferenz für Umverteilung (%)                            |
| `pfi`       | Präferenz für wirtschaftliche Intervention des Staats (%) |
    
: `BastenBetz` -- Variablen und Definitionen {#tbl-BastenBetzRed}

Für die Berechnung der optimalen Bandweite des FRDD verwenden wir einen MSE-optimalen Schätzer, der in der Funktion `rdrobust::rdbwselect()` implementiert ist.^[@BastenBetz2013 setzen BW = 5.01, den Durchschnitt von IK-Schätzungen über Modelle sämtlicher betrachteter Outcome-Variablen. Diese Bandweite liegt nahe des Ergebnisses von `rdbwselect`. Wir verwenden nachfolgend die Schätzung `OB`.]

```{webr}
# Bandweite schätzen (Bsp. für Freizeitpräferenz)
bw_selection <- rdbwselect(
  y = BastenBetz$pfl,
  x = BastenBetz$bord,
  fuzzy = BastenBetz$prot, 
  bwselect = "mserd", 
  kernel = "uniform"
) 

# Bandweite auslesen und zuweisen
(
  OB <- bw_selection$bws[1]
)
```

### Deskriptive Statistiken

Zur Reproduktion von Tabelle 1 aus @BastenBetz2013 erzeugen wir eine nach Kantonen gruppierte Zusammenfassung der Daten und berechnen deskriptive Statistiken. Wie im Paper berücksichtigen wir hierbei nur Gemeinden innerhalb der geschätzten optimalen Bandweite `OB`.

```{webr}
# Datensatz für Reproduktion von Table 1 formatieren
T1 <- BastenBetz %>%
  filter(abs(bord) < OB) %>%
  mutate(
    vaud = ifelse(
      test = vaud == 1, 
      yes = "Waadt", 
      no = "Freiburg"
    ),
    prot = prot * 100
  ) %>%
  group_by(vaud) %>%
  summarise(
    across(
      everything(), 
      list(
        Mean = mean, 
        SD = sd, 
        N = length
      )
    )
  ) %>%
  pivot_longer(
    cols = -vaud,
    names_to = c("variable", "statistic"), 
    names_sep = "_"
  )
```

Für die tabellarische Darstellung transformieren wir in ein weites Format, sodass die Tabelle die deskriptive Statistiken spaltenweise für die Kantone zeigt.

```{webr}
# Daten in weites Format überführen
T1_wider <- T1 %>% 
  pivot_wider(
    names_from = c("vaud", "statistic")
  )
```

Die Tabelle erzeugen wir mit `gt::gt()`.

```{webr}
# Tabelle mit gt() erzeugen
T1_wider %>%
  gt(
    rowname_col = "Variable", 
    caption = "Datensatz `BastenBetz` -- Zusammenfassende Statistiken"
  ) %>% 
  tab_spanner_delim(
    delim = "_",
  ) %>%
 tabopts()
```

Die Statistiken in der obigen Tabelle scheinen konsistent mit der (historischen) Verteilung der Religionszugehörigkeit und politischen Einstellung gemäß der Hypothese: Im überwiegend katholischen Freiburg finden wir eine größere Einkommensungleichkeit und höhere aus Wahlergebnissen abgeleitete Präferenzen für Freizeit, Umverteilung sowie staatliche Interventionen.


### Modellspezifikation und First-Stage-Ergebnisse

Die Kantone Waadt und Freiburg haben bis heute mehrheitlich protestantische bzw. katholische Gemeinden. Die Verteilung von Protestantismus ist also, u.a. aufgrund von Bevölkerungsbewegungen, nicht mehr deterministisch. An der Kantonsgrenze besteht jedoch eine deutliche Diskontinuität im Anteil protestantischer Einwohner, die auf die historische Verteilung der Religionszugehörigkeit zurückzuführen ist. Damit kann ein  FRDD implementiert werden, bei dem die Distanz zur Grenze (`bord`) die zentrierte Laufvariable ist und die Zugehörigkeit zum Kanton Waadt (`vaud`) ein Instrument für die Behandlungsvariable (`prot`) ist. 

Wir nutzen die Funktion `rdrobust::rdplot` um diesen Zusammenhang für verschiedene Bandweiten anhand des linearen Interaktionsmodells
\begin{align}
  \begin{split}
    \textup{prot}_i =&\, \alpha_0 + \alpha_1 \textup{vaud}_i + \alpha_2 \textup{bord}_i \\
  +&\, \alpha_3 \textup{bord}_i \times \textup{vaud}_i + u_i
  \end{split}\label{eq:BBFSR}
\end{align}
grafisch darzustellen. Dies ist die First-Stage-Regression für die 2SLS-Schätzung der Behandlungseffekte.

```{webr}
# Reproduktion von Abbildung 3 in Basten und Betz (2013)
plots_BB <- list(
  # gesch. optimale Bandweite
  p_OB = rdplot(
    y = BastenBetz$prot, 
    x = BastenBetz$bord, 
    h = c(OB, OB), 
    x.label = "Distanz zur Grenze (bord)",
    y.label = "Anteil Protestanten (prot)", 
    title = "Gesch. Bandweite",
    p = 1, 
    hide = T,
    nbins = c(6, 14), 
    masspoints = "off"
  ),
  
  # Bandweite 10
  p_BW10 = rdplot(
    y = BastenBetz$prot, 
    x = BastenBetz$bord, 
    h = c(10, 10), 
    x.label = "Distanz zur Grenze (bord)",
    y.label = "Anteil Protestanten  (prot)", 
    title = "Bandweite = 10",
    p = 1,
    hide = T,
    nbins = c(6, 14),
    masspoints = "off"
  ),
  
  # Bandweite 20
  p_BW20 = rdplot(
    y = BastenBetz$prot, 
    x = BastenBetz$bord, 
    h = c(20, 20), 
    x.label = "Distanz zur Grenze (bord)",
    y.label = "Anteil Protestanten  (prot)", 
    title = "Bandweite = 20",
    p = 1,
    hide = T,
    nbins = c(6, 14),
    masspoints = "off"
  ),
  
  # Gesamter Datensatz
  p_G = rdplot(
    y = BastenBetz$prot, 
    x = BastenBetz$bord,
    x.label = "Distanz zur Grenze (bord)",
    y.label = "Anteil Protestanten", 
    title = "Ges. Datensatz",
    p = 1,
    hide = T,
    nbins = c(6, 14),
    masspoints = "off"
  )
)
```

Wir sammeln die Ergebnisse in einem Plot-Gitter mit `cowplot::plot_grid()`.

```{webr}
# Reproduktion von Abbildung 3 in Basten und Betz (2013)
plot_grid(
  plotlist = purrr::map(plots_BB, ~ .$rdplot), 
  ncol = 2
)
```

Die Grafiken in zeigen deutliche Hinweise auf die Diskontinuität in `prot` nahe der Kantonsgrenze. Die Größe des geschätzten Sprungs scheint nur wenig sensitiv gegenüber der gewählten Bandweite zu sein. Die Signifikanz des Effekts können wir anhand der jeweiligen KQ-Regressionen beurteilen.^[Wir nutzen `update()` um die Regression mit weniger Code für verschiedene Bandweiten zu schätzen.] 


```{webr}
# Reproduktion der First-Stage-Regressionen
# s. Tabelle 2 in Basten und Betz (2013)

# (1) BW = OB
FS1 <- lm(
  formula = prot ~ vaud + bord + vaud * bord, 
  data = BastenBetz %>% 
    filter(
      abs(bord) <= OB
    )
)

# (2) BW = 10
FS2 <- update(
  FS1,
  data = BastenBetz %>% 
    filter(
      abs(bord) <= 10
    )
)

# (3) BW = 20
FS3 <- update(
  FS1,
  data = BastenBetz %>%
    filter(
      abs(bord) <= 20
    )
)

# (4) Ges. Datensatz
FS4 <- update(
  object = FS1,
  data = BastenBetz
)
```

```{webr}
# Tabellarische Darstellung
modelsummary(
  list(
    "BW=OB"= FS1, 
    "BW=10" = FS2, 
    "BW=20" = FS3, 
    "Ges. Datensatz" = FS4
  ), 
  vcov = "HC1", 
  stars = T, 
  gof_map = "nobs",
  title = "First-Stage-Regressionen",
  output = "gt"
) %>%
  tabopts()
```

Für die geschätze Bandweite schätzen wir einen hochsignifikanten Sprung in `prot` von etwa 67\% an der Kantonsgrenze. Auch für größere Bandweiten von 10km und 20km sowie für den gesamten Datensatz finden wir vergleichbare signifikante Effekte, was eine bei zunehmender Distanz zur Grenze persistente Diskrepanz der Religionszugehörigkeit bestätigt. 

### Second-Stage-Ergebnisse

Wir schätzen nun den LATE von Protestantismus für die Outcome-Variablen `gini`, `pfl`, `pfi` und `pfr`, vgl. @tbl-BastenBetzRed. Die Spezifikation für die Second-Stage-Regression der FRDD-Schätzung ist
\begin{align}
  \begin{split}
    Y_i = \gamma_0 + \gamma_1 \widehat{\textup{prot}}_i +  \gamma_2 \textup{bord}_i + \gamma_3 \textup{bord}_i  \times \textup{vaud}_i + e_i
  \end{split},
\end{align}
wobei $\widehat{\textup{prot}}_i$ angepasste Werte aus der KQ-Schätzung von \eqref{eq:BBFSR} mit Bandweite `OB` sind. Dazu erzeugen wir zunächst eine angepasste Version des Objekts `BastenBetz`, welche nur Gemeinden innerhalb der Bandweite enthält.

```{webr}
# Gemeinden innerhalb der Bandweite filtern
BastenBetz_OB <- BastenBetz %>% 
  filter(
    abs(bord) <= OB
  )
```

Zur Illustration schätzen wir nun die Second-Stage-Regression für $Y = \textup{pfl}$. 

```{webr}
# Second-Stage-Regression für `pfl`
BastenBetz_OB %>% 
  mutate(
    prot_fitted = fitted(FS1)
    ) %>%

lm(
  pfl ~ prot_fitted + bord + vaud:bord, 
  data = .
) %>% 
  summary()
```

Der Koeffizient `prot_fitted` ist der gesuchte Behandlungseffekt. Beachte, dass die von `summary()` berechneten Standardfehler ungültig sind, weil diese die zusätzliche Unsicherheit durch die Berechnung von $\widehat{\textup{prot}}$ über die First-Stage-Regression nicht berücksichtigen. Nachfolgend nutzen wir `AER::ivreg()`, um komfortabel gültige (heteroskedastie-robuste) Inferenz betreiben zu können.^[Die Autoren geben an, robuste SEs zu nutzen. Das scheint nicht der Fall zu sein, denn `vcov = "HC0"` liefert die Ergebinsse im Paper. Die von Stata berechneten HC1-SEs weichen ab. Dies ändert allerdings nichts
an der Signifikanz der Koeffizienten. Wir nutzen `vcov = "HC1"`.]

```{webr}
# Schätzung mit 2SlS
# s. Tabelle 4 in Basten und Betz (2013)
#
# Wir instrumentieren Treatment (`prot1980s`) 
# mit dem Schwellenindikator (`vaud`)
# ivreg: exogene Variablen instrumentieren sich selbst, 
# daher ' | vaud * borderdis '

library(AER)

# (1) Präferenz für Freizeit
SS_pfl <- ivreg(
  formula = pfl ~ prot + bord:vaud + bord | vaud * bord,
  data = BastenBetz_OB
)

# (2) Präferenz für Umverteilung
SS_pfr <- update(
  object = SS_pfl,
  formula = pfr ~ prot + bord:vaud + bord | vaud * bord,
)

# (3) Präferenz für Intervention
SS_pfi <- update(
  object = SS_pfl,
  formula = pfi ~ prot + bord:vaud + bord | vaud * bord,
)

# (4) Einkommensungleichheit
SS_gini <- update(
  object = SS_pfl,
  formula = pfi ~ prot + bord:vaud + bord | vaud * bord,
)
```

```{webr}
# Tabellarische Darstellung
modelsummary(
  list(
    "(1) Freizeit"= SS_pfl, 
    "(2) Umverteilung" = SS_pfr, 
    "(3) Intervention" = SS_pfi, 
    "(4) Ungleichheit" = SS_gini
  ), 
  vcov = "HC1", 
  stars = T, 
  gof_map = "nobs", 
  title = "Ergebnisse der Second-Stage-Regressionen",
  output = "gt"
) %>%
  tabopts()
```

Die Koeffizienten von `prot` in der obigen Tabelle sind die mit 2SLS ermittelten erwarteten Behandlungseffekte einer 100%-Reformation (d.h. von 100% katholisch zu 100% protestantisch) für eine durchschnittliche Gemeine nahe der Kantonsgrenze. Es handelt sich jeweils um einen lokalen durchschnittlichen Behandlungseffekt (LATE). Gem. der Definition der abhängigen Variablen, interpretieren wir die Koeffizienten von `prot` in de Regressionen (1), (2) und (3) als erwartete Prozentänderung durch Reformation. Der Koeffizient in Regression (4) gibt die erwartete Änderung des Gini-Index an. Sämtliche geschätzte Effekte sind signifikant und haben ein mit der Hypothese der Autoren konsistentes negatives Vorzeichen. 

Die Ergebnisse sind Evidenz, dass Protestantismus zu verringerter Präferenz für Freizeit, Umverteilung sowie wirtschaftspolitische Intervention seitens des Staats führt. Auch die ökonomische Ungleichheit ist signifikant geringer, als in einer durchschnittlichen vollständig katholischen Gemeinde.

### Addendum: FRDD-Schätzung mit `rdrobust()`

Die Funktion `rdrobust::rdrobust()` erlaubt die Schätzung von SRDD und FRDD mit einer Vielzahl von Optionen, s. `?rdrobust`. Dies erleichtert die Schätzung mehrerer Modellspezifikationenen und Bandweiten. Mit dem nachstehenden Befehl schätzen wir den LATE von Reformation auf die Präferenz für Umverteilung anhand lokaler quadratischer Regression. Der Output gibt einen Überblick der Bandweitenschätzung sowie der 2 Stufen des 2SLS-Schätzers, inkl. robuster Inferenzstatistiken.

```{webr}
pfr_rdr <- rdrobust(
  y = BastenBetz$pfr,
  x = BastenBetz$bord,
  fuzzy = BastenBetz$prot, 
  p = 2,
  kernel = "uniform",
  vce = "HC1"
) 

pfr_rdr %>% 
  summary()
```

Auch für die quadratische Spezifikation erhalten wir mit -5.047 ein vergleichbares signifikantes Ergebnis für den LATE von Protestantismus auf Umverteilung, vgl. Spalte (2) in der Tabele mit den 2SLS-Ergebnissen.

Mit der Option `bwselect = "msetwo"` kann die Bandweite jeweils für die lokale Regression links- und rechtssetig des Schwellenwerts geschätzt werden.

```{webr}
pfr_rdr %>% 
  update(bwselect = "msetwo") %>%
  summary()
```

Trotz Diskrepanz der geschätzten Bandweiten erhalten wir eine größere aber vergleichbare Schätzung für einen negativen Effekt.

## {{< fa stairs >}} Nicht-parametrische Regression {#sec-loess}

Nicht-parametrische Regression ist ein statistisches Verfahren, um die Beziehung zwischen Prädiktoren und einer Outcome-Variable zu modellieren, ohne eine spezifische Form der Regressionsfunktion festzulegen. Im Gegensatz zu parametrischen Verfahren, bei denen eine funktionale Form (z.B. eine lineare oder quadratische Beziehung) angenommen wird, lässt die nicht-parametrische Regression die Form der Funktion flexibel und passt sich den Daten *lokal* an.

Die **Nadaraya-Watson-Regression** (Kernel-Regression) ist ein Verfahren für nicht-parametrische Regression, bei dem die Schätzung der Outcome-Variable $Y$ an einem Prädiktorwert $x$ als gewichteter Durchschnitt der beobachteten $Y$-Werte der *benachbarten* Punkte berechnet wird. Die Gewichte werden durch eine *Kernel-Funktion* bestimmt, die die Nähe der Datenpunkte zum Prädiktorwert $x$ berücksichtigt: Je näher ein Datenpunkt, desto größer ist sein Einfluss auf die lokale Schätzung. Formal ist der Schätzer der Regressionsfunktion $\hat{f}(x)$ durch folgende Gleichung definiert:

\begin{align}
  \hat{f}(x) = \frac{\sum_{i=1}^n K\left(\frac{x - X_i}{h}\right) Y_i}{\sum_{i=1}^n K\left(\frac{x - X_i}{h}\right)}
\end{align}

$X_i$ und $Y_i$ sind die Beobachtungen für die Prädiktor- und Zielvariable. $K(\cdot)$ ist eine Kernel-Funktion, die die Gewichtung der Datenpunkte basierend auf ihrer Entfernung zu $x$ festlegt. 

Der Parameter $h$ ist die *Bandweite*, welche die Breite des Kernels kontrolliert. Mit $h$ wird festgelegt, wie viele Beobachtungen berücksichtigt werden und so die Glättung der Schätzung beeinflusst: Ein kleineres $h$ führt zu einer stärkeren Beeinflussung der lokalen Schätzung von $Y$ am Punkt $x$ durch wenige nahegelegenen Punkte, sodass die geschätzte Regressionsfunktion mitunter stark variieren kann. Ein größeres $h$ führt zu einer Berücksichtigung von mehr Beobachtungen, sodass die Schätzung einen weicheren Verlauf annimmt. Aufgrund dieser Eigenschaft sind nicht-parametrische Verfahren anfällig für "Überanpassung" (overfitting), wenn die Bandweite zu klein gewählt wird, und für "Unteranpassung" (underfitting), wenn die Bandweite $h$ zu groß ist.^[In der Praxis wird $h$ meist anhand von datengetriebenen Regeln gewählt.]

**Locally Estimated Scatterplot Smoothing (LOESS)** passt eine lokale Polynom-Regression zur Schätzung der Regressionsfunktion verwendet an. Im Gegensatz zur Kernel-Regression, die einen einfachen gewichteten Mittelwert berechnet, passt LOESS für jeden Punkt $x$ eine separate polynomiale Regression auf die Daten in der Nähe dieses Punktes an. Die Schätzung der Regressionsfunktion $\hat{f}(x)$ basiert auf einer *gewichteten Regression* der Datenpunkte innerhalb einer bestimmten Bandweite $h$:

\begin{align}
  \hat{f}(x) = \sum_{j=0}^p \widehat{\beta}_j(x) \cdot x^j
\end{align}

Hierbei wird für jeden Punkt $x$ ein lokales Polynom von Grad $p$ (in der Praxis wird oft $p = 1$ oder $p = 2$ gewählt) angepasst. Die Koeffizienten $\hat{\beta}_j(x)$ werden durch Minimierung der gewichteten Fehlerquadratsumme berechnet,

\begin{align}
  L_\textup{LOESS} = \sum_{i=1}^n K\left(\frac{x - X_i}{h}\right) \left(Y_i - \sum_{j=0}^p \beta_j x^j \right)^2.
\end{align}

Wie bei Kernel-Regression dient der Kernel $K(\cdot)$ als Gewichtsfunktion, die für die Abstände der Datenpunkte zu $x$ berechnet wird und Punkte in der Nähe von $x$ stärker gewichtet. Auch hier ist $h$ die Bandweite, die festlegt, wie weit entfernte Punkte in die Berechnung einbezogen werden.

LOESS bietet eine feinere Anpassung an lokale Strukturen und ist vorteilhaft, wenn die Daten starke nicht-lineare oder heterogene Muster aufweisen. Bspw. ist LOESS robuster gegenüber Ausreißern als Kernel-Regression. Die zusätzliche Flexibilität und Robustheit von LOESS macht die Berechnung jedoch rechenintensiver im Vergleich zu Kernel-Regression.

Die nachstehende interaktive Grafik illustriert die Schäzung einer nicht-linearen Regressionfunktion (graue Linie) mit LOESS (für $p=1$) und Kernel-Regression anhand einer Stichprobe (graue Punkte) und erlaubt die Auswirkungen der verschiedenen Konfigurationen auf die Schätzung des Zusammenhangs zu verstehen. 

```{r}
#| echo: false
#| column: margin
library(rsvg)
library(qrcode)
code <- qr_code("https://observablehq.com/d/6ad2c88d5f52fa8d")
path <- "img/npreg_qr.svg"
qrcode::generate_svg(
  qrcode = code, 
  filename =  "img/npreg_qr.svg"
  )
rsvg::rsvg_png(
  "img/npreg_qr.svg", "img/npreg_qr.png",
  width = 200, height = 200
)
knitr::include_graphics(path = "img/npreg_qr.png", dpi = 490)
```

<iframe width="100%" height="789" frameborder="0" class="box-shadow"
  src="https://observablehq.com/embed/6ad2c88d5f52fa8d?cells=viewof+startAnimation%2Cviewof+estimatorLabels%2Cviewof+thekernel%2Cviewof+bw_type%2Cviewof+bandwidth%2Cviewof+thevalue%2Ctheplot"></iframe>

- Durch Wechseln zwischen Nadaraya-Watson und LOESS können wir Unterschiede bei der Schätzung erkennen. LOESS liefert tendenziell eine glattere Anpassungen (insbesondere an den Rändern des Prädiktor-Intervalls). Die grüne Linie für den LOESS-Schätzer zeigt die Steigung der linearen lokalen Schätzung der Regressionsfunktion am aktuellen Prädiktorwert.

- Der orange hervorgehobene Bereich zeigt die durch die Kernel-Funktion und die Bandweite festgelegte Gewichtung der Datenpunkte um den Prädiktorwert an. Es wird illustriert, welche Punkte zur Schätzung herangezogen werden.

- Die Bandweite kann als Anteil nächster Beobachtungen an der gesamten Stichprobengröße (*NN Bandwidth*) oder wie in den oben gezeigten Formeln interpretiert werden.

- Der aktuelle Prädiktorwert kann über den Slider *Predictor value* variiert werden.

- Die Auswahl des Kernels (Dropdown-Menü *Kernel*) und der Bandweite (Slider *Bandwidth*) ermöglicht es, die Glättung der Schätzung zu steuern. Eine kleinere Bandweite fokussiert die Gewichtung auf engere Bereiche, was zu mehr Varianz und einer unregelmäßiger verlaufenden Schätzung führt, während eine größere Bandweite eine glattere Kurve erzeugt. Der Effekt des Kernels auf die Schätzung ist meist eher gering.

- Mit einem Klick auf den Button *Stop/Restart animation* wird der gewählte Schätzer schrittweise über den sichtbaren Wertebereich des Prädiktors berechnet. Durch Interaktion mit der Applikation in Echtzeit wird ersichtlich, wie kleine Änderungen in den Parametern die Form der geschätzten Regressionsfunktion beeinflussen.
